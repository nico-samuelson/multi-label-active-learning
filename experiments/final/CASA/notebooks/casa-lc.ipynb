{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae1a860",
   "metadata": {
    "papermill": {
     "duration": 0.01463,
     "end_time": "2025-02-25T17:32:56.224688",
     "exception": false,
     "start_time": "2025-02-25T17:32:56.210058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d645a6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:32:56.251812Z",
     "iopub.status.busy": "2025-02-25T17:32:56.251565Z",
     "iopub.status.idle": "2025-02-25T17:33:27.784441Z",
     "shell.execute_reply": "2025-02-25T17:33:27.783723Z"
    },
    "papermill": {
     "duration": 31.547818,
     "end_time": "2025-02-25T17:33:27.785927",
     "exception": false,
     "start_time": "2025-02-25T17:32:56.238109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d6099",
   "metadata": {
    "papermill": {
     "duration": 0.012294,
     "end_time": "2025-02-25T17:33:27.811152",
     "exception": false,
     "start_time": "2025-02-25T17:33:27.798858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2af565b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:27.837695Z",
     "iopub.status.busy": "2025-02-25T17:33:27.837219Z",
     "iopub.status.idle": "2025-02-25T17:33:27.840518Z",
     "shell.execute_reply": "2025-02-25T17:33:27.839875Z"
    },
    "papermill": {
     "duration": 0.018051,
     "end_time": "2025-02-25T17:33:27.841840",
     "exception": false,
     "start_time": "2025-02-25T17:33:27.823789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46cc6534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:27.868593Z",
     "iopub.status.busy": "2025-02-25T17:33:27.868317Z",
     "iopub.status.idle": "2025-02-25T17:33:27.872064Z",
     "shell.execute_reply": "2025-02-25T17:33:27.871437Z"
    },
    "papermill": {
     "duration": 0.018631,
     "end_time": "2025-02-25T17:33:27.873443",
     "exception": false,
     "start_time": "2025-02-25T17:33:27.854812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcf78ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:27.899270Z",
     "iopub.status.busy": "2025-02-25T17:33:27.899042Z",
     "iopub.status.idle": "2025-02-25T17:33:27.911786Z",
     "shell.execute_reply": "2025-02-25T17:33:27.911012Z"
    },
    "papermill": {
     "duration": 0.026795,
     "end_time": "2025-02-25T17:33:27.913021",
     "exception": false,
     "start_time": "2025-02-25T17:33:27.886226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258129f",
   "metadata": {
    "papermill": {
     "duration": 0.012756,
     "end_time": "2025-02-25T17:33:27.938261",
     "exception": false,
     "start_time": "2025-02-25T17:33:27.925505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28018aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:27.964100Z",
     "iopub.status.busy": "2025-02-25T17:33:27.963844Z",
     "iopub.status.idle": "2025-02-25T17:33:28.026602Z",
     "shell.execute_reply": "2025-02-25T17:33:28.025261Z"
    },
    "papermill": {
     "duration": 0.077384,
     "end_time": "2025-02-25T17:33:28.028108",
     "exception": false,
     "start_time": "2025-02-25T17:33:27.950724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-lc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f0f7f",
   "metadata": {
    "papermill": {
     "duration": 0.012541,
     "end_time": "2025-02-25T17:33:28.053147",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.040606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ce0917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.079540Z",
     "iopub.status.busy": "2025-02-25T17:33:28.079270Z",
     "iopub.status.idle": "2025-02-25T17:33:28.166566Z",
     "shell.execute_reply": "2025-02-25T17:33:28.165596Z"
    },
    "papermill": {
     "duration": 0.102552,
     "end_time": "2025-02-25T17:33:28.168224",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.065672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77df8a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.198453Z",
     "iopub.status.busy": "2025-02-25T17:33:28.198202Z",
     "iopub.status.idle": "2025-02-25T17:33:28.208789Z",
     "shell.execute_reply": "2025-02-25T17:33:28.207856Z"
    },
    "papermill": {
     "duration": 0.027557,
     "end_time": "2025-02-25T17:33:28.210377",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.182820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7537b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.241436Z",
     "iopub.status.busy": "2025-02-25T17:33:28.241217Z",
     "iopub.status.idle": "2025-02-25T17:33:28.251182Z",
     "shell.execute_reply": "2025-02-25T17:33:28.250198Z"
    },
    "papermill": {
     "duration": 0.026473,
     "end_time": "2025-02-25T17:33:28.252871",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.226398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c7e990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.280545Z",
     "iopub.status.busy": "2025-02-25T17:33:28.280339Z",
     "iopub.status.idle": "2025-02-25T17:33:28.292685Z",
     "shell.execute_reply": "2025-02-25T17:33:28.291680Z"
    },
    "papermill": {
     "duration": 0.027157,
     "end_time": "2025-02-25T17:33:28.294087",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.266930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d4fe0",
   "metadata": {
    "papermill": {
     "duration": 0.012577,
     "end_time": "2025-02-25T17:33:28.319753",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.307176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b394c527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.346213Z",
     "iopub.status.busy": "2025-02-25T17:33:28.345930Z",
     "iopub.status.idle": "2025-02-25T17:33:28.351936Z",
     "shell.execute_reply": "2025-02-25T17:33:28.351126Z"
    },
    "papermill": {
     "duration": 0.020708,
     "end_time": "2025-02-25T17:33:28.353235",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.332527",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac021be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.379495Z",
     "iopub.status.busy": "2025-02-25T17:33:28.379268Z",
     "iopub.status.idle": "2025-02-25T17:33:28.386704Z",
     "shell.execute_reply": "2025-02-25T17:33:28.385713Z"
    },
    "papermill": {
     "duration": 0.022067,
     "end_time": "2025-02-25T17:33:28.388177",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.366110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75df4168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:28.415268Z",
     "iopub.status.busy": "2025-02-25T17:33:28.415039Z",
     "iopub.status.idle": "2025-02-25T17:33:29.268333Z",
     "shell.execute_reply": "2025-02-25T17:33:29.267417Z"
    },
    "papermill": {
     "duration": 0.868112,
     "end_time": "2025-02-25T17:33:29.269750",
     "exception": false,
     "start_time": "2025-02-25T17:33:28.401638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca267d9025e4db785697c157597af8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba84d812a6e349af91d3bb00469cd414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac294bd2a21485b916fbe7b19bf84e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d6a831316d41ea9fe0b0bff4265b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4430efc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.298662Z",
     "iopub.status.busy": "2025-02-25T17:33:29.298401Z",
     "iopub.status.idle": "2025-02-25T17:33:29.302912Z",
     "shell.execute_reply": "2025-02-25T17:33:29.302018Z"
    },
    "papermill": {
     "duration": 0.020284,
     "end_time": "2025-02-25T17:33:29.304326",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.284042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d662a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.331586Z",
     "iopub.status.busy": "2025-02-25T17:33:29.331364Z",
     "iopub.status.idle": "2025-02-25T17:33:29.341315Z",
     "shell.execute_reply": "2025-02-25T17:33:29.340656Z"
    },
    "papermill": {
     "duration": 0.024867,
     "end_time": "2025-02-25T17:33:29.342497",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.317630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629915ea",
   "metadata": {
    "papermill": {
     "duration": 0.012912,
     "end_time": "2025-02-25T17:33:29.368547",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.355635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36609d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.395428Z",
     "iopub.status.busy": "2025-02-25T17:33:29.395213Z",
     "iopub.status.idle": "2025-02-25T17:33:29.398936Z",
     "shell.execute_reply": "2025-02-25T17:33:29.398121Z"
    },
    "papermill": {
     "duration": 0.018951,
     "end_time": "2025-02-25T17:33:29.400296",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.381345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a840f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.428038Z",
     "iopub.status.busy": "2025-02-25T17:33:29.427805Z",
     "iopub.status.idle": "2025-02-25T17:33:29.432443Z",
     "shell.execute_reply": "2025-02-25T17:33:29.431554Z"
    },
    "papermill": {
     "duration": 0.01962,
     "end_time": "2025-02-25T17:33:29.433730",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.414110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8d7c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.461317Z",
     "iopub.status.busy": "2025-02-25T17:33:29.461092Z",
     "iopub.status.idle": "2025-02-25T17:33:29.467566Z",
     "shell.execute_reply": "2025-02-25T17:33:29.466767Z"
    },
    "papermill": {
     "duration": 0.021611,
     "end_time": "2025-02-25T17:33:29.468860",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.447249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89f7a39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.496828Z",
     "iopub.status.busy": "2025-02-25T17:33:29.496610Z",
     "iopub.status.idle": "2025-02-25T17:33:29.522743Z",
     "shell.execute_reply": "2025-02-25T17:33:29.522036Z"
    },
    "papermill": {
     "duration": 0.041493,
     "end_time": "2025-02-25T17:33:29.524042",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.482549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86878df",
   "metadata": {
    "papermill": {
     "duration": 0.013063,
     "end_time": "2025-02-25T17:33:29.551088",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.538025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "023164bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.578050Z",
     "iopub.status.busy": "2025-02-25T17:33:29.577793Z",
     "iopub.status.idle": "2025-02-25T17:33:29.582716Z",
     "shell.execute_reply": "2025-02-25T17:33:29.582124Z"
    },
    "papermill": {
     "duration": 0.019668,
     "end_time": "2025-02-25T17:33:29.583928",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.564260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135e64d",
   "metadata": {
    "papermill": {
     "duration": 0.013168,
     "end_time": "2025-02-25T17:33:29.610440",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.597272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e9cbb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.637523Z",
     "iopub.status.busy": "2025-02-25T17:33:29.637292Z",
     "iopub.status.idle": "2025-02-25T17:33:29.652226Z",
     "shell.execute_reply": "2025-02-25T17:33:29.651409Z"
    },
    "papermill": {
     "duration": 0.029855,
     "end_time": "2025-02-25T17:33:29.653407",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.623552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = np.max(torch.sigmoid(outputs[i]).cpu().numpy())\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    # accelerator.print(len(X_pool), len(aspect_outputs))\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    max_pred = np.max(preds[i].cpu().numpy())\n",
    "                    sentiment_outputs[ori_index] = max_pred if max_pred > sentiment_outputs[ori_index] else sentiment_outputs[ori_index]\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = np.max(preds[i].cpu().numpy())\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = {indices: 1 - prob for indices, prob in aspect_outputs.items()}\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = ((1 - val) + aspect_outputs[key]) / 2\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(least_confident_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b3aea",
   "metadata": {
    "papermill": {
     "duration": 0.012751,
     "end_time": "2025-02-25T17:33:29.679298",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.666547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "476498a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.706886Z",
     "iopub.status.busy": "2025-02-25T17:33:29.706650Z",
     "iopub.status.idle": "2025-02-25T17:33:29.715721Z",
     "shell.execute_reply": "2025-02-25T17:33:29.714919Z"
    },
    "papermill": {
     "duration": 0.024501,
     "end_time": "2025-02-25T17:33:29.716930",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.692429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1fe78ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:29.744872Z",
     "iopub.status.busy": "2025-02-25T17:33:29.744618Z",
     "iopub.status.idle": "2025-02-25T17:33:29.748151Z",
     "shell.execute_reply": "2025-02-25T17:33:29.747063Z"
    },
    "papermill": {
     "duration": 0.019098,
     "end_time": "2025-02-25T17:33:29.749445",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.730347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408f4ba",
   "metadata": {
    "papermill": {
     "duration": 0.012973,
     "end_time": "2025-02-25T17:33:29.775816",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.762843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 52.99744772911072 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.08043149113655092\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 7.925274133682251 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6353, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5304, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Epoch 3/10, Train Loss: 0.4655, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4433, Accuracy: 0.7946, F1 Micro: 0.8848, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4072, Accuracy: 0.8073, F1 Micro: 0.8908, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3505, Accuracy: 0.8341, F1 Micro: 0.9037, F1 Macro: 0.9023\n",
      "Epoch 7/10, Train Loss: 0.3554, Accuracy: 0.8296, F1 Micro: 0.8982, F1 Macro: 0.8935\n",
      "Epoch 8/10, Train Loss: 0.3173, Accuracy: 0.8266, F1 Micro: 0.8966, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.2722, Accuracy: 0.8348, F1 Micro: 0.9011, F1 Macro: 0.8974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2483, Accuracy: 0.8415, F1 Micro: 0.905, F1 Macro: 0.9011\n",
      "\n",
      "Aspect detection accuracy: 0.8415, F1 Micro: 0.905, F1 Macro: 0.9011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.85      0.99      0.92       187\n",
      "     machine       0.78      0.99      0.88       175\n",
      "      others       0.85      0.78      0.81       158\n",
      "        part       0.86      0.94      0.89       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.86      0.96      0.90      1061\n",
      "   macro avg       0.86      0.95      0.90      1061\n",
      "weighted avg       0.86      0.96      0.90      1061\n",
      " samples avg       0.86      0.96      0.90      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6404, Accuracy: 0.7547, F1 Micro: 0.7547, F1 Macro: 0.4301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5295, Accuracy: 0.7736, F1 Micro: 0.7736, F1 Macro: 0.5062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4529, Accuracy: 0.8113, F1 Micro: 0.8113, F1 Macro: 0.7358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3104, Accuracy: 0.8679, F1 Micro: 0.8679, F1 Macro: 0.8168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1811, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.8382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.8805, F1 Micro: 0.8805, F1 Macro: 0.8426\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.8553, F1 Micro: 0.8553, F1 Macro: 0.823\n",
      "Epoch 8/10, Train Loss: 0.0334, Accuracy: 0.8616, F1 Micro: 0.8616, F1 Macro: 0.8295\n",
      "Epoch 9/10, Train Loss: 0.0207, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.8406\n",
      "Epoch 10/10, Train Loss: 0.0158, Accuracy: 0.8553, F1 Micro: 0.8553, F1 Macro: 0.8125\n",
      "\n",
      "Sentiment analysis accuracy: 0.8805, F1 Micro: 0.8805, F1 Macro: 0.8426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.79      0.77        39\n",
      "    positive       0.93      0.91      0.92       120\n",
      "\n",
      "    accuracy                           0.88       159\n",
      "   macro avg       0.83      0.85      0.84       159\n",
      "weighted avg       0.88      0.88      0.88       159\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8272, F1 Micro: 0.8272, F1 Macro: 0.5259\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.85      0.99      0.92       181\n",
      "    positive       0.80      0.17      0.28        24\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.55      0.39      0.40       216\n",
      "weighted avg       0.80      0.85      0.80       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      0.99      0.87       167\n",
      "    positive       0.50      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.43      0.34      0.31       216\n",
      "weighted avg       0.68      0.77      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.50      0.43        12\n",
      "     neutral       0.85      0.77      0.81       152\n",
      "    positive       0.50      0.60      0.54        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.62      0.59       216\n",
      "weighted avg       0.74      0.71      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.48      0.59        23\n",
      "     neutral       0.85      0.93      0.89       152\n",
      "    positive       0.57      0.49      0.53        41\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.74      0.63      0.67       216\n",
      "weighted avg       0.79      0.80      0.79       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 61.285492181777954 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03296253681182861\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 12.735586404800415 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5889, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5054, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4733, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4225, Accuracy: 0.8155, F1 Micro: 0.895, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3944, Accuracy: 0.8467, F1 Micro: 0.911, F1 Macro: 0.9104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3369, Accuracy: 0.8601, F1 Micro: 0.9176, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3091, Accuracy: 0.8876, F1 Micro: 0.9326, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2595, Accuracy: 0.9085, F1 Micro: 0.9438, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2165, Accuracy: 0.9196, F1 Micro: 0.9504, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1825, Accuracy: 0.9271, F1 Micro: 0.9549, F1 Macro: 0.9527\n",
      "\n",
      "Aspect detection accuracy: 0.9271, F1 Micro: 0.9549, F1 Macro: 0.9527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.88      0.97      0.92       175\n",
      "      others       0.88      0.92      0.90       158\n",
      "        part       0.90      0.97      0.93       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.96      1061\n",
      " samples avg       0.93      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6179, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3963, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2424, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8885\n",
      "Epoch 4/10, Train Loss: 0.104, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0697, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0564, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9071\n",
      "Epoch 7/10, Train Loss: 0.0366, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8997\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9046\n",
      "Epoch 9/10, Train Loss: 0.0175, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8657\n",
      "Epoch 10/10, Train Loss: 0.0201, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8965\n",
      "\n",
      "Sentiment analysis accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        69\n",
      "    positive       0.92      0.97      0.95       153\n",
      "\n",
      "    accuracy                           0.92       222\n",
      "   macro avg       0.93      0.89      0.91       222\n",
      "weighted avg       0.92      0.92      0.92       222\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8191\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.44      0.58        16\n",
      "     neutral       0.88      0.97      0.92       167\n",
      "    positive       0.74      0.52      0.61        33\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.83      0.64      0.70       216\n",
      "weighted avg       0.85      0.86      0.85       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.50      0.55        12\n",
      "     neutral       0.89      0.92      0.90       152\n",
      "    positive       0.69      0.63      0.66        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.69      0.70       216\n",
      "weighted avg       0.82      0.83      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.74      0.77        23\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.83      0.59      0.69        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.77      0.80       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 80.17115807533264 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.028815656900405884\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.433680772781372 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5867, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5147, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4605, Accuracy: 0.8043, F1 Micro: 0.8897, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3985, Accuracy: 0.8557, F1 Micro: 0.9161, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3286, Accuracy: 0.8951, F1 Micro: 0.9372, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2744, Accuracy: 0.9033, F1 Micro: 0.9411, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2223, Accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1962, Accuracy: 0.9256, F1 Micro: 0.9545, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1559, Accuracy: 0.9345, F1 Micro: 0.9593, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1305, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.9644\n",
      "\n",
      "Aspect detection accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.9644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.92      0.91      0.91       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.96      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.6944, F1 Micro: 0.6944, F1 Macro: 0.4221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.407, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2148, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9058\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 6/10, Train Loss: 0.0468, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8403\n",
      "Epoch 7/10, Train Loss: 0.0649, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9006\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8726\n",
      "Epoch 9/10, Train Loss: 0.0844, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8844\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8859\n",
      "\n",
      "Sentiment analysis accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        78\n",
      "    positive       0.93      0.95      0.94       174\n",
      "\n",
      "    accuracy                           0.92       252\n",
      "   macro avg       0.91      0.90      0.91       252\n",
      "weighted avg       0.92      0.92      0.92       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.853\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.88      0.64      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.75      0.80       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.58      0.58        12\n",
      "     neutral       0.92      0.91      0.91       152\n",
      "    positive       0.70      0.73      0.72        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.74      0.74       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.95      0.96      0.96       152\n",
      "    positive       0.78      0.78      0.78        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 78.49948453903198 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02290236651897431\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.710113048553467 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5795, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5152, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4363, Accuracy: 0.8467, F1 Micro: 0.911, F1 Macro: 0.9098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3675, Accuracy: 0.8936, F1 Micro: 0.9357, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2843, Accuracy: 0.9159, F1 Micro: 0.9479, F1 Macro: 0.945\n",
      "Epoch 6/10, Train Loss: 0.2299, Accuracy: 0.9115, F1 Micro: 0.945, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2009, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1563, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1352, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1098, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9681\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.95      0.91      0.93       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5391, Accuracy: 0.6908, F1 Micro: 0.6908, F1 Macro: 0.4208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3163, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1079, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9016\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8828\n",
      "Epoch 6/10, Train Loss: 0.0874, Accuracy: 0.8795, F1 Micro: 0.8795, F1 Macro: 0.8469\n",
      "Epoch 7/10, Train Loss: 0.0473, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0591, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9316\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8951\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.898\n",
      "\n",
      "Sentiment analysis accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        78\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.92      0.94      0.93       249\n",
      "weighted avg       0.94      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8585\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.76      0.81       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.42      0.50        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.71      0.85      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.73      0.73       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.90      0.63      0.74        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 86.09507870674133 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.017439603805541992\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.803239822387695 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5746, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4902, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4263, Accuracy: 0.8839, F1 Micro: 0.9302, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3182, Accuracy: 0.9062, F1 Micro: 0.9423, F1 Macro: 0.9391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2435, Accuracy: 0.9286, F1 Micro: 0.9552, F1 Macro: 0.9508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1926, Accuracy: 0.9397, F1 Micro: 0.9625, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1525, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1275, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1065, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0906, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9693\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4906, Accuracy: 0.6955, F1 Micro: 0.6955, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2824, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0969, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0847, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9325\n",
      "Epoch 6/10, Train Loss: 0.0777, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0489, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9167\n",
      "Epoch 9/10, Train Loss: 0.0472, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.924\n",
      "Epoch 10/10, Train Loss: 0.0396, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9081\n",
      "\n",
      "Sentiment analysis accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        77\n",
      "    positive       0.98      0.93      0.96       166\n",
      "\n",
      "    accuracy                           0.94       243\n",
      "   macro avg       0.93      0.95      0.94       243\n",
      "weighted avg       0.95      0.94      0.94       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8666\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.79      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.80      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.78      0.86        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.80      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 94.76285171508789 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013687980175018311\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.057629346847534 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.57, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4847, Accuracy: 0.8095, F1 Micro: 0.8923, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3877, Accuracy: 0.9003, F1 Micro: 0.9401, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3006, Accuracy: 0.9278, F1 Micro: 0.9557, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2282, Accuracy: 0.9353, F1 Micro: 0.9599, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1725, Accuracy: 0.9405, F1 Micro: 0.9628, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1482, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9685\n",
      "Epoch 8/10, Train Loss: 0.1176, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0976, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.0842, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.94      1.00      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5389, Accuracy: 0.719, F1 Micro: 0.719, F1 Macro: 0.5437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.28, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1905, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1218, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9354\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9278\n",
      "Epoch 6/10, Train Loss: 0.0911, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8725\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8937\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9192\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9149\n",
      "\n",
      "Sentiment analysis accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        79\n",
      "    positive       0.97      0.94      0.96       163\n",
      "\n",
      "    accuracy                           0.94       242\n",
      "   macro avg       0.93      0.94      0.94       242\n",
      "weighted avg       0.94      0.94      0.94       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8724\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.78      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.67      0.53        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.78      0.74       216\n",
      "weighted avg       0.87      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 90.23017287254333 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013512206077575683\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.918477058410645 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5701, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4826, Accuracy: 0.8058, F1 Micro: 0.8904, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3883, Accuracy: 0.9159, F1 Micro: 0.949, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2808, Accuracy: 0.9345, F1 Micro: 0.9599, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.212, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1597, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9698\n",
      "Epoch 7/10, Train Loss: 0.1281, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0974, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0839, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9667\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4938, Accuracy: 0.8387, F1 Micro: 0.8387, F1 Macro: 0.7872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2588, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1944, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.945\n",
      "Epoch 5/10, Train Loss: 0.1149, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9078\n",
      "Epoch 6/10, Train Loss: 0.0528, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9213\n",
      "Epoch 7/10, Train Loss: 0.0669, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8949\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9292\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8985\n",
      "Epoch 10/10, Train Loss: 0.0378, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9015\n",
      "\n",
      "Sentiment analysis accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        80\n",
      "    positive       0.97      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.94      0.95      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8536\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.50      0.36        12\n",
      "     neutral       0.94      0.88      0.90       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.66      0.71      0.68       216\n",
      "weighted avg       0.86      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 91.80155277252197 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012696981430053711\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.194031476974487 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4626, Accuracy: 0.8304, F1 Micro: 0.9027, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3458, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2437, Accuracy: 0.9442, F1 Micro: 0.9652, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1798, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1175, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0818, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9688\n",
      "Epoch 10/10, Train Loss: 0.0686, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9683\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.95      1.00      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5079, Accuracy: 0.8589, F1 Micro: 0.8589, F1 Macro: 0.8274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2456, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0838, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9493\n",
      "Epoch 5/10, Train Loss: 0.0891, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.08, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9496\n",
      "Epoch 7/10, Train Loss: 0.0851, Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.9408\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9364\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9327\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8957\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93        81\n",
      "    positive       0.98      0.95      0.97       160\n",
      "\n",
      "    accuracy                           0.95       241\n",
      "   macro avg       0.94      0.96      0.95       241\n",
      "weighted avg       0.96      0.95      0.95       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.8547\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.83      0.51        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.82      0.75       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.83      0.79        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.88      0.71      0.78        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 97.24397420883179 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012587767839431763\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.460189580917358 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5651, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4698, Accuracy: 0.8177, F1 Micro: 0.8965, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3591, Accuracy: 0.9271, F1 Micro: 0.9557, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2527, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9673\n",
      "Epoch 5/10, Train Loss: 0.1808, Accuracy: 0.9457, F1 Micro: 0.9662, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1466, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1192, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0923, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0769, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4977, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.8165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2353, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9283\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 4/10, Train Loss: 0.1375, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9207\n",
      "Epoch 5/10, Train Loss: 0.1025, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1134, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9317\n",
      "Epoch 7/10, Train Loss: 0.0959, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9198\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9202\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.926\n",
      "\n",
      "Sentiment analysis accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        80\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.93      0.94      0.93       250\n",
      "weighted avg       0.94      0.94      0.94       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8892\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.50      0.60        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.75      0.77       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 100.66885685920715 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010289600491523743\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.981908082962036 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.552, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.463, Accuracy: 0.8594, F1 Micro: 0.9174, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3331, Accuracy: 0.9308, F1 Micro: 0.9575, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2287, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1054, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Epoch 8/10, Train Loss: 0.0852, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9693\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.97\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5329, Accuracy: 0.8219, F1 Micro: 0.8219, F1 Macro: 0.7605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "Epoch 5/10, Train Loss: 0.1072, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 6/10, Train Loss: 0.0619, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1094, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9493\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8886\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9369\n",
      "\n",
      "Sentiment analysis accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        81\n",
      "    positive       0.96      0.97      0.97       166\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.95      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8743\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.83      0.49        12\n",
      "     neutral       0.94      0.87      0.90       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.70      0.81      0.72       216\n",
      "weighted avg       0.88      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.74650025367737 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.012372046709060669\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.195816278457642 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5498, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4552, Accuracy: 0.8378, F1 Micro: 0.9066, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.332, Accuracy: 0.9315, F1 Micro: 0.958, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2223, Accuracy: 0.9472, F1 Micro: 0.9674, F1 Macro: 0.9659\n",
      "Epoch 5/10, Train Loss: 0.1722, Accuracy: 0.9412, F1 Micro: 0.9631, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1267, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Epoch 7/10, Train Loss: 0.1043, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9675\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.493, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2289, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Epoch 3/10, Train Loss: 0.1481, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 4/10, Train Loss: 0.1213, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8949\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1076, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9383\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.087, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9333\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.92        81\n",
      "    positive       0.99      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.96      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8517\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.86      0.89       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.50      0.48        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.73      0.77      0.75        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.70      0.72      0.71       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.74      0.83        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.80      0.90      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.81        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.08717083930969 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010768502950668335\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.662222623825073 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5538, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4325, Accuracy: 0.8624, F1 Micro: 0.9193, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3173, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1284, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4873, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2379, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1312, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1129, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "Epoch 6/10, Train Loss: 0.1381, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9211\n",
      "Epoch 7/10, Train Loss: 0.1211, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9361\n",
      "Epoch 8/10, Train Loss: 0.1068, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9502\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9146\n",
      "\n",
      "Sentiment analysis accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        81\n",
      "    positive       0.98      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.95      0.95       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8878\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.83      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.52582025527954 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.011539903283119202\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.076476335525513 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5527, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4395, Accuracy: 0.8966, F1 Micro: 0.9383, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2817, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9675\n",
      "Epoch 4/10, Train Loss: 0.1981, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9692\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9671\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5096, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2389, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9207\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.948\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9207\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9279\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "\n",
      "Sentiment analysis accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        84\n",
      "    positive       0.97      0.96      0.97       181\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.95      0.95      0.95       265\n",
      "weighted avg       0.96      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9098\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.84      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.91143560409546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006907671689987183\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.86388897895813 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5449, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4287, Accuracy: 0.9226, F1 Micro: 0.9526, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2798, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9698\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4969, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2321, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9325\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8931\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1482, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9354\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0463, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9484\n",
      "\n",
      "Sentiment analysis accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        83\n",
      "    positive       0.98      0.95      0.97       183\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.96      0.95       266\n",
      "weighted avg       0.96      0.95      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.76      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.76      0.81      0.78       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.77660632133484 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.007838994264602661\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.213981628417969 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5526, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4243, Accuracy: 0.9115, F1 Micro: 0.9459, F1 Macro: 0.9443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2982, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1971, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4732, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2432, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9382\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0722, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.947\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.939\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9431\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        82\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8985\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.92      0.61        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.87      0.78       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.16756820678711 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.007949084043502808\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.837927579879761 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5434, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4098, Accuracy: 0.9182, F1 Micro: 0.9504, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2655, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1849, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1364, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Epoch 6/10, Train Loss: 0.1035, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.506, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2701, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9121\n",
      "Epoch 3/10, Train Loss: 0.1787, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9476\n",
      "Epoch 6/10, Train Loss: 0.0855, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9278\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9431\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9288\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9434\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        82\n",
      "    positive       0.98      0.96      0.97       182\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.95      0.95       264\n",
      "weighted avg       0.96      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.909\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.474529504776 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.008028149604797363\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.142157793045044 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5419, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.429, Accuracy: 0.9129, F1 Micro: 0.9474, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.271, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.055, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.98      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4809, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8879\n",
      "Epoch 2/10, Train Loss: 0.2289, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1559, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "Epoch 4/10, Train Loss: 0.1301, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9424\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9319\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9323\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9179\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9327\n",
      "Epoch 9/10, Train Loss: 0.0423, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.922\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.95       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.902\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.93      0.75      0.83        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.76       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.53837895393372 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.008959487080574036\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6902899742126465 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4259, Accuracy: 0.9196, F1 Micro: 0.9508, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2704, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0887, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4912, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2172, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 4/10, Train Loss: 0.1289, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9349\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9554\n",
      "\n",
      "Sentiment analysis accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        83\n",
      "    positive       0.97      0.98      0.97       176\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.96      0.95      0.96       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9007\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.83      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.46089124679565 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.008006080985069275\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.593414068222046 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5328, Accuracy: 0.808, F1 Micro: 0.8915, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3896, Accuracy: 0.936, F1 Micro: 0.9605, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2481, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0551, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.98       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4999, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2179, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1885, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1111, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9229\n",
      "Epoch 5/10, Train Loss: 0.1133, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0954, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9318\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Epoch 9/10, Train Loss: 0.0468, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.952\n",
      "\n",
      "Sentiment analysis accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       171\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.96      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9069\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.93      0.90      0.91       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.84      0.78       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.88979935646057 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0046846985816955565\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.001483917236328 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5277, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3984, Accuracy: 0.9286, F1 Micro: 0.9561, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.248, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9764\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.98      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4573, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2154, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1184, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0896, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9516\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.935\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9395\n",
      "Epoch 9/10, Train Loss: 0.0655, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9479\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       167\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.95       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8997\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.93      0.75      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.83      0.77       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.06210064888 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.005314463376998902\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4616284370422363 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5337, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4066, Accuracy: 0.9219, F1 Micro: 0.9519, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2518, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9812\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.98      0.95       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5118, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2272, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1218, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1144, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9491\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9369\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9205\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.945\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        86\n",
      "    positive       0.99      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.96      0.95       261\n",
      "weighted avg       0.96      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.92      0.52        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.93      0.75      0.83        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.85      0.76       216\n",
      "weighted avg       0.91      0.86      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.15047907829285 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004682940244674683\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9352598190307617 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3885, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2384, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1214, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9806\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.075, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9812\n",
      "Epoch 8/10, Train Loss: 0.0594, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.99      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4809, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2209, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1596, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 5/10, Train Loss: 0.1307, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Epoch 7/10, Train Loss: 0.0666, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9136\n",
      "Epoch 8/10, Train Loss: 0.0661, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9376\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.924\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.9054\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        84\n",
      "    positive       0.96      0.96      0.96       166\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.94      0.94       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8786\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.88      0.74        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.85      0.83       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.75      0.49        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.80      0.74       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.96      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.94338917732239 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.00442720353603363\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.4549314975738525 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5221, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3839, Accuracy: 0.9293, F1 Micro: 0.9562, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2488, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4397, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "Epoch 2/10, Train Loss: 0.2143, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9226\n",
      "Epoch 4/10, Train Loss: 0.1481, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9312\n",
      "Epoch 5/10, Train Loss: 0.1387, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9312\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9255\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Epoch 8/10, Train Loss: 0.0931, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9086\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9392\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9145\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.96      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8837\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.83      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.82      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.39473176002502 s\n",
      "Total runtime: 2782.0816814899445 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92748ba",
   "metadata": {
    "papermill": {
     "duration": 0.013705,
     "end_time": "2025-02-25T17:33:29.833289",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.819584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5560c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 55.61673069000244 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.058774116635322574\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 11.279558181762695 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6029, Accuracy: 0.7879, F1 Micro: 0.8776, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5146, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4672, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4408, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3966, Accuracy: 0.8043, F1 Micro: 0.8894, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.352, Accuracy: 0.8385, F1 Micro: 0.9069, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3211, Accuracy: 0.8601, F1 Micro: 0.9177, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2875, Accuracy: 0.878, F1 Micro: 0.9269, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2344, Accuracy: 0.8906, F1 Micro: 0.9336, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2035, Accuracy: 0.9115, F1 Micro: 0.9459, F1 Macro: 0.9439\n",
      "\n",
      "Aspect detection accuracy: 0.9115, F1 Micro: 0.9459, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.90      1.00      0.95       187\n",
      "     machine       0.90      0.99      0.94       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.88      0.97      0.92       158\n",
      "       price       0.93      1.00      0.96       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.91      0.98      0.95      1061\n",
      "   macro avg       0.91      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.95      1061\n",
      " samples avg       0.92      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6244, Accuracy: 0.699, F1 Micro: 0.699, F1 Macro: 0.4114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5385, Accuracy: 0.699, F1 Micro: 0.699, F1 Macro: 0.4114\n",
      "Epoch 3/10, Train Loss: 0.4988, Accuracy: 0.6939, F1 Micro: 0.6939, F1 Macro: 0.4096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.408, Accuracy: 0.7959, F1 Micro: 0.7959, F1 Macro: 0.6916\n",
      "Epoch 5/10, Train Loss: 0.3849, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.6639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2682, Accuracy: 0.8265, F1 Micro: 0.8265, F1 Macro: 0.7827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1822, Accuracy: 0.8367, F1 Micro: 0.8367, F1 Macro: 0.788\n",
      "Epoch 8/10, Train Loss: 0.1358, Accuracy: 0.8214, F1 Micro: 0.8214, F1 Macro: 0.7666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1305, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8492\n",
      "Epoch 10/10, Train Loss: 0.1622, Accuracy: 0.8622, F1 Micro: 0.8622, F1 Macro: 0.8401\n",
      "\n",
      "Sentiment analysis accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.86      0.80        59\n",
      "    positive       0.94      0.87      0.90       137\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.84      0.87      0.85       196\n",
      "weighted avg       0.88      0.87      0.87       196\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.7568\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.91      1.00      0.95       181\n",
      "    positive       0.91      0.42      0.57        24\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.94      0.62      0.72       216\n",
      "weighted avg       0.91      0.91      0.89       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.89      0.99      0.94       167\n",
      "    positive       0.86      0.55      0.67        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.92      0.70      0.78       216\n",
      "weighted avg       0.90      0.89      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.58      0.45        12\n",
      "     neutral       0.89      0.90      0.90       152\n",
      "    positive       0.79      0.65      0.72        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.68      0.71      0.69       216\n",
      "weighted avg       0.84      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.39      0.51        23\n",
      "     neutral       0.87      0.97      0.92       152\n",
      "    positive       0.71      0.59      0.64        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.78      0.65      0.69       216\n",
      "weighted avg       0.83      0.84      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.54      0.67        13\n",
      "     neutral       0.93      1.00      0.96       186\n",
      "    positive       1.00      0.47      0.64        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.94      0.67      0.76       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 71.31270408630371 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03671380877494813\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.298479318618774 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5942, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4968, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4547, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4285, Accuracy: 0.8065, F1 Micro: 0.8906, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3843, Accuracy: 0.8743, F1 Micro: 0.9249, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2997, Accuracy: 0.8996, F1 Micro: 0.9382, F1 Macro: 0.9359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2588, Accuracy: 0.9092, F1 Micro: 0.9439, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2368, Accuracy: 0.9226, F1 Micro: 0.9519, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1889, Accuracy: 0.9271, F1 Micro: 0.9546, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1551, Accuracy: 0.933, F1 Micro: 0.9582, F1 Macro: 0.956\n",
      "\n",
      "Aspect detection accuracy: 0.933, F1 Micro: 0.9582, F1 Macro: 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.93      0.93       175\n",
      "      others       0.89      0.92      0.90       158\n",
      "        part       0.91      0.98      0.94       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5852, Accuracy: 0.7061, F1 Micro: 0.7061, F1 Macro: 0.4139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4932, Accuracy: 0.7469, F1 Micro: 0.7469, F1 Macro: 0.5546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3601, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8489\n",
      "Epoch 4/10, Train Loss: 0.2087, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9161\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9092\n",
      "Epoch 8/10, Train Loss: 0.0466, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9024\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9067\n",
      "Epoch 10/10, Train Loss: 0.0182, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9069\n",
      "\n",
      "Sentiment analysis accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88        72\n",
      "    positive       0.95      0.95      0.95       173\n",
      "\n",
      "    accuracy                           0.93       245\n",
      "   macro avg       0.92      0.91      0.92       245\n",
      "weighted avg       0.93      0.93      0.93       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8447\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.93      0.93      0.93       167\n",
      "    positive       0.64      0.70      0.67        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.79      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.58      0.61        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.75      0.76       216\n",
      "weighted avg       0.85      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.81      0.73      0.77        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.74      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 79.51492595672607 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.026061415672302246\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.172869443893433 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5907, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5136, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4537, Accuracy: 0.8214, F1 Micro: 0.8983, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3794, Accuracy: 0.8891, F1 Micro: 0.9329, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3, Accuracy: 0.9167, F1 Micro: 0.9488, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2476, Accuracy: 0.9278, F1 Micro: 0.9554, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2015, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1707, Accuracy: 0.9405, F1 Micro: 0.963, F1 Macro: 0.9608\n",
      "Epoch 9/10, Train Loss: 0.1344, Accuracy: 0.936, F1 Micro: 0.9598, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1229, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.963\n",
      "\n",
      "Aspect detection accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.92      0.89      0.91       158\n",
      "        part       0.91      0.97      0.94       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5426, Accuracy: 0.7047, F1 Micro: 0.7047, F1 Macro: 0.4134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4106, Accuracy: 0.8661, F1 Micro: 0.8661, F1 Macro: 0.826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.261, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0709, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9023\n",
      "Epoch 7/10, Train Loss: 0.0628, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9051\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9098\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8638\n",
      "\n",
      "Sentiment analysis accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87        75\n",
      "    positive       0.94      0.95      0.95       179\n",
      "\n",
      "    accuracy                           0.93       254\n",
      "   macro avg       0.91      0.91      0.91       254\n",
      "weighted avg       0.92      0.93      0.93       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8368\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.73      0.73      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.76      0.79       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.25      0.33        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.68      0.83      0.75        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.70      0.66      0.66       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.48      0.61        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.80      0.78      0.79        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.74      0.78       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 89.0857765674591 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01922754943370819\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.439342260360718 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.585, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4285, Accuracy: 0.881, F1 Micro: 0.929, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3204, Accuracy: 0.9055, F1 Micro: 0.9414, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2745, Accuracy: 0.9278, F1 Micro: 0.9551, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2108, Accuracy: 0.9301, F1 Micro: 0.9563, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1693, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9633\n",
      "Epoch 8/10, Train Loss: 0.1469, Accuracy: 0.9442, F1 Micro: 0.9647, F1 Macro: 0.9623\n",
      "Epoch 9/10, Train Loss: 0.1233, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.9608\n",
      "Epoch 10/10, Train Loss: 0.1006, Accuracy: 0.9405, F1 Micro: 0.9625, F1 Macro: 0.9589\n",
      "\n",
      "Aspect detection accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.89      0.93      0.91       158\n",
      "        part       0.90      0.99      0.95       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5364, Accuracy: 0.7017, F1 Micro: 0.7017, F1 Macro: 0.4123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3969, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2148, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8952\n",
      "Epoch 5/10, Train Loss: 0.0825, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9231\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9079\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8996\n",
      "Epoch 9/10, Train Loss: 0.0396, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8894\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8883\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        71\n",
      "    positive       0.94      0.97      0.96       167\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.93      0.91      0.92       238\n",
      "weighted avg       0.94      0.94      0.94       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8372\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.72      0.79      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.77      0.81       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.21      0.58      0.30        12\n",
      "     neutral       0.94      0.82      0.88       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.65      0.72      0.65       216\n",
      "weighted avg       0.86      0.79      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.52      0.67        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       0.84      0.76      0.79        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.76      0.80       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 87.56077098846436 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0221063494682312\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.704213619232178 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5624, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4846, Accuracy: 0.8036, F1 Micro: 0.8893, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3886, Accuracy: 0.9122, F1 Micro: 0.9458, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2815, Accuracy: 0.9226, F1 Micro: 0.952, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2289, Accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1733, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1481, Accuracy: 0.9442, F1 Micro: 0.9648, F1 Macro: 0.9615\n",
      "Epoch 8/10, Train Loss: 0.1236, Accuracy: 0.9397, F1 Micro: 0.9621, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1052, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0841, Accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9639\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.94      0.83      0.88       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1061\n",
      "   macro avg       0.97      0.96      0.96      1061\n",
      "weighted avg       0.97      0.97      0.97      1061\n",
      " samples avg       0.97      0.96      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5088, Accuracy: 0.7117, F1 Micro: 0.7117, F1 Macro: 0.4158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3404, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1858, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1455, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.0917, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9068\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8817\n",
      "Epoch 7/10, Train Loss: 0.0635, Accuracy: 0.9307, F1 Micro: 0.9307, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9206\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9307, F1 Micro: 0.9307, F1 Macro: 0.9109\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.899\n",
      "\n",
      "Sentiment analysis accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89        79\n",
      "    positive       0.96      0.95      0.95       195\n",
      "\n",
      "    accuracy                           0.93       274\n",
      "   macro avg       0.92      0.92      0.92       274\n",
      "weighted avg       0.93      0.93      0.93       274\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.867\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.80      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.42      0.53        12\n",
      "     neutral       0.95      0.83      0.88       152\n",
      "    positive       0.62      0.90      0.73        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.76      0.72      0.71       216\n",
      "weighted avg       0.86      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.85      0.83      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 97.93413591384888 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013633054494857789\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.387978076934814 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5733, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.475, Accuracy: 0.8103, F1 Micro: 0.8925, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3705, Accuracy: 0.907, F1 Micro: 0.9427, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2716, Accuracy: 0.9293, F1 Micro: 0.9558, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2094, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.9635\n",
      "Epoch 6/10, Train Loss: 0.1611, Accuracy: 0.942, F1 Micro: 0.9634, F1 Macro: 0.9599\n",
      "Epoch 7/10, Train Loss: 0.1294, Accuracy: 0.9442, F1 Micro: 0.965, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.105, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0919, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9707\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5521, Accuracy: 0.6789, F1 Micro: 0.6789, F1 Macro: 0.4044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3365, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.908\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1209, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0901, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9205\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9172\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0837, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.921\n",
      "\n",
      "Sentiment analysis accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89        79\n",
      "    positive       0.95      0.95      0.95       167\n",
      "\n",
      "    accuracy                           0.93       246\n",
      "   macro avg       0.92      0.92      0.92       246\n",
      "weighted avg       0.93      0.93      0.93       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8805\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.76        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.69313549995422 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012878453731536864\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.363989114761353 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5643, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4723, Accuracy: 0.8155, F1 Micro: 0.8954, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3629, Accuracy: 0.9107, F1 Micro: 0.9454, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2485, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2054, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1613, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1271, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9675\n",
      "Epoch 8/10, Train Loss: 0.1027, Accuracy: 0.9472, F1 Micro: 0.9666, F1 Macro: 0.9635\n",
      "Epoch 9/10, Train Loss: 0.0919, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9663\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.6988, F1 Micro: 0.6988, F1 Macro: 0.4114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3367, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1928, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9124\n",
      "Epoch 4/10, Train Loss: 0.1104, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1126, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9299\n",
      "Epoch 8/10, Train Loss: 0.0533, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.918\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9174\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9149\n",
      "\n",
      "Sentiment analysis accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        78\n",
      "    positive       0.95      0.97      0.96       181\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.94      0.92      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8701\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.93      0.86      0.89       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.83      0.78       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.85      0.85      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 105.06907916069031 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.016362115740776062\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.351226091384888 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5471, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4425, Accuracy: 0.869, F1 Micro: 0.9231, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3271, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2277, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9681\n",
      "Epoch 6/10, Train Loss: 0.1451, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1108, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9501, F1 Micro: 0.9685, F1 Macro: 0.9656\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9687\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9449, F1 Micro: 0.9652, F1 Macro: 0.962\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5184, Accuracy: 0.6898, F1 Micro: 0.6898, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3138, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9297\n",
      "Epoch 4/10, Train Loss: 0.1415, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0916, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9332\n",
      "Epoch 6/10, Train Loss: 0.092, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0924, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.935\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9432\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9267\n",
      "\n",
      "Sentiment analysis accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        76\n",
      "    positive       0.97      0.96      0.96       169\n",
      "\n",
      "    accuracy                           0.95       245\n",
      "   macro avg       0.94      0.95      0.94       245\n",
      "weighted avg       0.95      0.95      0.95       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.873\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.92      0.44        12\n",
      "     neutral       0.94      0.83      0.88       152\n",
      "    positive       0.84      0.71      0.77        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.69      0.82      0.70       216\n",
      "weighted avg       0.88      0.81      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      0.99      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 108.88893389701843 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013003969192504888\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.380664825439453 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5463, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4618, Accuracy: 0.8609, F1 Micro: 0.9189, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3242, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.237, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1791, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9686\n",
      "Epoch 6/10, Train Loss: 0.138, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.7308, F1 Micro: 0.7308, F1 Macro: 0.5599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2774, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.933\n",
      "Epoch 3/10, Train Loss: 0.1484, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9209\n",
      "Epoch 4/10, Train Loss: 0.1095, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1062, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Epoch 6/10, Train Loss: 0.0579, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9509\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9411\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9423\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "\n",
      "Sentiment analysis accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        81\n",
      "    positive       0.97      0.97      0.97       179\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9084\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.84      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.95839810371399 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.013751882314682006\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.979916334152222 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5534, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4437, Accuracy: 0.872, F1 Micro: 0.9248, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3143, Accuracy: 0.9301, F1 Micro: 0.957, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2265, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1697, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1404, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.0893, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.7731, F1 Micro: 0.7731, F1 Macro: 0.6621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2659, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9472\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8795\n",
      "Epoch 4/10, Train Loss: 0.134, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0852, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9469\n",
      "Epoch 6/10, Train Loss: 0.0821, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9372\n",
      "Epoch 7/10, Train Loss: 0.071, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9437\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.943\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9427\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        82\n",
      "    positive       0.97      0.96      0.97       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9101\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.17388939857483 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00830867886543274\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.669046640396118 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5552, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4259, Accuracy: 0.8958, F1 Micro: 0.9369, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3105, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2086, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1609, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0839, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5175, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2995, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9403\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Epoch 4/10, Train Loss: 0.1707, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9545\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9451\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.9683, F1 Micro: 0.9683, F1 Macro: 0.9636\n",
      "Epoch 10/10, Train Loss: 0.0662, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9683, F1 Micro: 0.9683, F1 Macro: 0.9636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95        81\n",
      "    positive       0.98      0.98      0.98       171\n",
      "\n",
      "    accuracy                           0.97       252\n",
      "   macro avg       0.96      0.96      0.96       252\n",
      "weighted avg       0.97      0.97      0.97       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9097\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.82      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.84031963348389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.008335024118423462\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.814989805221558 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5472, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4029, Accuracy: 0.9152, F1 Micro: 0.9481, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2726, Accuracy: 0.9442, F1 Micro: 0.9655, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1973, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0948, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5846, Accuracy: 0.6721, F1 Micro: 0.6721, F1 Macro: 0.4019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3316, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9286\n",
      "Epoch 3/10, Train Loss: 0.205, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1762, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9496\n",
      "Epoch 5/10, Train Loss: 0.1073, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0853, Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9549\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9329\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9329\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9459\n",
      "\n",
      "Sentiment analysis accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        81\n",
      "    positive       0.99      0.95      0.97       166\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.96      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8938\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.82      0.75       216\n",
      "weighted avg       0.90      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.68322515487671 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.008987927436828613\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.18193244934082 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5484, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4202, Accuracy: 0.9182, F1 Micro: 0.9498, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.269, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1198, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5577, Accuracy: 0.7031, F1 Micro: 0.7031, F1 Macro: 0.4786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2838, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1733, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.148, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9648, F1 Micro: 0.9648, F1 Macro: 0.9595\n",
      "Epoch 7/10, Train Loss: 0.1138, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9688, F1 Micro: 0.9688, F1 Macro: 0.9643\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9557\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9251\n",
      "\n",
      "Sentiment analysis accuracy: 0.9688, F1 Micro: 0.9688, F1 Macro: 0.9643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.96      0.95        82\n",
      "    positive       0.98      0.97      0.98       174\n",
      "\n",
      "    accuracy                           0.97       256\n",
      "   macro avg       0.96      0.97      0.96       256\n",
      "weighted avg       0.97      0.97      0.97       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8955\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.67      0.80        12\n",
      "     neutral       0.91      0.94      0.92       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.90      0.79      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.78      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.88      0.93      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.82196402549744 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005529969930648804\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.910614013671875 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5356, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3873, Accuracy: 0.9241, F1 Micro: 0.9533, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2618, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1832, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5047, Accuracy: 0.852, F1 Micro: 0.852, F1 Macro: 0.814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2375, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.9045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.964, F1 Micro: 0.964, F1 Macro: 0.9598\n",
      "Epoch 5/10, Train Loss: 0.1341, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9288\n",
      "Epoch 6/10, Train Loss: 0.11, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9505\n",
      "Epoch 7/10, Train Loss: 0.0701, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9452\n",
      "Epoch 8/10, Train Loss: 0.0633, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9508\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Epoch 10/10, Train Loss: 0.0438, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9499\n",
      "\n",
      "Sentiment analysis accuracy: 0.964, F1 Micro: 0.964, F1 Macro: 0.9598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        82\n",
      "    positive       0.99      0.96      0.97       168\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.97      0.96       250\n",
      "weighted avg       0.97      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9131\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.78943681716919 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0049065351486206055\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.268437385559082 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4115, Accuracy: 0.91, F1 Micro: 0.9439, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2693, Accuracy: 0.9405, F1 Micro: 0.9632, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9708\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0642, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4944, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2224, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1583, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9514\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 5/10, Train Loss: 0.1459, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9462\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9688, F1 Micro: 0.9688, F1 Macro: 0.9648\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9478\n",
      "Epoch 9/10, Train Loss: 0.1095, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8987\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "\n",
      "Sentiment analysis accuracy: 0.9688, F1 Micro: 0.9688, F1 Macro: 0.9648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.98      0.95        83\n",
      "    positive       0.99      0.97      0.98       173\n",
      "\n",
      "    accuracy                           0.97       256\n",
      "   macro avg       0.96      0.97      0.96       256\n",
      "weighted avg       0.97      0.97      0.97       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9119\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.85      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.68617367744446 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0076760947704315186\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.776740550994873 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5216, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3846, Accuracy: 0.9174, F1 Micro: 0.9484, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2469, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9681\n",
      "Epoch 4/10, Train Loss: 0.176, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5375, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2731, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1716, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1762, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9479\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9654, F1 Micro: 0.9654, F1 Macro: 0.961\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9479\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9692, F1 Micro: 0.9692, F1 Macro: 0.965\n",
      "\n",
      "Sentiment analysis accuracy: 0.9692, F1 Micro: 0.9692, F1 Macro: 0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95        85\n",
      "    positive       0.98      0.98      0.98       175\n",
      "\n",
      "    accuracy                           0.97       260\n",
      "   macro avg       0.97      0.97      0.97       260\n",
      "weighted avg       0.97      0.97      0.97       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9361\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.28778553009033 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004183411598205566\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.3269202709198 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3716, Accuracy: 0.9211, F1 Micro: 0.9509, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2415, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1697, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5418, Accuracy: 0.8294, F1 Micro: 0.8294, F1 Macro: 0.7737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2579, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9556\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9347\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9643, F1 Micro: 0.9643, F1 Macro: 0.9602\n",
      "Epoch 7/10, Train Loss: 0.1058, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9643, F1 Micro: 0.9643, F1 Macro: 0.9602\n",
      "Epoch 9/10, Train Loss: 0.0408, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "\n",
      "Sentiment analysis accuracy: 0.9643, F1 Micro: 0.9643, F1 Macro: 0.9602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        83\n",
      "    positive       0.99      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.97      0.96       252\n",
      "weighted avg       0.97      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8872\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.75      0.69        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.81      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.38274264335632 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005944430828094482\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.7435810565948486 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3921, Accuracy: 0.9204, F1 Micro: 0.9505, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2519, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9754\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1045, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5518, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2434, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1668, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 6/10, Train Loss: 0.0861, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0773, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8919\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.92      0.63        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.86      0.79       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.32668662071228 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.005632844567298889\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.804920196533203 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5363, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3784, Accuracy: 0.9249, F1 Micro: 0.9533, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2394, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0928, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4685, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2272, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9324\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Epoch 5/10, Train Loss: 0.1076, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9067\n",
      "Epoch 6/10, Train Loss: 0.1275, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0926, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       179\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.92      0.65        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.87      0.79       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.40130019187927 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004216635227203369\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9871556758880615 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5246, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3752, Accuracy: 0.9301, F1 Micro: 0.9565, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2421, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9811\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.95      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4691, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2552, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9334\n",
      "Epoch 4/10, Train Loss: 0.1364, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9172\n",
      "Epoch 6/10, Train Loss: 0.1003, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9093\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9084\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.5797209739685 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003173640370368958\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.434706687927246 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5259, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3765, Accuracy: 0.9182, F1 Micro: 0.9495, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "Epoch 5/10, Train Loss: 0.1191, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.8431, F1 Micro: 0.8431, F1 Macro: 0.7976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2563, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9425\n",
      "Epoch 5/10, Train Loss: 0.1531, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "Epoch 6/10, Train Loss: 0.1006, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9302\n",
      "Epoch 7/10, Train Loss: 0.0851, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.929\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9428\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9234\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9116\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.7079212665558 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004254001379013062\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.156813383102417 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5155, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3731, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2392, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5223, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2577, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1579, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9458\n",
      "Epoch 5/10, Train Loss: 0.0922, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\n",
      "Epoch 6/10, Train Loss: 0.0936, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9107\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "Epoch 10/10, Train Loss: 0.0672, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.9065\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        87\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.96      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9081\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.50433444976807 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0020948588848114015\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3826217651367188 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5169, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3743, Accuracy: 0.9301, F1 Micro: 0.9566, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.243, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9777\n",
      "Epoch 6/10, Train Loss: 0.0967, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.073, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5076, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9324\n",
      "Epoch 2/10, Train Loss: 0.2424, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9236\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9295\n",
      "Epoch 4/10, Train Loss: 0.163, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9272\n",
      "Epoch 5/10, Train Loss: 0.105, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Epoch 8/10, Train Loss: 0.0977, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9272\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        87\n",
      "    positive       0.96      0.96      0.96       176\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.94      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9013\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.85      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.77869272232056 s\n",
      "Total runtime: 3030.766575574875 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801f4a2",
   "metadata": {
    "papermill": {
     "duration": 0.05122,
     "end_time": "2025-02-25T17:33:29.930992",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.879772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e50711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 61.0049991607666 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.05422058403491974\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 13.640478134155273 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6149, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4882, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4616, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4332, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3996, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3659, Accuracy: 0.8118, F1 Micro: 0.8929, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3336, Accuracy: 0.8318, F1 Micro: 0.9024, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2783, Accuracy: 0.8497, F1 Micro: 0.9119, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2508, Accuracy: 0.872, F1 Micro: 0.9241, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2103, Accuracy: 0.8832, F1 Micro: 0.9302, F1 Macro: 0.9282\n",
      "\n",
      "Aspect detection accuracy: 0.8832, F1 Micro: 0.9302, F1 Macro: 0.9282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.91      1.00      0.95       187\n",
      "     machine       0.88      0.97      0.92       175\n",
      "      others       0.83      0.94      0.88       158\n",
      "        part       0.79      1.00      0.89       158\n",
      "       price       0.91      1.00      0.95       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.88      0.99      0.93      1061\n",
      "   macro avg       0.88      0.98      0.93      1061\n",
      "weighted avg       0.88      0.99      0.93      1061\n",
      " samples avg       0.89      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6099, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5392, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4547, Accuracy: 0.7095, F1 Micro: 0.7095, F1 Macro: 0.4907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2938, Accuracy: 0.7365, F1 Micro: 0.7365, F1 Macro: 0.5645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2798, Accuracy: 0.8378, F1 Micro: 0.8378, F1 Macro: 0.7838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1991, Accuracy: 0.8649, F1 Micro: 0.8649, F1 Macro: 0.823\n",
      "Epoch 7/10, Train Loss: 0.1054, Accuracy: 0.8378, F1 Micro: 0.8378, F1 Macro: 0.7755\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.8378, F1 Micro: 0.8378, F1 Macro: 0.7976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8697\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.8378, F1 Micro: 0.8378, F1 Macro: 0.7976\n",
      "\n",
      "Sentiment analysis accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.87      0.82        46\n",
      "    positive       0.94      0.89      0.91       102\n",
      "\n",
      "    accuracy                           0.89       148\n",
      "   macro avg       0.86      0.88      0.87       148\n",
      "weighted avg       0.89      0.89      0.89       148\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.6658\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.91      1.00      0.96       181\n",
      "    positive       0.92      0.50      0.65        24\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.95      0.65      0.74       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.38      0.52        16\n",
      "     neutral       0.88      0.97      0.92       167\n",
      "    positive       0.75      0.55      0.63        33\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.83      0.63      0.69       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.17      0.21        12\n",
      "     neutral       0.84      0.95      0.89       152\n",
      "    positive       0.70      0.50      0.58        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.61      0.54      0.56       216\n",
      "weighted avg       0.77      0.80      0.78       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.17      0.29        23\n",
      "     neutral       0.79      1.00      0.88       152\n",
      "    positive       0.78      0.34      0.47        41\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.79      0.51      0.55       216\n",
      "weighted avg       0.79      0.79      0.74       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.31      0.47        13\n",
      "     neutral       0.91      1.00      0.95       186\n",
      "    positive       0.86      0.35      0.50        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.55      0.64       216\n",
      "weighted avg       0.91      0.91      0.89       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.74      0.81       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 71.81241607666016 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03142131567001343\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.14410662651062 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5743, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4729, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4472, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4072, Accuracy: 0.8043, F1 Micro: 0.8897, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3768, Accuracy: 0.8222, F1 Micro: 0.8988, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3138, Accuracy: 0.8571, F1 Micro: 0.9167, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2777, Accuracy: 0.8921, F1 Micro: 0.9357, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2191, Accuracy: 0.9092, F1 Micro: 0.9454, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1898, Accuracy: 0.9271, F1 Micro: 0.9553, F1 Macro: 0.9536\n",
      "Epoch 10/10, Train Loss: 0.1482, Accuracy: 0.9256, F1 Micro: 0.9546, F1 Macro: 0.9528\n",
      "\n",
      "Aspect detection accuracy: 0.9271, F1 Micro: 0.9553, F1 Macro: 0.9536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.92      0.95      0.93       175\n",
      "      others       0.84      0.98      0.91       158\n",
      "        part       0.91      0.98      0.94       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.99      0.96      1061\n",
      "   macro avg       0.92      0.99      0.95      1061\n",
      "weighted avg       0.93      0.99      0.96      1061\n",
      " samples avg       0.93      0.99      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6531, Accuracy: 0.6683, F1 Micro: 0.6683, F1 Macro: 0.4006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5028, Accuracy: 0.8146, F1 Micro: 0.8146, F1 Macro: 0.7639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.367, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2507, Accuracy: 0.878, F1 Micro: 0.878, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1255, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8908\n",
      "Epoch 7/10, Train Loss: 0.1074, Accuracy: 0.8488, F1 Micro: 0.8488, F1 Macro: 0.8085\n",
      "Epoch 8/10, Train Loss: 0.0279, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8865\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9002\n",
      "\n",
      "Sentiment analysis accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87        68\n",
      "    positive       0.93      0.94      0.93       137\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8084\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.45      0.59        11\n",
      "     neutral       0.95      1.00      0.97       181\n",
      "    positive       0.95      0.75      0.84        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.73      0.80       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.91      0.95      0.93       167\n",
      "    positive       0.71      0.67      0.69        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.73      0.76       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.67      0.57        12\n",
      "     neutral       0.85      0.96      0.90       152\n",
      "    positive       0.93      0.52      0.67        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.76      0.72      0.71       216\n",
      "weighted avg       0.85      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.79      0.66      0.72        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.76      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 77.49703907966614 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.029442518949508667\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.031057119369507 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5796, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5014, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4438, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3758, Accuracy: 0.8445, F1 Micro: 0.9101, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3077, Accuracy: 0.875, F1 Micro: 0.9264, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2576, Accuracy: 0.9234, F1 Micro: 0.9535, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2011, Accuracy: 0.942, F1 Micro: 0.9643, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1844, Accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.965\n",
      "Epoch 9/10, Train Loss: 0.1399, Accuracy: 0.9397, F1 Micro: 0.963, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1183, Accuracy: 0.9487, F1 Micro: 0.9683, F1 Macro: 0.9669\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.9683, F1 Macro: 0.9669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.85      0.96      0.90       158\n",
      "        part       0.94      1.00      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.94      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6163, Accuracy: 0.6622, F1 Micro: 0.6622, F1 Macro: 0.3984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4797, Accuracy: 0.8514, F1 Micro: 0.8514, F1 Macro: 0.8163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2657, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1298, Accuracy: 0.9279, F1 Micro: 0.9279, F1 Macro: 0.9184\n",
      "Epoch 5/10, Train Loss: 0.074, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0323, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9388\n",
      "Epoch 7/10, Train Loss: 0.0345, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9172\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        75\n",
      "    positive       0.96      0.96      0.96       147\n",
      "\n",
      "    accuracy                           0.95       222\n",
      "   macro avg       0.94      0.94      0.94       222\n",
      "weighted avg       0.95      0.95      0.95       222\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8618\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.78      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.58      0.64        12\n",
      "     neutral       0.85      0.96      0.90       152\n",
      "    positive       0.85      0.56      0.67        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.80      0.70      0.74       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.94      1.00      0.97       152\n",
      "    positive       0.93      0.68      0.79        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.87      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 84.08128762245178 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02024832665920258\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.264746904373169 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5664, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5078, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4449, Accuracy: 0.8259, F1 Micro: 0.9007, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3497, Accuracy: 0.8936, F1 Micro: 0.9366, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2699, Accuracy: 0.9397, F1 Micro: 0.963, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2063, Accuracy: 0.9412, F1 Micro: 0.9639, F1 Macro: 0.9626\n",
      "Epoch 7/10, Train Loss: 0.1685, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1359, Accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1155, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0905, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9665\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.84      0.97      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.94      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6225, Accuracy: 0.6486, F1 Micro: 0.6486, F1 Macro: 0.3934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4088, Accuracy: 0.8694, F1 Micro: 0.8694, F1 Macro: 0.8416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2201, Accuracy: 0.9279, F1 Micro: 0.9279, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.089, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.941\n",
      "Epoch 5/10, Train Loss: 0.0923, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9027\n",
      "Epoch 6/10, Train Loss: 0.0494, Accuracy: 0.9324, F1 Micro: 0.9324, F1 Macro: 0.928\n",
      "Epoch 7/10, Train Loss: 0.0375, Accuracy: 0.9324, F1 Micro: 0.9324, F1 Macro: 0.9252\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9363\n",
      "Epoch 9/10, Train Loss: 0.0248, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8917\n",
      "Epoch 10/10, Train Loss: 0.0135, Accuracy: 0.9369, F1 Micro: 0.9369, F1 Macro: 0.9295\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        78\n",
      "    positive       0.96      0.95      0.96       144\n",
      "\n",
      "    accuracy                           0.95       222\n",
      "   macro avg       0.94      0.94      0.94       222\n",
      "weighted avg       0.95      0.95      0.95       222\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.873\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.58      0.70        12\n",
      "     neutral       0.84      0.97      0.90       152\n",
      "    positive       0.87      0.52      0.65        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.86      0.69      0.75       216\n",
      "weighted avg       0.85      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.85      0.71      0.77        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.84      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 88.64116191864014 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01529550552368164\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.288498640060425 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5561, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4703, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4022, Accuracy: 0.8839, F1 Micro: 0.9313, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3078, Accuracy: 0.9249, F1 Micro: 0.9539, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.222, Accuracy: 0.9368, F1 Micro: 0.9611, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1798, Accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1389, Accuracy: 0.9487, F1 Micro: 0.9679, F1 Macro: 0.9654\n",
      "Epoch 8/10, Train Loss: 0.1142, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9644\n",
      "Epoch 9/10, Train Loss: 0.0911, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.89      0.90      0.90       158\n",
      "        part       0.93      1.00      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.545, Accuracy: 0.7224, F1 Micro: 0.7224, F1 Macro: 0.5372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2806, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.9046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1342, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9395\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9287\n",
      "Epoch 5/10, Train Loss: 0.0955, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9084\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.918\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9209\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9121\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9395\n",
      "\n",
      "Sentiment analysis accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        79\n",
      "    positive       0.96      0.96      0.96       166\n",
      "\n",
      "    accuracy                           0.95       245\n",
      "   macro avg       0.94      0.94      0.94       245\n",
      "weighted avg       0.95      0.95      0.95       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8916\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.90      0.90       152\n",
      "    positive       0.71      0.71      0.71        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.81      0.79      0.80       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.93      1.00      0.97       152\n",
      "    positive       0.93      0.68      0.79        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.84612202644348 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012464672327041626\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.096511125564575 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.565, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4915, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.395, Accuracy: 0.875, F1 Micro: 0.9262, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2916, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2165, Accuracy: 0.9464, F1 Micro: 0.967, F1 Macro: 0.9656\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1382, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1134, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9683\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.89      0.89       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5292, Accuracy: 0.7098, F1 Micro: 0.7098, F1 Macro: 0.4727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2605, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1294, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.101, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9548\n",
      "Epoch 5/10, Train Loss: 0.0876, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9446\n",
      "Epoch 6/10, Train Loss: 0.0792, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9393\n",
      "Epoch 7/10, Train Loss: 0.0449, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9256\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0313, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        79\n",
      "    positive       0.98      0.96      0.97       176\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8962\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.89      0.89       152\n",
      "    positive       0.71      0.75      0.73        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.81      0.80      0.80       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 98.30042552947998 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011322909593582153\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.336021423339844 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4794, Accuracy: 0.8051, F1 Micro: 0.8901, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3923, Accuracy: 0.904, F1 Micro: 0.9424, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2546, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1938, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1505, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9694\n",
      "Epoch 7/10, Train Loss: 0.1111, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9707\n",
      "Epoch 9/10, Train Loss: 0.0839, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.93      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5025, Accuracy: 0.8704, F1 Micro: 0.8704, F1 Macro: 0.8313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2166, Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9532\n",
      "Epoch 3/10, Train Loss: 0.1634, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9496\n",
      "Epoch 4/10, Train Loss: 0.1053, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9486\n",
      "Epoch 5/10, Train Loss: 0.1039, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8817\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9535\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.949\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8967\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        79\n",
      "    positive       0.97      0.97      0.97       168\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.95      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9024\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.83      0.78      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.29852604866028 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010030239820480347\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.382892847061157 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5652, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4716, Accuracy: 0.8177, F1 Micro: 0.8965, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.357, Accuracy: 0.9249, F1 Micro: 0.9543, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2419, Accuracy: 0.9472, F1 Micro: 0.9674, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1657, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.1014, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9694\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9706\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.97\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.971\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.88      0.96      0.92       158\n",
      "        part       0.95      1.00      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.8841, F1 Micro: 0.8841, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9657, F1 Micro: 0.9657, F1 Macro: 0.9612\n",
      "Epoch 3/10, Train Loss: 0.1291, Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.9521\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9402\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9349\n",
      "Epoch 6/10, Train Loss: 0.0665, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9339\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0547, Accuracy: 0.9657, F1 Micro: 0.9657, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9657, F1 Micro: 0.9657, F1 Macro: 0.9615\n",
      "Epoch 10/10, Train Loss: 0.0361, Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9568\n",
      "\n",
      "Sentiment analysis accuracy: 0.9657, F1 Micro: 0.9657, F1 Macro: 0.9615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95        76\n",
      "    positive       0.99      0.96      0.97       157\n",
      "\n",
      "    accuracy                           0.97       233\n",
      "   macro avg       0.96      0.97      0.96       233\n",
      "weighted avg       0.97      0.97      0.97       233\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8936\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.75      0.50        12\n",
      "     neutral       0.90      0.91      0.90       152\n",
      "    positive       0.87      0.65      0.75        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.72      0.77      0.72       216\n",
      "weighted avg       0.87      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.6819097995758 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.014955210685729985\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.251880168914795 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5566, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.473, Accuracy: 0.8132, F1 Micro: 0.8942, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3522, Accuracy: 0.9293, F1 Micro: 0.9569, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2385, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1834, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5289, Accuracy: 0.814, F1 Micro: 0.814, F1 Macro: 0.737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2506, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9485\n",
      "Epoch 3/10, Train Loss: 0.1694, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9478\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9463, F1 Micro: 0.9463, F1 Macro: 0.9374\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0682, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9491\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9143\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9351\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        78\n",
      "    positive       0.99      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.95       242\n",
      "   macro avg       0.94      0.96      0.95       242\n",
      "weighted avg       0.96      0.95      0.96       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8853\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.83      0.51        12\n",
      "     neutral       0.92      0.89      0.90       152\n",
      "    positive       0.83      0.67      0.74        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.80      0.72       216\n",
      "weighted avg       0.87      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.1795380115509 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.011581388115882874\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.147252798080444 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5591, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4654, Accuracy: 0.8371, F1 Micro: 0.9062, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3336, Accuracy: 0.9382, F1 Micro: 0.9621, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2257, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1695, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1037, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5159, Accuracy: 0.8543, F1 Micro: 0.8543, F1 Macro: 0.8078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2483, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9463\n",
      "Epoch 4/10, Train Loss: 0.1558, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9265\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.955\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.91\n",
      "Epoch 10/10, Train Loss: 0.0861, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "\n",
      "Sentiment analysis accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        81\n",
      "    positive       0.98      0.97      0.97       173\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.901\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.76      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.78      0.78       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.83868956565857 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010431051254272461\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.437463045120239 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5524, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4359, Accuracy: 0.8683, F1 Micro: 0.9225, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3159, Accuracy: 0.9315, F1 Micro: 0.9581, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.214, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1251, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4948, Accuracy: 0.8656, F1 Micro: 0.8656, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2315, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1425, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 4/10, Train Loss: 0.1165, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9224\n",
      "Epoch 5/10, Train Loss: 0.1637, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9138\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9016\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0727, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9408\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9376\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.89      0.92        83\n",
      "    positive       0.95      0.98      0.96       170\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.95      0.93      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.912\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.534996509552 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.006474316120147705\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.845610857009888 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5504, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4374, Accuracy: 0.8534, F1 Micro: 0.9148, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3024, Accuracy: 0.9427, F1 Micro: 0.9647, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2003, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1582, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4829, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2418, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1634, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9428\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "Epoch 6/10, Train Loss: 0.1299, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9411\n",
      "Epoch 7/10, Train Loss: 0.11, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1055, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9513\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9239\n",
      "\n",
      "Sentiment analysis accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        82\n",
      "    positive       0.99      0.95      0.97       170\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.94      0.96      0.95       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8868\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.67      0.50        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.77      0.73       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.79170680046082 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.006999143958091737\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.202279329299927 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4392, Accuracy: 0.8839, F1 Micro: 0.9312, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2905, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1999, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5319, Accuracy: 0.7829, F1 Micro: 0.7829, F1 Macro: 0.6886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2601, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1594, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Epoch 4/10, Train Loss: 0.148, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9102\n",
      "Epoch 5/10, Train Loss: 0.1059, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1014, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0625, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9224\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9179\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        84\n",
      "    positive       0.96      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8929\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.81      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.76097512245178 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006321176886558533\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.477411508560181 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5482, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4307, Accuracy: 0.9152, F1 Micro: 0.9483, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2748, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.511, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2091, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1737, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9431\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9302\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9379\n",
      "Epoch 9/10, Train Loss: 0.0876, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9127\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9316\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        83\n",
      "    positive       0.99      0.93      0.96       169\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9059\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.84      0.80       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 123.18648672103882 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0060662031173706055\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.496284484863281 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5329, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4245, Accuracy: 0.8929, F1 Micro: 0.9352, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2802, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1886, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4718, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2276, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1108, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.939\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9271\n",
      "Epoch 9/10, Train Loss: 0.0526, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9299\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9357\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       179\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.94      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9089\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.92      0.91      0.91       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.84      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.66927433013916 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005496695637702942\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.775606632232666 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4213, Accuracy: 0.9129, F1 Micro: 0.9471, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2708, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.0667, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5139, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9246\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1494, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.114, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9463\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9413\n",
      "Epoch 7/10, Train Loss: 0.0752, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.943\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9183\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9475\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       167\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.96      0.95       251\n",
      "weighted avg       0.96      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9211\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.32776427268982 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004158079624176025\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.301035404205322 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5225, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4053, Accuracy: 0.9137, F1 Micro: 0.9477, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2618, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1722, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9795\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.972\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.98       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4888, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2478, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1751, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.947\n",
      "Epoch 4/10, Train Loss: 0.1342, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9379\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9422\n",
      "Epoch 6/10, Train Loss: 0.0895, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0674, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.947\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9222\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       163\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.96      0.95       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8891\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.79      0.76       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.86      0.88      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.3719780445099 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006908386945724487\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.7114646434783936 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4079, Accuracy: 0.9085, F1 Micro: 0.9448, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2625, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1856, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 6/10, Train Loss: 0.1023, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4742, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.214, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9172\n",
      "Epoch 3/10, Train Loss: 0.1639, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8785\n",
      "Epoch 4/10, Train Loss: 0.1572, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9015\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9002\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8963\n",
      "Epoch 7/10, Train Loss: 0.1065, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9227\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9036\n",
      "Epoch 10/10, Train Loss: 0.0743, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.909\n",
      "\n",
      "Sentiment analysis accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        84\n",
      "    positive       0.97      0.93      0.95       179\n",
      "\n",
      "    accuracy                           0.93       263\n",
      "   macro avg       0.92      0.93      0.92       263\n",
      "weighted avg       0.93      0.93      0.93       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8944\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.75      0.58        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.82      0.77       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.14791631698608 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004141893982887268\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.559091329574585 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5321, Accuracy: 0.7976, F1 Micro: 0.8863, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.405, Accuracy: 0.9189, F1 Micro: 0.9505, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2466, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4983, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2402, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9239\n",
      "Epoch 3/10, Train Loss: 0.143, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1168, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1176, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9225\n",
      "Epoch 7/10, Train Loss: 0.0834, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9151\n",
      "Epoch 8/10, Train Loss: 0.0984, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9127\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8991\n",
      "\n",
      "Sentiment analysis accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        85\n",
      "    positive       0.96      0.96      0.96       183\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.93      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8828\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.67      0.55        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.76      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.78      0.74       216\n",
      "weighted avg       0.86      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.5755796432495 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003845471143722534\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.981534957885742 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5305, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4027, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2466, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9598, F1 Micro: 0.9751, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 6/10, Train Loss: 0.1003, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0744, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.96      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4636, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2268, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.917\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9091\n",
      "Epoch 4/10, Train Loss: 0.1455, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 5/10, Train Loss: 0.1183, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.067, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9009\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.902\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.91        85\n",
      "    positive       0.98      0.92      0.95       179\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8882\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.96      0.96       167\n",
      "    positive       0.74      0.79      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.73514556884766 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003910437226295472\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4418587684631348 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5207, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4044, Accuracy: 0.9278, F1 Micro: 0.9558, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1244, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "Epoch 9/10, Train Loss: 0.0508, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.48, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2042, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1213, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 9/10, Train Loss: 0.0874, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9159\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.94      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9006\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.84      0.78       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.60679960250854 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002831709384918213\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.964634895324707 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4007, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2478, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.041, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4788, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2312, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9428\n",
      "Epoch 3/10, Train Loss: 0.1548, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9256\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9524\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 8/10, Train Loss: 0.0534, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0465, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      1.00      0.71        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.90      0.83       216\n",
      "weighted avg       0.92      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.42151165008545 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0053108841180801395\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3607563972473145 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3837, Accuracy: 0.9293, F1 Micro: 0.9566, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2487, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9723\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0936, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9804\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9801\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4796, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2267, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Epoch 3/10, Train Loss: 0.194, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9307\n",
      "Epoch 4/10, Train Loss: 0.1277, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9233\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9296\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9346\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9304\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0787, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9335\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        85\n",
      "    positive       0.96      0.95      0.96       166\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.94      0.94      0.94       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9011\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.81      0.70        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.82      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.47528338432312 s\n",
      "Total runtime: 3044.521104812622 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9525dd4",
   "metadata": {
    "papermill": {
     "duration": 0.014065,
     "end_time": "2025-02-25T17:33:29.992136",
     "exception": false,
     "start_time": "2025-02-25T17:33:29.978071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "064acff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:33:30.020512Z",
     "iopub.status.busy": "2025-02-25T17:33:30.020295Z",
     "iopub.status.idle": "2025-02-25T18:24:40.456505Z",
     "shell.execute_reply": "2025-02-25T18:24:40.455311Z"
    },
    "papermill": {
     "duration": 3070.453018,
     "end_time": "2025-02-25T18:24:40.458811",
     "exception": false,
     "start_time": "2025-02-25T17:33:30.005793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 60.85418224334717 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.07268759906291962\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.272574424743652 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.578, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.484, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4382, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3956, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3717, Accuracy: 0.8125, F1 Micro: 0.8935, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.324, Accuracy: 0.8318, F1 Micro: 0.9032, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2794, Accuracy: 0.8564, F1 Micro: 0.9156, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2436, Accuracy: 0.8772, F1 Micro: 0.9269, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2077, Accuracy: 0.8899, F1 Micro: 0.9339, F1 Macro: 0.9324\n",
      "\n",
      "Aspect detection accuracy: 0.8899, F1 Micro: 0.9339, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      0.99      0.96       187\n",
      "     machine       0.82      1.00      0.90       175\n",
      "      others       0.81      0.97      0.88       158\n",
      "        part       0.89      0.94      0.92       158\n",
      "       price       0.93      1.00      0.96       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.99      0.93      1061\n",
      "   macro avg       0.89      0.98      0.93      1061\n",
      "weighted avg       0.89      0.99      0.93      1061\n",
      " samples avg       0.89      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6703, Accuracy: 0.6899, F1 Micro: 0.6899, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.57, Accuracy: 0.7405, F1 Micro: 0.7405, F1 Macro: 0.5728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4981, Accuracy: 0.7911, F1 Micro: 0.7911, F1 Macro: 0.7486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3723, Accuracy: 0.8481, F1 Micro: 0.8481, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2367, Accuracy: 0.8671, F1 Micro: 0.8671, F1 Macro: 0.8502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1702, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.066, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9054\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87        49\n",
      "    positive       0.95      0.93      0.94       109\n",
      "\n",
      "    accuracy                           0.92       158\n",
      "   macro avg       0.90      0.91      0.91       158\n",
      "weighted avg       0.92      0.92      0.92       158\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.7107\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.55      0.71        11\n",
      "     neutral       0.92      0.99      0.96       181\n",
      "    positive       0.93      0.58      0.72        24\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.95      0.71      0.79       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.81      1.00      0.90       167\n",
      "    positive       0.91      0.30      0.45        33\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.57      0.43      0.45       216\n",
      "weighted avg       0.77      0.82      0.76       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.33      0.42        12\n",
      "     neutral       0.81      0.97      0.88       152\n",
      "    positive       0.85      0.42      0.56        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.74      0.58      0.62       216\n",
      "weighted avg       0.80      0.81      0.78       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.74      0.63      0.68        41\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.82      0.76      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.93      1.00      0.97       186\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.71      0.81       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.71      0.77        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.75      0.80       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 77.66030669212341 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03507713675498963\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.448925018310547 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5776, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.491, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4803, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 4/10, Train Loss: 0.4329, Accuracy: 0.7879, F1 Micro: 0.8807, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3805, Accuracy: 0.8326, F1 Micro: 0.9026, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.349, Accuracy: 0.8668, F1 Micro: 0.9206, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2809, Accuracy: 0.8973, F1 Micro: 0.9377, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2286, Accuracy: 0.8996, F1 Micro: 0.9382, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1991, Accuracy: 0.9025, F1 Micro: 0.9395, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1631, Accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9493\n",
      "\n",
      "Aspect detection accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.84      1.00      0.91       175\n",
      "      others       0.86      0.97      0.91       158\n",
      "        part       0.92      0.91      0.91       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.92      0.98      0.95      1061\n",
      "   macro avg       0.92      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.95      1061\n",
      " samples avg       0.93      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6262, Accuracy: 0.6971, F1 Micro: 0.6971, F1 Macro: 0.4108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5359, Accuracy: 0.7596, F1 Micro: 0.7596, F1 Macro: 0.6663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4082, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1697, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9139\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1111, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9097\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.9327, F1 Micro: 0.9327, F1 Macro: 0.9235\n",
      "Epoch 10/10, Train Loss: 0.0352, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8981\n",
      "\n",
      "Sentiment analysis accuracy: 0.9327, F1 Micro: 0.9327, F1 Macro: 0.9235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        63\n",
      "    positive       0.99      0.92      0.95       145\n",
      "\n",
      "    accuracy                           0.93       208\n",
      "   macro avg       0.91      0.94      0.92       208\n",
      "weighted avg       0.94      0.93      0.93       208\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.805\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.19      0.32        16\n",
      "     neutral       0.83      1.00      0.91       167\n",
      "    positive       1.00      0.39      0.57        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.94      0.53      0.60       216\n",
      "weighted avg       0.87      0.85      0.81       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.50      0.55        12\n",
      "     neutral       0.87      0.97      0.92       152\n",
      "    positive       0.89      0.60      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.69      0.72       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.87      0.75        23\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.79      0.66      0.72        41\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.81      0.80       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.80      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 78.93673849105835 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.024495437741279602\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.78896164894104 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5582, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5117, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4586, Accuracy: 0.7946, F1 Micro: 0.8841, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4089, Accuracy: 0.8289, F1 Micro: 0.9011, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3315, Accuracy: 0.878, F1 Micro: 0.9263, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2763, Accuracy: 0.8951, F1 Micro: 0.9362, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2133, Accuracy: 0.9018, F1 Micro: 0.9393, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1761, Accuracy: 0.91, F1 Micro: 0.9441, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1411, Accuracy: 0.9219, F1 Micro: 0.9515, F1 Macro: 0.9489\n",
      "Epoch 10/10, Train Loss: 0.1298, Accuracy: 0.9182, F1 Micro: 0.9488, F1 Macro: 0.9458\n",
      "\n",
      "Aspect detection accuracy: 0.9219, F1 Micro: 0.9515, F1 Macro: 0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.85      1.00      0.92       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.94      0.86      0.90       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.94      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5989, Accuracy: 0.7339, F1 Micro: 0.7339, F1 Macro: 0.4233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4484, Accuracy: 0.8283, F1 Micro: 0.8283, F1 Macro: 0.762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2508, Accuracy: 0.8798, F1 Micro: 0.8798, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0986, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.068, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9057\n",
      "Epoch 9/10, Train Loss: 0.0312, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8962\n",
      "Epoch 10/10, Train Loss: 0.0189, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8749\n",
      "\n",
      "Sentiment analysis accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.94      0.87        62\n",
      "    positive       0.98      0.92      0.95       171\n",
      "\n",
      "    accuracy                           0.92       233\n",
      "   macro avg       0.89      0.93      0.91       233\n",
      "weighted avg       0.93      0.92      0.92       233\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.801\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.98      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.98      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.31      0.43        16\n",
      "     neutral       0.87      1.00      0.93       167\n",
      "    positive       1.00      0.48      0.65        33\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.86      0.60      0.67       216\n",
      "weighted avg       0.87      0.87      0.85       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.67      0.43        12\n",
      "     neutral       0.90      0.88      0.89       152\n",
      "    positive       0.83      0.67      0.74        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.68      0.74      0.69       216\n",
      "weighted avg       0.85      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.87      0.68        23\n",
      "     neutral       0.94      0.86      0.90       152\n",
      "    positive       0.75      0.73      0.74        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.75      0.82      0.77       216\n",
      "weighted avg       0.86      0.84      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.77      0.67        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.81      0.84      0.82       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 87.72837567329407 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.020157670974731444\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.62589716911316 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5714, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.4919, Accuracy: 0.7879, F1 Micro: 0.8812, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4599, Accuracy: 0.8043, F1 Micro: 0.8878, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3778, Accuracy: 0.8653, F1 Micro: 0.9196, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2961, Accuracy: 0.901, F1 Micro: 0.9395, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.235, Accuracy: 0.9085, F1 Micro: 0.9429, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1804, Accuracy: 0.9211, F1 Micro: 0.951, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1465, Accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1349, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1093, Accuracy: 0.942, F1 Micro: 0.9633, F1 Macro: 0.961\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9633, F1 Macro: 0.961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.97      0.98       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.93      0.88      0.90       158\n",
      "        part       0.96      0.94      0.95       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.96      1061\n",
      "   macro avg       0.96      0.96      0.96      1061\n",
      "weighted avg       0.96      0.97      0.96      1061\n",
      " samples avg       0.96      0.96      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5541, Accuracy: 0.7191, F1 Micro: 0.7191, F1 Macro: 0.4183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.378, Accuracy: 0.8577, F1 Micro: 0.8577, F1 Macro: 0.839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2095, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9085\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8947\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9038\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8937\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8991\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8985\n",
      "\n",
      "Sentiment analysis accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.97      0.87        75\n",
      "    positive       0.99      0.90      0.94       192\n",
      "\n",
      "    accuracy                           0.92       267\n",
      "   macro avg       0.89      0.94      0.91       267\n",
      "weighted avg       0.93      0.92      0.92       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9282, F1 Micro: 0.9282, F1 Macro: 0.8586\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.97      0.98       181\n",
      "    positive       0.79      0.96      0.87        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      1.00      0.97       167\n",
      "    positive       0.96      0.76      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.68      0.75      0.72        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.79      0.76       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.83      0.75        23\n",
      "     neutral       0.96      0.94      0.95       152\n",
      "    positive       0.85      0.80      0.83        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.85      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 92.4563238620758 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.017569690942764282\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.584495067596436 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5676, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5001, Accuracy: 0.7917, F1 Micro: 0.8826, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4244, Accuracy: 0.8571, F1 Micro: 0.9157, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3249, Accuracy: 0.8981, F1 Micro: 0.9383, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2469, Accuracy: 0.9271, F1 Micro: 0.9546, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1922, Accuracy: 0.9405, F1 Micro: 0.963, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1538, Accuracy: 0.9442, F1 Micro: 0.9648, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1211, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1002, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.967\n",
      "Epoch 10/10, Train Loss: 0.0864, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9666\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.92      0.89      0.90       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5186, Accuracy: 0.7043, F1 Micro: 0.7043, F1 Macro: 0.4132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3368, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1746, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1395, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.905\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0878, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0581, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9116\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9226\n",
      "\n",
      "Sentiment analysis accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.93      0.89        76\n",
      "    positive       0.97      0.93      0.95       181\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.91      0.93      0.92       257\n",
      "weighted avg       0.94      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8729\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.93      1.00      0.97       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.80      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.71      0.81      0.76        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.78      0.81      0.79       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.83      0.72        23\n",
      "     neutral       0.96      0.95      0.95       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.83       216\n",
      "weighted avg       0.91      0.90      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 101.02266883850098 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.014283329248428346\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.569490909576416 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5534, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 2/10, Train Loss: 0.4901, Accuracy: 0.7924, F1 Micro: 0.8816, F1 Macro: 0.8786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4252, Accuracy: 0.8638, F1 Micro: 0.9184, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3152, Accuracy: 0.9167, F1 Micro: 0.9488, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.23, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1471, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Epoch 8/10, Train Loss: 0.1141, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9659\n",
      "Epoch 9/10, Train Loss: 0.0937, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0824, Accuracy: 0.9487, F1 Micro: 0.9676, F1 Macro: 0.965\n",
      "\n",
      "Aspect detection accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4997, Accuracy: 0.6923, F1 Micro: 0.6923, F1 Macro: 0.4091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3222, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9442\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9325\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9234\n",
      "Epoch 6/10, Train Loss: 0.0863, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0724, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "Epoch 8/10, Train Loss: 0.0414, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.0793, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9125\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9397\n",
      "\n",
      "Sentiment analysis accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        76\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.8697\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.82      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.83      0.49        12\n",
      "     neutral       0.94      0.86      0.89       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.81      0.71       216\n",
      "weighted avg       0.87      0.82      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.77      0.69        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.44428634643555 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.016728806495666503\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.35610294342041 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.556, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.497, Accuracy: 0.7946, F1 Micro: 0.8841, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.398, Accuracy: 0.8906, F1 Micro: 0.9335, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3072, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2189, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1709, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Epoch 7/10, Train Loss: 0.1396, Accuracy: 0.939, F1 Micro: 0.9616, F1 Macro: 0.9584\n",
      "Epoch 8/10, Train Loss: 0.1085, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0902, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Epoch 10/10, Train Loss: 0.0747, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9675\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.56, Accuracy: 0.6802, F1 Micro: 0.6802, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3197, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1448, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.125, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9317\n",
      "Epoch 5/10, Train Loss: 0.0879, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.119, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "Epoch 7/10, Train Loss: 0.1024, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9138\n",
      "Epoch 8/10, Train Loss: 0.1092, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9295\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        78\n",
      "    positive       0.99      0.93      0.96       169\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.93      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.80      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.89      0.93      0.91       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.78      0.78       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.97      0.96      0.97       152\n",
      "    positive       0.85      0.85      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.2826578617096 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011409550905227661\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.76151990890503 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5601, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.5006, Accuracy: 0.7872, F1 Micro: 0.878, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3863, Accuracy: 0.8943, F1 Micro: 0.9364, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2605, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1784, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9686\n",
      "Epoch 6/10, Train Loss: 0.1416, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9674\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9683\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5052, Accuracy: 0.7214, F1 Micro: 0.7214, F1 Macro: 0.5146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3088, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1833, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.136, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1525, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.11, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9345\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8896\n",
      "Epoch 10/10, Train Loss: 0.0822, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9059\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        80\n",
      "    positive       0.98      0.93      0.96       182\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.95      0.93       262\n",
      "weighted avg       0.95      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8824\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.80      0.78      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.85      0.83      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.87740707397461 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008607786893844605\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.009187936782837 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5505, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.485, Accuracy: 0.814, F1 Micro: 0.8932, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3739, Accuracy: 0.9122, F1 Micro: 0.9468, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2572, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1818, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9685\n",
      "Epoch 6/10, Train Loss: 0.1411, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1146, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0797, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.065, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4985, Accuracy: 0.749, F1 Micro: 0.749, F1 Macro: 0.617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2593, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9265\n",
      "Epoch 3/10, Train Loss: 0.1668, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1327, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1096, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1194, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0489, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9353\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0463, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9278\n",
      "\n",
      "Sentiment analysis accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        79\n",
      "    positive       0.96      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.94       247\n",
      "   macro avg       0.93      0.93      0.93       247\n",
      "weighted avg       0.94      0.94      0.94       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.75      0.50        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.79      0.73       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 115.49302458763123 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.009431603550910947\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.454596519470215 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5352, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4669, Accuracy: 0.8356, F1 Micro: 0.9045, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3523, Accuracy: 0.9167, F1 Micro: 0.9492, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2365, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1785, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9686\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9487, F1 Micro: 0.9676, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1085, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9501, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5341, Accuracy: 0.6939, F1 Micro: 0.6939, F1 Macro: 0.4561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3123, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1916, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9236\n",
      "Epoch 4/10, Train Loss: 0.1461, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0821, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9319\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9151\n",
      "Epoch 7/10, Train Loss: 0.0783, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9319\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9267\n",
      "\n",
      "Sentiment analysis accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        79\n",
      "    positive       0.98      0.93      0.95       166\n",
      "\n",
      "    accuracy                           0.94       245\n",
      "   macro avg       0.92      0.94      0.93       245\n",
      "weighted avg       0.94      0.94      0.94       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8688\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.83      0.50        12\n",
      "     neutral       0.92      0.87      0.89       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.83      0.75       216\n",
      "weighted avg       0.89      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.85      0.73        13\n",
      "     neutral       0.99      0.98      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.96      0.95      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.92      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 114.34214496612549 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010591119527816772\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.678059816360474 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4663, Accuracy: 0.8177, F1 Micro: 0.8946, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3369, Accuracy: 0.9315, F1 Micro: 0.958, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2297, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Epoch 7/10, Train Loss: 0.1009, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.9689\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.94      0.91       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5028, Accuracy: 0.7059, F1 Micro: 0.7059, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2822, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9367\n",
      "Epoch 3/10, Train Loss: 0.1985, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9046\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9298\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9076\n",
      "Epoch 6/10, Train Loss: 0.0787, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9206\n",
      "Epoch 7/10, Train Loss: 0.0735, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0638, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9056\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9164\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        80\n",
      "    positive       0.99      0.93      0.96       175\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8916\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.89      0.93      0.91       152\n",
      "    positive       0.80      0.69      0.74        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.76      0.77       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.95096373558044 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.006638616323471069\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.078253269195557 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4649, Accuracy: 0.8512, F1 Micro: 0.9115, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3218, Accuracy: 0.9353, F1 Micro: 0.9595, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2119, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9719\n",
      "Epoch 5/10, Train Loss: 0.1461, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1174, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9684\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9576, F1 Micro: 0.9731, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5204, Accuracy: 0.75, F1 Micro: 0.75, F1 Macro: 0.6058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2838, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9501\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1157, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9381\n",
      "Epoch 6/10, Train Loss: 0.0787, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.945\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9374\n",
      "Epoch 8/10, Train Loss: 0.1135, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0919, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9199\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        80\n",
      "    positive       0.99      0.95      0.97       168\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.94      0.96      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8725\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.92      0.49        12\n",
      "     neutral       0.93      0.88      0.91       152\n",
      "    positive       0.90      0.67      0.77        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.82      0.72       216\n",
      "weighted avg       0.89      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.7518835067749 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.01054554879665375\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.3666369915008545 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5397, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4521, Accuracy: 0.8661, F1 Micro: 0.9195, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3004, Accuracy: 0.9397, F1 Micro: 0.963, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2043, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9676\n",
      "Epoch 5/10, Train Loss: 0.1504, Accuracy: 0.9427, F1 Micro: 0.9638, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9697\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.776, F1 Micro: 0.776, F1 Macro: 0.6693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9317\n",
      "Epoch 4/10, Train Loss: 0.1124, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9369\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.1023, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9245\n",
      "Epoch 9/10, Train Loss: 0.0592, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        80\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.93      0.95      0.94       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8797\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.67      0.48        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.77      0.73       216\n",
      "weighted avg       0.87      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 119.67742800712585 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.009970486164093018\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.904707193374634 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4476, Accuracy: 0.8586, F1 Micro: 0.9156, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3048, Accuracy: 0.9345, F1 Micro: 0.9591, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1966, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1513, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9708\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.504, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2325, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1847, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9137\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9298\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1051, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9551\n",
      "Epoch 8/10, Train Loss: 0.0896, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9371\n",
      "Epoch 9/10, Train Loss: 0.0949, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        81\n",
      "    positive       0.98      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.80717253684998 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004816174507141113\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.548602819442749 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5344, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4444, Accuracy: 0.8765, F1 Micro: 0.9261, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2987, Accuracy: 0.9442, F1 Micro: 0.9655, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1993, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0512, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5088, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2608, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9471\n",
      "Epoch 3/10, Train Loss: 0.1556, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9345\n",
      "Epoch 4/10, Train Loss: 0.124, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9281\n",
      "Epoch 7/10, Train Loss: 0.0732, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9124\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9341\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9383\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        81\n",
      "    positive       0.98      0.95      0.97       178\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8919\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.88      0.76        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.87      0.85       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.81        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 127.00158452987671 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005098208785057068\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.998860120773315 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4216, Accuracy: 0.8891, F1 Micro: 0.9335, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2692, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9681\n",
      "Epoch 4/10, Train Loss: 0.1854, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0551, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2071, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1686, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1286, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9482\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9479\n",
      "Epoch 7/10, Train Loss: 0.1067, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9287\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9287\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9437\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        82\n",
      "    positive       0.99      0.94      0.97       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.96      0.95       260\n",
      "weighted avg       0.96      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.9009\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      1.00      0.77        12\n",
      "     neutral       0.94      0.89      0.91       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.89      0.82       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.266175031662 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004313439130783081\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.410516738891602 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4232, Accuracy: 0.8884, F1 Micro: 0.933, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2717, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "Epoch 4/10, Train Loss: 0.1814, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.0968, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0785, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4836, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2598, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Epoch 4/10, Train Loss: 0.1226, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 5/10, Train Loss: 0.143, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 7/10, Train Loss: 0.0699, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.923\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.916\n",
      "Epoch 10/10, Train Loss: 0.0413, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9104\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8755\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.92      0.65        12\n",
      "     neutral       0.94      0.89      0.91       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.86      0.79       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.96      0.80        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.90      0.87       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 130.42915439605713 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005039960145950317\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.8724238872528076 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.7894, F1 Micro: 0.8818, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4274, Accuracy: 0.8914, F1 Micro: 0.9346, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2752, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1834, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0552, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5141, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9417\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9276\n",
      "Epoch 4/10, Train Loss: 0.1256, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9126\n",
      "Epoch 5/10, Train Loss: 0.1101, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9284\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9319\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9284\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.92\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9162\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9208\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        81\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8943\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.83      0.67      0.74        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.76      0.78       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.06124997138977 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003340831398963928\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.732485771179199 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5228, Accuracy: 0.7946, F1 Micro: 0.8837, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4175, Accuracy: 0.9085, F1 Micro: 0.9447, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2543, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1231, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0711, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5062, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2618, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2127, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 7/10, Train Loss: 0.0763, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9282\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        85\n",
      "    positive       0.98      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.92\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.83680987358093 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0034047722816467284\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.133784055709839 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7917, F1 Micro: 0.8829, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4177, Accuracy: 0.9152, F1 Micro: 0.9481, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2532, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1659, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.1022, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.531, Accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2533, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.19, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1174, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1257, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Epoch 8/10, Train Loss: 0.071, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9105\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9186\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9026\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 141.8085994720459 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0031257122755050664\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.551926851272583 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5218, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4158, Accuracy: 0.9085, F1 Micro: 0.9442, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2593, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1692, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.0888, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4831, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2276, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1434, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1071, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1147, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9174\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9271\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9087\n",
      "Epoch 9/10, Train Loss: 0.0471, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9165\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9276\n",
      "\n",
      "Sentiment analysis accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        85\n",
      "    positive       0.97      0.94      0.96       184\n",
      "\n",
      "    accuracy                           0.94       269\n",
      "   macro avg       0.93      0.94      0.93       269\n",
      "weighted avg       0.94      0.94      0.94       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8997\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.92      0.63        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.87      0.78       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.16904950141907 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003437620401382446\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0758442878723145 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.7969, F1 Micro: 0.8851, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4042, Accuracy: 0.9182, F1 Micro: 0.9495, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2422, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 7/10, Train Loss: 0.0702, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9782\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4816, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2401, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9271\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9345\n",
      "Epoch 5/10, Train Loss: 0.1121, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.085, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0657, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9322\n",
      "Epoch 8/10, Train Loss: 0.0561, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9378\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9338\n",
      "\n",
      "Sentiment analysis accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       187\n",
      "\n",
      "    accuracy                           0.95       274\n",
      "   macro avg       0.93      0.94      0.94       274\n",
      "weighted avg       0.95      0.95      0.95       274\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9235\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 149.45068740844727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017740577459335327\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.5112297534942627 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5262, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.416, Accuracy: 0.9062, F1 Micro: 0.9424, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.263, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0914, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4731, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9162\n",
      "Epoch 2/10, Train Loss: 0.2339, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9484\n",
      "Epoch 4/10, Train Loss: 0.1427, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9158\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9238\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9432\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9283\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9059\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.97       177\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.95       262\n",
      "weighted avg       0.96      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8961\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.76      0.76      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.79      0.81       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.89      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 150.38398051261902 s\n",
      "Total runtime: 3069.042628288269 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400cd9e",
   "metadata": {
    "papermill": {
     "duration": 0.176174,
     "end_time": "2025-02-25T18:24:40.821841",
     "exception": false,
     "start_time": "2025-02-25T18:24:40.645667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9087b515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T18:24:41.181350Z",
     "iopub.status.busy": "2025-02-25T18:24:41.180993Z",
     "iopub.status.idle": "2025-02-25T19:19:24.533098Z",
     "shell.execute_reply": "2025-02-25T19:19:24.532212Z"
    },
    "papermill": {
     "duration": 3283.530036,
     "end_time": "2025-02-25T19:19:24.534702",
     "exception": false,
     "start_time": "2025-02-25T18:24:41.004666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 71.19110107421875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.06025112867355347\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 16.8006010055542 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6061, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.504, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4681, Accuracy: 0.7946, F1 Micro: 0.8845, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4473, Accuracy: 0.8013, F1 Micro: 0.8874, F1 Macro: 0.8855\n",
      "Epoch 5/10, Train Loss: 0.4142, Accuracy: 0.8036, F1 Micro: 0.8865, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3902, Accuracy: 0.8147, F1 Micro: 0.8935, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3797, Accuracy: 0.8229, F1 Micro: 0.897, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3154, Accuracy: 0.8289, F1 Micro: 0.899, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2827, Accuracy: 0.843, F1 Micro: 0.907, F1 Macro: 0.9045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.272, Accuracy: 0.8504, F1 Micro: 0.911, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8504, F1 Micro: 0.911, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.85      0.99      0.92       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.88      0.85      0.87       158\n",
      "        part       0.87      0.95      0.91       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      1061\n",
      "   macro avg       0.86      0.97      0.91      1061\n",
      "weighted avg       0.86      0.97      0.91      1061\n",
      " samples avg       0.86      0.97      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6126, Accuracy: 0.7643, F1 Micro: 0.7643, F1 Macro: 0.4332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4259, Accuracy: 0.7643, F1 Micro: 0.7643, F1 Macro: 0.4332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3753, Accuracy: 0.7643, F1 Micro: 0.7643, F1 Macro: 0.4332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3571, Accuracy: 0.7929, F1 Micro: 0.7929, F1 Macro: 0.568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2751, Accuracy: 0.8286, F1 Micro: 0.8286, F1 Macro: 0.7247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1757, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.7825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1584, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8669\n",
      "Epoch 10/10, Train Loss: 0.0386, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.855\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.76      0.79        33\n",
      "    positive       0.93      0.95      0.94       107\n",
      "\n",
      "    accuracy                           0.91       140\n",
      "   macro avg       0.88      0.86      0.87       140\n",
      "weighted avg       0.91      0.91      0.91       140\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.841, F1 Micro: 0.841, F1 Macro: 0.5283\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.85      0.99      0.92       181\n",
      "    positive       0.80      0.17      0.28        24\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.55      0.39      0.40       216\n",
      "weighted avg       0.80      0.85      0.80       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.87      0.85      0.86       152\n",
      "    positive       0.62      0.65      0.64        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.70      0.72      0.71       216\n",
      "weighted avg       0.80      0.79      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.39      0.56        23\n",
      "     neutral       0.87      0.95      0.91       152\n",
      "    positive       0.68      0.68      0.68        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.85      0.68      0.72       216\n",
      "weighted avg       0.85      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.62      0.70       216\n",
      "weighted avg       0.91      0.92      0.90       216\n",
      "\n",
      "Total train time: 80.83333373069763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.04282335042953491\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 16.52159357070923 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6004, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5348, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5203, Accuracy: 0.7954, F1 Micro: 0.8852, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4748, Accuracy: 0.8088, F1 Micro: 0.8918, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4126, Accuracy: 0.817, F1 Micro: 0.8953, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3759, Accuracy: 0.8534, F1 Micro: 0.914, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.316, Accuracy: 0.8765, F1 Micro: 0.9256, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2533, Accuracy: 0.901, F1 Micro: 0.94, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2127, Accuracy: 0.9055, F1 Micro: 0.9418, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1693, Accuracy: 0.9196, F1 Micro: 0.95, F1 Macro: 0.947\n",
      "\n",
      "Aspect detection accuracy: 0.9196, F1 Micro: 0.95, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.95      1.00      0.98       187\n",
      "     machine       0.90      0.98      0.94       175\n",
      "      others       0.91      0.85      0.88       158\n",
      "        part       0.89      0.98      0.93       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.93      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5289, Accuracy: 0.7137, F1 Micro: 0.7137, F1 Macro: 0.4165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4197, Accuracy: 0.7137, F1 Micro: 0.7137, F1 Macro: 0.4165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2603, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1463, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1021, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9028\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.043, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0475, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.909\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8787\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8959\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.93      0.87        67\n",
      "    positive       0.97      0.92      0.94       167\n",
      "\n",
      "    accuracy                           0.92       234\n",
      "   macro avg       0.90      0.92      0.91       234\n",
      "weighted avg       0.93      0.92      0.92       234\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8096\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.96      1.00      0.98       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.76      0.81       216\n",
      "weighted avg       0.96      0.96      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.90      0.98      0.94       167\n",
      "    positive       0.89      0.48      0.63        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.74      0.78       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.67      0.53        12\n",
      "     neutral       0.91      0.85      0.88       152\n",
      "    positive       0.64      0.69      0.67        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.67      0.74      0.69       216\n",
      "weighted avg       0.82      0.80      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.74      0.81        23\n",
      "     neutral       0.89      0.99      0.93       152\n",
      "    positive       0.93      0.63      0.75        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.90      0.79      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.99      0.83      0.90       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 91.01532554626465 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.027045950293540955\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.976342916488647 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5744, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5195, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4822, Accuracy: 0.7946, F1 Micro: 0.8834, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4434, Accuracy: 0.8274, F1 Micro: 0.9005, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3643, Accuracy: 0.8668, F1 Micro: 0.9209, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2907, Accuracy: 0.9003, F1 Micro: 0.9393, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2273, Accuracy: 0.9167, F1 Micro: 0.949, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1877, Accuracy: 0.9196, F1 Micro: 0.9505, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1497, Accuracy: 0.9241, F1 Micro: 0.9525, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1222, Accuracy: 0.9315, F1 Micro: 0.9573, F1 Macro: 0.9544\n",
      "\n",
      "Aspect detection accuracy: 0.9315, F1 Micro: 0.9573, F1 Macro: 0.9544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.91      0.99      0.95       175\n",
      "      others       0.91      0.85      0.88       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.95      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4664, Accuracy: 0.7149, F1 Micro: 0.7149, F1 Macro: 0.4169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3413, Accuracy: 0.7562, F1 Micro: 0.7562, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1152, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9034\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8868\n",
      "Epoch 6/10, Train Loss: 0.0636, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8829\n",
      "Epoch 7/10, Train Loss: 0.0502, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8738\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8913\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8974\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8974\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.94      0.87        69\n",
      "    positive       0.98      0.91      0.94       173\n",
      "\n",
      "    accuracy                           0.92       242\n",
      "   macro avg       0.89      0.92      0.90       242\n",
      "weighted avg       0.93      0.92      0.92       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8341\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.91      0.99      0.95       167\n",
      "    positive       0.95      0.61      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.74      0.80       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.92      0.86      0.88       152\n",
      "    positive       0.66      0.79      0.72        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.75      0.77      0.76       216\n",
      "weighted avg       0.84      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.70      0.70        23\n",
      "     neutral       0.90      0.99      0.94       152\n",
      "    positive       0.96      0.63      0.76        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.77      0.80       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 94.31493830680847 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.018387052416801452\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.14596939086914 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5772, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.517, Accuracy: 0.7991, F1 Micro: 0.8869, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4818, Accuracy: 0.8222, F1 Micro: 0.8983, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3816, Accuracy: 0.8743, F1 Micro: 0.9249, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.297, Accuracy: 0.907, F1 Micro: 0.9427, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2267, Accuracy: 0.9256, F1 Micro: 0.9543, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1734, Accuracy: 0.9353, F1 Micro: 0.9601, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1417, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1181, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9618\n",
      "Epoch 10/10, Train Loss: 0.0958, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9595\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.92      0.99      0.96       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4529, Accuracy: 0.7113, F1 Micro: 0.7113, F1 Macro: 0.4156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2945, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8926\n",
      "Epoch 3/10, Train Loss: 0.1585, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0567, Accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.9075\n",
      "Epoch 5/10, Train Loss: 0.1004, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8911\n",
      "Epoch 6/10, Train Loss: 0.0582, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0509, Accuracy: 0.9456, F1 Micro: 0.9456, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.028, Accuracy: 0.9456, F1 Micro: 0.9456, F1 Macro: 0.9346\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9293\n",
      "Epoch 10/10, Train Loss: 0.0233, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9299\n",
      "\n",
      "Sentiment analysis accuracy: 0.9456, F1 Micro: 0.9456, F1 Macro: 0.9346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        69\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       239\n",
      "   macro avg       0.93      0.94      0.93       239\n",
      "weighted avg       0.95      0.95      0.95       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.8564\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.96      0.67      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.76      0.82       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.74      0.75      0.74        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.73      0.79      0.75       216\n",
      "weighted avg       0.85      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 101.44537901878357 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.016347676515579224\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.256206035614014 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.559, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4935, Accuracy: 0.8013, F1 Micro: 0.888, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4262, Accuracy: 0.8624, F1 Micro: 0.9191, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3226, Accuracy: 0.91, F1 Micro: 0.9453, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2379, Accuracy: 0.9278, F1 Micro: 0.9556, F1 Macro: 0.954\n",
      "Epoch 6/10, Train Loss: 0.1725, Accuracy: 0.9286, F1 Micro: 0.9555, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1424, Accuracy: 0.9345, F1 Micro: 0.959, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1153, Accuracy: 0.9412, F1 Micro: 0.9629, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.096, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0779, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9664\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.93      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4789, Accuracy: 0.6917, F1 Micro: 0.6917, F1 Macro: 0.4089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2933, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1489, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9151\n",
      "Epoch 4/10, Train Loss: 0.0997, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0719, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9265\n",
      "Epoch 8/10, Train Loss: 0.0514, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0479, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9295\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9107\n",
      "\n",
      "Sentiment analysis accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.91        74\n",
      "    positive       0.99      0.92      0.95       166\n",
      "\n",
      "    accuracy                           0.94       240\n",
      "   macro avg       0.92      0.95      0.93       240\n",
      "weighted avg       0.94      0.94      0.94       240\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.8639\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.75      0.81       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.89      0.93      0.91       152\n",
      "    positive       0.75      0.69      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.84      0.76      0.80       216\n",
      "weighted avg       0.85      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.23523616790771 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012140667438507082\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.134645462036133 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4903, Accuracy: 0.8013, F1 Micro: 0.8881, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.408, Accuracy: 0.8698, F1 Micro: 0.9233, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2946, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2254, Accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1637, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1283, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9679\n",
      "Epoch 8/10, Train Loss: 0.1058, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0718, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.51, Accuracy: 0.6885, F1 Micro: 0.6885, F1 Macro: 0.4078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2656, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 3/10, Train Loss: 0.1086, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9127\n",
      "Epoch 4/10, Train Loss: 0.1189, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1232, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0708, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9377\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9345\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9291\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9179\n",
      "Epoch 10/10, Train Loss: 0.0351, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9173\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        76\n",
      "    positive       0.96      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8834\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.90      0.94      0.92       152\n",
      "    positive       0.80      0.67      0.73        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.62419390678406 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010799366235733032\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.212349653244019 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5577, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4873, Accuracy: 0.8103, F1 Micro: 0.892, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3889, Accuracy: 0.8981, F1 Micro: 0.9388, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2792, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2073, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1485, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9664\n",
      "Epoch 7/10, Train Loss: 0.1199, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0823, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.91      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4937, Accuracy: 0.7149, F1 Micro: 0.7149, F1 Macro: 0.4766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2776, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.936\n",
      "Epoch 3/10, Train Loss: 0.1236, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9187\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9096\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9307\n",
      "Epoch 6/10, Train Loss: 0.0896, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9225\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9173\n",
      "Epoch 8/10, Train Loss: 0.0664, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9391\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9287\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        76\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       249\n",
      "   macro avg       0.93      0.94      0.94       249\n",
      "weighted avg       0.95      0.95      0.95       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8798\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.91      0.90       152\n",
      "    positive       0.73      0.73      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.82      0.80      0.81       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.90406608581543 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010928601026535034\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.985276699066162 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4711, Accuracy: 0.8222, F1 Micro: 0.8985, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3471, Accuracy: 0.9249, F1 Micro: 0.9538, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2376, Accuracy: 0.9442, F1 Micro: 0.9655, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1615, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Epoch 6/10, Train Loss: 0.1306, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.88      0.90       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.489, Accuracy: 0.7863, F1 Micro: 0.7863, F1 Macro: 0.6689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2578, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9417\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.928\n",
      "Epoch 4/10, Train Loss: 0.1154, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9262\n",
      "Epoch 5/10, Train Loss: 0.1084, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9295\n",
      "Epoch 6/10, Train Loss: 0.1412, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9375\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.937\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9413\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.899\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        79\n",
      "    positive       0.97      0.96      0.96       183\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.94      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8716\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.79      0.79      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.68      0.79      0.73        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.80      0.78      0.79       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.61      0.74        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.79      0.93      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.54940605163574 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009365475177764893\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.19918704032898 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5532, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4746, Accuracy: 0.8155, F1 Micro: 0.8949, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3581, Accuracy: 0.9219, F1 Micro: 0.9526, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2323, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9642\n",
      "Epoch 5/10, Train Loss: 0.1763, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1244, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9675\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9691\n",
      "Epoch 10/10, Train Loss: 0.0638, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.91      0.90      0.90       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5033, Accuracy: 0.8038, F1 Micro: 0.8038, F1 Macro: 0.7094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2863, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1528, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9043\n",
      "Epoch 4/10, Train Loss: 0.144, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1496, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0836, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9205\n",
      "Epoch 7/10, Train Loss: 0.1198, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9139\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9082\n",
      "Epoch 9/10, Train Loss: 0.1063, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9047\n",
      "Epoch 10/10, Train Loss: 0.0737, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9158\n",
      "\n",
      "Sentiment analysis accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89        80\n",
      "    positive       0.96      0.94      0.95       185\n",
      "\n",
      "    accuracy                           0.93       265\n",
      "   macro avg       0.92      0.93      0.92       265\n",
      "weighted avg       0.93      0.93      0.93       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8779\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.70      0.73      0.72        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.79      0.74       216\n",
      "weighted avg       0.84      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.18310523033142 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010375431180000304\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.719727516174316 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5561, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4613, Accuracy: 0.8318, F1 Micro: 0.9035, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3426, Accuracy: 0.9263, F1 Micro: 0.9548, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.233, Accuracy: 0.9442, F1 Micro: 0.9656, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1681, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1339, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1054, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4998, Accuracy: 0.8521, F1 Micro: 0.8521, F1 Macro: 0.8023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2543, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9259\n",
      "Epoch 3/10, Train Loss: 0.1405, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9416\n",
      "Epoch 5/10, Train Loss: 0.1073, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9153\n",
      "Epoch 6/10, Train Loss: 0.1109, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.91\n",
      "Epoch 7/10, Train Loss: 0.121, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9572, F1 Micro: 0.9572, F1 Macro: 0.9512\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9307\n",
      "\n",
      "Sentiment analysis accuracy: 0.9572, F1 Micro: 0.9572, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        80\n",
      "    positive       0.99      0.95      0.97       177\n",
      "\n",
      "    accuracy                           0.96       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.96      0.96       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8941\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.75      0.73      0.74        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.82      0.80      0.81       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.78      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.86      0.90      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.30710458755493 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.008799225091934204\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.022691011428833 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5391, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4646, Accuracy: 0.8348, F1 Micro: 0.905, F1 Macro: 0.9037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3072, Accuracy: 0.936, F1 Micro: 0.9607, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2163, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1503, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9673\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.969\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4847, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2559, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1267, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9276\n",
      "Epoch 4/10, Train Loss: 0.1093, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9206\n",
      "Epoch 5/10, Train Loss: 0.1538, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1082, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9349\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9358\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93        80\n",
      "    positive       0.98      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.73      0.69      0.71        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.72      0.78      0.74       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.2507336139679 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.008227914571762085\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.442895889282227 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5526, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.447, Accuracy: 0.8653, F1 Micro: 0.9209, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3019, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1989, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9688\n",
      "Epoch 5/10, Train Loss: 0.1457, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.962\n",
      "Epoch 6/10, Train Loss: 0.11, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7171, F1 Micro: 0.7171, F1 Macro: 0.5152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2673, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9413\n",
      "Epoch 4/10, Train Loss: 0.1601, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8996\n",
      "Epoch 5/10, Train Loss: 0.1038, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9276\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.912\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9195\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9327\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0311, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9319\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        80\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.894\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.91      0.94      0.92       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.83861351013184 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.007758399844169617\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.708462715148926 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.543, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4399, Accuracy: 0.8802, F1 Micro: 0.9287, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2778, Accuracy: 0.942, F1 Micro: 0.9643, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1742, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9651\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.7346, F1 Micro: 0.7346, F1 Macro: 0.5557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2801, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1733, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9025\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "Epoch 7/10, Train Loss: 0.1069, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9273\n",
      "Epoch 8/10, Train Loss: 0.0514, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        82\n",
      "    positive       0.98      0.95      0.97       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.96      0.95       260\n",
      "weighted avg       0.96      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.64301753044128 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006051167845726013\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.800076723098755 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4395, Accuracy: 0.8884, F1 Micro: 0.9332, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2791, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0851, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5112, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2593, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1544, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.14, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9213\n",
      "Epoch 7/10, Train Loss: 0.1082, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0411, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        83\n",
      "    positive       0.97      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.94       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9037\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.88      0.82       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.22839879989624 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006911426782608032\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.692102432250977 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4315, Accuracy: 0.8929, F1 Micro: 0.9359, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2763, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9674\n",
      "Epoch 4/10, Train Loss: 0.1855, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1322, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0714, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5127, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2622, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8895\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9095\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9112\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9169\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9156\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9215\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9089\n",
      "\n",
      "Sentiment analysis accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        81\n",
      "    positive       0.98      0.93      0.95       174\n",
      "\n",
      "    accuracy                           0.94       255\n",
      "   macro avg       0.92      0.94      0.93       255\n",
      "weighted avg       0.94      0.94      0.94       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8911\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.79      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.82974100112915 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004747748374938965\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.112023830413818 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4109, Accuracy: 0.9085, F1 Micro: 0.9446, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2695, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9749\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0804, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4776, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9426\n",
      "Epoch 3/10, Train Loss: 0.1283, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1037, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9508\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9422\n",
      "Epoch 8/10, Train Loss: 0.0834, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9062\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9411\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8863\n",
      "\n",
      "Sentiment analysis accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        82\n",
      "    positive       0.97      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.95      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8758\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.83      0.49        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.85      0.67      0.75        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.80      0.72       216\n",
      "weighted avg       0.88      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 134.74774360656738 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00460013747215271\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.620419502258301 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5282, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4144, Accuracy: 0.9159, F1 Micro: 0.9489, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2545, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0759, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9561, F1 Micro: 0.9721, F1 Macro: 0.9698\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5336, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.9503\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9217\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9217\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9174\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9217\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9384\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "\n",
      "Sentiment analysis accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.9503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        82\n",
      "    positive       0.97      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.95      0.95      0.95       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8766\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.84      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.83      0.49        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.82      0.74       216\n",
      "weighted avg       0.89      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.74816131591797 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.007311299443244934\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.9568850994110107 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5386, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4015, Accuracy: 0.9211, F1 Micro: 0.9519, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2675, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9727\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9554, F1 Micro: 0.9716, F1 Macro: 0.9688\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2453, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1595, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9407\n",
      "Epoch 5/10, Train Loss: 0.1006, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9237\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9392\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9323\n",
      "Epoch 9/10, Train Loss: 0.0401, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9367\n",
      "\n",
      "Sentiment analysis accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        80\n",
      "    positive       0.96      0.96      0.96       163\n",
      "\n",
      "    accuracy                           0.95       243\n",
      "   macro avg       0.94      0.94      0.94       243\n",
      "weighted avg       0.95      0.95      0.95       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8855\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.83      0.54        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.76       216\n",
      "weighted avg       0.90      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.85      0.76        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.94431924819946 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007109314203262329\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.8991992473602295 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4237, Accuracy: 0.9048, F1 Micro: 0.9424, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2524, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9735\n",
      "Epoch 10/10, Train Loss: 0.0435, Accuracy: 0.9576, F1 Micro: 0.9731, F1 Macro: 0.9707\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4618, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9262\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9133\n",
      "Epoch 3/10, Train Loss: 0.1527, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9108\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9049\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9164\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1082, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9379\n",
      "Epoch 10/10, Train Loss: 0.0448, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9164\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        81\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8766\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.92      0.49        12\n",
      "     neutral       0.94      0.86      0.90       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.84      0.73       216\n",
      "weighted avg       0.89      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.85      0.76        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.5036096572876 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.006155169010162353\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.2037103176116943 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4027, Accuracy: 0.9182, F1 Micro: 0.9503, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.243, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9704\n",
      "Epoch 4/10, Train Loss: 0.1623, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1176, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.0909, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.0728, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0422, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4533, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2063, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 4/10, Train Loss: 0.131, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9517\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.944\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.055, Accuracy: 0.962, F1 Micro: 0.962, F1 Macro: 0.956\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.938\n",
      "\n",
      "Sentiment analysis accuracy: 0.962, F1 Micro: 0.962, F1 Macro: 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        83\n",
      "    positive       0.97      0.97      0.97       180\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.96      0.96      0.96       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9034\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      1.00      0.71        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.89      0.81       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.66316866874695 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004561680555343628\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7649645805358887 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5334, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4083, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2499, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4903, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Epoch 3/10, Train Loss: 0.1831, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 4/10, Train Loss: 0.1167, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9355\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9285\n",
      "Epoch 8/10, Train Loss: 0.0663, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9306\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 151.79397344589233 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002878051996231079\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.214430809020996 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5275, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4102, Accuracy: 0.9308, F1 Micro: 0.9576, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2532, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1226, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0878, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0575, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4802, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2498, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1752, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9481\n",
      "Epoch 5/10, Train Loss: 0.1114, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9285\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9471\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9118\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9198\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9271\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        84\n",
      "    positive       0.96      0.97      0.97       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.95      0.94      0.95       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9035\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.87      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 155.4998860359192 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002327856421470642\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.557265043258667 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.409, Accuracy: 0.9204, F1 Micro: 0.9514, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2491, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1139, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4934, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2415, Accuracy: 0.962, F1 Micro: 0.962, F1 Macro: 0.9571\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9433\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9529\n",
      "Epoch 5/10, Train Loss: 0.1148, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9324\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9168\n",
      "\n",
      "Sentiment analysis accuracy: 0.962, F1 Micro: 0.962, F1 Macro: 0.9571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        85\n",
      "    positive       0.98      0.96      0.97       178\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.95      0.96      0.96       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9105\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 149.8576374053955 s\n",
      "Total runtime: 3282.4159939289093 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175447,
     "sourceId": 10843157,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6395.745812,
   "end_time": "2025-02-25T19:19:28.409120",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-25T17:32:52.663308",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01ab31a07ac94f7f81f644932fe4e682": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "105116520a864222bff13e8eebe222fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19221b975ac544f59bfb9c207b42bc81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1dffe42e4ee64621a0518c587f22c7e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2e6bfbc242cb489c8d5b6bbd825e8913": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2e826d114da6455198948e5986d53bb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ee5742fdce442dd92917f9fd02397b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e738d5c96f9e4e9fb80d3aacdcf5f916",
       "placeholder": "​",
       "style": "IPY_MODEL_01ab31a07ac94f7f81f644932fe4e682",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.0kB/s]"
      }
     },
     "3b684a7efbcc4e5baeae80273af126ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3befe4d680d44c388ba0bc7c7ea8a673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43539314157145958a68e9a8a618fea3",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a4c29508eca8413393d249a102478467",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "43227f5f75ff4c78ae14fdf29c5e1ed0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43539314157145958a68e9a8a618fea3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45cb0d391bd14f0dacee00a054f47bee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4aa859622c12440288fa100647ccb4f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a89a2d1039fe4e518109eef147f4da26",
       "placeholder": "​",
       "style": "IPY_MODEL_cbf5dc0f8ce9474d8832a8a6a0c01f7b",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "5b4ebb5cde9d4b55af8accbbdb9437f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_19221b975ac544f59bfb9c207b42bc81",
       "placeholder": "​",
       "style": "IPY_MODEL_5cd9144cc81545548213c52f9c0d11bd",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 164B/s]"
      }
     },
     "5b7526000f224937b62125b2e8fa8116": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cd9144cc81545548213c52f9c0d11bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5f7780f2d3c14da7a1789534f92f447d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "67bc4f50568b4de0aea2527afce957ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8465cf42decc430395f4d23211d862dc",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f6c9c78fb8ba491e878fe8b183254932",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "6fd44fe61f5840739158d473c3e67109": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73da50b041c54d00b243a54e98f03617": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7f219c26fce74ccd990bebec7863d30d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8465cf42decc430395f4d23211d862dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88193e5c3e294ff899ed2976b22a53ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6fd44fe61f5840739158d473c3e67109",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b66ac11f5e2444fb97c9e2e1e0cb87f4",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "8b31eca44a29447ebe5d79025db41d73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90d6a831316d41ea9fe0b0bff4265b50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a89dbc08b4fe4b1abf37b6e52c13ee9e",
        "IPY_MODEL_3befe4d680d44c388ba0bc7c7ea8a673",
        "IPY_MODEL_f53ad538783b49bf8c70827f6407eae8"
       ],
       "layout": "IPY_MODEL_d2143ae02de74da2a3c7eab5dc80ff16",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9c73a5537aea42729b6ea8a8972cf34b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e41f5429e6204b12a79aeee5001fdf7e",
       "placeholder": "​",
       "style": "IPY_MODEL_1dffe42e4ee64621a0518c587f22c7e3",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.45MB/s]"
      }
     },
     "9ca267d9025e4db785697c157597af8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4aa859622c12440288fa100647ccb4f9",
        "IPY_MODEL_88193e5c3e294ff899ed2976b22a53ef",
        "IPY_MODEL_5b4ebb5cde9d4b55af8accbbdb9437f8"
       ],
       "layout": "IPY_MODEL_badffb0a51544c688a83efd9cd11695b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a4c29508eca8413393d249a102478467": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a89a2d1039fe4e518109eef147f4da26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a89dbc08b4fe4b1abf37b6e52c13ee9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b31eca44a29447ebe5d79025db41d73",
       "placeholder": "​",
       "style": "IPY_MODEL_73da50b041c54d00b243a54e98f03617",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "b66ac11f5e2444fb97c9e2e1e0cb87f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ba84d812a6e349af91d3bb00469cd414": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2467accbc464385b621e6b419ccdbb7",
        "IPY_MODEL_d727fea52034476db23a6de459d791a3",
        "IPY_MODEL_9c73a5537aea42729b6ea8a8972cf34b"
       ],
       "layout": "IPY_MODEL_105116520a864222bff13e8eebe222fe",
       "tabbable": null,
       "tooltip": null
      }
     },
     "badffb0a51544c688a83efd9cd11695b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbf5dc0f8ce9474d8832a8a6a0c01f7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d2143ae02de74da2a3c7eab5dc80ff16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2467accbc464385b621e6b419ccdbb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3b684a7efbcc4e5baeae80273af126ff",
       "placeholder": "​",
       "style": "IPY_MODEL_2e6bfbc242cb489c8d5b6bbd825e8913",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "d727fea52034476db23a6de459d791a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45cb0d391bd14f0dacee00a054f47bee",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7f219c26fce74ccd990bebec7863d30d",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "dac294bd2a21485b916fbe7b19bf84e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_db85387ef05844f68a09688f6214eec3",
        "IPY_MODEL_67bc4f50568b4de0aea2527afce957ed",
        "IPY_MODEL_2ee5742fdce442dd92917f9fd02397b8"
       ],
       "layout": "IPY_MODEL_5b7526000f224937b62125b2e8fa8116",
       "tabbable": null,
       "tooltip": null
      }
     },
     "db85387ef05844f68a09688f6214eec3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e317e7ffbe914eed97818b067b3565b3",
       "placeholder": "​",
       "style": "IPY_MODEL_2e826d114da6455198948e5986d53bb5",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "e317e7ffbe914eed97818b067b3565b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e41f5429e6204b12a79aeee5001fdf7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e738d5c96f9e4e9fb80d3aacdcf5f916": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f53ad538783b49bf8c70827f6407eae8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43227f5f75ff4c78ae14fdf29c5e1ed0",
       "placeholder": "​",
       "style": "IPY_MODEL_5f7780f2d3c14da7a1789534f92f447d",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 147kB/s]"
      }
     },
     "f6c9c78fb8ba491e878fe8b183254932": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
