{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e7bcc5",
   "metadata": {
    "papermill": {
     "duration": 0.012164,
     "end_time": "2025-03-24T10:12:21.602902",
     "exception": false,
     "start_time": "2025-03-24T10:12:21.590738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a7af5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:21.626185Z",
     "iopub.status.busy": "2025-03-24T10:12:21.625949Z",
     "iopub.status.idle": "2025-03-24T10:12:44.466856Z",
     "shell.execute_reply": "2025-03-24T10:12:44.465947Z"
    },
    "papermill": {
     "duration": 22.854161,
     "end_time": "2025-03-24T10:12:44.468360",
     "exception": false,
     "start_time": "2025-03-24T10:12:21.614199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe64883",
   "metadata": {
    "papermill": {
     "duration": 0.01096,
     "end_time": "2025-03-24T10:12:44.490967",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.480007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff02ab37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.514420Z",
     "iopub.status.busy": "2025-03-24T10:12:44.513928Z",
     "iopub.status.idle": "2025-03-24T10:12:44.517413Z",
     "shell.execute_reply": "2025-03-24T10:12:44.516656Z"
    },
    "papermill": {
     "duration": 0.016457,
     "end_time": "2025-03-24T10:12:44.518637",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.502180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f427881a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.541619Z",
     "iopub.status.busy": "2025-03-24T10:12:44.541305Z",
     "iopub.status.idle": "2025-03-24T10:12:44.545130Z",
     "shell.execute_reply": "2025-03-24T10:12:44.544354Z"
    },
    "papermill": {
     "duration": 0.016455,
     "end_time": "2025-03-24T10:12:44.546271",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.529816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcca8cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.573380Z",
     "iopub.status.busy": "2025-03-24T10:12:44.573152Z",
     "iopub.status.idle": "2025-03-24T10:12:44.582279Z",
     "shell.execute_reply": "2025-03-24T10:12:44.581352Z"
    },
    "papermill": {
     "duration": 0.025225,
     "end_time": "2025-03-24T10:12:44.583502",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.558277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d0c9b",
   "metadata": {
    "papermill": {
     "duration": 0.010863,
     "end_time": "2025-03-24T10:12:44.605393",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.594530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c884198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.628177Z",
     "iopub.status.busy": "2025-03-24T10:12:44.627970Z",
     "iopub.status.idle": "2025-03-24T10:12:44.691112Z",
     "shell.execute_reply": "2025-03-24T10:12:44.689753Z"
    },
    "papermill": {
     "duration": 0.076402,
     "end_time": "2025-03-24T10:12:44.692733",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.616331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-lc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3147ee",
   "metadata": {
    "papermill": {
     "duration": 0.01198,
     "end_time": "2025-03-24T10:12:44.721156",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.709176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac157be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.754088Z",
     "iopub.status.busy": "2025-03-24T10:12:44.753757Z",
     "iopub.status.idle": "2025-03-24T10:12:44.845096Z",
     "shell.execute_reply": "2025-03-24T10:12:44.844256Z"
    },
    "papermill": {
     "duration": 0.107587,
     "end_time": "2025-03-24T10:12:44.846459",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.738872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216f72cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.870175Z",
     "iopub.status.busy": "2025-03-24T10:12:44.869959Z",
     "iopub.status.idle": "2025-03-24T10:12:44.879176Z",
     "shell.execute_reply": "2025-03-24T10:12:44.878525Z"
    },
    "papermill": {
     "duration": 0.022062,
     "end_time": "2025-03-24T10:12:44.880286",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.858224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5578c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.904380Z",
     "iopub.status.busy": "2025-03-24T10:12:44.904164Z",
     "iopub.status.idle": "2025-03-24T10:12:44.911258Z",
     "shell.execute_reply": "2025-03-24T10:12:44.910715Z"
    },
    "papermill": {
     "duration": 0.020716,
     "end_time": "2025-03-24T10:12:44.912517",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.891801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ffe8864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.936126Z",
     "iopub.status.busy": "2025-03-24T10:12:44.935920Z",
     "iopub.status.idle": "2025-03-24T10:12:44.946062Z",
     "shell.execute_reply": "2025-03-24T10:12:44.945326Z"
    },
    "papermill": {
     "duration": 0.023387,
     "end_time": "2025-03-24T10:12:44.947343",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.923956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9325234",
   "metadata": {
    "papermill": {
     "duration": 0.011407,
     "end_time": "2025-03-24T10:12:44.970897",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.959490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f619f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:44.994787Z",
     "iopub.status.busy": "2025-03-24T10:12:44.994522Z",
     "iopub.status.idle": "2025-03-24T10:12:45.000451Z",
     "shell.execute_reply": "2025-03-24T10:12:44.999868Z"
    },
    "papermill": {
     "duration": 0.019314,
     "end_time": "2025-03-24T10:12:45.001709",
     "exception": false,
     "start_time": "2025-03-24T10:12:44.982395",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "460a26f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:45.025957Z",
     "iopub.status.busy": "2025-03-24T10:12:45.025748Z",
     "iopub.status.idle": "2025-03-24T10:12:45.032933Z",
     "shell.execute_reply": "2025-03-24T10:12:45.032012Z"
    },
    "papermill": {
     "duration": 0.02052,
     "end_time": "2025-03-24T10:12:45.034244",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.013724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a82fd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:45.057931Z",
     "iopub.status.busy": "2025-03-24T10:12:45.057723Z",
     "iopub.status.idle": "2025-03-24T10:12:45.825401Z",
     "shell.execute_reply": "2025-03-24T10:12:45.824455Z"
    },
    "papermill": {
     "duration": 0.781139,
     "end_time": "2025-03-24T10:12:45.827090",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.045951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d773ad58bdb4daea9d2953c6e1e6c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393eed9ac0b84ca1839ba16fbc0c8d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db6a91d056b437d8e17442ebce5888c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea1692590cf46688caaacc191f8c9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13e0ebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:45.852637Z",
     "iopub.status.busy": "2025-03-24T10:12:45.852338Z",
     "iopub.status.idle": "2025-03-24T10:12:45.856804Z",
     "shell.execute_reply": "2025-03-24T10:12:45.855979Z"
    },
    "papermill": {
     "duration": 0.018388,
     "end_time": "2025-03-24T10:12:45.858029",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.839641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df163ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:45.883085Z",
     "iopub.status.busy": "2025-03-24T10:12:45.882847Z",
     "iopub.status.idle": "2025-03-24T10:12:45.892947Z",
     "shell.execute_reply": "2025-03-24T10:12:45.892141Z"
    },
    "papermill": {
     "duration": 0.02392,
     "end_time": "2025-03-24T10:12:45.894098",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.870178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05949c69",
   "metadata": {
    "papermill": {
     "duration": 0.011873,
     "end_time": "2025-03-24T10:12:45.918008",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.906135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d2276a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:45.942837Z",
     "iopub.status.busy": "2025-03-24T10:12:45.942550Z",
     "iopub.status.idle": "2025-03-24T10:12:45.946372Z",
     "shell.execute_reply": "2025-03-24T10:12:45.945508Z"
    },
    "papermill": {
     "duration": 0.017623,
     "end_time": "2025-03-24T10:12:45.947739",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.930116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c205480a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:45.973397Z",
     "iopub.status.busy": "2025-03-24T10:12:45.973161Z",
     "iopub.status.idle": "2025-03-24T10:12:45.978143Z",
     "shell.execute_reply": "2025-03-24T10:12:45.977272Z"
    },
    "papermill": {
     "duration": 0.019587,
     "end_time": "2025-03-24T10:12:45.979376",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.959789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2bcddcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.004612Z",
     "iopub.status.busy": "2025-03-24T10:12:46.004377Z",
     "iopub.status.idle": "2025-03-24T10:12:46.010417Z",
     "shell.execute_reply": "2025-03-24T10:12:46.009784Z"
    },
    "papermill": {
     "duration": 0.020106,
     "end_time": "2025-03-24T10:12:46.011571",
     "exception": false,
     "start_time": "2025-03-24T10:12:45.991465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc6800fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.036482Z",
     "iopub.status.busy": "2025-03-24T10:12:46.036262Z",
     "iopub.status.idle": "2025-03-24T10:12:46.062519Z",
     "shell.execute_reply": "2025-03-24T10:12:46.061653Z"
    },
    "papermill": {
     "duration": 0.040146,
     "end_time": "2025-03-24T10:12:46.063896",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.023750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ff1ff",
   "metadata": {
    "papermill": {
     "duration": 0.01166,
     "end_time": "2025-03-24T10:12:46.087512",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.075852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc92ec65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.112161Z",
     "iopub.status.busy": "2025-03-24T10:12:46.111944Z",
     "iopub.status.idle": "2025-03-24T10:12:46.117174Z",
     "shell.execute_reply": "2025-03-24T10:12:46.116556Z"
    },
    "papermill": {
     "duration": 0.019111,
     "end_time": "2025-03-24T10:12:46.118363",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.099252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c171d24",
   "metadata": {
    "papermill": {
     "duration": 0.011695,
     "end_time": "2025-03-24T10:12:46.142010",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.130315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfef6a6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.166188Z",
     "iopub.status.busy": "2025-03-24T10:12:46.165974Z",
     "iopub.status.idle": "2025-03-24T10:12:46.179940Z",
     "shell.execute_reply": "2025-03-24T10:12:46.179273Z"
    },
    "papermill": {
     "duration": 0.027454,
     "end_time": "2025-03-24T10:12:46.181146",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.153692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = np.max(preds[i].cpu().numpy())\n",
    "            \n",
    "            for j in range(len(preds[i])):\n",
    "                if int(preds[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "    \n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            ori_index = batch['ori_indices'][i].item()\n",
    "            if ori_index in sentiment_outputs.keys():\n",
    "                max_pred = np.max(preds[i].cpu().numpy())\n",
    "                sentiment_outputs[ori_index] = max_pred if max_pred > sentiment_outputs[ori_index] else sentiment_outputs[ori_index]\n",
    "            else:\n",
    "                sentiment_outputs[ori_index] = np.max(preds[i].cpu().numpy())\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        for key, val in sentiment_outputs.items():\n",
    "            aspect_outputs[key] = 1 - ((val + aspect_outputs[key]) / 2)\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25bc12",
   "metadata": {
    "papermill": {
     "duration": 0.011648,
     "end_time": "2025-03-24T10:12:46.204656",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.193008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c237052b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.229151Z",
     "iopub.status.busy": "2025-03-24T10:12:46.228933Z",
     "iopub.status.idle": "2025-03-24T10:12:46.237427Z",
     "shell.execute_reply": "2025-03-24T10:12:46.236852Z"
    },
    "papermill": {
     "duration": 0.022213,
     "end_time": "2025-03-24T10:12:46.238685",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.216472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54fba976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.262938Z",
     "iopub.status.busy": "2025-03-24T10:12:46.262704Z",
     "iopub.status.idle": "2025-03-24T10:12:46.265770Z",
     "shell.execute_reply": "2025-03-24T10:12:46.265087Z"
    },
    "papermill": {
     "duration": 0.016641,
     "end_time": "2025-03-24T10:12:46.267085",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.250444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e26c7",
   "metadata": {
    "papermill": {
     "duration": 0.011764,
     "end_time": "2025-03-24T10:12:46.290944",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.279180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2062e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 55.191133975982666 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.8998008251190186\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 3.8438658714294434 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6141, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5112, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8819\n",
      "Epoch 3/10, Train Loss: 0.4731, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.452, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4247, Accuracy: 0.7999, F1 Micro: 0.8873, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3861, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3652, Accuracy: 0.8378, F1 Micro: 0.9061, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3331, Accuracy: 0.8534, F1 Micro: 0.9147, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2809, Accuracy: 0.8795, F1 Micro: 0.9283, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2598, Accuracy: 0.8943, F1 Micro: 0.9361, F1 Macro: 0.9348\n",
      "\n",
      "Aspect detection accuracy: 0.8943, F1 Micro: 0.9361, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.89      1.00      0.94       187\n",
      "     machine       0.94      0.97      0.95       175\n",
      "      others       0.86      0.93      0.90       158\n",
      "        part       0.85      0.99      0.92       158\n",
      "       price       0.94      0.98      0.96       192\n",
      "     service       0.89      1.00      0.94       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.93      1061\n",
      "weighted avg       0.90      0.98      0.94      1061\n",
      " samples avg       0.90      0.98      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6486, Accuracy: 0.6954, F1 Micro: 0.6954, F1 Macro: 0.4102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6037, Accuracy: 0.6954, F1 Micro: 0.6954, F1 Macro: 0.4102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5149, Accuracy: 0.7529, F1 Micro: 0.7529, F1 Macro: 0.5833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4421, Accuracy: 0.7644, F1 Micro: 0.7644, F1 Macro: 0.6294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3884, Accuracy: 0.8161, F1 Micro: 0.8161, F1 Macro: 0.7602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2866, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2605, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1299, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1537, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8937\n",
      "Epoch 10/10, Train Loss: 0.1795, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.89      0.85        53\n",
      "    positive       0.95      0.92      0.93       121\n",
      "\n",
      "    accuracy                           0.91       174\n",
      "   macro avg       0.89      0.90      0.89       174\n",
      "weighted avg       0.91      0.91      0.91       174\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.704\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.36      0.50        11\n",
      "     neutral       0.89      1.00      0.94       181\n",
      "    positive       0.86      0.25      0.39        24\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.54      0.61       216\n",
      "weighted avg       0.88      0.88      0.86       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.97      0.95       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.81      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.75      0.75      0.74       216\n",
      "weighted avg       0.84      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.84      0.99      0.91       152\n",
      "    positive       0.91      0.51      0.66        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.87      0.68      0.74       216\n",
      "weighted avg       0.86      0.85      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.46      0.63        13\n",
      "     neutral       0.94      0.98      0.96       186\n",
      "    positive       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.68      0.74       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        14\n",
      "     neutral       0.89      1.00      0.94       185\n",
      "    positive       0.75      0.18      0.29        17\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.49      0.56       216\n",
      "weighted avg       0.89      0.89      0.86       216\n",
      "\n",
      "Total train time: 76.86386227607727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9461406111717224\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 4.937284469604492 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5963, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5157, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Epoch 3/10, Train Loss: 0.4929, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4647, Accuracy: 0.808, F1 Micro: 0.8913, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4149, Accuracy: 0.8333, F1 Micro: 0.9039, F1 Macro: 0.9033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3715, Accuracy: 0.8676, F1 Micro: 0.9223, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3137, Accuracy: 0.9129, F1 Micro: 0.9472, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2591, Accuracy: 0.9353, F1 Micro: 0.9602, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2191, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1794, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9646\n",
      "\n",
      "Aspect detection accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.86      0.97      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.97      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6643, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5287, Accuracy: 0.8044, F1 Micro: 0.8044, F1 Macro: 0.7841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3814, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.84\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2394, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2056, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8979\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8791\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8967\n",
      "Epoch 8/10, Train Loss: 0.1646, Accuracy: 0.8533, F1 Micro: 0.8533, F1 Macro: 0.8457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1493, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9094\n",
      "Epoch 10/10, Train Loss: 0.1201, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8823\n",
      "\n",
      "Sentiment analysis accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        72\n",
      "    positive       0.95      0.93      0.94       153\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.90      0.92      0.91       225\n",
      "weighted avg       0.92      0.92      0.92       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.929, F1 Micro: 0.929, F1 Macro: 0.8449\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.78      0.81       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.67      0.57        12\n",
      "     neutral       0.86      0.97      0.91       152\n",
      "    positive       0.87      0.50      0.63        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.71      0.71       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.62      0.73        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.81      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 81.2802402973175 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.21146264672279358\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.800411701202393 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5885, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.492, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4754, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4292, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3869, Accuracy: 0.8579, F1 Micro: 0.9167, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3358, Accuracy: 0.9115, F1 Micro: 0.9464, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2766, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2134, Accuracy: 0.9494, F1 Micro: 0.9688, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1742, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1443, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9687\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.89      0.94      0.92       158\n",
      "        part       0.94      0.99      0.96       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6837, Accuracy: 0.6749, F1 Micro: 0.6749, F1 Macro: 0.4148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5532, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3308, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "Epoch 4/10, Train Loss: 0.2304, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1934, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9303\n",
      "Epoch 6/10, Train Loss: 0.1048, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9198\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1044, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9323\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9272\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        80\n",
      "    positive       0.99      0.92      0.95       163\n",
      "\n",
      "    accuracy                           0.94       243\n",
      "   macro avg       0.92      0.95      0.93       243\n",
      "weighted avg       0.94      0.94      0.94       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8831\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.89      0.94      0.92       152\n",
      "    positive       0.80      0.63      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.78      0.76       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 87.02713704109192 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.07539478540420536\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.411576747894287 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5718, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4805, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4463, Accuracy: 0.811, F1 Micro: 0.8929, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3948, Accuracy: 0.8824, F1 Micro: 0.9304, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3121, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2439, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2012, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.148, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1249, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0957, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.67, Accuracy: 0.7976, F1 Micro: 0.7976, F1 Macro: 0.7835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5034, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2859, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1088, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9135\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88        83\n",
      "    positive       0.94      0.95      0.94       164\n",
      "\n",
      "    accuracy                           0.92       247\n",
      "   macro avg       0.91      0.91      0.91       247\n",
      "weighted avg       0.92      0.92      0.92       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8712\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.75      0.58        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.79      0.75       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 95.45962309837341 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.041591525077819824\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.1229588985443115 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.572, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4869, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4509, Accuracy: 0.8326, F1 Micro: 0.9035, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3502, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2743, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.207, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1502, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.131, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1014, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0877, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.8015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4541, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2557, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9231\n",
      "Epoch 5/10, Train Loss: 0.1615, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1414, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 7/10, Train Loss: 0.1279, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9067\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.1019, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0962, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       169\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.94      0.93       253\n",
      "weighted avg       0.94      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9051\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 98.7483446598053 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02973313331604004\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.620508432388306 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5737, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5017, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4211, Accuracy: 0.8891, F1 Micro: 0.9342, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.323, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2525, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1876, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 7/10, Train Loss: 0.1451, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.1128, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0955, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0778, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.621, Accuracy: 0.8157, F1 Micro: 0.8157, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3781, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2335, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.212, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1896, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Epoch 6/10, Train Loss: 0.1396, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Epoch 7/10, Train Loss: 0.1322, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 8/10, Train Loss: 0.1159, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9234\n",
      "Epoch 9/10, Train Loss: 0.1114, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9186\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8996\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.53544926643372 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.059939146041870096\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.30467963218689 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5621, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4792, Accuracy: 0.8095, F1 Micro: 0.8922, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3983, Accuracy: 0.9048, F1 Micro: 0.9428, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2951, Accuracy: 0.9449, F1 Micro: 0.966, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2195, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.1329, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6002, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.8444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4146, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3159, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9196\n",
      "Epoch 4/10, Train Loss: 0.2208, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1851, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9347\n",
      "Epoch 6/10, Train Loss: 0.1678, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 7/10, Train Loss: 0.1427, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9181\n",
      "Epoch 8/10, Train Loss: 0.1234, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9181\n",
      "Epoch 9/10, Train Loss: 0.0971, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1043, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "\n",
      "Sentiment analysis accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        85\n",
      "    positive       0.95      0.96      0.96       167\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.93      0.93      0.93       252\n",
      "weighted avg       0.94      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.96638631820679 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02167251706123352\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.033055305480957 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.472, Accuracy: 0.8118, F1 Micro: 0.8933, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3669, Accuracy: 0.9263, F1 Micro: 0.9551, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2603, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Epoch 5/10, Train Loss: 0.1896, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1369, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9707\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6103, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3482, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2445, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2468, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.202, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9203\n",
      "Epoch 7/10, Train Loss: 0.1237, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Epoch 9/10, Train Loss: 0.1098, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 10/10, Train Loss: 0.0906, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9229\n",
      "\n",
      "Sentiment analysis accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.93      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.906\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.73225831985474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.018940520286560063\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.784320116043091 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4728, Accuracy: 0.8177, F1 Micro: 0.8963, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3638, Accuracy: 0.9204, F1 Micro: 0.9517, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2758, Accuracy: 0.9464, F1 Micro: 0.967, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2017, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0934, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5567, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3783, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2001, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9213\n",
      "\n",
      "Sentiment analysis accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9008\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.81      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.21051573753357 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.019050681591033933\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.6311187744140625 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5472, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4756, Accuracy: 0.8192, F1 Micro: 0.8973, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3576, Accuracy: 0.9286, F1 Micro: 0.9564, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2625, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1397, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1111, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9712\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6028, Accuracy: 0.8852, F1 Micro: 0.8852, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3217, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2298, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9256\n",
      "Epoch 4/10, Train Loss: 0.195, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9222\n",
      "Epoch 5/10, Train Loss: 0.1829, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1737, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9243\n",
      "Epoch 8/10, Train Loss: 0.1355, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9452\n",
      "Epoch 10/10, Train Loss: 0.0774, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9154\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        83\n",
      "    positive       0.96      0.96      0.96       161\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.95      0.95      0.95       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8694\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.82      0.75       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.71      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.88       216\n",
      "weighted avg       0.95      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.19717979431152 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.022965669631958008\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.3036441802978516 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5487, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4502, Accuracy: 0.8452, F1 Micro: 0.9106, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3242, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2299, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.1232, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5575, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.28, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "Epoch 3/10, Train Loss: 0.2571, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1884, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 5/10, Train Loss: 0.1848, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8922\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Epoch 9/10, Train Loss: 0.0744, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9191\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        85\n",
      "    positive       0.98      0.93      0.96       178\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9015\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.77      0.82      0.79       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.99394202232361 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.03231930732727051\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.1528236865997314 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5416, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.437, Accuracy: 0.8757, F1 Micro: 0.9265, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3192, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2174, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9716\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3053, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Epoch 3/10, Train Loss: 0.2467, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2103, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2192, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1615, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 7/10, Train Loss: 0.1459, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 9/10, Train Loss: 0.0865, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9245\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        87\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9109\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.84      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.34374690055847 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.019313085079193115\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 2.9514293670654297 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5377, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4244, Accuracy: 0.904, F1 Micro: 0.9422, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3069, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2071, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5403, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9413\n",
      "Epoch 4/10, Train Loss: 0.2096, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8911\n",
      "Epoch 7/10, Train Loss: 0.1572, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9013\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8857\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.93      0.88      0.91       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.82      0.74       216\n",
      "weighted avg       0.87      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.86529016494751 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.018147766590118408\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8328933715820312 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5439, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4183, Accuracy: 0.9137, F1 Micro: 0.9475, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2869, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5031, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2831, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1923, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9046\n",
      "Epoch 10/10, Train Loss: 0.0955, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        85\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9024\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.43830585479736 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01845639944076538\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.721059799194336 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5378, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4388, Accuracy: 0.8966, F1 Micro: 0.9378, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2903, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1959, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1458, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5734, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2133, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.106, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "Epoch 6/10, Train Loss: 0.0776, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9437\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9099\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8806\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.83      0.50        12\n",
      "     neutral       0.94      0.86      0.90       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.69      0.81      0.72       216\n",
      "weighted avg       0.87      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 127.69747591018677 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.02011394500732422\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4317567348480225 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5389, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4168, Accuracy: 0.9241, F1 Micro: 0.9539, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2776, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1822, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0834, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5346, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9028\n",
      "Epoch 2/10, Train Loss: 0.2475, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9081\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0708, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       177\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.95      0.94       261\n",
      "weighted avg       0.95      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9079\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.84      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      1.00      0.93        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.25245594978333 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.012233495712280273\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3523991107940674 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4195, Accuracy: 0.9196, F1 Micro: 0.9508, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.272, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1308, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5587, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2656, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9339\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9255\n",
      "Epoch 4/10, Train Loss: 0.1367, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9277\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9251\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0894, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9336\n",
      "Epoch 8/10, Train Loss: 0.0669, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0871, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       166\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.93      0.94      0.94       249\n",
      "weighted avg       0.94      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8862\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.83      0.50        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.81      0.73       216\n",
      "weighted avg       0.89      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.03391623497009 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.018509119749069214\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.1791329383850098 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5389, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4149, Accuracy: 0.9122, F1 Micro: 0.9469, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.264, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.0992, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5189, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2786, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9366\n",
      "Epoch 3/10, Train Loss: 0.2019, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 5/10, Train Loss: 0.1551, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9125\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "    positive       0.95      0.97      0.96       175\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9067\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.69330382347107 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010201752185821533\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.083899736404419 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5374, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4156, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2568, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.18, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0967, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9801\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.98      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.1521, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9228\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9228\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9169\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9016\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8812\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.75      0.50        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.81      0.75       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.88678312301636 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.025575315952301024\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.125809669494629 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5262, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3917, Accuracy: 0.9315, F1 Micro: 0.9579, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1235, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9778\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.061, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4528, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2439, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9379\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9151\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1232, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9372\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9121\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.92\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9257\n",
      "Epoch 10/10, Train Loss: 0.0706, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9182\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       269\n",
      "   macro avg       0.93      0.94      0.94       269\n",
      "weighted avg       0.95      0.94      0.94       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9095\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.91      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.29101514816284 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.011265236139297486\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6388545036315918 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5331, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4048, Accuracy: 0.9129, F1 Micro: 0.9473, F1 Macro: 0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2534, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.484, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9167\n",
      "Epoch 2/10, Train Loss: 0.2543, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.925\n",
      "Epoch 4/10, Train Loss: 0.1395, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9481, F1 Micro: 0.9481, F1 Macro: 0.9413\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9219\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9098\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.085, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       184\n",
      "\n",
      "    accuracy                           0.95       270\n",
      "   macro avg       0.94      0.95      0.95       270\n",
      "weighted avg       0.95      0.95      0.95       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9286\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.2824637889862 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007991218566894531\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.542330265045166 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5228, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3877, Accuracy: 0.9286, F1 Micro: 0.9557, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2398, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.121, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       1.00      0.99      1.00       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4835, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2544, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9322\n",
      "Epoch 4/10, Train Loss: 0.128, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1196, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9264\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       181\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8986\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       1.00      0.99      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.98      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.82      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.48487043380737 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007982844114303589\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.2701761722564697 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5175, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3823, Accuracy: 0.9219, F1 Micro: 0.9516, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2489, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2165, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 3/10, Train Loss: 0.1544, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.91\n",
      "Epoch 4/10, Train Loss: 0.1198, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9233\n",
      "Epoch 5/10, Train Loss: 0.1005, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0882, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 7/10, Train Loss: 0.0764, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0591, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0353, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.91\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.86      0.82       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.2714660167694 s\n",
      "Total runtime: 2965.807635307312 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad7dea",
   "metadata": {
    "papermill": {
     "duration": 0.011515,
     "end_time": "2025-03-24T10:12:46.342949",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.331434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afeb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 57.05474901199341 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9374258995056153\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 3.969771385192871 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.603, Accuracy: 0.7403, F1 Micro: 0.8433, F1 Macro: 0.8018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4979, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4668, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4383, Accuracy: 0.8006, F1 Micro: 0.8876, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3929, Accuracy: 0.8051, F1 Micro: 0.8892, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3576, Accuracy: 0.8281, F1 Micro: 0.9007, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3356, Accuracy: 0.869, F1 Micro: 0.9222, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2741, Accuracy: 0.8869, F1 Micro: 0.9312, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2465, Accuracy: 0.8966, F1 Micro: 0.9365, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2031, Accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9392\n",
      "\n",
      "Aspect detection accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.87      0.88       158\n",
      "        part       0.89      0.97      0.93       158\n",
      "       price       0.95      0.97      0.96       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.91      0.97      0.94      1061\n",
      "   macro avg       0.91      0.97      0.94      1061\n",
      "weighted avg       0.91      0.97      0.94      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5659, Accuracy: 0.715, F1 Micro: 0.715, F1 Macro: 0.4328\n",
      "Epoch 2/10, Train Loss: 0.5337, Accuracy: 0.7101, F1 Micro: 0.7101, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.468, Accuracy: 0.744, F1 Micro: 0.744, F1 Macro: 0.6432\n",
      "Epoch 4/10, Train Loss: 0.3475, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.235, Accuracy: 0.7681, F1 Micro: 0.7681, F1 Macro: 0.7476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1642, Accuracy: 0.8213, F1 Micro: 0.8213, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1433, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.8014\n",
      "Epoch 8/10, Train Loss: 0.1269, Accuracy: 0.8019, F1 Micro: 0.8019, F1 Macro: 0.7824\n",
      "Epoch 9/10, Train Loss: 0.1273, Accuracy: 0.8213, F1 Micro: 0.8213, F1 Macro: 0.7934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0852, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.7821\n",
      "\n",
      "Sentiment analysis accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.7821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.65      0.68        60\n",
      "    positive       0.86      0.90      0.88       147\n",
      "\n",
      "    accuracy                           0.83       207\n",
      "   macro avg       0.79      0.77      0.78       207\n",
      "weighted avg       0.82      0.83      0.82       207\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.6692\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.64      0.74        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       0.88      0.58      0.70        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.74      0.80       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.81      0.67      0.73        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.76      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.42      0.37        12\n",
      "     neutral       0.90      0.88      0.89       152\n",
      "    positive       0.64      0.65      0.65        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.62      0.65      0.63       216\n",
      "weighted avg       0.81      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.80      0.68      0.74        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.85      0.73      0.77       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.96      0.97      0.97       186\n",
      "    positive       0.50      0.65      0.56        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.82      0.67      0.69       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 72.9481885433197 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9436831831932068\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 5.736773252487183 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5904, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4903, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4862, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4577, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4023, Accuracy: 0.8326, F1 Micro: 0.9038, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3388, Accuracy: 0.8891, F1 Micro: 0.9332, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2835, Accuracy: 0.9182, F1 Micro: 0.9497, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2241, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2027, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1669, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9603\n",
      "\n",
      "Aspect detection accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.88      0.92      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6228, Accuracy: 0.671, F1 Micro: 0.671, F1 Macro: 0.4139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5747, Accuracy: 0.7186, F1 Micro: 0.7186, F1 Macro: 0.5693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4497, Accuracy: 0.8485, F1 Micro: 0.8485, F1 Macro: 0.8312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2688, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8846\n",
      "Epoch 5/10, Train Loss: 0.1804, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1473, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8999\n",
      "Epoch 8/10, Train Loss: 0.0767, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8927\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.896\n",
      "Epoch 10/10, Train Loss: 0.0965, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8869\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        77\n",
      "    positive       0.95      0.91      0.93       154\n",
      "\n",
      "    accuracy                           0.91       231\n",
      "   macro avg       0.89      0.91      0.90       231\n",
      "weighted avg       0.91      0.91      0.91       231\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.8379\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.93      0.98      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.89      0.92      0.90       152\n",
      "    positive       0.76      0.65      0.70        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.78      0.77      0.77       216\n",
      "weighted avg       0.84      0.85      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.73      0.79       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 77.58998584747314 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.16653379797935486\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.701840162277222 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5698, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5056, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4603, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4356, Accuracy: 0.8304, F1 Micro: 0.9026, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3507, Accuracy: 0.9115, F1 Micro: 0.9458, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2871, Accuracy: 0.9204, F1 Micro: 0.9505, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2449, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1823, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1484, Accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "Epoch 10/10, Train Loss: 0.1229, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      0.99      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6009, Accuracy: 0.6733, F1 Micro: 0.6733, F1 Macro: 0.4024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4601, Accuracy: 0.8406, F1 Micro: 0.8406, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3081, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1162, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8926\n",
      "Epoch 6/10, Train Loss: 0.0741, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1533, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9079\n",
      "Epoch 9/10, Train Loss: 0.0381, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8997\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9052\n",
      "\n",
      "Sentiment analysis accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.94      0.88        82\n",
      "    positive       0.97      0.91      0.94       169\n",
      "\n",
      "    accuracy                           0.92       251\n",
      "   macro avg       0.90      0.92      0.91       251\n",
      "weighted avg       0.92      0.92      0.92       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8744\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.75      0.55        12\n",
      "     neutral       0.91      0.90      0.90       152\n",
      "    positive       0.80      0.67      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.77      0.73       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       1.00      0.68      0.81        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.89      0.88       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.98      0.99      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 84.98289203643799 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.09580594301223755\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.514836549758911 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4763, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4467, Accuracy: 0.811, F1 Micro: 0.893, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3654, Accuracy: 0.9092, F1 Micro: 0.9445, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3003, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2234, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9637\n",
      "Epoch 7/10, Train Loss: 0.1814, Accuracy: 0.9412, F1 Micro: 0.963, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1431, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1117, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.098, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6131, Accuracy: 0.7052, F1 Micro: 0.7052, F1 Macro: 0.5448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4505, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3009, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9237\n",
      "Epoch 5/10, Train Loss: 0.137, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.1179, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1002, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9269\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0828, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "    positive       0.93      0.97      0.95       165\n",
      "\n",
      "    accuracy                           0.93       251\n",
      "   macro avg       0.93      0.92      0.92       251\n",
      "weighted avg       0.93      0.93      0.93       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8776\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.78      0.79       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 90.69899702072144 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.06994962692260742\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.05504035949707 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5488, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4817, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4074, Accuracy: 0.8906, F1 Micro: 0.9345, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3113, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2411, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9654\n",
      "Epoch 6/10, Train Loss: 0.1836, Accuracy: 0.9449, F1 Micro: 0.9653, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1432, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1193, Accuracy: 0.9516, F1 Micro: 0.9694, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0975, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "Epoch 10/10, Train Loss: 0.0808, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6172, Accuracy: 0.7917, F1 Micro: 0.7917, F1 Macro: 0.7607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4709, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2571, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2277, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1973, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9139\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9178\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8932\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.88      0.91       152\n",
      "    positive       0.69      0.77      0.73        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 95.79589796066284 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.04017419815063477\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.778056621551514 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4773, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4015, Accuracy: 0.8943, F1 Micro: 0.9361, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3095, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2346, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1799, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.1399, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Epoch 8/10, Train Loss: 0.1139, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9676\n",
      "Epoch 10/10, Train Loss: 0.08, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6573, Accuracy: 0.7805, F1 Micro: 0.7805, F1 Macro: 0.7745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4707, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2879, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.254, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9512\n",
      "Epoch 5/10, Train Loss: 0.1947, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9466\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9341\n",
      "Epoch 7/10, Train Loss: 0.1167, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9364\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9469\n",
      "Epoch 9/10, Train Loss: 0.0853, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9341\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9424\n",
      "\n",
      "Sentiment analysis accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        84\n",
      "    positive       0.99      0.94      0.97       162\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.94      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8926\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.92      0.61        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.85      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.90      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 91.47688126564026 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0654220700263977\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.383734464645386 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4565, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.385, Accuracy: 0.9048, F1 Micro: 0.942, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2813, Accuracy: 0.9382, F1 Micro: 0.962, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2031, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1748, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1277, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0996, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9702\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6537, Accuracy: 0.7952, F1 Micro: 0.7952, F1 Macro: 0.7834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4146, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2276, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.943\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9251\n",
      "Epoch 5/10, Train Loss: 0.1584, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9458\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9134\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9221\n",
      "Epoch 9/10, Train Loss: 0.0899, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9217\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "\n",
      "Sentiment analysis accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        85\n",
      "    positive       0.95      0.98      0.96       164\n",
      "\n",
      "    accuracy                           0.95       249\n",
      "   macro avg       0.95      0.94      0.95       249\n",
      "weighted avg       0.95      0.95      0.95       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8869\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.81      0.80       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 97.95015621185303 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03274598717689514\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 3.947877883911133 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.534, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4652, Accuracy: 0.8185, F1 Micro: 0.8968, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3484, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2484, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1484, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.88      0.99      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6274, Accuracy: 0.8156, F1 Micro: 0.8156, F1 Macro: 0.8071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3745, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2423, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9455\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9381\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9421\n",
      "Epoch 9/10, Train Loss: 0.0987, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.94      0.97       161\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.96      0.95       244\n",
      "weighted avg       0.96      0.95      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8856\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.92      0.91      0.91       152\n",
      "    positive       0.94      0.65      0.77        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.73      0.80      0.72       216\n",
      "weighted avg       0.89      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 100.62988924980164 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0305534839630127\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.7483441829681396 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4484, Accuracy: 0.849, F1 Micro: 0.9122, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3363, Accuracy: 0.9241, F1 Micro: 0.9533, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.245, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.1138, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6496, Accuracy: 0.7248, F1 Micro: 0.7248, F1 Macro: 0.6252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4094, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2219, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2157, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9483\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8961\n",
      "Epoch 6/10, Train Loss: 0.1529, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8982\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9351\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9069\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.56612539291382 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.016970676183700562\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.628967523574829 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5483, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4522, Accuracy: 0.8467, F1 Micro: 0.9114, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3282, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2278, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1736, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.91      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6043, Accuracy: 0.7744, F1 Micro: 0.7744, F1 Macro: 0.7702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.357, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9151\n",
      "Epoch 3/10, Train Loss: 0.2236, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Epoch 5/10, Train Loss: 0.1889, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8798\n",
      "Epoch 6/10, Train Loss: 0.1672, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9354\n",
      "Epoch 10/10, Train Loss: 0.0638, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9236\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "    positive       0.96      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.94      0.93      0.94       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9035\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.91      0.91       152\n",
      "    positive       0.73      0.77      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.82      0.81      0.81       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.99681091308594 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015492081642150879\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.442115068435669 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4452, Accuracy: 0.8683, F1 Micro: 0.9227, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.311, Accuracy: 0.9338, F1 Micro: 0.9587, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2193, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Epoch 5/10, Train Loss: 0.1562, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0977, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5989, Accuracy: 0.8662, F1 Micro: 0.8662, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.336, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9091\n",
      "Epoch 3/10, Train Loss: 0.2478, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9296\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.094, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9453\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 10/10, Train Loss: 0.0716, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9288\n",
      "\n",
      "Sentiment analysis accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.94      0.96      0.95       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9078\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.82      0.79      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.8275363445282 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.014702200889587402\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.1687777042388916 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5423, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4289, Accuracy: 0.8914, F1 Micro: 0.9351, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3148, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2162, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.57, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9047\n",
      "\n",
      "Sentiment analysis accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        86\n",
      "    positive       0.96      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.94       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8782\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.75      0.73      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.82      0.78      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.85      0.83      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.05705118179321 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0196561336517334\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 2.9483442306518555 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.413, Accuracy: 0.904, F1 Micro: 0.9417, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2851, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2004, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1451, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.872, F1 Micro: 0.872, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2769, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1224, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9462\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9302\n",
      "Epoch 6/10, Train Loss: 0.0866, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9474\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9302\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       166\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.96      0.95       250\n",
      "weighted avg       0.96      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8866\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.83      0.77       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.6502935886383 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01993626356124878\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.860546112060547 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.401, Accuracy: 0.9144, F1 Micro: 0.9478, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.271, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1919, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9759\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2998, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 3/10, Train Loss: 0.2208, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "Epoch 6/10, Train Loss: 0.139, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.0751, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9268\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9148\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.79      0.82       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.58402276039124 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01566159725189209\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.6649863719940186 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4087, Accuracy: 0.8973, F1 Micro: 0.936, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.268, Accuracy: 0.9472, F1 Micro: 0.9674, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "Epoch 6/10, Train Loss: 0.1013, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0877, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5704, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3063, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 3/10, Train Loss: 0.201, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8929\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.151, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9024\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.85      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.99613189697266 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.011480391025543213\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4739017486572266 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5211, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3891, Accuracy: 0.9129, F1 Micro: 0.9463, F1 Macro: 0.9438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2672, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1805, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1063, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9802\n",
      "Epoch 8/10, Train Loss: 0.0647, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.99      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5519, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2586, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9426\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.938\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9219\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9426\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "Epoch 8/10, Train Loss: 0.0711, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9174\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9423\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       163\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.94      0.95      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8972\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.95      0.71      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.82      0.76       216\n",
      "weighted avg       0.91      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.87746095657349 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.017687857151031494\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.5601119995117188 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5246, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3824, Accuracy: 0.9249, F1 Micro: 0.9533, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2594, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1044, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9782\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5178, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8976\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9214\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1305, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0748, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.90        87\n",
      "    positive       0.98      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.94      0.93       267\n",
      "weighted avg       0.94      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.97754287719727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00911027193069458\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.333732843399048 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5236, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3885, Accuracy: 0.9219, F1 Micro: 0.9514, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2456, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0638, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2353, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9256\n",
      "Epoch 6/10, Train Loss: 0.1217, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9107\n",
      "Epoch 7/10, Train Loss: 0.0978, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        87\n",
      "    positive       0.96      0.97      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.94      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9002\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.84      0.81       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.02443385124207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.018247365951538086\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1926915645599365 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3839, Accuracy: 0.9085, F1 Micro: 0.9423, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.247, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5156, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2796, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9295\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 8/10, Train Loss: 0.0963, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.911\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.06780409812927 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010328638553619384\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9592077732086182 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5156, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3729, Accuracy: 0.9278, F1 Micro: 0.9551, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9813\n",
      "Epoch 10/10, Train Loss: 0.0416, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.886, F1 Micro: 0.886, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9226\n",
      "Epoch 3/10, Train Loss: 0.1515, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9222\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9348\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.9039\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.85      0.91        88\n",
      "    positive       0.93      0.99      0.96       184\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.95      0.92      0.93       272\n",
      "weighted avg       0.95      0.94      0.94       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9069\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.96      0.89      0.93       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.88      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 150.40133213996887 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.009494292736053466\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8826684951782227 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3671, Accuracy: 0.9293, F1 Micro: 0.9562, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2311, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1601, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0773, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4876, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2018, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9437\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        85\n",
      "    positive       0.99      0.95      0.97       167\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9003\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.85      0.77       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 148.69303107261658 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.013039946556091309\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6050803661346436 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3603, Accuracy: 0.9263, F1 Micro: 0.9538, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2333, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0909, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0653, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0532, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.974, F1 Micro: 0.9836, F1 Macro: 0.9826\n",
      "\n",
      "Aspect detection accuracy: 0.974, F1 Micro: 0.9836, F1 Macro: 0.9826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4818, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9065\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9446\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 10/10, Train Loss: 0.0725, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9368\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9273\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 151.76309633255005 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.006323903799057007\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3507733345031738 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3625, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2296, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9771\n",
      "Epoch 5/10, Train Loss: 0.1212, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0592, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0464, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2283, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1465, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1204, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9251\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9133\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9162\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9311\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9045\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 149.97421288490295 s\n",
      "Total runtime: 2968.4016976356506 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8fc52",
   "metadata": {
    "papermill": {
     "duration": 0.049299,
     "end_time": "2025-03-24T10:12:46.432423",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.383124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df4eaa96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T10:12:46.457496Z",
     "iopub.status.busy": "2025-03-24T10:12:46.457207Z",
     "iopub.status.idle": "2025-03-24T11:01:25.478131Z",
     "shell.execute_reply": "2025-03-24T11:01:25.477140Z"
    },
    "papermill": {
     "duration": 2919.035239,
     "end_time": "2025-03-24T11:01:25.479749",
     "exception": false,
     "start_time": "2025-03-24T10:12:46.444510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 63.860013246536255 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9325591504573822\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 3.531332492828369 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6192, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4908, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4285, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4123, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3981, Accuracy: 0.8244, F1 Micro: 0.8991, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.341, Accuracy: 0.8281, F1 Micro: 0.9006, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.294, Accuracy: 0.8579, F1 Micro: 0.9159, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.265, Accuracy: 0.8728, F1 Micro: 0.9239, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2299, Accuracy: 0.8951, F1 Micro: 0.9368, F1 Macro: 0.936\n",
      "\n",
      "Aspect detection accuracy: 0.8951, F1 Micro: 0.9368, F1 Macro: 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.93      0.99      0.96       187\n",
      "     machine       0.91      0.98      0.95       175\n",
      "      others       0.83      0.95      0.88       158\n",
      "        part       0.91      0.97      0.94       158\n",
      "       price       0.86      1.00      0.93       192\n",
      "     service       0.91      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.89      0.98      0.94      1061\n",
      "   macro avg       0.89      0.98      0.94      1061\n",
      "weighted avg       0.89      0.98      0.94      1061\n",
      " samples avg       0.90      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7227, Accuracy: 0.6845, F1 Micro: 0.6845, F1 Macro: 0.4064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6022, Accuracy: 0.6845, F1 Micro: 0.6845, F1 Macro: 0.4064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5799, Accuracy: 0.6964, F1 Micro: 0.6964, F1 Macro: 0.4456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4987, Accuracy: 0.7321, F1 Micro: 0.7321, F1 Macro: 0.5805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3989, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.7968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3188, Accuracy: 0.9226, F1 Micro: 0.9226, F1 Macro: 0.908\n",
      "Epoch 7/10, Train Loss: 0.1785, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1737, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.923\n",
      "Epoch 9/10, Train Loss: 0.1395, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8688\n",
      "Epoch 10/10, Train Loss: 0.1195, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8926\n",
      "\n",
      "Sentiment analysis accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89        53\n",
      "    positive       0.94      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.93       168\n",
      "   macro avg       0.93      0.92      0.92       168\n",
      "weighted avg       0.93      0.93      0.93       168\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8866, F1 Micro: 0.8866, F1 Macro: 0.6853\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.94      0.99      0.97       181\n",
      "    positive       0.76      0.54      0.63        24\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.72      0.79       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.44      0.61        16\n",
      "     neutral       0.91      0.98      0.95       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.72      0.78       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.83      0.95      0.89       152\n",
      "    positive       0.86      0.48      0.62        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.80      0.73      0.74       216\n",
      "weighted avg       0.83      0.83      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.65      0.79        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.79      0.73      0.76        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.90      0.79      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.87      1.00      0.93       186\n",
      "    positive       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.62      0.35      0.35       216\n",
      "weighted avg       0.82      0.87      0.81       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        14\n",
      "     neutral       0.91      1.00      0.95       185\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.55      0.63       216\n",
      "weighted avg       0.90      0.90      0.88       216\n",
      "\n",
      "Total train time: 74.14335203170776 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9526485204696655\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 4.985275030136108 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5877, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.501, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4877, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4527, Accuracy: 0.7984, F1 Micro: 0.8863, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4162, Accuracy: 0.8192, F1 Micro: 0.8959, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3563, Accuracy: 0.8512, F1 Micro: 0.912, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3112, Accuracy: 0.8862, F1 Micro: 0.9309, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2548, Accuracy: 0.9167, F1 Micro: 0.9493, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2272, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1759, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9592\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.86      0.94      0.90       158\n",
      "        part       0.93      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6131, Accuracy: 0.6652, F1 Micro: 0.6652, F1 Macro: 0.3995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4915, Accuracy: 0.7376, F1 Micro: 0.7376, F1 Macro: 0.6252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.299, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8836\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1754, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9108\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8651\n",
      "Epoch 7/10, Train Loss: 0.1317, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8997\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8944\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.0994, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8717\n",
      "\n",
      "Sentiment analysis accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.93      0.88        74\n",
      "    positive       0.96      0.91      0.94       147\n",
      "\n",
      "    accuracy                           0.92       221\n",
      "   macro avg       0.90      0.92      0.91       221\n",
      "weighted avg       0.92      0.92      0.92       221\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8218\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.84      0.64      0.72        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.73      0.78       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.86      0.94      0.90       152\n",
      "    positive       0.86      0.58      0.69        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.76      0.75       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.86      0.76      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.83      0.85       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.57      0.70        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.72      0.79       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 78.06629514694214 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9533956944942474\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.557117223739624 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5722, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.499, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4657, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.44, Accuracy: 0.8118, F1 Micro: 0.8922, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3755, Accuracy: 0.8504, F1 Micro: 0.9109, F1 Macro: 0.9087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3332, Accuracy: 0.9025, F1 Micro: 0.9406, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2709, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2162, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1711, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9674\n",
      "Epoch 10/10, Train Loss: 0.1413, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9655\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.96      0.92       158\n",
      "        part       0.93      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6753, Accuracy: 0.6567, F1 Micro: 0.6567, F1 Macro: 0.3964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4893, Accuracy: 0.7725, F1 Micro: 0.7725, F1 Macro: 0.7073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3324, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2174, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1376, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1419, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "Epoch 10/10, Train Loss: 0.0693, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9082\n",
      "\n",
      "Sentiment analysis accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        79\n",
      "    positive       0.95      0.94      0.95       154\n",
      "\n",
      "    accuracy                           0.93       233\n",
      "   macro avg       0.92      0.93      0.92       233\n",
      "weighted avg       0.93      0.93      0.93       233\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8508\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.93      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.79      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.75      0.51        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.78      0.73       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.78      0.77        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.86      0.76      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 92.0604977607727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.10158747434616096\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.267376184463501 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5685, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4831, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.466, Accuracy: 0.8006, F1 Micro: 0.8875, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3988, Accuracy: 0.8423, F1 Micro: 0.9078, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3346, Accuracy: 0.9025, F1 Micro: 0.9404, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2713, Accuracy: 0.9345, F1 Micro: 0.9593, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2275, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1691, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1389, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "Epoch 10/10, Train Loss: 0.1216, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.967\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.94      0.97      0.96       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6339, Accuracy: 0.7231, F1 Micro: 0.7231, F1 Macro: 0.5746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4926, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3119, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9175\n",
      "Epoch 4/10, Train Loss: 0.2609, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9092\n",
      "Epoch 5/10, Train Loss: 0.2169, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9048\n",
      "Epoch 6/10, Train Loss: 0.1385, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.915\n",
      "Epoch 7/10, Train Loss: 0.1468, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1202, Accuracy: 0.9298, F1 Micro: 0.9298, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1532, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9362\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        80\n",
      "    positive       0.98      0.93      0.96       162\n",
      "\n",
      "    accuracy                           0.94       242\n",
      "   macro avg       0.93      0.95      0.94       242\n",
      "weighted avg       0.95      0.94      0.94       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8734\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.75      0.69        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.81      0.81      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.81      0.76       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.8483054637909 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0700751543045044\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 4.988062381744385 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4732, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4404, Accuracy: 0.8237, F1 Micro: 0.8994, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3632, Accuracy: 0.9018, F1 Micro: 0.9398, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2699, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.215, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1643, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1231, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1079, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6302, Accuracy: 0.8182, F1 Micro: 0.8182, F1 Macro: 0.7963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4889, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3057, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2385, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9514\n",
      "Epoch 5/10, Train Loss: 0.2234, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9474\n",
      "Epoch 6/10, Train Loss: 0.1835, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.1633, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1361, Accuracy: 0.9605, F1 Micro: 0.9605, F1 Macro: 0.9554\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9605, F1 Micro: 0.9605, F1 Macro: 0.9557\n",
      "\n",
      "Sentiment analysis accuracy: 0.9605, F1 Micro: 0.9605, F1 Macro: 0.9557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        83\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.95      0.96      0.96       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9179\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.84      0.71      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 98.75497531890869 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03343925476074221\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.783622980117798 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5528, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.7984, F1 Micro: 0.8866, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4177, Accuracy: 0.8504, F1 Micro: 0.9113, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3359, Accuracy: 0.9115, F1 Micro: 0.9454, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2467, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1929, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.1536, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9717\n",
      "Epoch 8/10, Train Loss: 0.1221, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Epoch 9/10, Train Loss: 0.1036, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6389, Accuracy: 0.7765, F1 Micro: 0.7765, F1 Macro: 0.7129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4012, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3121, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9564\n",
      "Epoch 5/10, Train Loss: 0.1793, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Epoch 7/10, Train Loss: 0.1398, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0934, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.095, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "Epoch 10/10, Train Loss: 0.108, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9467\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        84\n",
      "    positive       0.99      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.84      0.85       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 96.27419304847717 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.04879755973815918\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.301027297973633 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5541, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4802, Accuracy: 0.8021, F1 Micro: 0.8883, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4027, Accuracy: 0.8661, F1 Micro: 0.9201, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3088, Accuracy: 0.9338, F1 Micro: 0.959, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2276, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1679, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.136, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1053, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0871, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6421, Accuracy: 0.8088, F1 Micro: 0.8088, F1 Macro: 0.77\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4162, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2837, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2012, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9558\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0958, Accuracy: 0.9641, F1 Micro: 0.9641, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0885, Accuracy: 0.9641, F1 Micro: 0.9641, F1 Macro: 0.9603\n",
      "\n",
      "Sentiment analysis accuracy: 0.9641, F1 Micro: 0.9641, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        85\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.96      0.96      0.96       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.91      0.94      0.93       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.13633489608765 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.022867143154144287\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.114540100097656 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5431, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4754, Accuracy: 0.808, F1 Micro: 0.8909, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3824, Accuracy: 0.9129, F1 Micro: 0.9473, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2723, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1955, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Epoch 7/10, Train Loss: 0.1109, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5884, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3449, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3046, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9426\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9221\n",
      "Epoch 5/10, Train Loss: 0.2218, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.166, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9562\n",
      "Epoch 7/10, Train Loss: 0.1332, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9351\n",
      "Epoch 8/10, Train Loss: 0.1149, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9474\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "Epoch 10/10, Train Loss: 0.1095, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        85\n",
      "    positive       0.99      0.95      0.97       165\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8912\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.80      0.79       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.87762498855591 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.025971746444702157\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.7693378925323486 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5558, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4607, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3714, Accuracy: 0.9077, F1 Micro: 0.944, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2726, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1977, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.15, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1116, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0951, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6104, Accuracy: 0.852, F1 Micro: 0.852, F1 Macro: 0.8282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.347, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2721, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "Epoch 4/10, Train Loss: 0.2009, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.938\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9215\n",
      "Epoch 6/10, Train Loss: 0.1558, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9302\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9207\n",
      "Epoch 9/10, Train Loss: 0.0885, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9257\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        85\n",
      "    positive       0.97      0.96      0.96       165\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9042\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.80      0.69      0.74        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.80      0.81       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 107.37859010696411 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.03917145133018494\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.523441791534424 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4663, Accuracy: 0.8058, F1 Micro: 0.8893, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3714, Accuracy: 0.9092, F1 Micro: 0.945, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.26, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1417, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6002, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3022, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2608, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.952\n",
      "Epoch 4/10, Train Loss: 0.2044, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.1617, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9438\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.092, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9525\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9468\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9376\n",
      "\n",
      "Sentiment analysis accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94        85\n",
      "    positive       0.99      0.94      0.97       168\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.94      0.96      0.95       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8956\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.81      0.79       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.94367361068726 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.020868301391601562\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.3815219402313232 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5419, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4602, Accuracy: 0.8348, F1 Micro: 0.9044, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3431, Accuracy: 0.9323, F1 Micro: 0.9586, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9759\n",
      "Epoch 5/10, Train Loss: 0.1772, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5455, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2852, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9466\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9255\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.1179, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.937\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9251\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        82\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8924\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.81      0.77       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.61581945419312 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.027663826942443848\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.0886051654815674 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.541, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4399, Accuracy: 0.8609, F1 Micro: 0.9176, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3283, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2262, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1671, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5734, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9375\n",
      "Epoch 3/10, Train Loss: 0.1827, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9114\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1041, Accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9593\n",
      "Epoch 8/10, Train Loss: 0.0925, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9421\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9408\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9546\n",
      "\n",
      "Sentiment analysis accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.95      0.95        84\n",
      "    positive       0.97      0.97      0.97       160\n",
      "\n",
      "    accuracy                           0.96       244\n",
      "   macro avg       0.96      0.96      0.96       244\n",
      "weighted avg       0.96      0.96      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8961\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.75      0.45        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.71      0.79      0.72       216\n",
      "weighted avg       0.89      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.6167631149292 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015311688184738166\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 2.896437644958496 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4371, Accuracy: 0.869, F1 Micro: 0.9214, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3135, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1572, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5707, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2922, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9218\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9315\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9052\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.86      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.66107058525085 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.012413978576660156\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8146491050720215 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5339, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4339, Accuracy: 0.8973, F1 Micro: 0.9383, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3023, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2044, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5439, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3102, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2098, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.931\n",
      "Epoch 6/10, Train Loss: 0.0857, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8929\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.82      0.75       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.17896795272827 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01938498020172119\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.633721351623535 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5401, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4381, Accuracy: 0.8705, F1 Micro: 0.9231, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.309, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9761\n",
      "Epoch 5/10, Train Loss: 0.1471, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2754, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.238, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1712, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.1069, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9482\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9244\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.84      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.8183331489563 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.010279238224029541\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.467386245727539 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4245, Accuracy: 0.8929, F1 Micro: 0.9358, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2783, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5409, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2839, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9235\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.0923, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0959, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9295\n",
      "Epoch 9/10, Train Loss: 0.0904, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9422\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        83\n",
      "    positive       0.97      0.96      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.94      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9027\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.90      0.91       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.77      0.83      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.90255737304688 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.026294052600860596\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3609187602996826 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5333, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4206, Accuracy: 0.9033, F1 Micro: 0.9408, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2687, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1826, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9606, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.99      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5679, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.277, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "Epoch 3/10, Train Loss: 0.2069, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.935\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9386\n",
      "Epoch 6/10, Train Loss: 0.133, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9305\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8955\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.92      0.51        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.95      0.71      0.81        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.84      0.75       216\n",
      "weighted avg       0.91      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.38475632667542 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.011599302291870117\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.0782463550567627 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.416, Accuracy: 0.9144, F1 Micro: 0.9481, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2712, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0781, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5048, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2687, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1819, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9376\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9209\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1065, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9369\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0667, Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9534\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.932\n",
      "Epoch 10/10, Train Loss: 0.082, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        86\n",
      "    positive       0.98      0.96      0.97       183\n",
      "\n",
      "    accuracy                           0.96       269\n",
      "   macro avg       0.95      0.96      0.95       269\n",
      "weighted avg       0.96      0.96      0.96       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9234\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.42209839820862 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010243189334869384\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0638344287872314 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5276, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.9234, F1 Micro: 0.9533, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.262, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9737\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0519, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.524, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2247, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2156, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9478\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9237\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9067\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9148\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9233\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.84      0.71      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 132.56043362617493 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.011508369445800781\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8547439575195312 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4098, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.252, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9708\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1229, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0526, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4981, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9552\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1139, Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9552\n",
      "Epoch 5/10, Train Loss: 0.0768, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9419\n",
      "Epoch 6/10, Train Loss: 0.0845, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9319\n",
      "Epoch 8/10, Train Loss: 0.057, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9283\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       161\n",
      "\n",
      "    accuracy                           0.96       245\n",
      "   macro avg       0.95      0.96      0.96       245\n",
      "weighted avg       0.96      0.96      0.96       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9005\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.80      0.77       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.12930798530579 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.016652333736419677\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6257078647613525 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5257, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3947, Accuracy: 0.9196, F1 Micro: 0.9503, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2512, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9743\n",
      "Epoch 5/10, Train Loss: 0.1271, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4902, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Epoch 4/10, Train Loss: 0.1321, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0862, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9148\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9133\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9129\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.30156636238098 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.008621621131896972\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.4631149768829346 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3907, Accuracy: 0.9286, F1 Micro: 0.956, F1 Macro: 0.9544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2367, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9774\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4717, Accuracy: 0.8774, F1 Micro: 0.8774, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2173, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9441\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "Epoch 6/10, Train Loss: 0.0935, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8913\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9161\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.886\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.83      0.75       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.69244837760925 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007939273118972778\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.2709381580352783 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.403, Accuracy: 0.9204, F1 Micro: 0.9513, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2515, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.475, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.143, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9488\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 5/10, Train Loss: 0.1376, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9287\n",
      "Epoch 6/10, Train Loss: 0.1102, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9488\n",
      "Epoch 8/10, Train Loss: 0.0584, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9729, F1 Micro: 0.9729, F1 Macro: 0.9692\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9729, F1 Micro: 0.9729, F1 Macro: 0.9692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.94      0.96        86\n",
      "    positive       0.97      0.99      0.98       172\n",
      "\n",
      "    accuracy                           0.97       258\n",
      "   macro avg       0.97      0.97      0.97       258\n",
      "weighted avg       0.97      0.97      0.97       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9009\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.84      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.23714399337769 s\n",
      "Total runtime: 2918.1437652111053 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c175d54",
   "metadata": {
    "papermill": {
     "duration": 0.148297,
     "end_time": "2025-03-24T11:01:25.784120",
     "exception": false,
     "start_time": "2025-03-24T11:01:25.635823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a564e1ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T11:01:26.083669Z",
     "iopub.status.busy": "2025-03-24T11:01:26.083312Z",
     "iopub.status.idle": "2025-03-24T11:50:22.078802Z",
     "shell.execute_reply": "2025-03-24T11:50:22.078030Z"
    },
    "papermill": {
     "duration": 2936.147923,
     "end_time": "2025-03-24T11:50:22.080149",
     "exception": false,
     "start_time": "2025-03-24T11:01:25.932226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 62.367618799209595 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9322364866733551\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 4.036345481872559 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6192, Accuracy: 0.782, F1 Micro: 0.8763, F1 Macro: 0.873\n",
      "Epoch 2/10, Train Loss: 0.535, Accuracy: 0.7775, F1 Micro: 0.8743, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5001, Accuracy: 0.7879, F1 Micro: 0.8813, F1 Macro: 0.8797\n",
      "Epoch 4/10, Train Loss: 0.5051, Accuracy: 0.7842, F1 Micro: 0.8776, F1 Macro: 0.8746\n",
      "Epoch 5/10, Train Loss: 0.4748, Accuracy: 0.7924, F1 Micro: 0.8809, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4241, Accuracy: 0.8051, F1 Micro: 0.8871, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.383, Accuracy: 0.8304, F1 Micro: 0.9, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3486, Accuracy: 0.8445, F1 Micro: 0.9069, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2947, Accuracy: 0.8631, F1 Micro: 0.9172, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2407, Accuracy: 0.8802, F1 Micro: 0.9263, F1 Macro: 0.9222\n",
      "\n",
      "Aspect detection accuracy: 0.8802, F1 Micro: 0.9263, F1 Macro: 0.9222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.90      0.98      0.94       175\n",
      "      others       0.88      0.77      0.82       158\n",
      "        part       0.82      0.99      0.90       158\n",
      "       price       0.98      0.96      0.97       192\n",
      "     service       0.86      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.90      0.95      0.93      1061\n",
      "   macro avg       0.90      0.95      0.92      1061\n",
      "weighted avg       0.90      0.95      0.93      1061\n",
      " samples avg       0.90      0.95      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5225, Accuracy: 0.7653, F1 Micro: 0.7653, F1 Macro: 0.4335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.573, Accuracy: 0.7653, F1 Micro: 0.7653, F1 Macro: 0.4335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3291, Accuracy: 0.7653, F1 Micro: 0.7653, F1 Macro: 0.4335\n",
      "Epoch 4/10, Train Loss: 0.3867, Accuracy: 0.7606, F1 Micro: 0.7606, F1 Macro: 0.432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2958, Accuracy: 0.7746, F1 Micro: 0.7746, F1 Macro: 0.58\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2304, Accuracy: 0.8357, F1 Micro: 0.8357, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1722, Accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7829\n",
      "Epoch 8/10, Train Loss: 0.1446, Accuracy: 0.8263, F1 Micro: 0.8263, F1 Macro: 0.753\n",
      "Epoch 9/10, Train Loss: 0.1144, Accuracy: 0.8404, F1 Micro: 0.8404, F1 Macro: 0.8028\n",
      "Epoch 10/10, Train Loss: 0.1203, Accuracy: 0.831, F1 Micro: 0.831, F1 Macro: 0.7794\n",
      "\n",
      "Sentiment analysis accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.66      0.67        50\n",
      "    positive       0.90      0.90      0.90       163\n",
      "\n",
      "    accuracy                           0.85       213\n",
      "   macro avg       0.78      0.78      0.78       213\n",
      "weighted avg       0.84      0.85      0.84       213\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.6517\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.89      0.71      0.79        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.25      0.38        16\n",
      "     neutral       0.89      0.98      0.93       167\n",
      "    positive       0.74      0.61      0.67        33\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.81      0.61      0.66       216\n",
      "weighted avg       0.86      0.87      0.85       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.50      0.36        12\n",
      "     neutral       0.88      0.78      0.83       152\n",
      "    positive       0.53      0.62      0.57        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.57      0.63      0.59       216\n",
      "weighted avg       0.76      0.73      0.74       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.30      0.44        23\n",
      "     neutral       0.82      0.99      0.90       152\n",
      "    positive       0.80      0.49      0.61        41\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.80      0.59      0.65       216\n",
      "weighted avg       0.81      0.82      0.79       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.96      0.97       186\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.81      0.88      0.84       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.79       216\n",
      "\n",
      "Total train time: 68.5671751499176 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9422729969024658\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 5.780041694641113 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5842, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4881, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4542, Accuracy: 0.7969, F1 Micro: 0.8855, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.434, Accuracy: 0.8155, F1 Micro: 0.8931, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3795, Accuracy: 0.8452, F1 Micro: 0.9085, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.325, Accuracy: 0.8876, F1 Micro: 0.9316, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2659, Accuracy: 0.904, F1 Micro: 0.9409, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.221, Accuracy: 0.9159, F1 Micro: 0.9477, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1843, Accuracy: 0.9174, F1 Micro: 0.9489, F1 Macro: 0.9471\n",
      "\n",
      "Aspect detection accuracy: 0.9174, F1 Micro: 0.9489, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.87      0.89      0.88       158\n",
      "        part       0.96      0.93      0.95       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.88      1.00      0.93       191\n",
      "\n",
      "   micro avg       0.93      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.93      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5684, Accuracy: 0.6991, F1 Micro: 0.6991, F1 Macro: 0.4115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.6991, F1 Micro: 0.6991, F1 Macro: 0.4115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4286, Accuracy: 0.8186, F1 Micro: 0.8186, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3007, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2196, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.8594\n",
      "Epoch 6/10, Train Loss: 0.208, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.136, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1489, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1129, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9028\n",
      "Epoch 10/10, Train Loss: 0.073, Accuracy: 0.8805, F1 Micro: 0.8805, F1 Macro: 0.8507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        68\n",
      "    positive       0.96      0.92      0.94       158\n",
      "\n",
      "    accuracy                           0.92       226\n",
      "   macro avg       0.89      0.91      0.90       226\n",
      "weighted avg       0.92      0.92      0.92       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.7512\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.80      0.83      0.82        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.76      0.81       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.74      0.80       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.87      0.89      0.88       152\n",
      "    positive       0.68      0.65      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.85      0.77      0.80       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.70      0.71        23\n",
      "     neutral       0.96      0.93      0.94       152\n",
      "    positive       0.74      0.85      0.80        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.13        14\n",
      "     neutral       0.88      1.00      0.93       185\n",
      "    positive       0.50      0.12      0.19        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.40      0.42       216\n",
      "weighted avg       0.86      0.87      0.82       216\n",
      "\n",
      "Total train time: 81.43882012367249 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9610178470611572\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.468984603881836 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5665, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4913, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4847, Accuracy: 0.7924, F1 Micro: 0.8836, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4436, Accuracy: 0.8185, F1 Micro: 0.8953, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3826, Accuracy: 0.8423, F1 Micro: 0.9082, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3189, Accuracy: 0.8966, F1 Micro: 0.9364, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2727, Accuracy: 0.9263, F1 Micro: 0.9541, F1 Macro: 0.9511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2102, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1716, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1526, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      1.00      0.98       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.94      0.97      0.96       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5952, Accuracy: 0.6778, F1 Micro: 0.6778, F1 Macro: 0.404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5325, Accuracy: 0.8243, F1 Micro: 0.8243, F1 Macro: 0.7689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3311, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2426, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1578, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1776, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1051, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9077\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8915\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9072\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        77\n",
      "    positive       0.94      0.94      0.94       162\n",
      "\n",
      "    accuracy                           0.92       239\n",
      "   macro avg       0.91      0.91      0.91       239\n",
      "weighted avg       0.92      0.92      0.92       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8614\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.73      0.76        11\n",
      "     neutral       0.97      1.00      0.98       181\n",
      "    positive       0.95      0.75      0.84        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.80      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.79      0.71      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 86.50279521942139 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.1520117342472077\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.367152690887451 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5559, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5018, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4587, Accuracy: 0.7976, F1 Micro: 0.8862, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3977, Accuracy: 0.8542, F1 Micro: 0.914, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.326, Accuracy: 0.9085, F1 Micro: 0.9439, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2623, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2086, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1552, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9673\n",
      "Epoch 9/10, Train Loss: 0.1376, Accuracy: 0.9449, F1 Micro: 0.9651, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1123, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.90      0.92       158\n",
      "        part       0.95      0.97      0.96       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6446, Accuracy: 0.7333, F1 Micro: 0.7333, F1 Macro: 0.5893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5261, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3208, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9046\n",
      "Epoch 4/10, Train Loss: 0.2601, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9005\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1763, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1137, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9076\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0992, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9163\n",
      "Epoch 10/10, Train Loss: 0.1029, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9046\n",
      "\n",
      "Sentiment analysis accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.84      0.88        81\n",
      "    positive       0.93      0.97      0.95       174\n",
      "\n",
      "    accuracy                           0.93       255\n",
      "   macro avg       0.93      0.91      0.92       255\n",
      "weighted avg       0.93      0.93      0.93       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.876\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.79      0.88        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.70      0.73      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.82      0.78       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 89.54341626167297 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.05681091547012329\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.052003860473633 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4806, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4323, Accuracy: 0.8155, F1 Micro: 0.8939, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3685, Accuracy: 0.8899, F1 Micro: 0.9339, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2813, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.206, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1561, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1227, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Epoch 9/10, Train Loss: 0.1082, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9639\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9669\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6365, Accuracy: 0.7742, F1 Micro: 0.7742, F1 Macro: 0.7304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5181, Accuracy: 0.879, F1 Micro: 0.879, F1 Macro: 0.8507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3634, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9331\n",
      "Epoch 4/10, Train Loss: 0.2614, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.201, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9323\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1194, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1209, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9501\n",
      "Epoch 9/10, Train Loss: 0.0928, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        82\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.95      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8852\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.95      0.86      0.90       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.86      0.78       216\n",
      "weighted avg       0.87      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       1.00      0.68      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.85      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 96.28293108940125 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03777046203613284\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.711578130722046 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4734, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.43, Accuracy: 0.8356, F1 Micro: 0.9045, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3431, Accuracy: 0.9159, F1 Micro: 0.9478, F1 Macro: 0.9447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2581, Accuracy: 0.942, F1 Micro: 0.9635, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2045, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1489, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.1258, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9687\n",
      "Epoch 9/10, Train Loss: 0.0999, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6417, Accuracy: 0.7833, F1 Micro: 0.7833, F1 Macro: 0.7705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.458, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2937, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2444, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Epoch 5/10, Train Loss: 0.2177, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1215, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 8/10, Train Loss: 0.124, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9195\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1011, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9346\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "    positive       0.95      0.97      0.96       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.94      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9091\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 104.61730909347534 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.027119517326354977\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.418694019317627 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4918, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4225, Accuracy: 0.8631, F1 Micro: 0.9174, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3264, Accuracy: 0.9375, F1 Micro: 0.961, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2292, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9704\n",
      "Epoch 6/10, Train Loss: 0.1766, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Epoch 7/10, Train Loss: 0.1381, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0752, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6278, Accuracy: 0.8249, F1 Micro: 0.8249, F1 Macro: 0.7856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2649, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2099, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1651, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9077\n",
      "Epoch 7/10, Train Loss: 0.1484, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Epoch 8/10, Train Loss: 0.1115, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.113, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0988, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        85\n",
      "    positive       0.95      0.97      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9116\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.01009821891785 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0262281596660614\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.103303670883179 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.8043, F1 Micro: 0.8894, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3939, Accuracy: 0.9107, F1 Micro: 0.9454, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2904, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2032, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.077, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.95      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5887, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3703, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Epoch 3/10, Train Loss: 0.2108, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9326\n",
      "Epoch 4/10, Train Loss: 0.1966, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 6/10, Train Loss: 0.1296, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9282\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Epoch 10/10, Train Loss: 0.1, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        88\n",
      "    positive       0.96      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9168\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.81      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.94      0.95      0.95       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.74675846099854 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.035633397102355975\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.794858694076538 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5484, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4901, Accuracy: 0.7984, F1 Micro: 0.8866, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4013, Accuracy: 0.9018, F1 Micro: 0.94, F1 Macro: 0.9376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2949, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1963, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1489, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1154, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0804, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5771, Accuracy: 0.845, F1 Micro: 0.845, F1 Macro: 0.8149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3752, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2546, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "Epoch 4/10, Train Loss: 0.2062, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.0997, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 8/10, Train Loss: 0.1082, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9228\n",
      "Epoch 10/10, Train Loss: 0.0713, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        85\n",
      "    positive       0.96      0.96      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.94      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9068\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.80      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.46669173240662 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.02072939872741699\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.8965892791748047 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4688, Accuracy: 0.8021, F1 Micro: 0.8875, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3833, Accuracy: 0.9182, F1 Micro: 0.9494, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2681, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1849, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 6/10, Train Loss: 0.1389, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0933, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6175, Accuracy: 0.7638, F1 Micro: 0.7638, F1 Macro: 0.6867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3837, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2428, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9476\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9439\n",
      "Epoch 5/10, Train Loss: 0.1711, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9439\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9427\n",
      "Epoch 7/10, Train Loss: 0.14, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9381\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9439\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9356\n",
      "Epoch 10/10, Train Loss: 0.0798, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9145\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.28543615341187 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.06263315677642822\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.4459404945373535 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5428, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4662, Accuracy: 0.811, F1 Micro: 0.8911, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3559, Accuracy: 0.9256, F1 Micro: 0.9544, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2495, Accuracy: 0.9464, F1 Micro: 0.967, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6031, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3701, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9372\n",
      "Epoch 4/10, Train Loss: 0.1991, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 5/10, Train Loss: 0.146, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1406, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9165\n",
      "Epoch 8/10, Train Loss: 0.1204, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9444\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9243\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.92019963264465 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015025854110717773\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.2026286125183105 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4576, Accuracy: 0.8214, F1 Micro: 0.8963, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3396, Accuracy: 0.933, F1 Micro: 0.9582, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2341, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9706\n",
      "Epoch 5/10, Train Loss: 0.1627, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.12, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0765, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6063, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3346, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9239\n",
      "Epoch 3/10, Train Loss: 0.2541, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1849, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8943\n",
      "Epoch 6/10, Train Loss: 0.1639, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9311\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        86\n",
      "    positive       0.97      0.94      0.95       179\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9182\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.89237546920776 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.014003252983093262\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.038198947906494 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5295, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4551, Accuracy: 0.8512, F1 Micro: 0.9117, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3151, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2158, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1601, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1175, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.514, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2618, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1975, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9353\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1483, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9398\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1079, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9442\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9337\n",
      "Epoch 10/10, Train Loss: 0.0789, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9357\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8986\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      1.00      0.67        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.89      0.79       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.77387762069702 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.02257704734802246\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8562045097351074 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5346, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4529, Accuracy: 0.8467, F1 Micro: 0.9088, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3156, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.206, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5345, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.1174, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9428\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Epoch 10/10, Train Loss: 0.0852, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9042\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        85\n",
      "    positive       0.96      0.97      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.95      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8804\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.96      0.80        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.89      0.87       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 127.04730772972107 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.016882896423339844\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.6736910343170166 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5387, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4489, Accuracy: 0.8594, F1 Micro: 0.9168, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.303, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5986, Accuracy: 0.8031, F1 Micro: 0.8031, F1 Macro: 0.7389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3411, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1988, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9473\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 6/10, Train Loss: 0.1224, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9518\n",
      "Epoch 8/10, Train Loss: 0.0893, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9263\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9153\n",
      "Epoch 10/10, Train Loss: 0.0892, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9173\n",
      "\n",
      "Sentiment analysis accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8895\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.82      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.2470474243164 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.014672040939331055\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.569211006164551 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4368, Accuracy: 0.8571, F1 Micro: 0.9163, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3023, Accuracy: 0.9442, F1 Micro: 0.9652, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1918, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9524, F1 Micro: 0.9698, F1 Macro: 0.9663\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5565, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2535, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1794, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9415\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9546\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9499\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.914\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9405\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Epoch 10/10, Train Loss: 0.1019, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        81\n",
      "    positive       0.99      0.95      0.97       163\n",
      "\n",
      "    accuracy                           0.96       244\n",
      "   macro avg       0.95      0.96      0.95       244\n",
      "weighted avg       0.96      0.96      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.81      0.65        16\n",
      "     neutral       0.98      0.97      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.80      0.83      0.80       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.86      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.49657416343689 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.016425907611846924\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.315426826477051 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4249, Accuracy: 0.9025, F1 Micro: 0.9405, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2727, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 7/10, Train Loss: 0.0773, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5429, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2848, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2132, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1307, Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.9553\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.955\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.9466\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.942\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9208\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        82\n",
      "    positive       0.99      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.97      0.96       248\n",
      "weighted avg       0.97      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.83      0.81       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.14569139480591 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01952582597732544\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.2091894149780273 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4281, Accuracy: 0.8824, F1 Micro: 0.9298, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2822, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 6/10, Train Loss: 0.0972, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0683, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4969, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 2/10, Train Loss: 0.2834, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Epoch 7/10, Train Loss: 0.0822, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1201, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9351\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "    positive       0.96      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.88      0.87       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.17324328422546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010578113794326782\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1192359924316406 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5221, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.422, Accuracy: 0.8981, F1 Micro: 0.9376, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2625, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0488, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5031, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2362, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9194\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1266, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9357\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9033\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9011\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.90      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      1.00      0.56        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.87      0.76       216\n",
      "weighted avg       0.90      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.594140291214 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010434579849243163\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9013302326202393 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.9085, F1 Micro: 0.9436, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2487, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0615, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.232, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1937, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9273\n",
      "Epoch 5/10, Train Loss: 0.1398, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9184\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9376\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9171\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8923\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.81      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.07477235794067 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.01345815658569336\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6541824340820312 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5339, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4085, Accuracy: 0.9018, F1 Micro: 0.9388, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4544, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1964, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1636, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1379, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 5/10, Train Loss: 0.1084, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0755, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9363\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9322\n",
      "Epoch 8/10, Train Loss: 0.0683, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8905\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.931\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9157\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        85\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.906\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.08091521263123 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007253575325012207\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.573328971862793 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5196, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4004, Accuracy: 0.9159, F1 Micro: 0.9483, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2465, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1583, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0573, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0405, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4892, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2537, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1338, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9259\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.94       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9109\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.84      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 143.8591330051422 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.005109953880310059\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.2716143131256104 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5194, Accuracy: 0.7924, F1 Micro: 0.882, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4067, Accuracy: 0.9196, F1 Micro: 0.951, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2587, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4731, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2337, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9162\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.085, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 7/10, Train Loss: 0.0856, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.925\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9259\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9014\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.41855669021606 s\n",
      "Total runtime: 2935.2326929569244 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e45584",
   "metadata": {
    "papermill": {
     "duration": 0.34116,
     "end_time": "2025-03-24T11:50:22.716453",
     "exception": false,
     "start_time": "2025-03-24T11:50:22.375293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64ffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 68.44549107551575 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9247112333774566\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 3.8856942653656006 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5046, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4848, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4985, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4552, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4116, Accuracy: 0.8192, F1 Micro: 0.8967, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3835, Accuracy: 0.8408, F1 Micro: 0.9073, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3501, Accuracy: 0.875, F1 Micro: 0.9259, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2705, Accuracy: 0.8906, F1 Micro: 0.9343, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2389, Accuracy: 0.9092, F1 Micro: 0.9449, F1 Macro: 0.9432\n",
      "\n",
      "Aspect detection accuracy: 0.9092, F1 Micro: 0.9449, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.88      1.00      0.94       175\n",
      "      others       0.83      0.94      0.88       158\n",
      "        part       0.91      0.96      0.94       158\n",
      "       price       0.92      1.00      0.96       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.91      0.99      0.94      1061\n",
      "   macro avg       0.91      0.98      0.94      1061\n",
      "weighted avg       0.91      0.99      0.95      1061\n",
      " samples avg       0.91      0.99      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7022, Accuracy: 0.6648, F1 Micro: 0.6648, F1 Macro: 0.3993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6131, Accuracy: 0.6813, F1 Micro: 0.6813, F1 Macro: 0.4633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.589, Accuracy: 0.8297, F1 Micro: 0.8297, F1 Macro: 0.7925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4854, Accuracy: 0.8352, F1 Micro: 0.8352, F1 Macro: 0.7878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4023, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8815\n",
      "Epoch 6/10, Train Loss: 0.2812, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2469, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9137\n",
      "Epoch 8/10, Train Loss: 0.166, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1392, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9384\n",
      "Epoch 10/10, Train Loss: 0.1409, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9122\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        61\n",
      "    positive       0.96      0.96      0.96       121\n",
      "\n",
      "    accuracy                           0.95       182\n",
      "   macro avg       0.94      0.94      0.94       182\n",
      "weighted avg       0.95      0.95      0.95       182\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.7643\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.95      1.00      0.97       181\n",
      "    positive       0.94      0.67      0.78        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.80      0.87       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.87      1.00      0.93       167\n",
      "    positive       0.93      0.39      0.55        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.90      0.67      0.74       216\n",
      "weighted avg       0.89      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.25      0.40        12\n",
      "     neutral       0.83      0.95      0.89       152\n",
      "    positive       0.70      0.54      0.61        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.84      0.58      0.63       216\n",
      "weighted avg       0.81      0.81      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.81      0.73      0.77        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.78      0.82       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        13\n",
      "     neutral       0.93      1.00      0.96       186\n",
      "    positive       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.62      0.71       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.75      0.82       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Total train time: 75.57317662239075 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9313085675239563\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 5.260819435119629 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5938, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.522, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5117, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4894, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4555, Accuracy: 0.8125, F1 Micro: 0.8938, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4071, Accuracy: 0.8534, F1 Micro: 0.9146, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3292, Accuracy: 0.9062, F1 Micro: 0.9433, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2775, Accuracy: 0.9301, F1 Micro: 0.9569, F1 Macro: 0.9551\n",
      "Epoch 9/10, Train Loss: 0.2254, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.174, Accuracy: 0.933, F1 Micro: 0.9583, F1 Macro: 0.9553\n",
      "\n",
      "Aspect detection accuracy: 0.933, F1 Micro: 0.9583, F1 Macro: 0.9553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.87      0.87      0.87       158\n",
      "        part       0.92      0.97      0.94       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6939, Accuracy: 0.6751, F1 Micro: 0.6751, F1 Macro: 0.403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5961, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4281, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3297, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2171, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2271, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1962, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "Epoch 8/10, Train Loss: 0.1819, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.1453, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.1367, Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.9299\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        77\n",
      "    positive       0.97      0.95      0.96       160\n",
      "\n",
      "    accuracy                           0.95       237\n",
      "   macro avg       0.94      0.95      0.94       237\n",
      "weighted avg       0.95      0.95      0.95       237\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.8599\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.91      0.99      0.95       167\n",
      "    positive       0.95      0.55      0.69        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.78      0.83       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.88      0.88      0.88       152\n",
      "    positive       0.67      0.67      0.67        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.77      0.77      0.77       216\n",
      "weighted avg       0.82      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.63      0.74        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 82.70105028152466 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.22141918540000916\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.786818027496338 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5669, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5084, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4886, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4556, Accuracy: 0.8036, F1 Micro: 0.8894, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4078, Accuracy: 0.8408, F1 Micro: 0.9078, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3468, Accuracy: 0.8996, F1 Micro: 0.9392, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2867, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2157, Accuracy: 0.9397, F1 Micro: 0.9624, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1605, Accuracy: 0.9412, F1 Micro: 0.9629, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1398, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.90      0.91      0.90       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6706, Accuracy: 0.6914, F1 Micro: 0.6914, F1 Macro: 0.4653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5996, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4085, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3203, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9211\n",
      "Epoch 5/10, Train Loss: 0.2009, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1991, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9404\n",
      "Epoch 7/10, Train Loss: 0.1925, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8694\n",
      "Epoch 8/10, Train Loss: 0.1714, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.1195, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.1102, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "\n",
      "Sentiment analysis accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        79\n",
      "    positive       0.98      0.94      0.96       164\n",
      "\n",
      "    accuracy                           0.95       243\n",
      "   macro avg       0.93      0.95      0.94       243\n",
      "weighted avg       0.95      0.95      0.95       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.8751\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.90      0.91      0.90       152\n",
      "    positive       0.76      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.82      0.80       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.90      0.68      0.78        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 86.86103367805481 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0862779200077058\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.445393800735474 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5633, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4981, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4724, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4251, Accuracy: 0.8415, F1 Micro: 0.9079, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3498, Accuracy: 0.8988, F1 Micro: 0.939, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2816, Accuracy: 0.9301, F1 Micro: 0.9565, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2095, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1693, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1283, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "Epoch 10/10, Train Loss: 0.1013, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.88      0.97      0.92       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6692, Accuracy: 0.7137, F1 Micro: 0.7137, F1 Macro: 0.591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5728, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3367, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2505, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9337\n",
      "Epoch 6/10, Train Loss: 0.2052, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9109\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9256\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9067\n",
      "Epoch 9/10, Train Loss: 0.1297, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9109\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9269\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.91        81\n",
      "    positive       0.94      0.97      0.96       160\n",
      "\n",
      "    accuracy                           0.94       241\n",
      "   macro avg       0.94      0.93      0.93       241\n",
      "weighted avg       0.94      0.94      0.94       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8769\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.92      0.69        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.90      0.67      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.84      0.79       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.91      0.75        23\n",
      "     neutral       0.98      0.96      0.97       152\n",
      "    positive       0.88      0.73      0.80        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.87      0.84       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 89.75533127784729 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.07417160272598267\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.105099678039551 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5356, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4625, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4362, Accuracy: 0.8289, F1 Micro: 0.902, F1 Macro: 0.9011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3648, Accuracy: 0.881, F1 Micro: 0.929, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2681, Accuracy: 0.9308, F1 Micro: 0.9571, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2108, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1487, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.119, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.1017, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0822, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6707, Accuracy: 0.7431, F1 Micro: 0.7431, F1 Macro: 0.7384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8063, F1 Micro: 0.8063, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3347, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "Epoch 4/10, Train Loss: 0.2689, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "Epoch 6/10, Train Loss: 0.1609, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9133\n",
      "Epoch 7/10, Train Loss: 0.1023, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9088\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0997, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9207\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        80\n",
      "    positive       0.99      0.93      0.96       173\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8994\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.79      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 94.02401494979858 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03524131774902344\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.790825605392456 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5481, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4734, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4256, Accuracy: 0.8393, F1 Micro: 0.9072, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3497, Accuracy: 0.9211, F1 Micro: 0.9517, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2496, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1798, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1406, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1158, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6663, Accuracy: 0.7733, F1 Micro: 0.7733, F1 Macro: 0.7692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4927, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9093\n",
      "Epoch 3/10, Train Loss: 0.3018, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2764, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2035, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9508\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9212\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9256\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.0995, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        83\n",
      "    positive       0.98      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.96      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9092\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.89      0.96      0.92       152\n",
      "    positive       0.85      0.67      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 99.39269399642944 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03621525764465332\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.64466667175293 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5505, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4846, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4024, Accuracy: 0.8534, F1 Micro: 0.9149, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.317, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2297, Accuracy: 0.942, F1 Micro: 0.9636, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1699, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0986, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6374, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 3/10, Train Loss: 0.264, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2072, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1636, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1524, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1208, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9092\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.28595066070557 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.021922707557678223\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.161174535751343 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5495, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4827, Accuracy: 0.814, F1 Micro: 0.8945, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3983, Accuracy: 0.8921, F1 Micro: 0.9355, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2657, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1367, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.1092, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6468, Accuracy: 0.7968, F1 Micro: 0.7968, F1 Macro: 0.7254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4075, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2181, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Epoch 4/10, Train Loss: 0.2213, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "Epoch 7/10, Train Loss: 0.1043, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Epoch 8/10, Train Loss: 0.0958, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9296\n",
      "Epoch 9/10, Train Loss: 0.0875, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.937\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.95       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9032\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.07436943054199 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.018632209300994875\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.823359727859497 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4674, Accuracy: 0.811, F1 Micro: 0.893, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3937, Accuracy: 0.9122, F1 Micro: 0.9468, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2733, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1917, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1455, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.618, Accuracy: 0.8514, F1 Micro: 0.8514, F1 Macro: 0.8242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3579, Accuracy: 0.8916, F1 Micro: 0.8916, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3177, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2016, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9263\n",
      "Epoch 6/10, Train Loss: 0.169, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9239\n",
      "Epoch 7/10, Train Loss: 0.1388, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9286\n",
      "Epoch 8/10, Train Loss: 0.1043, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.1096, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9163\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9196\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.93      0.94      0.94       249\n",
      "weighted avg       0.94      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8956\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.80      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.25590395927429 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.03544610738754272\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.816182851791382 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.541, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4775, Accuracy: 0.811, F1 Micro: 0.8931, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3785, Accuracy: 0.9144, F1 Micro: 0.9479, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2574, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1457, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1058, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6282, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3347, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2165, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.2111, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9302\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        83\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9035\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.96      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.54336643218994 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0207061767578125\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.655635356903076 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5376, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4678, Accuracy: 0.8289, F1 Micro: 0.902, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3497, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.236, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1611, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1217, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0833, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.99      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6292, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3218, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2115, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1778, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9502\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8887\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9141\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9337\n",
      "Epoch 10/10, Train Loss: 0.0346, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9169\n",
      "\n",
      "Sentiment analysis accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        82\n",
      "    positive       0.97      0.96      0.97       168\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.95      0.95       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8768\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.30      0.83      0.44        12\n",
      "     neutral       0.92      0.89      0.91       152\n",
      "    positive       0.95      0.67      0.79        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.80      0.71       216\n",
      "weighted avg       0.90      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 117.34098720550537 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.02245807647705078\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.335648536682129 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5377, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4573, Accuracy: 0.8318, F1 Micro: 0.9037, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3407, Accuracy: 0.9382, F1 Micro: 0.9618, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2154, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1567, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1185, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5781, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.325, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Epoch 3/10, Train Loss: 0.2137, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9107\n",
      "Epoch 4/10, Train Loss: 0.1928, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9428\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "Epoch 7/10, Train Loss: 0.1133, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Epoch 9/10, Train Loss: 0.1022, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        84\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9153\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.31994485855103 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.014288115501403815\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.128779172897339 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4573, Accuracy: 0.8549, F1 Micro: 0.9152, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3217, Accuracy: 0.939, F1 Micro: 0.9622, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5699, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3241, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 3/10, Train Loss: 0.2383, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 4/10, Train Loss: 0.1515, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9248\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        82\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9125\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.84      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.3845865726471 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.012202143669128418\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.890854597091675 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.542, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4587, Accuracy: 0.8631, F1 Micro: 0.9199, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3097, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9687\n",
      "Epoch 4/10, Train Loss: 0.1967, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6124, Accuracy: 0.8779, F1 Micro: 0.8779, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3254, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9316\n",
      "Epoch 3/10, Train Loss: 0.2341, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1827, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9445\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9202\n",
      "Epoch 6/10, Train Loss: 0.1365, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.1039, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9202\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9005\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.96      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.907\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.93960499763489 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.013831257820129395\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8371355533599854 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5397, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4522, Accuracy: 0.8653, F1 Micro: 0.9207, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3124, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9649\n",
      "Epoch 4/10, Train Loss: 0.2028, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1413, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5335, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2481, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 5/10, Train Loss: 0.1265, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9221\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Epoch 7/10, Train Loss: 0.0924, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Epoch 8/10, Train Loss: 0.0952, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9257\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        86\n",
      "    positive       0.97      0.94      0.95       179\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8905\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.94      0.88      0.90       152\n",
      "    positive       0.79      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.85      0.80       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.65538430213928 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.014435946941375732\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.498844623565674 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5496, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.435, Accuracy: 0.8802, F1 Micro: 0.9285, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2926, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1892, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Epoch 5/10, Train Loss: 0.1393, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.104, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.502, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2442, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9392\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 4/10, Train Loss: 0.1284, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9443\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0838, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9296\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.97       180\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.96      0.95       263\n",
      "weighted avg       0.96      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.81      0.82       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.4437940120697 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.010259628295898438\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3103532791137695 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5338, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4193, Accuracy: 0.8862, F1 Micro: 0.9325, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2779, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9685\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5478, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2928, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2032, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9243\n",
      "Epoch 4/10, Train Loss: 0.1181, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.90        84\n",
      "    positive       0.97      0.93      0.95       171\n",
      "\n",
      "    accuracy                           0.93       255\n",
      "   macro avg       0.92      0.94      0.93       255\n",
      "weighted avg       0.94      0.93      0.93       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8852\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.83      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.75      0.55        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.80      0.75       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.54277348518372 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.014330416917800903\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.1589694023132324 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4254, Accuracy: 0.8988, F1 Micro: 0.939, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2786, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.102, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.515, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2564, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9366\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9096\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.931\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9166\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9078\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.85      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.52605414390564 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.012040162086486816\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1109306812286377 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4203, Accuracy: 0.9174, F1 Micro: 0.9497, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2647, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.481, Accuracy: 0.8774, F1 Micro: 0.8774, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2498, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "Epoch 6/10, Train Loss: 0.0942, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 8/10, Train Loss: 0.0663, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        85\n",
      "    positive       0.97      0.96      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8989\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.89      0.84       216\n",
      "weighted avg       0.90      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.74402165412903 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.01127331256866455\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.840770959854126 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5249, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4131, Accuracy: 0.9152, F1 Micro: 0.9487, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2532, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0482, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4725, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2439, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9322\n",
      "Epoch 4/10, Train Loss: 0.1476, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.93      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9002\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.28264164924622 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.009955364465713502\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6286418437957764 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5198, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4086, Accuracy: 0.9226, F1 Micro: 0.9531, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2513, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1151, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0733, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0606, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4949, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 3/10, Train Loss: 0.1973, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9106\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 6/10, Train Loss: 0.0934, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 7/10, Train Loss: 0.0664, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9031\n",
      "Epoch 10/10, Train Loss: 0.0371, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9092\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.95      0.94       258\n",
      "weighted avg       0.95      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8861\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.83      0.76       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.68975448608398 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.018068289756774904\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.4270648956298828 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5284, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4001, Accuracy: 0.9286, F1 Micro: 0.9562, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2417, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.9057\n",
      "Epoch 2/10, Train Loss: 0.205, Accuracy: 0.8773, F1 Micro: 0.8773, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1969, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1342, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "Epoch 7/10, Train Loss: 0.0779, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9253\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.9019\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9174\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.94      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9055\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.57654809951782 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.005964386463165283\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.2921793460845947 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7991, F1 Micro: 0.8853, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.247, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1682, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "Epoch 5/10, Train Loss: 0.1209, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2709, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1468, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9498\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9492\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.954\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9455\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9281\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9411\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        80\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8895\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.96      0.89      0.93       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.83      0.74       216\n",
      "weighted avg       0.91      0.86      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.04979634284973 s\n",
      "Total runtime: 2923.735000371933 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6734022,
     "sourceId": 10843162,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5887.392045,
   "end_time": "2025-03-24T11:50:26.357883",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-24T10:12:18.965838",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01abee3804f1401b9ac57674303c40af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "05fe7bf5d9394b39b0fcba2e9272305c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "088bbba46ac14ecc91b3a3572dcda94a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c42cd7a089d448eb20bd551d0d0a370": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "139f8a8a27604594a6283d599aa4f0f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1682d5d0c3ed47d9b59d69a1e18973c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_700547a175974fcbb7e33b076a07ee3f",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ac9baf46139740feb9d058ace319313e",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "1aa53799abd642959493b93d07ef6eab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7c7f4d1fc8444a1eb6470d6b6c0593c0",
       "placeholder": "​",
       "style": "IPY_MODEL_9e814ee4df874aaaa0560867a092469d",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "1d773ad58bdb4daea9d2953c6e1e6c7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6df7cdcdba284ea4930bd22e46e63720",
        "IPY_MODEL_5e86eb87d6e74f858b9df9ceff28486c",
        "IPY_MODEL_8ffb3adb531142939f47467ed4044201"
       ],
       "layout": "IPY_MODEL_64308929f7b347d597d699f77dd6015a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1fcae1e30e1e42ab9e6571158f5b8487": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_088bbba46ac14ecc91b3a3572dcda94a",
       "placeholder": "​",
       "style": "IPY_MODEL_7810cba9c7244e9797b78b247a00a23c",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "2b0ed161ab3d43f9a7d161ed0aa4c16f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b519a3e30d44f63b65912196659d3f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "393eed9ac0b84ca1839ba16fbc0c8d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1fcae1e30e1e42ab9e6571158f5b8487",
        "IPY_MODEL_d9b8c0c51dd5440e8dd3ddda0295d3b1",
        "IPY_MODEL_9327a2a7586548df9e6ed1c610145f3a"
       ],
       "layout": "IPY_MODEL_7c26a0f8f6f74e64926a649d4930fb6e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3ff236a95ea5496f874c12e7101cda19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4a20c8913ea549a4b4d501debc76ccb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4db6a91d056b437d8e17442ebce5888c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1aa53799abd642959493b93d07ef6eab",
        "IPY_MODEL_5beb4486df17451ebe2ea7b13bf65c6d",
        "IPY_MODEL_5c990ff192a145679460e7c703eb1745"
       ],
       "layout": "IPY_MODEL_67da07d050294409a6a724df3d99c0cd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5beb4486df17451ebe2ea7b13bf65c6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b8ecaf912e2e4b498c277e84c5589302",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_05fe7bf5d9394b39b0fcba2e9272305c",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "5c990ff192a145679460e7c703eb1745": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b0ed161ab3d43f9a7d161ed0aa4c16f",
       "placeholder": "​",
       "style": "IPY_MODEL_3ff236a95ea5496f874c12e7101cda19",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 11.4kB/s]"
      }
     },
     "5e86eb87d6e74f858b9df9ceff28486c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_de45ad6238c34542ba354a01093b6e96",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b4a7fcdc0a6d422b8d114eee34e219b5",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "64308929f7b347d597d699f77dd6015a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67da07d050294409a6a724df3d99c0cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6da101d960ba4d3ea311f8763eb68459": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6df7cdcdba284ea4930bd22e46e63720": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aa243daa7ddb47e0b3b57d7076710cad",
       "placeholder": "​",
       "style": "IPY_MODEL_d6c984bfc07e4b819fea335efd2d43e6",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "700547a175974fcbb7e33b076a07ee3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7810cba9c7244e9797b78b247a00a23c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7c26a0f8f6f74e64926a649d4930fb6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c7f4d1fc8444a1eb6470d6b6c0593c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bddfdf64b2c4d049581fce6cac13af1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ffb3adb531142939f47467ed4044201": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_afcba5a839704373956d25b901206f39",
       "placeholder": "​",
       "style": "IPY_MODEL_0c42cd7a089d448eb20bd551d0d0a370",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 167B/s]"
      }
     },
     "9327a2a7586548df9e6ed1c610145f3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6da101d960ba4d3ea311f8763eb68459",
       "placeholder": "​",
       "style": "IPY_MODEL_01abee3804f1401b9ac57674303c40af",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.05MB/s]"
      }
     },
     "9e814ee4df874aaaa0560867a092469d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa243daa7ddb47e0b3b57d7076710cad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac9baf46139740feb9d058ace319313e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aea1692590cf46688caaacc191f8c9e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d4b53c8c80fe445abc925a46631c7c4c",
        "IPY_MODEL_1682d5d0c3ed47d9b59d69a1e18973c5",
        "IPY_MODEL_b7526f5b648643d190602c0d4d4cfcd5"
       ],
       "layout": "IPY_MODEL_cd179c30a7df42d4ad2efa15ef188431",
       "tabbable": null,
       "tooltip": null
      }
     },
     "afcba5a839704373956d25b901206f39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4a7fcdc0a6d422b8d114eee34e219b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b7526f5b648643d190602c0d4d4cfcd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ccbde7b4007344eca473c75b0d5fb5a2",
       "placeholder": "​",
       "style": "IPY_MODEL_2b519a3e30d44f63b65912196659d3f2",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 149kB/s]"
      }
     },
     "b8ecaf912e2e4b498c277e84c5589302": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccbde7b4007344eca473c75b0d5fb5a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd179c30a7df42d4ad2efa15ef188431": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4b53c8c80fe445abc925a46631c7c4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_139f8a8a27604594a6283d599aa4f0f6",
       "placeholder": "​",
       "style": "IPY_MODEL_d776d4830663477bab3f237fd29bf3e2",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "d6c984bfc07e4b819fea335efd2d43e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d776d4830663477bab3f237fd29bf3e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d9b8c0c51dd5440e8dd3ddda0295d3b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a20c8913ea549a4b4d501debc76ccb1",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8bddfdf64b2c4d049581fce6cac13af1",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "de45ad6238c34542ba354a01093b6e96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
