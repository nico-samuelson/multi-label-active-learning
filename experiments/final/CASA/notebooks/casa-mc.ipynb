{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaba5362",
   "metadata": {
    "papermill": {
     "duration": 0.012211,
     "end_time": "2025-03-23T11:12:44.143940",
     "exception": false,
     "start_time": "2025-03-23T11:12:44.131729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b2bbaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:12:44.167952Z",
     "iopub.status.busy": "2025-03-23T11:12:44.167618Z",
     "iopub.status.idle": "2025-03-23T11:13:10.315631Z",
     "shell.execute_reply": "2025-03-23T11:13:10.314969Z"
    },
    "papermill": {
     "duration": 26.161274,
     "end_time": "2025-03-23T11:13:10.317106",
     "exception": false,
     "start_time": "2025-03-23T11:12:44.155832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6bef0",
   "metadata": {
    "papermill": {
     "duration": 0.011031,
     "end_time": "2025-03-23T11:13:10.339952",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.328921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49810c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.364026Z",
     "iopub.status.busy": "2025-03-23T11:13:10.363494Z",
     "iopub.status.idle": "2025-03-23T11:13:10.367186Z",
     "shell.execute_reply": "2025-03-23T11:13:10.366348Z"
    },
    "papermill": {
     "duration": 0.017621,
     "end_time": "2025-03-23T11:13:10.368567",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.350946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4af07bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.393264Z",
     "iopub.status.busy": "2025-03-23T11:13:10.393032Z",
     "iopub.status.idle": "2025-03-23T11:13:10.396537Z",
     "shell.execute_reply": "2025-03-23T11:13:10.395940Z"
    },
    "papermill": {
     "duration": 0.017242,
     "end_time": "2025-03-23T11:13:10.397732",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.380490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3d7c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.422157Z",
     "iopub.status.busy": "2025-03-23T11:13:10.421945Z",
     "iopub.status.idle": "2025-03-23T11:13:10.431221Z",
     "shell.execute_reply": "2025-03-23T11:13:10.430645Z"
    },
    "papermill": {
     "duration": 0.02236,
     "end_time": "2025-03-23T11:13:10.432298",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.409938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4b00f",
   "metadata": {
    "papermill": {
     "duration": 0.01096,
     "end_time": "2025-03-23T11:13:10.454442",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.443482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1c490e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.477382Z",
     "iopub.status.busy": "2025-03-23T11:13:10.477181Z",
     "iopub.status.idle": "2025-03-23T11:13:10.534620Z",
     "shell.execute_reply": "2025-03-23T11:13:10.533233Z"
    },
    "papermill": {
     "duration": 0.070604,
     "end_time": "2025-03-23T11:13:10.536076",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.465472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-mc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d9829",
   "metadata": {
    "papermill": {
     "duration": 0.010864,
     "end_time": "2025-03-23T11:13:10.558376",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.547512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30f72cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.581681Z",
     "iopub.status.busy": "2025-03-23T11:13:10.581426Z",
     "iopub.status.idle": "2025-03-23T11:13:10.657990Z",
     "shell.execute_reply": "2025-03-23T11:13:10.657171Z"
    },
    "papermill": {
     "duration": 0.089843,
     "end_time": "2025-03-23T11:13:10.659324",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.569481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68995129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.682624Z",
     "iopub.status.busy": "2025-03-23T11:13:10.682393Z",
     "iopub.status.idle": "2025-03-23T11:13:10.691407Z",
     "shell.execute_reply": "2025-03-23T11:13:10.690597Z"
    },
    "papermill": {
     "duration": 0.021828,
     "end_time": "2025-03-23T11:13:10.692562",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.670734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb958a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.716312Z",
     "iopub.status.busy": "2025-03-23T11:13:10.716088Z",
     "iopub.status.idle": "2025-03-23T11:13:10.725245Z",
     "shell.execute_reply": "2025-03-23T11:13:10.724372Z"
    },
    "papermill": {
     "duration": 0.022545,
     "end_time": "2025-03-23T11:13:10.726639",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.704094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973b6863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.750328Z",
     "iopub.status.busy": "2025-03-23T11:13:10.750055Z",
     "iopub.status.idle": "2025-03-23T11:13:10.764398Z",
     "shell.execute_reply": "2025-03-23T11:13:10.763478Z"
    },
    "papermill": {
     "duration": 0.027605,
     "end_time": "2025-03-23T11:13:10.765764",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.738159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a9f6c",
   "metadata": {
    "papermill": {
     "duration": 0.011111,
     "end_time": "2025-03-23T11:13:10.789055",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.777944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d11dd94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.812789Z",
     "iopub.status.busy": "2025-03-23T11:13:10.812572Z",
     "iopub.status.idle": "2025-03-23T11:13:10.818150Z",
     "shell.execute_reply": "2025-03-23T11:13:10.817565Z"
    },
    "papermill": {
     "duration": 0.018541,
     "end_time": "2025-03-23T11:13:10.819218",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.800677",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907ba877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.842660Z",
     "iopub.status.busy": "2025-03-23T11:13:10.842458Z",
     "iopub.status.idle": "2025-03-23T11:13:10.848927Z",
     "shell.execute_reply": "2025-03-23T11:13:10.848332Z"
    },
    "papermill": {
     "duration": 0.019378,
     "end_time": "2025-03-23T11:13:10.850106",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.830728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907dc123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:10.873705Z",
     "iopub.status.busy": "2025-03-23T11:13:10.873494Z",
     "iopub.status.idle": "2025-03-23T11:13:22.237885Z",
     "shell.execute_reply": "2025-03-23T11:13:22.237195Z"
    },
    "papermill": {
     "duration": 11.377823,
     "end_time": "2025-03-23T11:13:22.239315",
     "exception": false,
     "start_time": "2025-03-23T11:13:10.861492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb1d249339a4190b8acc04ef8b3fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdba1212f2743238bd2a62a2d189ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357cb264aa834dc3bda4492e3faf7156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaed654b2b834405910cb972dc6dfe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92620b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.265984Z",
     "iopub.status.busy": "2025-03-23T11:13:22.265694Z",
     "iopub.status.idle": "2025-03-23T11:13:22.270040Z",
     "shell.execute_reply": "2025-03-23T11:13:22.269354Z"
    },
    "papermill": {
     "duration": 0.018551,
     "end_time": "2025-03-23T11:13:22.271351",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.252800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a2f784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.296395Z",
     "iopub.status.busy": "2025-03-23T11:13:22.296187Z",
     "iopub.status.idle": "2025-03-23T11:13:22.305452Z",
     "shell.execute_reply": "2025-03-23T11:13:22.304907Z"
    },
    "papermill": {
     "duration": 0.022783,
     "end_time": "2025-03-23T11:13:22.306646",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.283863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f37972",
   "metadata": {
    "papermill": {
     "duration": 0.011489,
     "end_time": "2025-03-23T11:13:22.329959",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.318470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc708abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.354667Z",
     "iopub.status.busy": "2025-03-23T11:13:22.354463Z",
     "iopub.status.idle": "2025-03-23T11:13:22.357670Z",
     "shell.execute_reply": "2025-03-23T11:13:22.357126Z"
    },
    "papermill": {
     "duration": 0.016753,
     "end_time": "2025-03-23T11:13:22.358897",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.342144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58cff8e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.383597Z",
     "iopub.status.busy": "2025-03-23T11:13:22.383385Z",
     "iopub.status.idle": "2025-03-23T11:13:22.387674Z",
     "shell.execute_reply": "2025-03-23T11:13:22.387118Z"
    },
    "papermill": {
     "duration": 0.0181,
     "end_time": "2025-03-23T11:13:22.388917",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.370817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61973369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.413229Z",
     "iopub.status.busy": "2025-03-23T11:13:22.413025Z",
     "iopub.status.idle": "2025-03-23T11:13:22.418807Z",
     "shell.execute_reply": "2025-03-23T11:13:22.418249Z"
    },
    "papermill": {
     "duration": 0.019199,
     "end_time": "2025-03-23T11:13:22.420040",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.400841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7917d1fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.444299Z",
     "iopub.status.busy": "2025-03-23T11:13:22.444098Z",
     "iopub.status.idle": "2025-03-23T11:13:22.469362Z",
     "shell.execute_reply": "2025-03-23T11:13:22.468770Z"
    },
    "papermill": {
     "duration": 0.038776,
     "end_time": "2025-03-23T11:13:22.470524",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.431748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b571ba",
   "metadata": {
    "papermill": {
     "duration": 0.011453,
     "end_time": "2025-03-23T11:13:22.493866",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.482413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f02f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.518361Z",
     "iopub.status.busy": "2025-03-23T11:13:22.518140Z",
     "iopub.status.idle": "2025-03-23T11:13:22.523402Z",
     "shell.execute_reply": "2025-03-23T11:13:22.522769Z"
    },
    "papermill": {
     "duration": 0.018908,
     "end_time": "2025-03-23T11:13:22.524575",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.505667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa549b94",
   "metadata": {
    "papermill": {
     "duration": 0.011715,
     "end_time": "2025-03-23T11:13:22.548247",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.536532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dac35ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.572518Z",
     "iopub.status.busy": "2025-03-23T11:13:22.572313Z",
     "iopub.status.idle": "2025-03-23T11:13:22.588984Z",
     "shell.execute_reply": "2025-03-23T11:13:22.588346Z"
    },
    "papermill": {
     "duration": 0.030107,
     "end_time": "2025-03-23T11:13:22.590049",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.559942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monte_carlo_dropout_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, mc_passes=3, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.train()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.train()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    aspect_uncertainties = []\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        batch_probs = []\n",
    "        \n",
    "        for i in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()  # Shape: (batch_size, num_classes)\n",
    "                batch_probs.append(probs)\n",
    "                \n",
    "        # Stack the probabilities from multiple MC passes\n",
    "        batch_probs = np.stack(batch_probs, axis=0)  # Shape: (mc_passes, batch_size, num_classes)\n",
    "\n",
    "        # Calculate mean probability and uncertainty for each sample in the batch\n",
    "        mean_probs = np.mean(batch_probs, axis=0)  # Shape: (batch_size, num_classes)\n",
    "        uncertainties = np.mean(np.var(batch_probs, axis=0), axis=1)  # Shape: (batch_size,)\n",
    "        aspect_uncertainties.extend(uncertainties)\n",
    "\n",
    "        for i in range(len(mean_probs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = [np.max(torch.sigmoid(outputs[i]).cpu().numpy())]\n",
    "            \n",
    "            for j in range(len(mean_probs[i])):\n",
    "                if int(mean_probs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    aspect_outputs = {i: aspect_uncertainties[i] for i in range(len(aspect_uncertainties))}\n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        batch_probs = []\n",
    "        for i in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "                for j in range(len(preds)):\n",
    "                    ori_index = batch['ori_indices'][j].item()\n",
    "                    if ori_index in sentiment_outputs.keys():\n",
    "                        sentiment_outputs[ori_index].append(preds[j].cpu().numpy())\n",
    "                    else:\n",
    "                        sentiment_outputs[ori_index] = [preds[j].cpu().numpy()]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    for indices, probs in sentiment_outputs.items():\n",
    "        sentiment_outputs[indices] = [[probs[i], probs[i+1], probs[i+2]] for i in range(int(len(probs) / 3))]\n",
    "        \n",
    "        variance = np.var(sentiment_outputs[indices], axis=1)\n",
    "        mean_aspect_variance = np.mean(variance, axis=1)\n",
    "        mean_data_variance = np.mean(mean_aspect_variance)\n",
    "        \n",
    "        sentiment_outputs[indices] = np.mean(np.mean(np.var(sentiment_outputs[indices], axis=0), axis=0), axis=0)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = (val + aspect_outputs[key]) / 2\n",
    "\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3652a",
   "metadata": {
    "papermill": {
     "duration": 0.011505,
     "end_time": "2025-03-23T11:13:22.613253",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.601748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "323f4e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.637116Z",
     "iopub.status.busy": "2025-03-23T11:13:22.636913Z",
     "iopub.status.idle": "2025-03-23T11:13:22.645255Z",
     "shell.execute_reply": "2025-03-23T11:13:22.644653Z"
    },
    "papermill": {
     "duration": 0.021586,
     "end_time": "2025-03-23T11:13:22.646400",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.624814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(monte_carlo_dropout_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73a895ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.670817Z",
     "iopub.status.busy": "2025-03-23T11:13:22.670602Z",
     "iopub.status.idle": "2025-03-23T11:13:22.673419Z",
     "shell.execute_reply": "2025-03-23T11:13:22.672841Z"
    },
    "papermill": {
     "duration": 0.016424,
     "end_time": "2025-03-23T11:13:22.674662",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.658238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec893acc",
   "metadata": {
    "papermill": {
     "duration": 0.01141,
     "end_time": "2025-03-23T11:13:22.697961",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.686551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0832b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 54.224839210510254 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008176815987098964\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 8.343161344528198 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6175, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5199, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4808, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.445, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4485, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3903, Accuracy: 0.8147, F1 Micro: 0.8947, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3793, Accuracy: 0.843, F1 Micro: 0.9092, F1 Macro: 0.9085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3259, Accuracy: 0.8579, F1 Micro: 0.9163, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2756, Accuracy: 0.875, F1 Micro: 0.9255, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2484, Accuracy: 0.8966, F1 Micro: 0.9373, F1 Macro: 0.9363\n",
      "\n",
      "Aspect detection accuracy: 0.8966, F1 Micro: 0.9373, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.84      1.00      0.91       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.86      0.93      0.90       158\n",
      "        part       0.90      0.98      0.94       158\n",
      "       price       0.95      0.98      0.97       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.94      1061\n",
      "weighted avg       0.90      0.98      0.94      1061\n",
      " samples avg       0.90      0.98      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.6685, F1 Micro: 0.6685, F1 Macro: 0.4007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5724, Accuracy: 0.6685, F1 Micro: 0.6685, F1 Macro: 0.4007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5082, Accuracy: 0.7072, F1 Micro: 0.7072, F1 Macro: 0.5357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4235, Accuracy: 0.7569, F1 Micro: 0.7569, F1 Macro: 0.647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3107, Accuracy: 0.8177, F1 Micro: 0.8177, F1 Macro: 0.7761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2083, Accuracy: 0.8564, F1 Micro: 0.8564, F1 Macro: 0.8302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.8359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.8674, F1 Micro: 0.8674, F1 Macro: 0.8399\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.7927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.88\n",
      "\n",
      "Sentiment analysis accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        60\n",
      "    positive       0.91      0.93      0.92       121\n",
      "\n",
      "    accuracy                           0.90       181\n",
      "   macro avg       0.89      0.88      0.88       181\n",
      "weighted avg       0.89      0.90      0.89       181\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.7029\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.85      1.00      0.92       181\n",
      "    positive       1.00      0.08      0.15        24\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.62      0.36      0.36       216\n",
      "weighted avg       0.82      0.85      0.79       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.88      0.98      0.93       167\n",
      "    positive       0.77      0.52      0.62        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.68      0.75       216\n",
      "weighted avg       0.87      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.58      0.64        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.74      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.77      0.71      0.74       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.70      0.74        23\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.80      0.59      0.68        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.75      0.79       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.95      0.98      0.97       186\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.77      0.81       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.70      0.77       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Total train time: 75.998361825943 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001401702687144281\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 12.724542379379272 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5992, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5225, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4912, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4649, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.429, Accuracy: 0.8177, F1 Micro: 0.8962, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3748, Accuracy: 0.8757, F1 Micro: 0.9267, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3293, Accuracy: 0.9159, F1 Micro: 0.9488, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.271, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2345, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1916, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "\n",
      "Aspect detection accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.99      0.98       187\n",
      "     machine       0.92      0.98      0.95       175\n",
      "      others       0.90      0.93      0.91       158\n",
      "        part       0.92      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6028, Accuracy: 0.6795, F1 Micro: 0.6795, F1 Macro: 0.4046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.526, Accuracy: 0.7094, F1 Micro: 0.7094, F1 Macro: 0.54\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.415, Accuracy: 0.8376, F1 Micro: 0.8376, F1 Macro: 0.7937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2166, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.92\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9083\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9151\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9071\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9077\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9117\n",
      "\n",
      "Sentiment analysis accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        75\n",
      "    positive       0.93      0.96      0.95       159\n",
      "\n",
      "    accuracy                           0.93       234\n",
      "   macro avg       0.92      0.91      0.92       234\n",
      "weighted avg       0.93      0.93      0.93       234\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9282, F1 Micro: 0.9282, F1 Macro: 0.8551\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.97      0.99      0.98       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.92      0.98      0.95       167\n",
      "    positive       0.78      0.64      0.70        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.77      0.81       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.93      0.91       152\n",
      "    positive       0.79      0.71      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.81      0.80      0.80       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.92      0.99      0.96       152\n",
      "    positive       0.84      0.66      0.74        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 81.29651379585266 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0017040643142536283\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.393900632858276 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5895, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5116, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4497, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3999, Accuracy: 0.8609, F1 Micro: 0.9177, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3489, Accuracy: 0.9152, F1 Micro: 0.9476, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2833, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2298, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1764, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1588, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9671\n",
      "\n",
      "Aspect detection accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6064, Accuracy: 0.6923, F1 Micro: 0.6923, F1 Macro: 0.4091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.463, Accuracy: 0.8138, F1 Micro: 0.8138, F1 Macro: 0.7377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2891, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.9033\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8855\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8877\n",
      "Epoch 7/10, Train Loss: 0.1386, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1132, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9107\n",
      "Epoch 9/10, Train Loss: 0.1114, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8924\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.902\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        76\n",
      "    positive       0.95      0.94      0.94       171\n",
      "\n",
      "    accuracy                           0.92       247\n",
      "   macro avg       0.91      0.92      0.91       247\n",
      "weighted avg       0.92      0.92      0.92       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8667\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.77      0.78       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.19640684127808 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014492561575025326\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.32290267944336 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5938, Accuracy: 0.7961, F1 Micro: 0.8854, F1 Macro: 0.8838\n",
      "Epoch 2/10, Train Loss: 0.5331, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5047, Accuracy: 0.8132, F1 Micro: 0.8941, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4332, Accuracy: 0.8571, F1 Micro: 0.9166, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3617, Accuracy: 0.9241, F1 Micro: 0.9532, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2867, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2271, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1827, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1421, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1203, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5843, Accuracy: 0.6776, F1 Micro: 0.6776, F1 Macro: 0.4039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3978, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9147\n",
      "Epoch 5/10, Train Loss: 0.1814, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1918, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9137\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.9016\n",
      "Epoch 10/10, Train Loss: 0.0901, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9089\n",
      "\n",
      "Sentiment analysis accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        79\n",
      "    positive       0.98      0.92      0.95       166\n",
      "\n",
      "    accuracy                           0.93       245\n",
      "   macro avg       0.92      0.94      0.93       245\n",
      "weighted avg       0.94      0.93      0.94       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8848\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.79      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.99675345420837 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0011264084605500102\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.774689674377441 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.575, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4839, Accuracy: 0.8281, F1 Micro: 0.9017, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4064, Accuracy: 0.9062, F1 Micro: 0.9429, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3162, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2478, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1491, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.122, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1067, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5326, Accuracy: 0.689, F1 Micro: 0.689, F1 Macro: 0.519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3423, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1906, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1567, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1145, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8947\n",
      "Epoch 7/10, Train Loss: 0.1478, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 8/10, Train Loss: 0.1044, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.927\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.93      0.95       169\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9078\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.75948929786682 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008436530712060634\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.662755489349365 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5759, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5266, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4663, Accuracy: 0.8482, F1 Micro: 0.9121, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3729, Accuracy: 0.9286, F1 Micro: 0.956, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2968, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2395, Accuracy: 0.9494, F1 Micro: 0.9681, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1862, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.1436, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.1218, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1034, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7126, F1 Micro: 0.7126, F1 Macro: 0.5421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2975, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 4/10, Train Loss: 0.2114, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9263\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1196, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "Epoch 8/10, Train Loss: 0.1463, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Epoch 9/10, Train Loss: 0.0996, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "Epoch 10/10, Train Loss: 0.0802, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        84\n",
      "    positive       0.98      0.94      0.95       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9057\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.647625207901 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.000688252120744437\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.638885974884033 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5765, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5257, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4599, Accuracy: 0.8594, F1 Micro: 0.9181, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3752, Accuracy: 0.9315, F1 Micro: 0.958, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2856, Accuracy: 0.9487, F1 Micro: 0.9679, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2194, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.163, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.129, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1078, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0899, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4686, Accuracy: 0.8071, F1 Micro: 0.8071, F1 Macro: 0.7528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9158\n",
      "Epoch 4/10, Train Loss: 0.1388, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9051\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8947\n",
      "Epoch 6/10, Train Loss: 0.1442, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1234, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1001, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 9/10, Train Loss: 0.1056, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9071\n",
      "Epoch 10/10, Train Loss: 0.09, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9094\n",
      "\n",
      "Sentiment analysis accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90        84\n",
      "    positive       0.97      0.92      0.95       170\n",
      "\n",
      "    accuracy                           0.93       254\n",
      "   macro avg       0.91      0.94      0.92       254\n",
      "weighted avg       0.93      0.93      0.93       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8901\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.81      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.96      0.81        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 111.67961096763611 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005463595443870872\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.6728675365448 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5082, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4346, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3299, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2397, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1867, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.1098, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0766, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.7308, F1 Micro: 0.7308, F1 Macro: 0.5793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2996, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9195\n",
      "Epoch 3/10, Train Loss: 0.1739, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1533, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1451, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 8/10, Train Loss: 0.0921, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9155\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.915\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        85\n",
      "    positive       0.98      0.93      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.95      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9038\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.43190956115723 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005325875361450021\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.849511384963989 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.8155, F1 Micro: 0.8953, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4341, Accuracy: 0.9144, F1 Micro: 0.948, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3219, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2452, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Epoch 6/10, Train Loss: 0.191, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1436, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.1155, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0975, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4881, Accuracy: 0.7695, F1 Micro: 0.7695, F1 Macro: 0.6732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2602, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1721, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1111, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9119\n",
      "Epoch 7/10, Train Loss: 0.1189, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9166\n",
      "Epoch 8/10, Train Loss: 0.1167, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9124\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9148\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        86\n",
      "    positive       0.96      0.94      0.95       170\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.92      0.93      0.93       256\n",
      "weighted avg       0.94      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.88359117507935 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0003043390257516874\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.317504644393921 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5602, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.498, Accuracy: 0.8222, F1 Micro: 0.8985, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.402, Accuracy: 0.9204, F1 Micro: 0.9508, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2979, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2308, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1686, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.1297, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0911, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0706, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5022, Accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "Epoch 3/10, Train Loss: 0.1577, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9228\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1135, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9278\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9162\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9152\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9172\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        85\n",
      "    positive       0.97      0.94      0.95       182\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.92      0.93      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8963\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.50      0.44        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.70      0.74      0.71       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.66552090644836 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0003250475856475532\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.770417928695679 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5703, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5082, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4079, Accuracy: 0.9189, F1 Micro: 0.9498, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2964, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2272, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1655, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1312, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0861, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4548, Accuracy: 0.8171, F1 Micro: 0.8171, F1 Macro: 0.7616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "Epoch 5/10, Train Loss: 0.1094, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9218\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9214\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9073\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9167\n",
      "Epoch 9/10, Train Loss: 0.0913, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8929\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9027\n",
      "\n",
      "Sentiment analysis accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91        86\n",
      "    positive       0.98      0.92      0.95       171\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.92      0.94      0.93       257\n",
      "weighted avg       0.94      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8753\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.67      0.47        12\n",
      "     neutral       0.92      0.89      0.91       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.70      0.77      0.72       216\n",
      "weighted avg       0.87      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.26446175575256 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00021115904382895678\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.149433374404907 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5563, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4872, Accuracy: 0.8266, F1 Micro: 0.901, F1 Macro: 0.9001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3554, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2662, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1965, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1407, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1112, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.508, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2337, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1574, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9166\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0398, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.917\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        86\n",
      "    positive       0.98      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8988\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.85      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.08339953422546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00020333983848104287\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.751411199569702 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5546, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4808, Accuracy: 0.8549, F1 Micro: 0.9153, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.351, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2584, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1793, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1493, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4821, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2691, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9127\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.95      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9055\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.53654623031616 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00013101370132062584\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.240965843200684 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.564, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4802, Accuracy: 0.84, F1 Micro: 0.9075, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3559, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2413, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1674, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1334, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1063, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0867, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4683, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2549, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 4/10, Train Loss: 0.1471, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1335, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9256\n",
      "Epoch 7/10, Train Loss: 0.0968, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8998\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.83      0.82       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.92      0.77        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.85      0.84       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.09583067893982 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00010496540926396847\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.863322973251343 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.466, Accuracy: 0.8497, F1 Micro: 0.9129, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3336, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2232, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1629, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2581, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9311\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9163\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9203\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1257, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        85\n",
      "    positive       0.98      0.93      0.96       180\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9065\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.84      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      1.00      0.90        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.3494610786438 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 7.401363109238446e-05\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.386341333389282 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5497, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4608, Accuracy: 0.9137, F1 Micro: 0.9477, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3102, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5082, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9338\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1186, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9423\n",
      "Epoch 5/10, Train Loss: 0.0835, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9303\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0579, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9376\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9368\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8935\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.90      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.90      0.95        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.74340748786926 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00014161912258714437\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.901916027069092 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5455, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4527, Accuracy: 0.8996, F1 Micro: 0.9398, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3066, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1519, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5044, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9141\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9212\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0895, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "    positive       0.94      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.93       263\n",
      "   macro avg       0.92      0.92      0.92       263\n",
      "weighted avg       0.93      0.93      0.93       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.97302913665771 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.0086820920114405e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.473677635192871 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5454, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4369, Accuracy: 0.9144, F1 Micro: 0.9482, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2081, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4773, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2178, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9026\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9291\n",
      "\n",
      "Sentiment analysis accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        87\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9194\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.87      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.4038233757019 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 3.001175027748104e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.3248345851898193 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5289, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4409, Accuracy: 0.9301, F1 Micro: 0.9569, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2809, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4632, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9263\n",
      "Epoch 3/10, Train Loss: 0.208, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9124\n",
      "Epoch 4/10, Train Loss: 0.1455, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9279\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9216\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9142\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        87\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9195\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.90      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.67580103874207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.061998988618142e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.889136791229248 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4085, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2715, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4717, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2173, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 3/10, Train Loss: 0.1619, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8975\n",
      "Epoch 4/10, Train Loss: 0.1578, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9271\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9487\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.95       262\n",
      "weighted avg       0.96      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9653, F1 Micro: 0.9653, F1 Macro: 0.9339\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.05022597312927 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.6841603246575692e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.2476797103881836 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5412, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4163, Accuracy: 0.9226, F1 Micro: 0.9526, F1 Macro: 0.9511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2684, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.183, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0839, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9643, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4428, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2472, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9206\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9219\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.887\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        85\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.895\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.75      0.55        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.82      0.77       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.64161205291748 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.992001743928995e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.201805353164673 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3908, Accuracy: 0.9301, F1 Micro: 0.9566, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2456, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.98      0.95       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5001, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9341\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1313, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9341\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9245\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9215\n",
      "Epoch 9/10, Train Loss: 0.0794, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9215\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9202\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        83\n",
      "    positive       0.99      0.93      0.96       167\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.93      0.95      0.94       250\n",
      "weighted avg       0.95      0.94      0.94       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8946\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.85      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.93      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.88      0.82       216\n",
      "weighted avg       0.92      0.90      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.96      0.80        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.60134959220886 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.703367776528466e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3961865901947021 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3999, Accuracy: 0.9301, F1 Micro: 0.957, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2439, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4673, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2246, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9298\n",
      "Epoch 3/10, Train Loss: 0.1576, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Epoch 5/10, Train Loss: 0.1102, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9223\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8993\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9289\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.0919, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        86\n",
      "    positive       0.98      0.93      0.96       187\n",
      "\n",
      "    accuracy                           0.94       273\n",
      "   macro avg       0.92      0.95      0.93       273\n",
      "weighted avg       0.95      0.94      0.94       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8949\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.77      0.82      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.7332227230072 s\n",
      "Total runtime: 3117.8745589256287 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d45712",
   "metadata": {
    "papermill": {
     "duration": 0.0115,
     "end_time": "2025-03-23T11:13:22.749837",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.738337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c747a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 59.669870376586914 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006264137045945973\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.232650995254517 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6022, Accuracy: 0.7917, F1 Micro: 0.8827, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.4997, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4948, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4575, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4221, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3712, Accuracy: 0.8371, F1 Micro: 0.9061, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3461, Accuracy: 0.8757, F1 Micro: 0.9263, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3188, Accuracy: 0.8899, F1 Micro: 0.9335, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.259, Accuracy: 0.9003, F1 Micro: 0.9393, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2231, Accuracy: 0.9137, F1 Micro: 0.9473, F1 Macro: 0.9453\n",
      "\n",
      "Aspect detection accuracy: 0.9137, F1 Micro: 0.9473, F1 Macro: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.85      0.92      0.89       158\n",
      "        part       0.88      0.97      0.92       158\n",
      "       price       0.92      1.00      0.96       192\n",
      "     service       0.96      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.91      0.98      0.95      1061\n",
      "   macro avg       0.91      0.98      0.95      1061\n",
      "weighted avg       0.92      0.98      0.95      1061\n",
      " samples avg       0.92      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6035, Accuracy: 0.6869, F1 Micro: 0.6869, F1 Macro: 0.4072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5774, Accuracy: 0.6869, F1 Micro: 0.6869, F1 Macro: 0.4072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.546, Accuracy: 0.6869, F1 Micro: 0.6869, F1 Macro: 0.4072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4752, Accuracy: 0.6919, F1 Micro: 0.6919, F1 Macro: 0.4386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3119, Accuracy: 0.7172, F1 Micro: 0.7172, F1 Macro: 0.5909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2564, Accuracy: 0.7929, F1 Micro: 0.7929, F1 Macro: 0.7537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.148, Accuracy: 0.7929, F1 Micro: 0.7929, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.8081, F1 Micro: 0.8081, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.8333, F1 Micro: 0.8333, F1 Macro: 0.8054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8481\n",
      "\n",
      "Sentiment analysis accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.95      0.81        62\n",
      "    positive       0.97      0.82      0.89       136\n",
      "\n",
      "    accuracy                           0.86       198\n",
      "   macro avg       0.84      0.88      0.85       198\n",
      "weighted avg       0.89      0.86      0.86       198\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.7757\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       1.00      0.58      0.74        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.80      0.87       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.87      0.61      0.71        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.80      0.84       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.50      0.34        12\n",
      "     neutral       0.85      0.92      0.89       152\n",
      "    positive       0.83      0.46      0.59        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.65      0.63      0.61       216\n",
      "weighted avg       0.81      0.79      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.65      0.71        23\n",
      "     neutral       0.88      0.97      0.92       152\n",
      "    positive       0.86      0.59      0.70        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.74      0.78       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.46      0.57        13\n",
      "     neutral       0.92      1.00      0.96       186\n",
      "    positive       1.00      0.35      0.52        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.60      0.68       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.96      0.99      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 73.33043146133423 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0012020639376714827\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.03787899017334 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5302, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5061, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4823, Accuracy: 0.8095, F1 Micro: 0.8922, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4292, Accuracy: 0.8482, F1 Micro: 0.9113, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3626, Accuracy: 0.8936, F1 Micro: 0.9358, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.317, Accuracy: 0.9249, F1 Micro: 0.9538, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2579, Accuracy: 0.9278, F1 Micro: 0.9554, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2186, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.186, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9612\n",
      "\n",
      "Aspect detection accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.96      0.95       175\n",
      "      others       0.85      0.97      0.90       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.6711, F1 Micro: 0.6711, F1 Macro: 0.4016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4301, Accuracy: 0.6711, F1 Micro: 0.6711, F1 Macro: 0.4016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3891, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2341, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2309, Accuracy: 0.9422, F1 Micro: 0.9422, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8831\n",
      "Epoch 7/10, Train Loss: 0.1163, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9237\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9147\n",
      "Epoch 9/10, Train Loss: 0.0945, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9195\n",
      "Epoch 10/10, Train Loss: 0.1456, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9168\n",
      "\n",
      "Sentiment analysis accuracy: 0.9422, F1 Micro: 0.9422, F1 Macro: 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        74\n",
      "    positive       0.95      0.96      0.96       151\n",
      "\n",
      "    accuracy                           0.94       225\n",
      "   macro avg       0.94      0.93      0.93       225\n",
      "weighted avg       0.94      0.94      0.94       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9282, F1 Micro: 0.9282, F1 Macro: 0.8574\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.76      0.67      0.71        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.85      0.97      0.91       152\n",
      "    positive       0.86      0.46      0.60        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.77      0.70      0.72       216\n",
      "weighted avg       0.84      0.83      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 80.6619348526001 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014250980457291007\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.36351490020752 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5941, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5423, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5074, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4658, Accuracy: 0.8586, F1 Micro: 0.9174, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3771, Accuracy: 0.9025, F1 Micro: 0.9409, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3132, Accuracy: 0.9196, F1 Micro: 0.9504, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2594, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2082, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1742, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1444, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9688\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.97      0.96      0.96       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5495, Accuracy: 0.6774, F1 Micro: 0.6774, F1 Macro: 0.4038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4665, Accuracy: 0.7056, F1 Micro: 0.7056, F1 Macro: 0.5088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2689, Accuracy: 0.871, F1 Micro: 0.871, F1 Macro: 0.8524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1917, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9052\n",
      "Epoch 5/10, Train Loss: 0.097, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1248, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.91\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.8629, F1 Micro: 0.8629, F1 Macro: 0.8387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0915, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Epoch 10/10, Train Loss: 0.0962, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8913\n",
      "\n",
      "Sentiment analysis accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.95      0.89        80\n",
      "    positive       0.97      0.91      0.94       168\n",
      "\n",
      "    accuracy                           0.92       248\n",
      "   macro avg       0.90      0.93      0.92       248\n",
      "weighted avg       0.93      0.92      0.92       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8687\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.91      0.64      0.75        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.77      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.91      0.81        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.37908554077148 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001502620242536068\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.126099348068237 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5867, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5349, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5062, Accuracy: 0.817, F1 Micro: 0.8961, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4259, Accuracy: 0.8869, F1 Micro: 0.9317, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3585, Accuracy: 0.9137, F1 Micro: 0.9474, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2913, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2336, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1931, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1508, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1209, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5237, Accuracy: 0.6745, F1 Micro: 0.6745, F1 Macro: 0.4028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4485, Accuracy: 0.6745, F1 Micro: 0.6745, F1 Macro: 0.4028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.319, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0924, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1351, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       255\n",
      "   macro avg       0.93      0.94      0.93       255\n",
      "weighted avg       0.94      0.94      0.94       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9009\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.96      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 102.41774463653564 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010901810601353645\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.259694337844849 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5743, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5081, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4591, Accuracy: 0.8571, F1 Micro: 0.9162, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3846, Accuracy: 0.9122, F1 Micro: 0.9466, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.306, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2385, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1831, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1425, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.121, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0983, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5536, Accuracy: 0.6758, F1 Micro: 0.6758, F1 Macro: 0.4033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3643, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2173, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "Epoch 6/10, Train Loss: 0.1324, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9229\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 9/10, Train Loss: 0.1231, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 10/10, Train Loss: 0.0919, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9325\n",
      "\n",
      "Sentiment analysis accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        83\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.95       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9061\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 102.3314118385315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010199714917689562\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.650906801223755 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5745, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5212, Accuracy: 0.7991, F1 Micro: 0.8868, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4419, Accuracy: 0.8713, F1 Micro: 0.9228, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3613, Accuracy: 0.9152, F1 Micro: 0.948, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2844, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2258, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.182, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1472, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.1177, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0975, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5168, Accuracy: 0.6705, F1 Micro: 0.6705, F1 Macro: 0.4014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3347, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1573, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "Epoch 4/10, Train Loss: 0.1346, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9444\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9052\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.67152881622314 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005910211126320063\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.613202810287476 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5136, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4378, Accuracy: 0.8891, F1 Micro: 0.933, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3386, Accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2623, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2278, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1626, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1357, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.1081, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 10/10, Train Loss: 0.0909, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5025, Accuracy: 0.6732, F1 Micro: 0.6732, F1 Macro: 0.4023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3518, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1571, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1374, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9437\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9017\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.57328867912292 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005274599243421108\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.92799973487854 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4932, Accuracy: 0.8237, F1 Micro: 0.8993, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3873, Accuracy: 0.8929, F1 Micro: 0.9344, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3158, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2335, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1905, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1504, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1187, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.096, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0783, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.579, Accuracy: 0.682, F1 Micro: 0.682, F1 Macro: 0.4055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3345, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2103, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1673, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Epoch 7/10, Train Loss: 0.1256, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Epoch 8/10, Train Loss: 0.117, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0977, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 10/10, Train Loss: 0.1054, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9002\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.95500349998474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005333866574801507\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.94382643699646 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5532, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5037, Accuracy: 0.8125, F1 Micro: 0.8939, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4043, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3133, Accuracy: 0.9338, F1 Micro: 0.959, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2506, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1518, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1239, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0987, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0818, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.7843, F1 Micro: 0.7843, F1 Macro: 0.7086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2749, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0781, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9069\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8833\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.83      0.77       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.52107095718384 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0003663053415948525\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.479770660400391 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5536, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4809, Accuracy: 0.8519, F1 Micro: 0.914, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3792, Accuracy: 0.9211, F1 Micro: 0.9512, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2883, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2252, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1696, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.129, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.109, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.539, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.8278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2677, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.196, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1121, Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9457\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0872, Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9451\n",
      "Epoch 10/10, Train Loss: 0.0921, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.95      0.95       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9062\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.84917259216309 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0002508923935238272\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.021188259124756 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5507, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4689, Accuracy: 0.8795, F1 Micro: 0.9283, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3566, Accuracy: 0.9174, F1 Micro: 0.9496, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2651, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2085, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1517, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.6692, F1 Micro: 0.6692, F1 Macro: 0.4009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3238, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9227\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9291\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        87\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9047\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      1.00      0.63        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.90      0.80       216\n",
      "weighted avg       0.91      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.02234554290771 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00020688785298261791\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.159600257873535 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.552, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4461, Accuracy: 0.878, F1 Micro: 0.9278, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3375, Accuracy: 0.9263, F1 Micro: 0.9548, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2564, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1899, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.146, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1106, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.813, F1 Micro: 0.813, F1 Macro: 0.7601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2077, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1587, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9398\n",
      "Epoch 5/10, Train Loss: 0.1528, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9439\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9349\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9198\n",
      "Epoch 9/10, Train Loss: 0.0816, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Epoch 10/10, Train Loss: 0.0548, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        84\n",
      "    positive       0.98      0.95      0.96       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9108\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.87      0.80       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.4323878288269 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00016147472488228234\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.687549352645874 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4519, Accuracy: 0.8899, F1 Micro: 0.9339, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3362, Accuracy: 0.9286, F1 Micro: 0.9555, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2426, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1776, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1355, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8411, F1 Micro: 0.8411, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2915, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9243\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0834, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9284\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9017\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8966\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.85      1.00      0.92        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.87179446220398 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.421714665018953e-05\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.862967014312744 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4253, Accuracy: 0.8921, F1 Micro: 0.9342, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3103, Accuracy: 0.9301, F1 Micro: 0.9559, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2297, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9816\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.497, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2248, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2051, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1369, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1174, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.086, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        88\n",
      "    positive       0.96      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.94      0.94      0.94       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9057\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.89      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.74243068695068 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 9.31748072616756e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.833467483520508 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5543, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4325, Accuracy: 0.8988, F1 Micro: 0.9382, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3042, Accuracy: 0.9427, F1 Micro: 0.9643, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2147, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "Epoch 9/10, Train Loss: 0.0669, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.7041, F1 Micro: 0.7041, F1 Macro: 0.5177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2551, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1363, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.93\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0727, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        88\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9077\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.88      0.83       216\n",
      "weighted avg       0.90      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.2347321510315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.545504533685744e-05\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.449476003646851 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4284, Accuracy: 0.9025, F1 Micro: 0.9411, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3033, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2158, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.97      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.7196, F1 Micro: 0.7196, F1 Macro: 0.534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2725, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9186\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1242, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0942, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9378\n",
      "\n",
      "Sentiment analysis accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       184\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.93      0.95      0.94       271\n",
      "weighted avg       0.95      0.94      0.95       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9246\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.98      0.97      0.97       167\n",
      "    positive       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.84      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.59660029411316 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.6755594414426014e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.949533700942993 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.8996, F1 Micro: 0.9372, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2897, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2073, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.482, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "Epoch 3/10, Train Loss: 0.2219, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9408\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9157\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 10/10, Train Loss: 0.0798, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9156\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.4906361103058 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 3.225389991712291e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.457753896713257 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5335, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4121, Accuracy: 0.904, F1 Micro: 0.9406, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2904, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0592, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.95      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5496, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2434, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.935\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.136, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.099, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9425\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9382\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9225\n",
      "\n",
      "Sentiment analysis accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.92        88\n",
      "    positive       0.98      0.94      0.96       184\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.93      0.95      0.94       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.76      0.85      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.86       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.95      0.90      0.93       152\n",
      "    positive       0.79      0.87      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.87      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.80792427062988 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 5.6163001863751555e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.326042413711548 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5399, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3855, Accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2648, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.977\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4926, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1891, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Epoch 6/10, Train Loss: 0.0994, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "Epoch 8/10, Train Loss: 0.062, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9042\n",
      "Epoch 9/10, Train Loss: 0.0864, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9111\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8994\n",
      "\n",
      "Sentiment analysis accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        85\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.94      0.93       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8798\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.64      0.74        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 139.71550154685974 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.036119426018558e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9293057918548584 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3867, Accuracy: 0.9211, F1 Micro: 0.9509, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0755, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4742, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1884, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9268\n",
      "Epoch 3/10, Train Loss: 0.1871, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9222\n",
      "Epoch 4/10, Train Loss: 0.1243, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9261\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9233\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9456\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.93        88\n",
      "    positive       0.97      0.96      0.96       184\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.94      0.95      0.95       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9282\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.11453819274902 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.1180823387112473e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.362375497817993 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3777, Accuracy: 0.9263, F1 Micro: 0.9545, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2554, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.529, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2675, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 3/10, Train Loss: 0.1568, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9287\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1226, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9405\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9235\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.943\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9207\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.97       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8979\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.20872282981873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.3680803385796026e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9114272594451904 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3604, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2273, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1162, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.071, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0511, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4793, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9258\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1338, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9073\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0834, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9107\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9337\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9145\n",
      "\n",
      "Sentiment analysis accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        87\n",
      "    positive       0.95      0.97      0.96       183\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.94      0.93      0.94       270\n",
      "weighted avg       0.94      0.94      0.94       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9134\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.30272459983826 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 9.808790491661056e-06\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3630788326263428 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.519, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3719, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2259, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.0903, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4785, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 2/10, Train Loss: 0.1975, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9302\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9185\n",
      "Epoch 4/10, Train Loss: 0.1136, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\n",
      "Epoch 5/10, Train Loss: 0.0909, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9189\n",
      "Epoch 10/10, Train Loss: 0.0714, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.906\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.92      0.69        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.88      0.81       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.20186638832092 s\n",
      "Total runtime: 3186.05224442482 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADrQklEQVR4nOzde3zO9f/H8ce18xhz2sGc5nxuzlMkioQKCSU5JJVQ3+hACAmV8hMKKZFDpJBOIiJScz4z5zA2m8Nms+N1Xb8/PjPWhp2v7drzfrtdt13X5/p8ruv12Xf2fbbr9Xm9TVar1YqIiIiIiIiIiIiIiIiIiIhIHnCwdQEiIiIiIiIiIiIiIiIiIiJSeKhRQURERERERERERERERERERPKMGhVEREREREREREREREREREQkz6hRQURERERERERERERERERERPKMGhVEREREREREREREREREREQkz6hRQURERERERERERERERERERPKMGhVEREREREREREREREREREQkz6hRQURERERERERERERERERERPKMGhVEREREREREREREREREREQkz6hRQURERERERETytX79+uHv72/rMkREREREREQkh6hRQUQkiz777DNMJhOBgYG2LkVEREREJFvmz5+PyWRK9zZixIiU/dauXcuAAQOoV68ejo6OmW4euPGazz//fLrPjxo1KmWfiIiI7JySiIiIiBQiyrMiIgWPk60LEBEpqBYvXoy/vz/btm3j+PHjVKtWzdYliYiIiIhky7vvvkvlypVTbatXr17K/SVLlrBs2TIaNWqEn59flt7Dzc2N77//ns8++wwXF5dUz33zzTe4ubkRFxeXavvcuXOxWCxZej8RERERKTzya54VEZG0NFFBRCQLTp06xdatW5k6dSpeXl4sXrzY1iWlKyYmxtYliIiIiEgB0qFDB3r37p3q1qBBg5TnJ02aRFRUFH/99RcBAQFZeo9HHnmEqKgofv3111Tbt27dyqlTp+jUqVOaY5ydnXF1dc3S+93KYrHoj8YiIiIidiy/5tncpr8Di0hBpEYFEZEsWLx4MSVLlqRTp048+eST6TYqXL16lddeew1/f39cXV0pX748ffr0STXyKy4ujnHjxlGjRg3c3NwoW7YsTzzxBCdOnABg48aNmEwmNm7cmOq1T58+jclkYv78+Snb+vXrh4eHBydOnKBjx44UK1aMZ555BoDNmzfTvXt3KlasiKurKxUqVOC1114jNjY2Td1HjhyhR48eeHl54e7uTs2aNRk1ahQAf/zxByaTiZUrV6Y5bsmSJZhMJv7+++9Mfz9FREREpGDw8/PD2dk5W69Rrlw5WrVqxZIlS1JtX7x4MfXr1091xdsN/fr1SzOW12Kx8Mknn1C/fn3c3Nzw8vLikUceYceOHSn7mEwmhgwZwuLFi6lbty6urq6sWbMGgN27d9OhQweKFy+Oh4cHDz30EP/880+2zk1ERERE8jdb5dmc+vsswLhx4zCZTBw6dIhevXpRsmRJWrZsCUBSUhITJkygatWquLq64u/vz9tvv018fHy2zllEJDdo6QcRkSxYvHgxTzzxBC4uLjz99NPMmjWL7du307RpUwCio6O5//77OXz4MM899xyNGjUiIiKC1atXc+7cOcqUKYPZbObRRx9l/fr1PPXUU7z66qtcu3aNdevWceDAAapWrZrpupKSkmjfvj0tW7bko48+okiRIgAsX76c69evM2jQIEqXLs22bduYMWMG586dY/ny5SnH79u3j/vvvx9nZ2deeOEF/P39OXHiBD/++CMTJ06kdevWVKhQgcWLF9O1a9c035OqVaty7733ZuM7KyIiIiK2FBkZmWYt3TJlyuT4+/Tq1YtXX32V6OhoPDw8SEpKYvny5QwbNizDEw8GDBjA/Pnz6dChA88//zxJSUls3ryZf/75hyZNmqTst2HDBr799luGDBlCmTJl8Pf35+DBg9x///0UL16cN998E2dnZ+bMmUPr1q3ZtGkTgYGBOX7OIiIiIpL78muezam/z96qe/fuVK9enUmTJmG1WgF4/vnnWbBgAU8++STDhw8nKCiIyZMnc/jw4XQvPhMRsSU1KoiIZNLOnTs5cuQIM2bMAKBly5aUL1+exYsXpzQqTJkyhQMHDrBixYpUH+iPHj06JTR+/fXXrF+/nqlTp/Laa6+l7DNixIiUfTIrPj6e7t27M3ny5FTbP/jgA9zd3VMev/DCC1SrVo23336bM2fOULFiRQCGDh2K1Wpl165dKdsA3n//fcC4Iq13795MnTqVyMhIPD09AQgPD2ft2rWpOntFREREpOBp27Ztmm1ZzaZ38uSTTzJkyBBWrVpF7969Wbt2LRERETz99NN89dVXdz3+jz/+YP78+bzyyit88sknKduHDx+ept7g4GD2799PnTp1UrZ17dqVxMREtmzZQpUqVQDo06cPNWvW5M0332TTpk05dKYiIiIikpfya57Nqb/P3iogICDVVIe9e/eyYMECnn/+eebOnQvAyy+/jLe3Nx999BF//PEHbdq0ybHvgYhIdmnpBxGRTFq8eDE+Pj4poc5kMtGzZ0+WLl2K2WwG4PvvvycgICDN1IEb+9/Yp0yZMgwdOvS2+2TFoEGD0my7NQTHxMQQERHBfffdh9VqZffu3YDRbPDnn3/y3HPPpQrB/62nT58+xMfH891336VsW7ZsGUlJSfTu3TvLdYuIiIiI7X366aesW7cu1S03lCxZkkceeYRvvvkGMJYRu++++6hUqVKGjv/+++8xmUyMHTs2zXP/zdIPPPBAqiYFs9nM2rVr6dKlS0qTAkDZsmXp1asXW7ZsISoqKiunJSIiIiI2ll/zbE7+ffaGl156KdXjX375BYBhw4al2j58+HAAfv7558ycoohIrtNEBRGRTDCbzSxdupQ2bdpw6tSplO2BgYF8/PHHrF+/nocffpgTJ07QrVu3O77WiRMnqFmzJk5OOfer2MnJifLly6fZfubMGd555x1Wr17NlStXUj0XGRkJwMmTJwHSXUPtVrVq1aJp06YsXryYAQMGAEbzRvPmzalWrVpOnIaIiIiI2EizZs1SLZuQm3r16sWzzz7LmTNnWLVqFR9++GGGjz1x4gR+fn6UKlXqrvtWrlw51ePw8HCuX79OzZo10+xbu3ZtLBYLZ8+epW7duhmuR0RERETyh/yaZ3Py77M3/Dfn/vvvvzg4OKT5G62vry8lSpTg33//zdDriojkFTUqiIhkwoYNG7hw4QJLly5l6dKlaZ5fvHgxDz/8cI693+0mK9yY3PBfrq6uODg4pNm3Xbt2XL58mbfeeotatWpRtGhRQkJC6NevHxaLJdN19enTh1dffZVz584RHx/PP//8w8yZMzP9OiIiIiJSeD3++OO4urrSt29f4uPj6dGjR668z61Xr4mIiIiI5JSM5tnc+Pss3D7nZmdar4hIXlKjgohIJixevBhvb28+/fTTNM+tWLGClStXMnv2bKpWrcqBAwfu+FpVq1YlKCiIxMREnJ2d092nZMmSAFy9ejXV9sx0v+7fv5+jR4+yYMEC+vTpk7L9v2PPboy9vVvdAE899RTDhg3jm2++ITY2FmdnZ3r27JnhmkRERERE3N3d6dKlC4sWLaJDhw6UKVMmw8dWrVqV3377jcuXL2doqsKtvLy8KFKkCMHBwWmeO3LkCA4ODlSoUCFTrykiIiIihU9G82xu/H02PZUqVcJisXDs2DFq166dsj0sLIyrV69meJk1EZG84nD3XUREBCA2NpYVK1bw6KOP8uSTT6a5DRkyhGvXrrF69Wq6devG3r17WblyZZrXsVqtAHTr1o2IiIh0JxHc2KdSpUo4Ojry559/pnr+s88+y3Ddjo6OqV7zxv1PPvkk1X5eXl60atWKefPmcebMmXTruaFMmTJ06NCBRYsWsXjxYh555JFM/WFZRERERATg9ddfZ+zYsYwZMyZTx3Xr1g2r1cr48ePTPPff7Ppfjo6OPPzww/zwww+cPn06ZXtYWBhLliyhZcuWFC9ePFP1iIiIiEjhlJE8mxt/n01Px44dAZg2bVqq7VOnTgWgU6dOd30NEZG8pIkKIiIZtHr1aq5du8bjjz+e7vPNmzfHy8uLxYsXs2TJEr777ju6d+/Oc889R+PGjbl8+TKrV69m9uzZBAQE0KdPH77++muGDRvGtm3buP/++4mJieH333/n5ZdfpnPnznh6etK9e3dmzJiByWSiatWq/PTTT1y8eDHDddeqVYuqVavy+uuvExISQvHixfn+++/TrIUGMH36dFq2bEmjRo144YUXqFy5MqdPn+bnn39mz549qfbt06cPTz75JAATJkzI+DdSRERERAqsffv2sXr1agCOHz9OZGQk7733HgABAQE89thjmXq9gIAAAgICMl1HmzZtePbZZ5k+fTrHjh3jkUcewWKxsHnzZtq0acOQIUPuePx7773HunXraNmyJS+//DJOTk7MmTOH+Pj4O64tLCIiIiIFmy3ybG79fTa9Wvr27cvnn3/O1atXeeCBB9i2bRsLFiygS5cutGnTJlPnJiKS29SoICKSQYsXL8bNzY127dql+7yDgwOdOnVi8eLFxMfHs3nzZsaOHcvKlStZsGAB3t7ePPTQQ5QvXx4wOml/+eUXJk6cyJIlS/j+++8pXbo0LVu2pH79+imvO2PGDBITE5k9ezaurq706NGDKVOmUK9evQzV7ezszI8//sgrr7zC5MmTcXNzo2vXrgwZMiRNiA4ICOCff/5hzJgxzJo1i7i4OCpVqpTu+mqPPfYYJUuWxGKx3LZ5Q0RERETsy65du9JcLXbjcd++fTP9h93s+Oqrr7jnnnv48ssveeONN/D09KRJkybcd999dz22bt26bN68mZEjRzJ58mQsFguBgYEsWrSIwMDAPKheRERERGzBFnk2t/4+m54vvviCKlWqMH/+fFauXImvry8jR45k7NixOX5eIiLZZbJmZF6MiIjIfyQlJeHn58djjz3Gl19+aetyREREREREREREREREpIBwsHUBIiJSMK1atYrw8HD69Olj61JERERERERERERERESkANFEBRERyZSgoCD27dvHhAkTKFOmDLt27bJ1SSIiIiIiIiIiIiIiIlKAaKKCiIhkyqxZsxg0aBDe3t58/fXXti5HREREREREREREREREChhNVBAREREREREREREREREREZE8o4kKIiIiIiIiIiIiIiIiIiIikmfUqCAiIiIiIiIiIiIiIiIiIiJ5xsnWBeQUi8XC+fPnKVasGCaTydbliIiIiEguslqtXLt2DT8/Pxwc7K/3VtlWREREpPBQthURERERe5GZbGs3jQrnz5+nQoUKti5DRERERPLQ2bNnKV++vK3LyHHKtiIiIiKFj7KtiIiIiNiLjGRbu2lUKFasGGCcdPHixW1cjYiIiIjkpqioKCpUqJCSAe2Nsq2IiIhI4aFsKyIiIiL2IjPZ1m4aFW6MDStevLgCr4iIiEghYa+jY5VtRURERAofZVsRERERsRcZybb2t+iZiIiIiIiIiIiIiIiIiIiI5FtqVBAREREREREREREREREREZE8o0YFERERERERERERERERERERyTNqVBAREREREREREREREREREZE8o0YFERERERERERERERERERERyTNqVBAREREREREREREREREREZE8o0YFERERERERERERERERERERyTNqVBAREREREREREREREREREZE8o0YFERERERERERERERERERERyTNqVBAREREREREREREREREREZE8o0YFERERERERERERERERERERyTNqVBAREREREREREREREREREZE8o0YFERERERERERERERERERERyTNZalT49NNP8ff3x83NjcDAQLZt23bbfRMTE3n33XepWrUqbm5uBAQEsGbNmjT7hYSE0Lt3b0qXLo27uzv169dnx44dWSlPRERERCTDlG1FRERERERERERE8lamGxWWLVvGsGHDGDt2LLt27SIgIID27dtz8eLFdPcfPXo0c+bMYcaMGRw6dIiXXnqJrl27snv37pR9rly5QosWLXB2dubXX3/l0KFDfPzxx5QsWTLrZyYiIiJSwF24AMeP27oK+6ZsKyIiIpJHYi/ANYVbERERESn4QqNDOXH5hK3LKPBMVqvVmpkDAgMDadq0KTNnzgTAYrFQoUIFhg4dyogRI9Ls7+fnx6hRoxg8eHDKtm7duuHu7s6iRYsAGDFiBH/99RebN2/O8olERUXh6elJZGQkxYsXz/LriIiIiOQHV65A7dpw8SJMnw5Dhti6ovwlp7Kfsq2IiIhIHki4Aj/VhriL0Hg61FS4vZW9Zz97Pz8REREpXCKuR1Dn0zpcir3EN92+oUfdHrYuKV/JTPbL1ESFhIQEdu7cSdu2bW++gIMDbdu25e+//073mPj4eNzc3FJtc3d3Z8uWLSmPV69eTZMmTejevTve3t40bNiQuXPn3rGW+Ph4oqKiUt1ERERE7MXEiRAWBlYrDB0Ko0YZ9yXnKNuKiIiI5JEDEyEuDLDCzqGwV+FWRERExN7EJsbauoQ88fb6twm/Ho7FauGZFc/w09GfbF1SgZWpRoWIiAjMZjM+Pj6ptvv4+BAaGpruMe3bt2fq1KkcO3YMi8XCunXrWLFiBRcuXEjZ5+TJk8yaNYvq1avz22+/MWjQIF555RUWLFhw21omT56Mp6dnyq1ChQqZORURERGRfOvkSZgxw7jfI7khd9IkeO45SEy0XV32RtlWREREJA9En4SjyeG2YnK4PTgJgp4Di8KtiIiISEG3N3QvD8x/gCKTilD709q8ue5N/vz3T5IsSbYuLcdtD9nOF7u+AOCBSg+QZEniyW+fZP3J9TaurGByyu03+OSTTxg4cCC1atXCZDJRtWpV+vfvz7x581L2sVgsNGnShEmTJgHQsGFDDhw4wOzZs+nbt2+6rzty5EiGDRuW8jgqKkp/0BUREbFjZ8/CvHmwaROULAm+vsatbNnUX729wdnZ1tVmz4gRkJAADz8My5ZBu3bw0kswf74xZWH5ciha1NZVFk7KtiIiIpIjYs7CyXlwcRO4lAQ3X+PmXhbck7+6+YKbNzgU8HC7ZwRYEsD3YWi5DI63g+0vwcn5EBsG9y8HJ4VbERERkYLm0vVLjPljDHN2zsFitQBwJOIIRyKOMGXrFEq6laRD9Q48VuMx2ldtT0n3kjauOHssVguDfxmMFSu97+nNvMfn0eO7Hqw6sorHlz7O2t5raVGxha3LLFAy1ahQpkwZHB0dCQsLS7U9LCwMX1/fdI/x8vJi1apVxMXFcenSJfz8/BgxYgRVqlRJ2ads2bLUqVMn1XG1a9fm+++/v20trq6uuLq6ZqZ8ERERKWCSkuDXX+Hzz+GXX8BiufsxJhOUKZN+E8N/txUrZuyfn2zdajQiODjARx8Z255/3qi5Rw/j+9GmDfz8M3h52bbWgk7ZVkRERPKUJQnO/wrHP4cLv4A1A+EWE7iWMZoX3P7bxPCfxganfBhuw7fCmeVgcoBGyeG22vNGzVt6wIVf4fc20PpncFO4FRERESkIzBYzn+/8nNF/jOZy7GUAetTtwTut3uFg+EF+PPojvxz7hcuxl1myfwlL9i/B0eRIy4oteazGYzxa41Fqlqlp47PIvC93fcn289sp5lKMD9t+iLOjM0u7LTWaFE6speOSjmzos4HGfo1tXWqBkalGBRcXFxo3bsz69evp0qULYFwxtn79eoYMGXLHY93c3ChXrhyJiYl8//339Lgxxxho0aIFwcHBqfY/evQolSpVykx5IiIiYifOnIEvvzRuISE3t7duDU8/bSx/EBoKFy4YX2/cDwsDsxnCw43b/v13fp/AQNi8Of9MYLBaYfhw437//lC//s3nHn0UNmwwvm7fDi1awJo1cMvn45JJyrYiIiKSJ2LOwIkvjVvsLeHWuzX4P20sfxAbCnEXkr+GQuwFiAsDqxniw40bdwm3pQOh3eb8M4HBaoVdyeG2Sn8ocUu4LfcoPLQBNj0Kl7fDuhbQZg14KNyKiIiI5Gd//vsnr/z6CnvD9gJQ37s+0ztMp7V/awDqetelR90emC1m/jn3Dz8e/ZGfjv7EwfCDbPp3E5v+3cTr616neqnqPFrjUR6r8RgtK7bE2TGfZNjbuBx7mZHrRwLwbpt3KVusLACuTq6s7LmSRxY9wuYzm3l40cNs6reJet71bFlugWGyWq3WzBywbNky+vbty5w5c2jWrBnTpk3j22+/5ciRI/j4+NCnTx/KlSvH5MmTAQgKCiIkJIQGDRoQEhLCuHHjOHXqFLt27aJEiRIAbN++nfvuu4/x48fTo0cPtm3bxsCBA/n888955plnMlRXVFQUnp6eREZGUrx48cx9F0RERCRdViucOGEsM1C2bO6+V1KSMSXg88+NqQE3Ekrp0tCvHwwcCDXv0mhrsUBEROrmhfQaGkJDISrKOGbpUujZM1dPLcO+/daopWhROHYs/e95cDC0bw///gs+PsakiUaN8r5WW8up7KdsKyIiUohYrRB9wlhmwD2Xw60lCc7/bExPOP8rkBxuXUtD5X5QbSAUv0u4tVogPuI/zQvJX/+7LTE53LZYCpXySbj991v4q6fx/X7sWPrf86hg+KM9xPwLbj7Q+hcoVfjCrb1nP3s/PxERkcLgXNQ53lz3Jt8c+AaAkm4lmdBmAi82eREnh7tfF3/yykl+PvozPx79kY2nN5JoSUx5ztPVk0eqPcKjNR6lQ7UOlC5SOtfOI6sG/TSI2TtnU8+7Hrtf3J3mnKPio2j7dVu2n9+Or4cvf/b7k+qlq9uoWtvKTPbLdKMCwMyZM5kyZQqhoaE0aNCA6dOnExgYCEDr1q3x9/dn/vz5AGzatIlBgwZx8uRJPDw86NixI++//z5+fn6pXvOnn35i5MiRHDt2jMqVKzNs2DAGDhyY4ZoUeEVERHJOVBQsWWI0DezebWwrWxYaN059+8//nWfJ6dPG5IR58+D8+ZvbH3zQaE7o2hVyYyL+uHEwfjw0bw5//53zr59Z8fFQuzacOmXU9c47t9/3/Hno2BH27gUPD1ixAtq1y7ta84OczH7KtiIiInYuMQpOLzGaBq4kh1v3slCyMZS65VYkB8Jt9GljcsLJeRB7S7j1eRCqDoQKXcExF8LtvnFwYDyUbg7t80G4NcfDT7Uh5hTUHw/17xBur5+HjR3h6l5w8oD7V0DZwhVu7T372fv5iYiI2LO4pDim/j2ViZsncj3xOiZMvND4Bd578D3KFCmTpde8Fn+NtSfW8tOxn/j56M+EXw9Pec7B5MB9Fe5jcNPBPFXvqZw6jWzZeX4nTec2xYqVTf020apSq3T3uxx7mTYL2rAvbB8Vildgc//NVCpR+Cas5nqjQn6kwCsiIpI9VquxpMDnn8M338D168Z2Z2djOQVLOkvo+vqm37xwt6VxExPhp5+M9/rtt5vTE8qUMZY8GDgQqudyw2lYGFSsCAkJRqNC8+a5+35389FH8MYbxvfv6FFjqsKdREbCE08Yy0E4OcH8+ZDBi/Wz7PhxY6mMbt3A1nHL3rOfvZ+fiIhIrrNa4dJ2OPE5nP4GzMnh1sHZWE7Bmk64dfNN3bhQqjG4ZyDcWhIh5CejEeLCb9ycnlDGWPKg6kAonsvhNjYMfqgIlgR4+G8oY+Nwe/gj2P2G8f177KgxVeFOEiJh8xMQtgFMTtB8PlTO5XB77Thc3AwVu4GzbfOWvWc/ez8/ERERe2S1Wvnx6I+89ttrnLxyEoAWFVowo8MMGpZtmGPvY7Fa2BayjZ+O/sSPR39kX9i+lOf+HvA3zcvbNtdarBbu+/I+gkKC6FW/F4ufWHzH/cOiw3hg/gMEXwqmWqlq/Nnvz5RlInKT1Wrl/LXz+BXzw3S3/37JZWpUUOAVERHJsMhIWLzYaBrYu/fm9tq14YUX4Nlnwc3NeG7nzpu3Q4fSb17w8UnbvFCunPH33VOn4IsvjOkJoaE3j3noIeO9OnfOnekJt9OvHyxYAE89ZTRn2EpEBFSrZvxv8dVXRl0ZER8PffvCsmXG448+guHDc7a26Gj47jujrj//NLa1aQPr1oGjY86+V2bYe/az9/MTERHJNQmRcHqx0TRw9ZZwW7wWVHsBKvcBRze4sgcu77x5izp8m+YFn3SaF5LDbfQpOPEFnJhnLL9wg89DxnuV75w70xNu5+9+cGoBVHoKWtgw3MZFwI/VIDESAudB1f4ZO84cD3/3hTPJ4bbhR1A7h8NtYjSc/Q5OfgUXk8OtTxtosw4cbBdu7T372fv5iYiI2JvgiGD+99v/WHN8DQB+xfyY0m4KT9d7Otc/BD8TeYbXfnuNFYdXcG/5e/nrub9s+sH7vN3zGLB6AB4uHgQPCcav2N2nsJ2LOsf9X93P6aunqeNVh039NmV5+sTdWK1W1p5Yyzsb32FbyDZ61u3JV52/wt3ZPVfeLyPUqKDAKyLpiI42PowNCjLWuW/a1FjXPXlJcZF86cIF4wPhzZuN6QXt2hlX/ru4ZO91rVbj38Lnnxsfct+YnuDqCj16GE0DLVrc+eKx69fTb14wm9Pu6+1tTC/YufPm9ARvb2N6wvPPGx/S28Lu3cbvAScno4mifHnb1PHqqzB9OgQEGN+jzDQAWCxGc8K0acbj114zGhYcHLJej9VqTJmYN8/4+YiONrY7OBjfq4QEGDUK3nsv6++RXfae/ez9/EQkByRGGx/GXgoy1rkv1dRY192lhK0rE7m92AtwYR2EbzamF5RtZyxV4JgD4fZSkNGc8O+yW6YnuELF7kbTgFfLO4fbpBi4svc/zQuHbtO84A1FKhr73Jie4OadPD3heShmo3B7eTesaWRMJOh8CorYKNzueBWOTocSAfDIzsw1AFgtsGs4BE8zHtd8DRp9BKZshtuIv43lOP5dBknJ4dbkYHyvLAlQdxQE2C7c2nv2s/fzExGRwifJkkRwRDC7Q3cTHBFMq0qtaFe14C9dFRUfxYRNE5gWNI0kSxIuji4Maz6MUa1G4eHikWd1nL92nuozqnM98TrfPvkt3et2z7P3vtWV2CvUmFmDiOsRfNTuI4bfl/Em2pNXTnL/V/dz/tp5Gvo2ZEPfDZRwK5Gj9W08vZExf4xhy5ktqbY3K9eMVT1X5ckkh/SoUUGBV0RucfAgzJoFX38N166lfb56dWjS5OatYUMoVizv6xQBiIszmhLWrjVu+/al3adoUWjd2mhaaNfOmHyQ0abSq1dvTk+49bXr1IEXX4TevaFUqazXf/268bq3Ni8cPJi6eaFdO6MR4vHHs99wkRNat4ZNm2DkSJg0Ke/f/+hRqFsXkpLg99+N6RKZZbXCxx8bS0cAPP20MQEhs9MpLlwwfld+9RUEB9/cXq0aPPcc9OljTFXo1cvY/ssv0KFD5uvNCfae/ez9/EQkG64ehGOz4NTXkJROuC1WHUo1MW6lm0DJhuCscCs2Yo4zRuuHroULa+FqOuHWqSh4twbfdkbjQvFMhNuEq7dMT7jltT3rQNUXoPKz4JqNcJt03WheuLLrZvNC5EFj6YgbfNsZjRDlHs9+w0VO+L01XNwEdUZCAxuE26ij8HNdsCbBg7+DbxbD7ZGPjaUjACo9Dc2/yvx0itgLxu/Kk19B1C3h1qMaVH3OmK5x8U/YmhxuW/8CfrYJt/ae/ez9/ERExL7FJcVx4OIBdl3Yxe4Lu9kdupt9YfuITYpNtd+z9zzLtEemUco9G/nTRixWC4v2LeKt398iNNqYFPZojUeZ+vBUqpfO5SXMbmPcxnGM3zSeyiUqc3jwYVyd8nBSWbIhvwzh0+2fUserDnte3IOzo3Omjj8ScYRWX7Ui/Ho491W4j996/5YjDR9bz25lzB9j2HBqAwCujq683PRlWlVqxYDVA7gce5nyxcvz49M/0sC3QbbfL7PUqKDAK1LoJSTAypXw2Wc3R5WD0ZTQrRucPAk7dhhf/8tkMj74vbV5ISAAihTJu/ql8LBajSkEa9fCb78ZH5jHxd183mQylk5o0wbOnTM+yA4PT/0a5cpB27ZGA0DbtsbSC/99j3/+uTk9ITY5Q7u5Qc+eRtPAvfdm/O/BmRUbazQvHDsG990HVarkzvtk1apV0LWr0aBx9mze/1vv2tWooVMn+Omn7L3W4sXGshFJSUbDw4oVcLdYlJAAP/9sTE/49debTSVFi0L37kaDQsv/XIA4eLDx+7VUKWMqRcWK2as7K+w9+9n7+YlIJpkT4NxKOPbZzVHlYDQlVOgG0Sfh8g7jaxom8Kx9s3mhVBMoGQBOCreSC6xWiDyU3Jjwm/GBufmWcIvJWDrBpw1cPwehv0P8f8KteznwbWs0APi2Bfd0wm3EP3DixvSE5HDr6AYVexhNA2Xuy71wmxRrNEVcOwZe94FHPgu3Z1fB5q7gUgq6nM37f+t/doVzq8CvE7TOZrg9tRj+6Wc0Pfg8BK1WgPNdcpE5Ac7/bCzHceHXm00lTkWN6RpVnks7XWP7YOP3q0sp6LAbiuZ9uLX37Gfv5yciIvYjKj6KPaF7jKaE0N3svrCbQ+GHMFvTjpAt6lyUBr4NKFusLCsOr8BiteDr4cusTrPoUqtL3hefDqvVSmxSLFdir3A59jKXYy9zJe6W+8nbd1zYwY7zOwCoXqo60x6ZRsfqHW1ae0xCDNVnVOdC9IVMTzPICXtC99D488ZYrBY29NlAm8ptsvQ6e0P30npBa67GXeXByg/y09M/ZXlZhh3ndzDmjzEpS3I4OzjzQuMXePv+t1OWpDh++TiPffMYRyKOUNS5KEu6LeHxmo9n6f2ySo0KCrwihdaZM8aHsV98AWFhxjZHR+PK7ZdfhgcfTD0O/dIl44rvHTtu3s6eTfu6jo7GFc+3Ni/cc0/mr1aW/CsiwviAOi8+pI6IMBoObkxNCAlJ/byfH7RvDw8/bDQelLll+SqLxVhuYd26m0tCxMenPj4g4GbTwtGjxr+JAwduPl+vnjE94ZlnoGTJ3DvPgsJsNpqYTp2COXOMxo28smmTMdHB0RH27zeapLJr3Tp44gljuYYGDYypB2XTmfJ14IDRnLBoUermlxYtjOaE7t1vP10mPt5oXtixAwIDjYawvJ6OYe/Zz97PT0QyKOaMcaX4iS8gLjncmhyNK7drvAw+D6Yehx5/Kfmq7x1waYfx9Xo64dbkCJ51b05dKNUEStyT+auVJf+KizA+oM6LD6njIoyGgxtTE2L/E27d/aBse/B92Gg8cLsl3FotxsSC0HXG7eJmsPwn3JYIMCYt+LSFa0eNfxORt4Rbz3pGc0Ll3uCicIvFDD9Wh5hT0GyO8b3JK2GbYH1r43dMx33GZIvsurAONj9hLNdQsoEx9cA9nXB79YDRnHB6UermF68WRnNCxe63ny5jjod1LY3fmaUDoe2feT4dw96zn72fn4hkjMVq4XLsZS7GXCQ8Jpzw6+Fpvl6Nu4qjgyNODk5pbs4Ozuluz/J+jnfez9XRlVLupSjpXhInBydbf/sKJYvVwvw981m8fzEmTHi4eFDUpShFnYsa952LUtQl9f2U59K57+LogumWZsWw6LCUZoRdoca0hBNXTqRbS5kiZWjo29C4lW1Io7KNqFaqGg7J/z32z7l/6P9Df45EHAHg6XpPM73DdMoUKZPu6+WE0OhQ1hxfw7moc2kaEG5tQog3x9/9xQAPFw/GtBrD/5r/D5f8MCkMmLd7HgNWD6CEWwmODz1O6SKl8+R9LVYL9391P1vPbqVn3Z4sfXJptl4v6FwQbRe2JTohmk7VO7Gi54pMfY/3hu7lnY3vsDp4NQCOJkf6N+jP6FajqVSiUpr9r8ZdpcfyHqw7uQ4TJj5o+wGv3/d6qp//3KRGBQVekULFYjE+mPvsM+NqZEvyEqK+vsYHjgMHZm7d+bAwo3lh+3bjQ7jt2282PdzK2dloVri1eaFuXWO7FBxHjsArrxg/Q2BcRe7tbdy8vNK/f+Oxl1fGPpxNSDAmGvz2m9GYsHOncSHYDW5u8MADRmNC+/bGMgwZzQyxsbBly83GhT170t/P3R2eesr4NxEYmHsXmBVU//d/MGyY8b0/cCBvvj8WCzRrZvw8vPSSsURNTtm1y1iS4eJF8Pc3fvZq1DCW/li61GhQ2L795v5lyxrLOvTvDzVrZuw9Tp+GRo3gyhXj39Ann+Rc/Rlh79nP3s9PRO7AajE+mDv2GZz/yXgM4OZrfOBYbWDm1p2PDUtuXtie3Lyw/WbTw60cnI1mhVuXjfCsa2yXgiPyCOx8xfjQH4yryF29wc0bXL2Mr/+9f+Oxq1fGPpw1J8Clf4yJCRfWGj9f3BJuHd3A+wGjMaFse+PD6oyGq6RYCN9ys3Hhyp7093N0h0o9jeUdyjRXuP2vI/8Hu4YZ3/uOeRRurRb4rZnx81DtJWiWg+H28i7Y2AHiLkJRf2jzGxSvYSz98e9So0Hh8i3h1r2ssaxDlf5QPIPhNvo0rGkECVegxivQJG/DbV5nv08//ZQpU6YQGhpKQEAAM2bMoFmzZunum5iYyOTJk1mwYAEhISHUrFmTDz74gEceeSTD76dsK2KfkixJXLp+Kd2Gg4sxF9NsvxR7CcuNbFvAeLp6Usq91G1vpd1Lp9lW0r1kvvmwtyAKOhfE0F+Hsv389rvvnEFODk4pDQ1mi5mwmHT+uwioULwCjco2SmlKaOjbkPLFy9/1Q964pDjGbxzPh1s/xGK14F3Um087fsqTdZ7MsXMIjghm1ZFVrApeRdC5IKxk7CNeJwcn4+fSrWSqn9FSbsZ9r6JedK3VlbLF0mkItSGzxUyjzxuxL2wfrzR7hU865E1GW7BnAf1+6EdR56IcGXKE8sUz8d/gt7Hp9CYeWfwIcUlxdK/TnSXdlty1CepQ+CHGbRzH8kPLAXAwOdD7nt680+odqpaqesdjE82JvLrmVWbtmIWTgxN7X9pLHa8caCTOADUqKPCKFAqXLhnrqM+eDSduaXRs08aYntC5c840DVitcP78zYkLNxoYLl1Ku6+rq3EFc5Mm0LSp8bVWLeNqaclfoqJgwgSYNs0Yk59VJUrcvpHBYoENG4xbdHTq4+rXvzk14f77jWaFnHDxIqxfbzQtbNxoTEx47jljekKJEjnzHvYoMtJoaIqONppJ2rXL/fdcvBh69zamFhw/bvzc5KSTJ42fsePHoXRp45xWrbq5tIiTkzFt5rnnjP2csnBxwE8/wWOPGfe//daYwpBX7D372fv5iUg64i8Z66gfmw3Rt4RbnzZQ/WUo3zlnmgasVog9f8vUhe3G/fh0wq2Dq3EFc6kmULqp8bV4LXBQuM13EqPgwAQ4Ms0Yk59VziWSmxe8bjY43GhksFogbINxS/pPuC1R/+bUBO/7jWaFnBB3EULXG00LYRuNiQlVnwP/Z8ClRM68hz1KiIRV5Y3/ndqsNSZS5LZTi+Hv3uBUDB4/bvzc5KTok7ChPUQfB9fSxtIg51bdXFrE5ATlHzemJ5RtD1m58jXkJ9iUHG5bfmtMYcgjeZn9li1bRp8+fZg9ezaBgYFMmzaN5cuXExwcjHc6/1Hy1ltvsWjRIubOnUutWrX47bffGDZsGFu3bqVhw4YZek9lW5GCIdGcSMT1iJTGgjTNBv9pRLgSeyXDH5LeqoRbCbyKeOFV1Avvot7G/eTHJdxKYLVaSbIkpXtLtCTe9rkc2d98c//YpFii4qOy9T31cPG4bSPDnRodXJ0K76SzsOgwRqwfwfw98wEo5lKMES1HUNGzIjEJMcQkxhCdEJ36fmLM7Z9LiCHRkpjue5kwUaN0DWNCgm8jGpZtSAPfBtmegrDj/A76/9CfAxeNKWBP1nmSTzt+infRzOcji9XC9pDtKc0JNyY23NCsXDPu8b4ndfPBrQ0zyY0JHi4eeXY1fU77/eTvtFvYDicHJw6+fJAapWvk6vtdjbtKzZk1uRhzkQ/afsCbLd7Msddec3wNj3/zOImWRPoG9GVe53kpUzludezSMcZvGs+S/UtSfs/2rNuTca3HUatMrQy/n9VqZea2mbg5uTGw8cAcO4+7UaOCAq+I3bJaYds2Y3rCsmU3R957ekLfvsZVyTkxOj0jdfz7b+rmhZ07jQ87/6tIEeOq41snL1SvnnoJCsk7VqvxAfEbb0BoqLHt8cdh6lSjueDiReMWHp7+/RuPw8ONJQMyysvL+KC4fXvja3qj+MW2XnkFZsyAjh3h559z971iY43JBWfPwqRJMHJk7rzPxYvw6KOppyfUq2c0J/TubfxcZtfIkfD+++DhYUz0qHrnZt4cY+/Zz97PT0SSWa1waZsxPeHfZTdH3jt7QuW+UP0l8MyjcBvzr9GwcHkHXNpuXBWdmE64dSwCpRqlnrxQrHrqJSgk71itcHox7H4D4pLDbbnHodFUo9kg7qJxiw+/ef/Wx/E3HkdAOuvu3parl/FBcdn2xofg6Y3iF9va8QocnQF+HaF1LofbpFj4qaax1EzAJKibS+E27iJsfDT19ATPesnNK72Nn/ns2jMSDr0PTh7QYQ8Uy5twm5fZLzAwkKZNmzJz5kwALBYLFSpUYOjQoYwYMSLN/n5+fowaNYrBgwenbOvWrRvu7u4sWrQoQ++pbCuSf5y+epqFexdyNurszckHtyy7kFkmTClXY99oNvAqcksDwn+2lylSBmfHgjOxK8mSxNW4q1yOvcyl65dSjdVPucVdTvP81birWWriuMHV0RV3Z3fcnNxwdzK+/vd243k3x3S2/Xffu7xGaffSNm+OSDQnMmPbDMZvGp/SINKvQT8mPzQZXw/fbL12gjkhpXnhxleL1UKtMrXwcPHIifLTiE+K570/32PylsmYrWZKu5dmZseZ9Kzb864NA/FJ8fxx+g9WHVnF6uDVXIi+kPKcs4MzD1Z+kC61uvB4zcfxK+aXK/XnN52WdOKXY7/QpVYXVvZcmavv9cqvrzBj2wxqlanF3pf25vhklJWHV9J9eXfMVjODmgzi046fpvxMnL56mgmbJrBg7wLMyf991rVWV8a3Hk99n/o5WkduUqOCAq+I3YmJgW++MUaj79p1c3vDhsb0hKefNkb225LFYkx2uNG8sGOH0bwQE5N232LFoHFj41a/vvHBYe3aRlOD5J7du2HoUPjrL+Nx9erGuPoOHTL/WhaLMfL+Tg0NcXHQooUxNaFBAzWn5HfHjhnNA1arsfxD3bq5916TJ8Pbb0OFChAcbCzNkVuio+Gtt4yJv/36Gb93crKBOikJ2rY1fo99/LExWSYv2Hv2s/fzEyn0kmLg9DdwbBZcuSXclmxoTE/wf9oY2W9LVgtcO3GzeeHyDqN5ISmdcOtUDEo1Nm4l6kOJelC8Njgp3Oaqy7th51AITw63xapD40/ALwvh1moxRt6n19gQfxHiwo0r171aQNmHjUkbak7J36KOGc0DWI3lH0rkYrg9OBn2vg1FKsCjweCUi+E2MRr2vAWYoEo/4/dOToZbSxJsaGs0QDT6GBzzJtzmVfZLSEigSJEifPfdd3Tp0iVle9++fbl69So//PBDmmNKly7Nhx9+yIABA1K29e7dmy1btnD69Ol03yc+Pp74G1eWYJxfhQoVlG1FbOjgxYN88NcHLNm/JOXDr/Q4mBwoU6RM6iaD/zQc3NqEUMq91F1HlxdGZouZyPjIlMaFdJsc4i6nef5K3BWbLI/h6erJ5Icm82KTF9O9uju3rTuxjlfWvJIyLaCJXxNmdJhB8/LN87yWnLb7wm76/9CfvWF7AehSqwuzOs1K03wRGRfJL8d+4YfgH/jl2C9cS7iW8lwxl2J0qtGJzjU706FaBzzdPPP0HPKDQ+GHuGfWPZitZr7q/BX9GvTLlffZG7qXRp83wmK1sO7ZdbSt0jZX3mfxvsU8u/JZrFh5/d7XebX5q0z8cyJf7v4yZQJIx+odebf1uzT2a5wrNeQmNSoo8IrYjSNHjOaEBQtuTitwdYWePY0GhWbN8vdypGaz8SHkrc0Lu3ffHL1+K5PJuBK5Xr3Utxo1cmYJi8Ls0iUYMwbmzDEaDIoWhdGj4bXX8u5DVSkYHn8cfvwRfHzgu++gZcucf4+LF6FaNbh2DRYuNCYbFHTx8Xn/b8nes5+9n59IoRV5xGhOOLXg5rQCB1eo1NNoUCidz8OtxQzXgpOXjEi+Xdl9c/R6KibwqGo0LXjWu/m1eI2cWcKiMIu/BPvGwPE5RoOBU1GoOxpqvZZnH6pKAbHpcQj5Edx8oOV34J0L4TbuIqyuBknX4N6FUNkOwq05Ps//LeVV9jt//jzlypVj69at3HvvvSnb33zzTTZt2kRQUFCaY3r16sXevXtZtWoVVatWZf369XTu3Bmz2ZyqGeFW48aNY/z48Wm2K9uK5L2gc0FM3jKZH4JvNiK1rdKWVhVbpZl2cKPxwBYfVIvBYrUQFR/F1birxCfFE5cUR1xSHLFJsSn3/3uLTUznOfMdnvvPa8YmxqY0r7So0IK5j82ltlceTHUDTl45yfC1w1l1ZBUAXkW8eL/t+/Rr0M+ufg4TzAlM3jyZ9za/R5IliZJuJZneYTpt/NuwOng1q4JX8cepP1ItUVHWoyyda3amS60utPZvbfOJF/nBjUkHYCyD8FmnzyjlXirHXt9qtdJqfiu2nNnCk3WeZHn35Tn22umZu3MuL/z0AgBODk4kWYwl/NpWacu7rd/l3gr33unwfE2NCgq8IgVaYiL88IOxvMMff9zcXqUKDBoE/fsb660XVImJcOjQzaaFgwdh/37jw/T0ODsbV3n/t4GhcuX8d4W+1QoREXDqFJw+nfqrh4dxVXfTpnlXj9kMc+fCqFFw+bKx7amnYMoUKF8+7+qQguPsWejUyfg36eRkTNwYNChnPzN6+WWjAatJEwgKyn//jgsKe89+9n5+IoWKJRHO/WAs7xB2S7j1qALVB0GV/sZ66wWVJREiDyU3LuyGyIMQud/4MD09Ds5QrGbaBgaPyvnvCn2r1VgSIfoUxJyGmFMQnfzVyQPqvAWl8zDcWsxwYi7sHQUJyeG20lPQcAoUUbiVdMSchU2d4Op+MDkZEzeq53C43f6y0YBVqgm0D8p//44LiPzcqBAeHs7AgQP58ccfMZlMVK1albZt2zJv3jxiY2PTfR9NVBCxLavVyvpT65m8ZTIbTm0AjCUanqj9BCNbjiyQV+dK7rFYLczaPosR60cQnRCNi6MLo+8fzVst38rxkfc3XE+8zvtb3ufDvz4k3hyPo8mRoc2GMrb1WEq4lciV98wP9oXto/8P/dl1YVe6z9cuU5sutbrQpVYXmvg1satmjZyQaE5k0uZJTPhzAmarGb9ifsx7fB7tq7XPkddfuHchfVb1oYhzEY4MPkIFzwo58rp3Mu2fabz222sA3F/xfia0mcAD/g/k+vvmNjUqKPCKFEjnzhkfKs+dCxeSl11ycDDWV3/5ZWjXzn4/0LNajausDxxIe4uOTv+YIkWgTp20DQx+frl7Id7Vq0bjQXrNCKdPp7/Uxa169oSJE3N/HfutW2HIEKMZBIwlNmbMgAcK/v/PSy6LiYEBA2DZMuNx//5G45SbW/Zf+/Bh42fRbIZNm6BVq+y/ZmFl79nP3s9PpFC4fg6OzzU+WI5NDrcmB/B71JieULad/X6gZ7UaV1lHHoCrB1J/TbpNuHUsAp51bjYu3GhicM/lcJtwNbkR4ZYmhBtfY06nv9TFrSr2hICJub+OffhW2DHEmGABxhIbjWeAj8Kt3EVSDPwzAM4kh9sq/aHpZ+CYA+E28jD8Uh+sZnhoo34esyE/L/1wQ1xcHJcuXcLPz48RI0bw008/cfDgwQy9r7KtSN6wWC38cOQHJm2ZxI7zOwDjKt3e9/TmrRZvUatMLRtXKPnZ2cizDPp5ED8f+xmAul51mfvY3By9qttqtbL80HJeX/s6Z6POAvBg5QeZ/sh06nrn4jJV+UiiOZEpW6cwftN4Es2JNC/fnC61utC5Zmdqlqlp6/IKhG0h23h25bMcvXQUgMFNB/Nhuw8p4pz1pQcj4yKpObMmYTFhTHpwEiPvH5lT5d7V2hNrcXNy4/6K92PKzxMWM0GNCgq8IgWGxQIbNhhXF//wg/HhHYC3NwwcCC+8ABUr2rZGW7Ja4cyZtM0Lhw8bo9bTU6JE2uaFevUyPoUiOjptA8Kt928swXEnfn7GxAd//5tf//zTGHNvtRpTIl5+2Vh+oUyZjNWVURcuGJMbFi40HpcoAe++a1wV76Ql8ySDrFb4+GPjZ8liMaYfrFgBFbLZSPvoo/Dzz9ClC6xcmSOlFlr2nv3s/fxE7JbVAmEbjKuLz/1gfHgH4OYNVQdCtRegaCEPt9fPpG1eiDwMltuEW+cSaacvlKiX8SkUidFGw8GNqQg3mhJu3E/MQLh19zMmPhT1h6KVwcMfLv4JpxYCVmNKRPWXjeUX3HI43MZegN1vwenkcOtcAu5517gqXutBS0ZZrXDkY9jzlvF7qlQTuH8FFM1muN34KJz/Gcp3hlarcqTUwiovs19gYCDNmjVjxgxjdLLFYqFixYoMGTKEESNG3PX4xMREateuTY8ePZg0aVKG3lPZViR3JZoTWbJ/CR/89QGHIw4D4O7kzsBGAxl+33Aqehbi/CmZYrVa+fbgtwz9dSjh18MxYWJIsyFMfHAixVyLZeu194ft55U1r7Dx9EYAKnlWYmr7qXSt1dVuPpzNjMi4SBLMCXgV9bJ1KQXS9cTrvLXuLWZunwlAjdI1WNR1EU3LZW3i3WtrXmNa0DSql6rO/kH7tdRGNqlRQYFXJN+7cgXmz4fZs+Ho0ZvbW7UyPsDu2hVccmeylF1ISoITJ9I2MBw7drPZ4798fVM3Lvj6Gk0Q/21GiIi4+/t7e6duQqhc+eb9ihVvf+X53r3GB7+//WY8Ll4cRoyAV181JkRkR2IiTJ8O48fDtWvGhXcDBsCkSeClvCdZ9PvvxhSQy5eNn6Ply7M+lWP9emjb1miYOXgQatTI2VoLG3vPfvZ+fiJ2J+EKnJwPx2bDtVvCrXcr4wPs8l0hl8am2gVLEkSfSNvAcO3YzWaP/3LzTd244OZrNEGkTEVIbkaIz0C4dfNO3YRQtPItjQkVb3/l+ZW9xge/F5LDrXNxqDMCar4KTtkMt5ZECJ4O+8dD0jXABFUHQMAkcFO4lSwK/R229DSWDnH1gpbLsz4FIXQ9bGhrLCnR6SAUV7jNjrzMfsuWLaNv377MmTOHZs2aMW3aNL799luOHDmCj48Pffr0oVy5ckyePBmAoKAgQkJCaNCgASEhIYwbN45Tp06xa9cuSpQokaH3VLYVyR3XE68zb/c8pmydwpnIMwB4unoypNkQXg18VR+ASpZdun6J19e9zvw98wGoULwCszrNolONTpl+rSuxVxi7cSyfbf8Ms9WMm5MbI1qM4I0Wb2TrCngRMKYR9P+hP+evncfR5MjoVqMZdf8onB2dM/wa+8P203BOQ8xWM2ueWZNjS0kUZmpUUOAVybd27DCmJ3zzDdxYyrBYMejTx7jivW7hmPCUa+LiIDg4bQPD6dOZe52SJdNvQqhcGSpVgqJFs1fnunXw5puwZ4/xuFw5Y+pB377g6Ji113vlFThyxHjcrBnMnAlN83DJYLFfp07BE08YP6+OjjB1Kgwdmrkp1GYzNG5sNOsMHWo01Uj22Hv2s/fzE7Ebl3YY0xP+/QbMyeHWqRhU7mNc8V5C4TZbzHEQFZy2gSHmdOZex6Vk+k0IHpWhaCVwyma4vbAO9rwJV/YYj93LGVMPKvcFhyyE2wvrYOcrEJUcbks3gyYzobTCreSA6FOw+Qnj59XkCI2mQo1MhluLGdY0hqt7jWObKNxmV15nv5kzZzJlyhRCQ0Np0KAB06dPJzAwEIDWrVvj7+/P/PnzAdi0aRODBg3i5MmTeHh40LFjR95//338/Pwy/H7KtiI562rcVT7b/hnT/plG+PVwAHyK+jDs3mG81OQlirvq35nkjHUn1vHiTy9y6uopAJ6u9zTTHpmGd1Hvux5rtpj5cveXvL3+bS7FXgKgW+1ufPzwx1QqUSlX65bC5XLsZV7++WWWHTSWOmvq15SFXRdmaCkNq9VK6wWt+fPfP+laqysreq7I5WoLBzUqKPCK5CvXrxtrvc+aBdu339x+zz3G9IRevYxmBck90dFw6FDq5oXwcGP6wX+bEfz9wdMz92uyWIyGlVGj4N9/jW316sEHH0CHDhn7O9m//8KwYcZIfjCueH//fejXDxzsdMlnsY3r142laBYvNh4/+yzMmQPu7hk7fv586N/f+Ld1/HjOL3lSGNl79rP38xMp0JKuw7/LjAaFy7eE2xL3GNMT/HuBs8JtrkqMhshDqZsX4sOhSMWbDQgpExH8wSUPwq3VAqe/gX2jICY53HrWgwYfgF8Gw23Mv7BrGJxNDreuXtDgfajSD0wKt5KDkq7DthfgdHK49X8Wms0BpwyG25Pz4Z/+4OwJjx3P+SVPCiF7z372fn4ieSUsOoxp/0zjsx2fERUfBYB/CX/evO9N+jXoh7tzBn+Pi2RCTEIM4zaOY+o/U7FYLZRyL8XUh6fSJ6DPbZds2Hp2K0N/HcquC7sAqONVh+mPTOehKg/lZelSyHyz/xte/uVlrsZdxd3JnSntpvBy05fvuLTIkv1LeGbFM7g7uXN48GE10eQQNSoo8IrkC8eOGUs7fPWVsdQDGMs5dO9uNCjce2/mLtoQ+xQXB599Bu+9d/PnpHVrmDIFmjRJ/5jYWOP5yZON4x0dYfBgY9mHDE6eFMk0qxU++QRef92YkNCokdEkU+ku+TUmxljm4fx54+f29dfzpl57Z+/Zz97PT6RAijoGx2fDya+MpR4AHFygYnejQaGMwq1gTIE4+hkcfO/mz4l3a2g4BUrfJtwmxcLhKXBosnG8yRGqD4Z7xoNLibyqXAobqxWCP4HdrxtLrJRsBK1WGFNG7iQpBn6sAbHnocGHUOeNvKnXztl79rP38xPJbaevnmbKX1OYt2cecUlxANT1qsvIliPpWa8nTg5ONq5QCoMd53fw/Orn2Ru2F4C2Vdoy59E5VClZJWWf89fO89bvb7Fo3yLAWIpkfOvxvNz05UyN4hfJqnNR5+j/Q39+P/k7AA9XfZh5j8+jXPFyafaNio+i1sxaXIi+wIQ2ExjdanRel2u31KigwCtiUxs3wqRJxjj+G/z94aWX4LnnjKveRf7ryhWj8WD6dIiPN7Y99RRMnAhVkvOu1QqrV8Nrrxnj+MFoapg+HerXt0nZUgj98Qf06AEREcZkhG+/hTZtbr//u+/C2LHG78HDh8HtNstcS+bYe/az9/MTKVDCNsLBSRB6S7gt6g/VX4Iqz4Gbwq2kI+EKHJwMwdPBkhxuKz0FARPB45ZwG7Iadr4GMcnh1ru1MUa/hMKt5JGwP2BLD4iPANcy0PJb8LlDuN3/Luwfa/wefPQwOCrc5gR7z372fn4iueXgxYN88NcHLNm/BLPVDEBguUDevv9tHq3xKA6auCR5LNGcyNS/pzJu0zjikuJwd3JnQpsJDGo6iJnbZjLhzwlEJ0RjwsRzDZ9j0kOTMrRMhEhOslgtfLrtU978/U3ikuIo6VaSWZ1m0bNez1T7vb72dT7++2OqlarG/kH7cXNSrs0palRQ4BWxib/+gnfegQ0bjMcmE3TsaExPaN/euOpd5G7OnIExY2DhQuNvt87Oxs/QU08ZExPWrDH2K18ePvrI+MBYFy9KXjtzBrp2hV27jN9tU6bA//6X9mfxwgWoXt2YqrB0KfTsme7LSRbYe/az9/MTKRDC/4J970BYcrjFBH4djekJZduDg8KtZEDMGdg3Bk4tBKzg4Gz8DFV6CvaPhwvJ4bZIeWj4EVRUuBUbiDkDf3aFK7uMiR4Np0DN/6X9WYy9AD9WN6YqtFgKlRRuc4q9Zz97Pz+RnBZ0LojJWybzQ/APKdvaVWnHyJYjae3f+o5jzEXywrFLx3jhpxfYeHojAO5O7sQmxQJGM82MDjNoWq6pDSsUgcPhh3l25bPsvLATgKfrPc2nHT+lpHtJDoUfImB2AEmWJH7p9QsdqnewcbX2RY0KCrwieSooyGhQWLvWeOzsDAMHGuPNK1e2bW1ScO3dC2+9Bb/9lnq7i4vxs/X221C0qG1qEwFjCZKXXoKvvzYe9+oFc+dCkSI39xk4EL74Apo3h61b9blDTrL37Gfv5yeSr0UEGQ0Kocnh1sEZqg6E2q+Dh8KtZNGVvbDnLbjwn3Dr4GL8bNV9G5wUbsWGkmJh+0twKjncVuoFgXPB6ZZwGzQQTnwBpQPh4b8VbnOQvWc/ez8/kZxgtVpZf2o9k7dMZsMpo1HWhIknaj/BiJYjaOJ3myWkRGzEarUyb/c8hq8dTmR8JD5Fffig7Qc8G/Cspn1IvpFoTuS9P99j4uaJmK1myhUrx1edv2Lylsn8cfoPOtfszKqnVtm6TLujRgUFXpE8sXOnMc7855+Nx05OxtIOo0ZBxYq2rU3sx7p18OabsGcPdOoE06ZBtWq2rkrEYLXCzJkwbBgkJUFAAKxcaTRp7d8PDRqAxWJMnLnvPltXa1/sPfvZ+/mJ5EuXd8K+sXA+OdyanKDqc1B3FBRVuJUccmEd7HkTruwBv07QeBoUU7iVfMJqhaMzYdcwsCZBiQBotdJo0rq6H35tAFYLtPsLvBRuc5K9Zz97Pz+R7LBYLfxw5AcmbZnEjvM7AHBycKL3Pb15q8Vb1CpTy8YVitxZaHQo60+u57Gaj1HcVb/jJX8KOhfEsyuf5djlYynb3JzcODz4MP4l/G1XmJ3KTPZzyqOaRMSO7N0L48bBqlXGY0dH6NMHRo+GKlVsWZnYo3btjKaYCxegXDlbVyOSmskEQ4caDQrduxu/H5s0MZZ5+Ogjo0nhySfVpCAikq9d2Qv7x8G5VcZjkyNU7gP1RoOHwq3ksLLtwHenMUK/iMKt5DMmE9QcCiUDYEt3uLoX1jQxlnk4/JHRpFDhSTUpiIjkgERzIkv2L+GDvz7gcMRhwBifP7DRQIbfN5yKnmqUlYLB18OXZ+55xtZliNxRYPlAdr+4mzfWvcGsHbMAGNlypJoU8gFNVBCRDDt40GhQ+O4747HJBM88Yyz7UL26TUsTEbG5c+fgiSdg+3bj96PVaiyFc/gwVK1q6+rsj71nP3s/P5F84epBo0HhbHK4xQT+z0C9d6C4wq2IFHLXz8GfT8Dl7YAJsBpL4XQ6DMUUbnOavWc/ez8/kcy4nnidebvnMWXrFM5EngHA09WTIc2G8Grgq3gV9bJxhSIi9u2PU3+wN2wvLzd9GRdHF1uXY5c0UUFEclRwMIwfb1whbLUaH8D16GEs+1C7tq2rExHJH8qXhz//hJdfhq++MrYNHaomBRGRfCcqGPaPh3+XAlbABBV7QP2x4KlwKyICQJHy0O5P2P4ynEwOt9WHqElBRCSLrsZd5bPtnzHtn2mEXw8HwKeoD681f41BTQdpZL6ISB5pU7kNbSq3sXUZkkyNCiJyW8ePw4QJsGiRMb4cjKuFx42D+vVtWpqISL7k5gZffgmtWxuTFcaOtXVFIiKS4tpxODABTi8yxpcDVHgC6o+DEgq3IiJpOLpB4Jfg3dqYrHDPOFtXJCJS4IRFhzHtn2l8tuMzouKjAPAv4c+b971Jvwb9cHd2t3GFIiIitqNGBRFJ4/RpeO89mD8fzGZj2+OPGw0KDRvasDARkQLAZII+fYybiIjkA9Gn4eB7cHI+WJPDbbnHjQaFUgq3IiJ3ZDJBlT7GTUREMuz01dNM+WsK8/bMIy4pDoC6XnUZ0XIET9V7CicHfTQjIiKi/zcUkRRnz8LEicbVwElJxrYOHYxlH5o2tW1tIiIiIiKZEnMWDk6EE1+CNTnclu0A94yH0gq3IiIiIpLzDl48yAd/fcCS/UswJzfJBpYL5O373+bRGo/iYHKwcYUiIiL5hxoVRITz52HyZPj8c0hIMLa1bQvvvgv33mvb2kREREREMuX6eTg0GY5/DpbkcOvbFuq/C14KtyIiIiKSfVarlUuxlzh66WjKbdeFXfx24reUfdpVacfIliNp7d8ak8lkw2pFRETyJzUqiBRiYWHwwQcwaxbEGRPIeOABo0GhVSvb1iYiIiIikimxYXDoAzg+C8zJ4db7AbjnXfBWuBURERGRzItOiObYpWM3GxIuG1+PXTrGlbgrafY3YaJr7a6MbDmSJn5NbFCxiIhIwaFGBZFCKCICPvwQZs6E2Fhj2333wYQJ0KaNsQSliIiIiEiBEBcBhz+EozPBnBxuy9wH90wAH4VbEREREbmzBHMCp66cSjUd4UZDwvlr5+94bEXPitQoXYMapWpQvXR1Hqn2CLXK1MqjykVERAo2NSqIFCKXL8PHH8P06RAdbWxr1syYoPDww/obroiIiIgUIPGX4cjHEDwdkpLDbelmxhIPZRVuRUREROQmi9XCuahzqZsRLh3l2OVjnLpyCrPVfNtjyxQpYzQjJDck3LhftVRVijgXycOzEBERsS9qVBApBK5ehWnT4P/+D6KijG2NGhkNCh076m+4IiIiIlKAJFyFI9Mg+P8gMTnclmxkLPHgp3ArIiIiUlhZrVYirkdw7PKxdBsS4pLibntsUeeiN5sRbrlVL1Wdku4l8/AsRERECg81KojYsWvXjOkJH31kNCsA1K9vNCh07qy/4YqIiIhIAZJ4zZiecPgjSLxqbCtR35igUF7hVkRERKSwiE6I5tilY2mWaTh66ShX467e9jhnB2eqlqpK9VLV0zQklPUoi0l5UkREJE+pUUHEDsXEwMyZMGUKXLpkbKtdG8aPh27dwMHBtvWJiIiIiGRYUgwcnQmHp0B8crgtXhvuGQ8VuoFJ4VZERETE3iSYEzh15VTqyQjJDQnnr52/47EVPSumWaahRukaVCpRCScHfSQiIiKSX+j/lUXsSGwszJoF778P4eHGtho1YOxY6NkTHB1tW5+IiIiISIYlxcKxWXDofYhPDrfFakD9sVCxJzgo3IqIiIjYk90XdjNu0zgOXjzI6aunMVvNt93Xq4hXquUZbtyvVqoa7s7ueVi1iIiIZFWWLj359NNP8ff3x83NjcDAQLZt23bbfRMTE3n33XepWrUqbm5uBAQEsGbNmtvu//7772Mymfjf//6XldJECqW4OJgxA6pUgeHDjSaFKlVg/nw4eBB69VKTgoiIyO0o24rkM+Y4CJ4Bq6vA7uFGk4JHFWg+HzodBP9ealIQERERsTOb/93MA/MfYHXwak5cOYHZaqaoc1Ea+jakZ92ejGk1hoVdFxL0fBCX37zMxTcusuW5LczrPI+R94+kW51u1PepryYFERGRAiTTExWWLVvGsGHDmD17NoGBgUybNo327dsTHByMt7d3mv1Hjx7NokWLmDt3LrVq1eK3336ja9eubN26lYYNG6bad/v27cyZM4d77rkn62ckUogkJMC8eTBxIpw7Z2yrVAnGjIE+fcDZ2bb1iYiI5HfKtiL5iDkBTs6DgxPhenK4LVoJ6o2Byn3AQeFWRERExB6tO7GOzks7E5sUS2v/1ox9YCw1StegrEdZTCaTrcsTERGRXJLpiQpTp05l4MCB9O/fnzp16jB79myKFCnCvHnz0t1/4cKFvP3223Ts2JEqVaowaNAgOnbsyMcff5xqv+joaJ555hnmzp1LyZIls3Y2IoVEYiJ88QVUrw6DBhlNCuXKGcs+HD0KAwaoSUFERCQjlG1F8gFLIhz/An6sDtsHGU0K7uWg6Sx49ChUHaAmBRERERE7tTp4NY9+8yixSbF0rN6RX3r9Qmv/1vgV81OTgoiIiJ3LVKNCQkICO3fupG3btjdfwMGBtm3b8vfff6d7THx8PG5ubqm2ubu7s2XLllTbBg8eTKdOnVK99p3Ex8cTFRWV6iZi78xm+PprqFULBg6EM2fA1xemT4fjx+Gll8DFxdZVioiIFAzKtiI2ZjHDya/hp1qwbSBcPwNuvtB4Ojx+HKq/BI4KtyIiIiL2aumBpTyx7AkSzAl0q92NlT1XaukGERGRQiRTSz9ERERgNpvx8fFJtd3Hx4cjR46ke0z79u2ZOnUqrVq1omrVqqxfv54VK1ZgNptT9lm6dCm7du1i+/btGa5l8uTJjB8/PjPlixRoGzbAsGGwd6/x2MsLRowwJiq4K7+LiIhkmrKtiA2FboBdw+Bqcrh19YI6I6D6IHBSuBURERGxd/N2z+P51c9jxUrve3rzVeevcHLI9ErVIiIiUoBleumHzPrkk0+oXr06tWrVwsXFhSFDhtC/f38cHIy3Pnv2LK+++iqLFy9Oc3XanYwcOZLIyMiU29mzZ3PrFERs6uhR6NwZHnrIaFLw9ITJk+HUKaNxQU0KIiIieUfZViSboo7Cps6w4SGjScHZEwImQ+dTUHuYmhRERERECoEZQTMYsHoAVqy82PhFFnRZoCYFERGRQihT/+9fpkwZHB0dCQsLS7U9LCwMX1/fdI/x8vJi1apVxMXFcenSJfz8/BgxYgRVqlQBYOfOnVy8eJFGjRqlHGM2m/nzzz+ZOXMm8fHxODo6pnldV1dXXF1dM1O+SIFy6RK8+y589hkkJYGjozE9YexYKFPG1tWJiIgUfMq2Inko/hLsfxeOfQbWJDA5GtMT6o0FN4VbERERkcLi/S3vM3L9SACGNR/GRw9/hMlksnFVIiIiYguZmqjg4uJC48aNWb9+fco2i8XC+vXruffee+94rJubG+XKlSMpKYnvv/+ezp07A/DQQw+xf/9+9uzZk3Jr0qQJzzzzDHv27En3D7ki9iwhAaZNg+rVYfp0o0mhUyfYvx9mzFCTgoiISE5RthXJA+YEODINfqwOR6cbTQp+naDjfmgyQ00KIiIiIoWE1Wpl9IbRKU0K77R6R00KIiIihVym5ykNGzaMvn370qRJE5o1a8a0adOIiYmhf//+APTp04dy5coxefJkAIKCgggJCaFBgwaEhIQwbtw4LBYLb775JgDFihWjXr16qd6jaNGilC5dOs12EXtmtcIPP8Abb8Dx48a2+vXh44+hXTvb1iYiImKvlG1FconVCud+gN1vQHRyuC1RHxp+DGUVbkVEREQKE6vVyrDfhjEtaBoAH7T9gDdbvGnbokRERMTmMt2o0LNnT8LDw3nnnXcIDQ2lQYMGrFmzBh8fHwDOnDmTskYvQFxcHKNHj+bkyZN4eHjQsWNHFi5cSIkSJXLsJEQKul27YPhw2LjReOztDe+9B889Zyz5ICIiIrlD2VYkF1zeBbuGw8WNxmM3b7jnPajyHDgo3IqIiIgUJmaLmUE/D2LurrkAzOwwk8HNBtu4KhEREckPTFar1WrrInJCVFQUnp6eREZGUrx4cVuXI5Ih58/DqFGwYIFx0Zmrq9GwMGIEFCtm6+pERETyL3vPfvZ+fmKnrp+HfaPg5ALACg6uUHs41BkBzgq3IiIit2Pv2c/ez09uL8mSRL9V/Vi8fzEOJge+fPxL+jXoZ+uyREREJBdlJvtleqKCiGRfTIyxpMMHH8D168a2Xr1g0iSoVMm2tYmIiIiIZEpSDBz+GA59AObkcFupFzSYBEUVbkVEREQKo/ikeJ7+/mlWHlmJk4MTi7ouome9nrYuS0RERPIRNSqI5CGLBRYtgrffhpAQY9u998LUqdC8uW1rExERERHJFKsFTi2CvW9DbHK4LXMvNJoKZRRuRURERAqr64nX6fZtN9YcX4OroyvLuy/nsZqP2bosERERyWfUqCCSR/78E4YNg507jcf+/sZEhe7dwWSyaWkiIiIiIplz8U/YNQwuJ4fbov7Q4AOoqHArIiIiUphdi7/GY988xqZ/N1HEuQg/PPUDbau0tXVZIiIikg+pUUEklx0/Dm+9BStWGI+LFYNRo+DVV8HNzba1iYiIiIhkyrXjsOctOJscbp2KQb1RUPNVcFS4FRERESnMrsReocPiDgSFBFHctTg/9/qZlhVb2rosERERyafUqCCSS65ehQkTYMYMSEwEBwd44QUYPx68vW1dnYiIiIhIJiRchQMT4OgMsCSCyQGqvgD3jAc3hVsRERGRwu5izEUeXvgwe8P2Usq9FL/1/o0mfk1sXZaIiIjkY2pUEMlhiYkwZw6MGweXLhnb2reHjz6CevVsWpqIiIiISOZYEuHYHDgwDuKTw23Z9tDwIyihcCsiIiIiEBIVQtuFbTkScQSfoj6se3Yd9X3q27osERERyefUqCCSQ6xW+PlneP11CA42ttWpAx9/DI88YtvaREREREQyxWqF8z/D7tchKjncetaBhh+Dn8KtiIiIiBhOXTnFQ18/xKmrpyhfvDzr+6ynRukati5LRERECgA1KojkgH37YPhw+P1347GXF7z7Ljz/PDjpX5mIiIiIFCRX9sHu4RCaHG5dveCed6Hq8+CgcCsiIiIihuCIYNoubMu5qHNULVmV3/v8jn8Jf1uXJSIiIgWE/sokkg2hoTBmDMybBxYLuLjA//4Hb78Nnp62rk5EREREJBNiQ2HfGDg5D6wWcHCBmv+Dum+Di8KtiIiIiNy0L2wf7Ra242LMRWqXqc3vfX7Hr5ifrcsSERGRAkSNCiJZEBsL//d/MHkyREcb23r0gPffh8qVbVubiIiIiEimJMVC8P/BwcmQlBxuK/aABu+Dh8KtiIiIiKS2PWQ77Re150rcFRr4NmBt77V4FfWydVkiIiJSwKhRQSQTrFb45hsYMQLOnjW2NWsGU6dCixa2rU1EREREJFOsVvj3G9gzAq4nh9vSzaDRVPBSuBURERGRtDb/u5lOSzpxLeEazcs359dnfqWEWwlblyUiIiIFkBoVRDJo61YYNgyCgozHFSoYExSeegocHGxbm4iIiIhIpoRvhV3D4FJyuC1SwZigUOkpMCncioiIiEha606so/PSzsQmxdLavzWrn1pNMdditi5LRERECig1KojcxalTxgSFb781Hnt4wMiR8Npr4O5u29pERERERDIl+pQxQeFMcrh18oC6I6Hma+CkcCsiIiIi6VsdvJruy7uTYE6gQ7UOfN/je9ydlR9FREQk69SoIHIbkZEwaRJMmwYJCWAywYABMGEC+PraujoRERERkUxIiISDkyB4GlgSABNUHQD3TAB3hVsRERERub2lB5bSe0VvzFYz3Wp3Y0m3Jbg4uti6LBERESng1Kgg8h9JSfDFF/DOOxAebmx76CH4+GMICLBtbSIiIiIimWJJghNfwL53ID453Po8BI0+hpIKtyIiIiJyZ/N2z+P51c9jxUrve3rzVeevcHLQxwoiIiKSfUoUIrf47TcYPhwOHjQe16xpNCh07GhMVBARERERKTDO/wa7h0NkcrgtXhMafgx+CrciIiIicnczt81k6K9DAXix8Yt81ukzHEwONq5KRERE7IUaFUQwGhNefx3WrDEelyoF48fDiy+Cs7NtaxMRERERyZSrB2H363AhOdy6lIL646H6i+CgcCsiIiIid/f+lvcZuX4kAK81f42PH/4Yk5pdRUREJAepUUEKtYsXYexY+PxzsFiMpoShQ2H0aChZ0tbViYiIiIhkQtxF2DcWTnwOVovRlFBjKNQbDS4KtyIiIiJyd1arlTF/jGHi5okAjGk1hvGtx6tJQURERHKcGhWkUIqLg+nTYeJEiIoytj3xBHzwAVSrZtvaREREREQyxRwHwdPh4ERITA63FZ6ABh9AMYVbEREREckYq9XKsN+GMS1oGgAftP2AN1u8aduiRERExG6pUUEKnR07oEcPOHXKeNy4MUydCq1a2bYuEREREZFMu7QDtvSAmORwW6oxNJoK3gq3IiIiIpJxZouZQT8PYu6uuQDM7DCTwc0G27gqERERsWcOti5AJC+Fh0OXLkaTQrly8PXXsG2bmhREREREpACKC4c/uxhNCu7l4N6vof02NSmIiIjIHX366af4+/vj5uZGYGAg27Ztu+P+06ZNo2bNmri7u1OhQgVee+014uLi8qhayQtJliT6rurL3F1zcTA58FXnr9SkICIiIrlOExWk0DCboXdvCAmBmjWNBoXixW1dlYiIiIhIFljMsLU3xIZA8ZpGg4Kzwq2IiIjc2bJlyxg2bBizZ88mMDCQadOm0b59e4KDg/H29k6z/5IlSxgxYgTz5s3jvvvu4+jRo/Tr1w+TycTUqVNtcAaS0+KT4nn6+6dZeWQlTg5OLOq6iJ71etq6LBERESkENFFBCo2JE2HtWnB3h+++U5OCiIiIiBRgBydC6FpwdIeW36lJQURERDJk6tSpDBw4kP79+1OnTh1mz55NkSJFmDdvXrr7b926lRYtWtCrVy/8/f15+OGHefrpp+86hUEKhuuJ1+myrAsrj6zExdGFFT1WqElBRERE8owaFaRQ+P13GDfOuD9rFtSrZ9NyRERERESyLvR32D/OuN90FpRQuBUREZG7S0hIYOfOnbRt2zZlm4ODA23btuXvv/9O95j77ruPnTt3pjQmnDx5kl9++YWOHTvmSc2Se67FX6Pj4o6sOb6GIs5F+LnXzzxW8zFblyUiIiKFiJZ+ELsXEgK9eoHVCgMGQN++tq5IRERERCSLrofAX70AK1QdAFUUbkVERCRjIiIiMJvN+Pj4pNru4+PDkSNH0j2mV69eRERE0LJlS6xWK0lJSbz00ku8/fbbt32f+Ph44uPjUx5HRUXlzAlIjrkSe4UOizsQFBJEcdfi/NzrZ1pWbGnrskRERKSQ0UQFsWtJSfDUUxAeDgEBMGOGrSsSEREREckiSxL89RTEh0OJAGiscCsiIiK5a+PGjUyaNInPPvuMXbt2sWLFCn7++WcmTJhw22MmT56Mp6dnyq1ChQp5WLHczcWYi7RZ0IagkCBKuZdifZ/1alIQERERm9BEBbFro0bBli1QrBgsXw7u7rauSEREREQki/aOgvAt4FQMWi4HJ4VbERERybgyZcrg6OhIWFhYqu1hYWH4+vqme8yYMWN49tlnef755wGoX78+MTExvPDCC4waNQoHh7TXwY0cOZJhw4alPI6KilKzQj4REhVC24VtORJxBJ+iPqx7dh31ferbuiwREREppDRRQezW6tXw4YfG/a++gurVbVuPiIiIiEiWnVsNh5PDbfOvoLjCrYiIiGSOi4sLjRs3Zv369SnbLBYL69ev59577033mOvXr6dpRnB0dATAarWme4yrqyvFixdPdRPbO331NK3mt+JIxBHKFy/Pn/3/VJOCiIiI2JQmKohdOnUK+iYv1/vqq9Ctm23rERERERHJsuhT8HdyuK35KlRUuBUREZGsGTZsGH379qVJkyY0a9aMadOmERMTQ//+/QHo06cP5cqVY/LkyQA89thjTJ06lYYNGxIYGMjx48cZM2YMjz32WErDguR/wRHBtF3YlnNR56hSsgrr+6zHv4S/rcsSERGRQk6NCmJ34uOhRw+4ehUCA29OVRARERERKXDM8bClByRehdKB0EDhVkRERLKuZ8+ehIeH88477xAaGkqDBg1Ys2YNPj4+AJw5cybVBIXRo0djMpkYPXo0ISEheHl58dhjjzFx4kRbnYJk0r6wfbRb2I6LMRepXaY2v/f5Hb9ifrYuS0RERAST9XYzugqYqKgoPD09iYyM1DixQm7IEPj0UyhVCnbvhooVbV2RiIiI5DR7z372fn6SCduHwLFPwaUUdNgNRRVuRURE7I29Zz97P7/8bHvIdtovas+VuCs08G3A2t5r8SrqZeuyRERExI5lJvs53PFZkQJm2TKjSQFg0SI1KYiIiIhIAfbvMqNJAeC+RWpSEBEREZEM23JmCw99/RBX4q7QvHxz/uj7h5oUREREJF9Ro4LYjeBgeP554/7bb0OHDratR0REREQky6KCISg53NZ9G/wUbkVEREQkY9adWMfDCx/mWsI1Wvu3Zm3vtZRwK2HrskRERERSUaOC2IXr1+HJJyE6Glq3hvHjbV2RiIiIiEgWJV2HzU9CUjR4t4b6CrciIiIikjGrg1fz6DePEpsUS4dqHfil1y8Ucy1m67JERERE0lCjgtiFwYPhwAHw8YElS8DJydYViYiIiIhk0Y7BEHkA3HygxRJwULgVERERkbtbemApTyx7ggRzAk/UfoKVPVfi7uxu67JERERE0pWlRoVPP/0Uf39/3NzcCAwMZNu2bbfdNzExkXfffZeqVavi5uZGQEAAa9asSbXP5MmTadq0KcWKFcPb25suXboQHBycldKkEJo3D+bPBwcHWLoUypa1dUUiIiJSkCjbSr5yYh6cnA8mB2ixFNwVbkVERETk7ubtnkev73thtprpfU9vlj25DFcnV1uXJSIiInJbmW5UWLZsGcOGDWPs2LHs2rWLgIAA2rdvz8WLF9Pdf/To0cyZM4cZM2Zw6NAhXnrpJbp27cru3btT9tm0aRODBw/mn3/+Yd26dSQmJvLwww8TExOT9TOTQmHvXmOaAsCECcayDyIiIiIZpWwr+cqVvcY0BYB7JoBPa5uWIyIiIiIFw8xtMxmwegBWrLzY+EUWdFmAk6ZyiYiISD5nslqt1swcEBgYSNOmTZk5cyYAFouFChUqMHToUEaMGJFmfz8/P0aNGsXgG58mA926dcPd3Z1Fixal+x7h4eF4e3uzadMmWrVqlaG6oqKi8PT0JDIykuLFi2fmlKSAioqCJk3g2DHo2BF+/NGYqiAiIiL2L6eyn7Kt5BuJUbCmCVw7Bn4d4YEfjakKIiIiYvfsPfvZ+/nZ2vtb3mfk+pEAvNb8NT5++GNMJpONqxIREZHCKjPZL1N/+UpISGDnzp20bdv25gs4ONC2bVv+/vvvdI+Jj4/Hzc0t1TZ3d3e2bNly2/eJjIwEoFSpUrfdJz4+nqioqFQ3KTysVhgwwGhSqFABvv5aTQoiIiKSOcq2km9YrfDPAKNJoUgFuPdrNSmIiIiIyF2N2TAmpUlhTKsxalIQERGRAiVTf/2KiIjAbDbj4+OTaruPjw+hoaHpHtO+fXumTp3KsWPHsFgsrFu3jhUrVnDhwoV097dYLPzvf/+jRYsW1KtX77a1TJ48GU9Pz5RbhQoVMnMqUsDNnAnffQfOzvDtt1C6tK0rEhERkYJG2VbyjaMz4ex34OAMLb8FV4VbEREREbmzbSHbeG/zewC8/9D7vNvmXTUpiIiISIGS65fpfPLJJ1SvXp1atWrh4uLCkCFD6N+/Pw63ufx98ODBHDhwgKVLl97xdUeOHElkZGTK7ezZs7lRvuRDQUEwfLhxf8oUaN7ctvWIiIhI4aFsKzkuIgh2J4fbBlOgjMKtiIiIiNzdptObAHi85uO81fItG1cjIiIiknmZalQoU6YMjo6OhIWFpdoeFhaGr69vusd4eXmxatUqYmJi+Pfffzly5AgeHh5UqVIlzb5Dhgzhp59+4o8//qB8+fJ3rMXV1ZXixYunuon9u3QJevSAxETo1g1eecXWFYmIiEhBpWwrNhd/Cbb0AEsiVOgGNRVuRURERCRjgkKCAGhRoYWNKxERERHJmkw1Kri4uNC4cWPWr1+fss1isbB+/XruvffeOx7r5uZGuXLlSEpK4vvvv6dz584pz1mtVoYMGcLKlSvZsGEDlStXzuRpSGFgsUCfPnDmDFSrBl9+CZpmJiIiIlmlbCs2ZbXA333g+hnwqAaBCrciIiIiknHbQrYB0KxcMxtXIiIiIpI1Tpk9YNiwYfTt25cmTZrQrFkzpk2bRkxMDP379wegT58+lCtXjsmTJwMQFBRESEgIDRo0ICQkhHHjxmGxWHjzzTdTXnPw4MEsWbKEH374gWLFiqWsCezp6Ym7u3tOnKfYgQ8/hF9+AVdX+O478PS0dUUiIiJS0Cnbis0c+hDO/wIOrnD/d+CicCsiIiIiGXPh2gXORp3FhInGZRvbuhwRERGRLMl0o0LPnj0JDw/nnXfeITQ0lAYNGrBmzRp8fHwAOHPmTKo1euPi4hg9ejQnT57Ew8ODjh07snDhQkqUKJGyz6xZswBo3bp1qvf66quv6NevX+bPSuzOpk0wapRxf+ZMCAiwbT0iIiJiH5RtxSbCNsG+5HDbZCaUVLgVERERkYy7MU2hrnddirkWs3E1IiIiIlljslqtVlsXkROioqLw9PQkMjJSa/ramdBQaNjQ+NqnD8yfr6m4IiIihZ29Zz97P79CLTYUfm0IcaFQuQ80n69wKyIiUsjZe/az9/OzhVHrRzFpyySea/AcX3b+0tbliIiIiKTITPZzuOOzIjZmNkOvXkaTQt268Nln+juuiIiIiBRQFjNs7WU0KXjWhaYKtyIiIiKSedvOGxMVAssH2rgSERERkaxTo4Lka2PHwh9/gIcHfPcdFC1q64pERERERLJo/1gI+wOcPKDld+CkcCsiIiIimWOxWlKWfmhWrpmNqxERERHJOjUqSL71668wcaJx//PPoVYt29YjIiIiIpJl53+Fg8nhttnn4KlwKyIiIiKZd/TSUaLio3B3cqeedz1blyMiIiKSZWpUkHzp7Fl49lnj/qBB8PTTtq1HRERERCTLYs7C38nhtvog8Fe4FREREZGsCToXBEBjv8Y4OTjZuBoRERGRrFOjguQ7CQnQowdcugSNG8P//Z+tKxIRERERySJzAmzpAfGXoFRjaKRwKyIiIiJZl7Lsg5+WfRAREZGCTY0Kku+89Rb88w+UKAHLl4Orq60rEhERERHJoj1vwaV/wLkEtFwOjgq3IiIiIpJ1284nNyqUU6OCiIiIFGxqVJB8ZcUKmDbNuL9gAVSubNNyRERERESy7uwKCJ5m3L93AXgo3IqIiIhI1sUlxbE3dC8AgeUDbVyNiIiISPaoUUHyjePHoX9/4/4bb8Djj9u2HhERERGRLLt2HP5JDre134DyCrciIiIikj17QveQaEnEq4gXlTwr2bocERERkWxRo4LkC7Gx0L07REVBy5YwcaKtKxIRERERyaKkWNjSHRKjwKslBCjcioiIiEj2bQsxln0ILB+IyWSycTUiIiIi2aNGBckXXn0V9uwBLy9YuhScnW1dkYiIiIhIFu18Fa7sAVcvaLEUHBRuRURERCT7gkKCAGjm18zGlYiIiIhknxoVxOYWLoS5c8FkgiVLoFw5W1ckIiIiIpJFpxbCibmACVosgSIKtyIiIiKSM25MVGhWTo0KIiIiUvCpUUFs6uBBeOkl4/7YsdC2rW3rERERERHJsqsHYVtyuK0/FnwVbkVEREQkZ1y6fonjl48D0LRcUxtXIyIiIpJ9alQQm4mOhu7d4fp1aNcORo+2dUUiIiIiIlmUGA1buoP5Ovi2g7oKtyIiIiKSc7af3w5A9VLVKeVeysbViIiIiGSfGhXEJqxWePFFOHwY/Pxg0SJwdLR1VSIiIiIiWWC1wrYXIeowuPvBfYvAQeFWRERERHKOln0QERERe6NGBbGJOXNgyRKjOWHZMvD2tnVFIiIiIiJZdHwO/LsETI7QYhm4KdyKiIiISM4KCgkCILBcoI0rEREREckZalSQPLdzJ7z6qnH//fehZUvb1iMiIiIikmWXd8LO5HDb4H3wVrgVERERkZxltVo1UUFERETsjhoVJE9dvQrdu0NCAnTuDMOH27oiEREREZEsSrgKm7uDJQHKd4ZaCrciIiIikvNOXz1NxPUInB2cCfANsHU5IiIiIjlCjQqSZ6xW6N8fTp2CypVh/nwwmWxdlYiIiIhIFlit8E9/iDkFRStD8/kKtyIiIiKSK24s+9DAtwFuTm42rkZEREQkZ6hRQfLM1KmwahW4uMDy5VCihK0rEhERERHJoiNT4dwqcHCB+5eDSwlbVyQiIiIidkrLPoiIiIg9UqOC5Im//oK33jLuT5sGjRvbtBwRERERkawL/wv2JIfbxtOglMKtiIiIiOSeGxMVAssF2rgSERERkZyjRgXJdeHh0LMnmM3w9NPw0ku2rkhEREREJIviwmFLT7CaodLTUE3hVkRERERyT6I5kV0XdgGaqCAiIiL2RY0KkqvMZujdG0JCoFYt+PxzLd0rIiIiIgWUxQxbe0NsCBSvBc0UbkVEREQkdx24eIC4pDg8XT2pXrq6rcsRERERyTFqVJBcNXEirF0LRYrAd9+Bh4etKxIRERERyaKDEyF0LTgWgZbfgbPCrYiIiIjkrhvLPjQr1wwHk/6cLyIiIvZDyUZyze+/w7hxxv3Zs6FuXZuWIyIiIiKSdaG/w/5xxv1ms6GEwq2IiIiI5L5tIdsALfsgIiIi9keNCpIrQkKgVy+wWuH55+HZZ21dkYiIiIhIFl0Pgb96AVao+jxUVrgVERERkbyhRgURERGxV2pUkByXlARPPQXh4dCgAUyfbuuKRERERESyyJIEfz0F8eFQsgE0VrgVERERkbwRFR/FofBDgBoVRERExP6oUUFy3KhRsGULFC8Oy5eDu7utKxIRERERyaK9oyB8CzgXh5bLwUnhVkRERETyxs7zO7FipaJnRXw9fG1djoiIiEiOUqOC5KjVq+HDD437X30F1arZth4RERERkSw7txoOJ4fb5l9BMYVbEREREck7N5Z9CCwXaONKRERERHKeGhUkx5w6BX37Gvf/9z944gmbliMiIiIiknXRp+Dv5HBb839QQeFWRERERPJWUEgQoGUfRERExD6pUUFyRHw89OgBV69C8+bwwQe2rkhEREREJIvM8bClByRehdLNoYHCrYiIiIjkvRsTFdSoICIiIvZIjQqSI4YPhx07oFQpWLYMXFxsXZGIiIiISBbtGg6Xd4BLKWi5DBwVbkVEREQkb4VEhRByLQQHkwONyza2dTkiIiIiOU6NCpJty5bBp58a9xctgooVbVuPiIiIiEiW/bsMjiWH2/sWQVGFWxERERHJezemKdTzrkdRl6I2rkZEREQk56lRQbIlOBief964P2oUdOhg23pERERERLIsKhiCksNt3VHgp3ArIiIiIraRsuyDn5Z9EBEREfukRgXJsuvX4cknIToa2rSB8eNtXZGIiIiISBYlXYfNT0JSNPi0gfoKtyIiIiJiO0EhQQAElg+0cSUiIiIiuUONCpJlgwfDgQPg6wtLloCjo60rEhERERHJoh2DIfIAuPnCfUvAQeFWRERERGzDbDGz4/wOAJqV00QFERERsU9ZalT49NNP8ff3x83NjcDAQLZt23bbfRMTE3n33XepWrUqbm5uBAQEsGbNmmy9ptjevHkwfz44OMA33xjNCiIiIiIFkbKtcGIenJwPJgdo8Q24K9yKiIiIiO0EXwrmWsI1ijoXpa5XXVuXIyIiIpIrMt2osGzZMoYNG8bYsWPZtWsXAQEBtG/fnosXL6a7/+jRo5kzZw4zZszg0KFDvPTSS3Tt2pXdu3dn+TXFtvbuNaYpALz3HrRubdNyRERERLJM2Va4steYpgBwz3vg09qm5YiIiIjktsw01bZu3RqTyZTm1qlTpzysuPAJOmcs+9DYrzGOmvQlIiIidspktVqtmTkgMDCQpk2bMnPmTAAsFgsVKlRg6NChjBgxIs3+fn5+jBo1isE3PtkGunXrhru7O4sWLcrSa6YnKioKT09PIiMjKV68eGZOSTIhKgqaNIFjx6BjR/jxR2OqgoiIiEheyqnsp2xbyCVGwZomcO0Y+HWEB340piqIiIiI5KG8zH7Lli2jT58+zJ49m8DAQKZNm8by5csJDg7G29s7zf6XL18mISEh5fGlS5cICAjgiy++oF+/fhl6T2XbzBv00yBm75zN6/e+zpSHp9i6HBEREZEMy0z2y9Rf4RISEti5cydt27a9+QIODrRt25a///473WPi4+Nxc3NLtc3d3Z0tW7Zk+TVvvG5UVFSqm+QuqxUGDDCaFCpWhK+/VpOCiIiIFFzKtoWc1Qr/DDCaFIpUhHu/VpOCiIiI2L2pU6cycOBA+vfvT506dZg9ezZFihRh3rx56e5fqlQpfH19U27r1q2jSJEidO/ePY8rL1yCQoyJCoHlA21ciYiIiEjuydRf4iIiIjCbzfj4+KTa7uPjQ2hoaLrHtG/fnqlTp3Ls2DEsFgvr1q1jxYoVXLhwIcuvCTB58mQ8PT1TbhUqVMjMqUgWzJwJ330Hzs7w7bdQurStKxIRERHJOmXbQu7oTDj7HTg4Q8tvwVXhVkREROxbVptqb/Xll1/y1FNPUbRo0dvuoybc7IlNjGVf2D4AmpVrZuNqRERERHJPrl8y9Mknn1C9enVq1aqFi4sLQ4YMoX///jhk81L8kSNHEhkZmXI7e/ZsDlUs6QkKguHDjfsffQSBauYVERGRQkjZ1k5EBMHu5HDb8CMoo3ArIiIi9i+rTbU3bNu2jQMHDvD888/fcT814WbP7tDdmK1mfIr6UKG4vnciIiJivzL1F9UyZcrg6OhIWFhYqu1hYWH4+vqme4yXlxerVq0iJiaGf//9lyNHjuDh4UGVKlWy/JoArq6uFC9ePNVNcselS9CjByQmQvfuMHSorSsSERERyT5l20Iq/hJs6QGWRKjYHWoo3IqIiIhkxJdffkn9+vVp1uzOV/mrCTd7gs7dXPbBZDLZuBoRERGR3JOpRgUXFxcaN27M+vXrU7ZZLBbWr1/Pvffee8dj3dzcKFeuHElJSXz//fd07tw5268puc9igT594MwZqF4dvvgClI9FRETEHijbFkJWC/zdB66fgWLVIVDhVkRERAqPrDbVAsTExLB06VIGDBhw1/dRE272bDu/DYBmflr2QUREROxbpmfUDhs2jLlz57JgwQIOHz7MoEGDiImJoX///gD06dOHkSNHpuwfFBTEihUrOHnyJJs3b+aRRx7BYrHw5ptvZvg1xXb++AN++QXc3GD5ctB/V4iIiIg9UbYtZML+gPO/gKMbtFwOzgq3IiIiUnhkp6l2+fLlxMfH07t379wus9DbFmI0KgSW1/JkIiIiYt+cMntAz549CQ8P55133iE0NJQGDRqwZs2alLXNzpw5k2qN3ri4OEaPHs3Jkyfx8PCgY8eOLFy4kBIlSmT4NcV21q0zvj71FAQE2LYWERERkZymbFvIhCaH20pPQUmFWxERESl8hg0bRt++fWnSpAnNmjVj2rRpaRp1y5Urx+TJk1Md9+WXX9KlSxdKly5ti7ILjfCYcE5eOQlAE78mNq5GREREJHeZrFar1dZF5ISoqCg8PT2JjIzUOLEc1LQp7NgBCxeCGqZFREQkv7D37Gfv52cza5rC5R1w70KorHArIiIi+UNeZ7+ZM2cyZcqUlKba6dOnExhoXL3funVr/P39mT9/fsr+wcHB1KpVi7Vr19KuXbtMv5+ybcb9cuwXOi3pRM3SNTky5IityxERERHJtMxkv0xPVJDC48oV2LXLuP/gg7atRUREREQkWxKuwJXkcOujcCsiIiKF15AhQxgyZEi6z23cuDHNtpo1a2In17rle0HnggAt+yAiIiKFg8Pdd5HCatMmsFigVi3w87N1NSIiIiIi2RC2CawWKF4LiijcioiIiEj+s+38NgCa+TWzcSUiIiIiuU+NCnJbGzYYXzVNQUREREQKvLDkcKtpCiIiIiKSD1mtVraFJDcqlFOjgoiIiNg/NSrIba1fb3x96CHb1iEiIiIikm1hyeHWV+FWRERERPKfE1dOcDn2Mi6OLgT4Bti6HBEREZFcp0YFSVdoKBw6BCYTtG5t62pERERERLIhNhQiDwEm8G5t62pERERERNK4MU2hoW9DXBxdbFyNiIiISO5To4Kk68ayDw0bQqlStq1FRERERCRbbiz7ULIhuCrcioiIiEj+o2UfREREpLBRo4Kk60ajwoNawldERERECrobjQq+CrciIiIikj8FhQQBEFgu0MaViIiIiOQNNSpIutYnL+H7kJbwFREREZGCLjQ53Poo3IqIiIhI/pNgTmD3hd2AJiqIiIhI4aFGBUnj1Ck4fRqcnKBlS1tXIyIiIiKSDdGnIOY0mJzAS+FWRERERPKffWH7iDfHU9KtJNVKVbN1OSIiIiJ5Qo0KksaNaQrNm4OHh21rERERERHJlhvTFMo0B2eFWxERERHJf7aFbAOMaQomk8nG1YiIiIjkDTUqSBobkpfwfVBL+IqIiIhIQReWHG59FG5FREREJH+6tVFBREREpLBQo4KkYrXebFR4SEv4ioiIiEhBZrXebFTwVbgVERERkfwpKCQIgMBygTauRERERCTvqFFBUjl0CMLCwN0dApWLRURERKQgizwEcWHg6A6lFW5FREREJP+JjIvkSMQRAJqWa2rjakRERETyjhoVJJX1yUv43n8/uLrathYRERERkWwJSw63XveDo8KtiIiIiOQ/O87vAMC/hD/eRb1tXI2IiIhI3lGjgqRyY9mHB7WEr4iIiIgUdCnLPijcioiIiEj+pGUfREREpLBSo4KkSEqCjRuN+w9pCV8RERERKcgsSRC20bjvo3ArIiIiIvnTtpBtADQr18zGlYiIiIjkLTUqSIrduyEyEkqUgIYNbV2NiIiIiEg2XNkNiZHgXAJKKtyKiIiISP5jtVo1UUFEREQKLTUqSIr1yUv4tm4Njo42LUVEREREJHtCk8OtT2twULgVERERkfznXNQ5QqNDcTQ50rCsmmtFRESkcFGjgqTYkLyE74NawldERERECrqw5HDro3ArIiIiIvnTjWUf6vvUp4hzERtXIyIiIpK31KggAMTHw5Ytxv2HtISviIiIiBRk5ngITw63vgq3IiIiIpI/adkHERERKczUqCAA/PMPxMaCry/Urm3rakREREREsiHiHzDHgpsvFFe4FREREZH86cZEhWblmtm4EhEREZG8p0YFAWB98hK+Dz4IJpNtaxERERERyZaw5HDro3ArIiIiIvmT2WJmx/kdgBoVREREpHBSo4IAsCF5Cd8HtYSviIiIiBR0Ycnh1lfhVkRERETyp0Phh4hJjMHDxYPaZTQFTERERAofNSoI0dEQZCyHxkNawldERERECrLEaIhIDrc+CrciIiLy/+3deVyVdd7/8fc57KDgykEQxcoll9whtLSAtOUmrZly0tSstEXvFqdFc2v5pdNMY3bP2Fjdac1dTdZk5YxmY7i0aKC4Vua+hQKaC4IKyvn+/uBw8iigyHKdg6/n48HDwznX9b0+18VZ3tGH7xfwTqXLPvSI7iE/u5/F1QAAANQ+GhWgr7+WTp+WWrWS4uKsrgYAAACoggNfS+a0FNZKqhdndTUAAABAmUobFRJiEiyuBAAAwBo0KkBpriV8mU0BAAAAPi/bFW6jCLcAAADwXulZJbOAxcfEW1wJAACANWhUgJa4lvBNYglfAAAA+LocV7h1EG4BAADgnQqKCvR97veSaFQAAACXLhoVLnG//CKtW1dym0YFAAAA+LTCX6TD60pu06gAAAAAL7Vm/xoVm2JF149W8/DmVpcDAABgCRoVLnHLlknGSB06SA6H1dUAAAAAVZCzTJKRIjpIIYRbAAAAeKeMrAxJzKYAAAAubTQqXOLSXEv4JrOELwAAAHxdjivcOgi3AAAA8F4Z+1yNCtE0KgAAgEsXjQqXuCWuJXxZ9gEAAAA+L8cVbqMItwAAAPBe6T+nS5ISmidYXAkAAIB1aFS4hGVlSZs3S3a71Lev1dUAAAAAVXA8S8rbLNnsUiThFgAAAN4pJz9Hu4/ulk029YjuYXU5AAAAlqFR4RJWOptC9+5SgwaWlgIAAABUTelsCg27S4ENLC0FAAAAKM+qfaskSVc2vVLhQeEWVwMAAGAdGhUuYWmuJXyTWcIXAAAAvi7bFW6jCLcAAADwXqXLPsTHxFtcCQAAgLVoVLhEGfPrjApJLOELAAAAX2bMrzMqOAi3AAAA8F4Z+zIkSfHRNCoAAIBL20U1KsycOVNxcXEKDg5WQkKCMjIyKtx+xowZatu2rUJCQhQbG6vHH39cJ0+edD9eXFysSZMmqVWrVgoJCdHll1+uF154QcaYiykPF2DbNmnvXikwUOrd2+pqAAAArEO2rQOObZOO75XsgVJTwi0AAAC8k9M4lZFV8t8bCc0TLK4GAADAWv6V3WHu3LkaO3asZs2apYSEBM2YMUP9+/fX5s2bFRkZec7277//vsaNG6fZs2erV69e2rJli+655x7ZbDZNnz5dkvTSSy/pb3/7m9555x116NBBq1ev1ogRIxQREaFHHnmk6meJc5TOppCYKIWGWlsLAACAVci2dUTpbApNEiV/wi0AAAC807ZD23Tk5BEF+QWpU2Qnq8sBAACwVKVnVJg+fbpGjhypESNGqH379po1a5ZCQ0M1e/bsMrdfsWKFevfurcGDBysuLk79+vXTXXfd5fGXaitWrNCAAQN0yy23KC4uTr/97W/Vr1+/8/41Gy5emmsJ32SW8AUAAJcwsm0dkeMKtw7CLQAAALxX6WwK3Zp1U4BfgMXVAAAAWKtSjQpFRUXKzMxUSkrKrwPY7UpJSdHKlSvL3KdXr17KzMx0/2J2x44dWrhwoW6++WaPbdLS0rRlyxZJ0vr16/XNN9/opptuKreWwsJC5eXleXzhwjid0tKlJbeTWMIXAABcosi2dYRxSjmucBtFuAUAAID3Sv85XZKUEMOyDwAAAJVa+uHgwYMqLi6Ww+HwuN/hcOinn34qc5/Bgwfr4MGDuuaaa2SM0enTp/Xggw/qmWeecW8zbtw45eXlqV27dvLz81NxcbFefPFFDRkypNxapk2bpueee64y5cNl40bp4EEpLEyKj7e6GgAAAGuQbeuIIxulwoOSf5jUmHALAAAA75Wxr6ThOT6G3AoAAFDppR8qa9myZZo6dapee+01rVmzRvPmzdOCBQv0wgsvuLf58MMP9d577+n999/XmjVr9M477+jll1/WO++8U+6448eP19GjR91fe/furelTqTOWuJbw7dNHCmCGMQAAgAtGtvVCOa5w27SPZCfcAgAAwDsVni7Uuux1kmhUAAAAkCo5o0KTJk3k5+ennJwcj/tzcnIUFRVV5j6TJk3S0KFDdf/990uSOnXqpIKCAo0aNUoTJkyQ3W7Xk08+qXHjxul3v/ude5vdu3dr2rRpGj58eJnjBgUFKSgoqDLlwyXNtYRvMkv4AgCASxjZto7IdoXbKMItAAAAvNf6nPUqKi5S45DGuqzhZVaXAwAAYLlKzagQGBio7t27K630/3RLcjqdSktLU2JiYpn7HD9+XHa752H8/PwkScaYCrdxOp2VKQ8X4NQpafnykttJLOELAAAuYWTbOsB5Ssp1hVsH4RYAAADeKyPr12UfbDabxdUAAABYr1IzKkjS2LFjNXz4cPXo0UPx8fGaMWOGCgoKNGLECEnSsGHDFBMTo2nTpkmSUlNTNX36dHXt2lUJCQnatm2bJk2apNTUVPcvdVNTU/Xiiy+qRYsW6tChg9auXavp06fr3nvvrcZThSStXi3l50uNGkmdO1tdDQAAgLXItj7ul9XS6XwpsJHUkHALAAAA75WelS5JSohJsLgSAAAA71DpRoVBgwbpwIEDmjx5srKzs9WlSxctWrRIDodDkrRnzx6PvyCbOHGibDabJk6cqKysLDVt2tT9y9tSf/nLXzRp0iQ9/PDDys3NVXR0tB544AFNnjy5Gk4RZ1riWsL3+usle6Xm0wAAAKh7yLY+LscVbh3XSzbCLQAAALzXmTMqAAAAQLKZ0jlqfVxeXp4iIiJ09OhRhYeHW12O10pKkpYulV57TXroIaurAQAAuDh1PfvV9fOrNmlJUs5SqedrUmvCLQAA8E11PfvV9fO7EIdPHFajPzaSJB148oCahDaxuCIAAICaUZnsx58dXUJOnJBWrCi5ncQSvgAAAPBlp09IB1zh1kG4BQAAgPdatW+VJOnyhpfTpAAAAOBCo8IlZMUKqbBQiomR2rSxuhoAAACgCg6ukJyFUkiMVJ9wCwAAAO/Fsg8AAADnolHhErLEtYRvUpJks1lbCwAAAFAlOa5w6yDcAgAAwLvRqAAAAHAuGhUuIWlpJf8mJ1tbBwAAAFBl2a5wG0W4BQAAgPcyxig9K12SlBCTYHE1AAAA3oNGhUvE0aPSqpKl0JTEEr4AAADwZUVHpUOucOsg3AIAAMB77Tm6R7kFufK3+6tLVBerywEAAPAaNCpcIr76SnI6pdatpdhYq6sBAAAAqiD3K8k4pfqtpTDCLQAAQGXMnDlTcXFxCg4OVkJCgjIyMirc/siRIxo9erSaNWumoKAgtWnTRgsXLqylan1f6bIPnR2dFRIQYnE1AAAA3sPf6gJQO5a4lvBlNgUAAAD4vBxXuGU2BQAAgEqZO3euxo4dq1mzZikhIUEzZsxQ//79tXnzZkVGRp6zfVFRkW644QZFRkbqn//8p2JiYrR79241aNCg9ov3UaXLPsTHxFtcCQAAgHehUeESkeZawjeZJXwBAADg63Jc4TaKcAsAAFAZ06dP18iRIzVixAhJ0qxZs7RgwQLNnj1b48aNO2f72bNn69ChQ1qxYoUCAgIkSXFxcbVZss8rnVGBRgUAAABPLP1wCcjNlTZuLLl93XWWlgIAAABUzclc6Ygr3EZeZ2kpAAAAvqSoqEiZmZlKSUlx32e325WSkqKVK1eWuc/8+fOVmJio0aNHy+FwqGPHjpo6daqKi4trq2yfdtp5Wpn7MyVJCTEJFlcDAADgXZhR4RKwdGnJv507S02bWlsLAAAAUCU5rnDboLMUTLgFAAC4UAcPHlRxcbEcDofH/Q6HQz/99FOZ++zYsUNLlizRkCFDtHDhQm3btk0PP/ywTp06pSlTppS5T2FhoQoLC93f5+XlVd9J+Jgfcn/Q8VPHVT+wvto2aWt1OQAAAF6FGRUuAUtcS/gmsYQvAAAAfF2OK9w6CLcAAAA1zel0KjIyUm+88Ya6d++uQYMGacKECZo1a1a5+0ybNk0RERHur9jY2Fqs2LuULvvQM6an7DZ+FQ8AAHAm0tElIM21hG8yS/gCAADA12W7wm0U4RYAAKAymjRpIj8/P+Xk5Hjcn5OTo6ioqDL3adasmdq0aSM/Pz/3fVdeeaWys7NVVFRU5j7jx4/X0aNH3V979+6tvpPwMelZ6ZJY9gEAAKAsNCrUcbt3S9u3S35+0rXXWl0NAAAAUAUFu6X87ZLNT4ok3AIAAFRGYGCgunfvrrTSv2pSyYwJaWlpSkxMLHOf3r17a9u2bXI6ne77tmzZombNmikwMLDMfYKCghQeHu7xdakqnVEhPibe4koAAAC8D40KdVzpsg/x8dIl/N8EAAAAqAuyXeG2cbwUQLgFAACorLFjx+rNN9/UO++8o02bNumhhx5SQUGBRowYIUkaNmyYxo8f797+oYce0qFDh/Too49qy5YtWrBggaZOnarRo0dbdQo+I78oXz8c+EESMyoAAACUxd/qAlCzShsVkljCFwAAAL4uxxVuHYRbAACAizFo0CAdOHBAkydPVnZ2trp06aJFixbJ4XBIkvbs2SO7/de/bYuNjdUXX3yhxx9/XFdddZViYmL06KOP6umnn7bqFHxG5r5MOY1TzcObq1n9ZlaXAwAA4HVoVKjDjJFKZ3JLZglfAAAA+DJjpBxXuI0i3AIAAFysMWPGaMyYMWU+tmzZsnPuS0xM1HfffVfDVdU9LPsAAABQMZZ+qMM2b5b275eCg6VylpkDAAAAfEPeZunEfskvWGpCuAUAAIB3S89Kl8SyDwAAAOWhUaEOK51NoXfvkmYFAAAAwGeVzqbQpHdJswIAAADgxZhRAQAAoGI0KtRhS1xL+CaxhC8AAAB8XY4r3EYRbgEAAODd9h/br715e2WTTd2bdbe6HAAAAK9Eo0IdVVwsLV1acjuZJXwBAADgy5zFUo4r3DoItwAAAPBupbMpdIjsoPpB9S2uBgAAwDvRqFBHrV8vHT4shYdL3WnaBQAAgC87sl4qOiwFhEuNCLcAAADwbu5lH6JZ9gEAAKA8NCrUUWmuJXz79pX8/a2tBQAAAKiSbFe4jewr2Qm3AAAA8G4Z+0oaFRKaJ1hcCQAAgPeiUaGOWuJawjeJJXwBAADg63Jc4dZBuAUAAIB3cxrnrzMqxDCjAgAAQHloVKiDioqkr74quZ3MEr4AAADwZcVFUq4r3EYRbgEAAODdtvyyRXmFeQrxD1HHyI5WlwMAAOC1aFSogzIypOPHpaZNpQ4drK4GAAAAqIJfMqTi41JQUymCcAsAAADvlv5zuiSpe3R3+bNsGQAAQLloVKiD0lxL+CYlSXZ+wgAAAPBlOa5w60iSbIRbAAAAeDf3sg/RLPsAAABQEX7TVwctcS3hm8QSvgAAAPB1Oa5wG0W4BQAAgPfL2OdqVIihUQEAAKAiNCrUMQUF0sqVJbeTWcIXAAAAvux0gXTQFW4dhFsAAAB4t5OnT2p99npJUkLzBIurAQAA8G40KtQx334rnToltWghXXaZ1dUAAAAAVXDgW8l5SgptIdUj3AIAAMC7rctep1POU2oa2lQtI1paXQ4AAIBXo1GhjklzLeGbnCzZbNbWAgAAAFRJtivcRhFuAQAA4P0ysn5d9sFGfgUAAKgQjQp1zBLXEr5JLOELAAAAX5fjCrcOwi0AAAC8X3pWuiQpIYZlHwAAAM6HRoU65PBhKTOz5DaNCgAAAPBpRYelQ65wS6MCAAAAfMCZMyoAAACgYjQq1CHLl0vGSO3aSdHRVlcDAAAAVEHOcklGCm8nhRJuAQAA4N1+Of6Lth3aJknqGdPT4moAAAC8H40KdUiaawnf5GRr6wAAAACqLMcVbh2EWwAAAHi/VftWSZJaN2qtRiGNLK4GAADA+9GoUIcscS3hy7IPAAAA8Hk5rnAbRbgFAACA92PZBwAAgMq5qEaFmTNnKi4uTsHBwUpISFBGRkaF28+YMUNt27ZVSEiIYmNj9fjjj+vkyZMe22RlZenuu+9W48aNFRISok6dOmn16tUXU94laf9+6ccfJZtNuu46q6sBAADwHWRbL3Riv3T0R0k2KfI6q6sBAAAAzis9K12SlBCTYHElAAAAvsG/sjvMnTtXY8eO1axZs5SQkKAZM2aof//+2rx5syIjI8/Z/v3339e4ceM0e/Zs9erVS1u2bNE999wjm82m6dOnS5IOHz6s3r176/rrr9fnn3+upk2bauvWrWrYsGHVz/ASsXRpyb9du0qNmFkMAADggpBtvVSOK9w27CoFEW4BAADg3YwxzKgAAABQSZVuVJg+fbpGjhypESNGSJJmzZqlBQsWaPbs2Ro3btw5269YsUK9e/fW4MGDJUlxcXG66667lJ6e7t7mpZdeUmxsrObMmeO+r1WrVpU+mUtZmmsJ32SW8AUAALhgZFsvle0Kt1GEWwAAAHi/XUd26eDxgwqwB6hzVGerywEAAPAJlVr6oaioSJmZmUpJSfl1ALtdKSkpWrlyZZn79OrVS5mZme4pdHfs2KGFCxfq5ptvdm8zf/589ejRQ3fccYciIyPVtWtXvfnmmxXWUlhYqLy8PI+vS9kS1xK+SSzhCwAAcEHItl4sxxVuHYRbAAAAeL/SZR+6RHVRsH+wxdUAAAD4hko1Khw8eFDFxcVyOBwe9zscDmVnZ5e5z+DBg/X888/rmmuuUUBAgC6//HJdd911euaZZ9zb7NixQ3/729/UunVrffHFF3rooYf0yCOP6J133im3lmnTpikiIsL9FRsbW5lTqVN27JB27ZL8/aVrr7W6GgAAAN9AtvVS+Tukgl2SzV+KJNwCAADA+7HsAwAAQOVVqlHhYixbtkxTp07Va6+9pjVr1mjevHlasGCBXnjhBfc2TqdT3bp109SpU9W1a1eNGjVKI0eO1KxZs8odd/z48Tp69Kj7a+/evTV9Kl6rdDaFq6+WwsKsrQUAAKAuI9vWgmxXuG1yteRPuAUAAID3K21USIhJsLgSAAAA3+FfmY2bNGkiPz8/5eTkeNyfk5OjqKioMveZNGmShg4dqvvvv1+S1KlTJxUUFGjUqFGaMGGC7Ha7mjVrpvbt23vsd+WVV+rjjz8ut5agoCAFBQVVpvw6K821hG8yS/gCAABcMLKtl8pxhVsH4RYAAADe71TxKWXuz5TEjAoAAACVUakZFQIDA9W9e3ellf6fcZX8xVhaWpoSExPL3Of48eOy2z0P4+fnJ0kyxkiSevfurc2bN3tss2XLFrVs2bIy5V2SjPl1RoUklvAFAAC4YGRbL2SMlOMKt1GEWwAAAHi/73O/18nTJxURFKHWjVtbXQ4AAIDPqNSMCpI0duxYDR8+XD169FB8fLxmzJihgoICjRgxQpI0bNgwxcTEaNq0aZKk1NRUTZ8+XV27dlVCQoK2bdumSZMmKTU11f1L3ccff1y9evXS1KlTdeeddyojI0NvvPGG3njjjWo81brphx+k3FwpJKRk6QcAAABcOLKtlzn6g3QyV/ILkRoTbgEAAOD90rPSJZXMpmC31fhKywAAAHVGpRsVBg0apAMHDmjy5MnKzs5Wly5dtGjRIjkcDknSnj17PP7KbOLEibLZbJo4caKysrLUtGlTpaam6sUXX3Rv07NnT33yyScaP368nn/+ebVq1UozZszQkCFDquEU67bS2RSuvVYKDLS2FgAAAF9DtvUypbMpNL1W8iPcAgAAwPtlZGVIYtkHAACAyrKZ0jlqfVxeXp4iIiJ09OhRhYeHW11OrRkwQJo/X3rpJempp6yuBgAAoHbU9exX18+vXMsHSFnzpS4vSe0JtwAA4NJQ17NfXT+/jq911A8HftBnv/tMt7a91epyAAAALFWZ7MdcVD7s9Glp2bKS20ks4QsAAABf5jwt5S4rue0g3AIAAMD75RXm6ccDP0piRgUAAIDKolHBh61ZI+XlSQ0aSF27Wl0NAAAAUAWH1kin8qSABlJDwi0AAAC8X+a+TBkZtYhooah6UVaXAwAA4FNoVPBhS1xL+F53neTnZ2kpAAAAQNXkuMKt4zrJTrgFAACA98vIypAkJcQkWFwJAACA76FRwYelpZX8m5xsbR0AAABAleW4wq2DcAsAAADfkJ6VLollHwAAAC4GjQo+qrBQ+uabkttJLOELAAAAX1ZcKB1whdsowi0AAAB8Q+mMCjQqAAAAVB6NCj5q5Urp5EkpKkq68kqrqwEAAACq4OBKqfikFBwlhRNuAQAA4P2y8rKUdSxLdptd3Zt1t7ocAAAAn0Ojgo9a4lrCNylJstmsrQUAAACokhxXuHUQbgEAAOAbSmdT6BjZUWGBYRZXAwAA4HtoVPBRaa4lfJNZwhcAAAC+LtsVbqMItwAAAPAN7mUfoln2AQAA4GLQqOCDjh2TMkpysJJYwhcAAAC+7NQx6RdXuHUQbgEAAOAb0rPSJUkJzRMsrgQAAMA30ajgg77+Wjp9WrrsMikuzupqAAAAgCrI/Voyp6V6l0n14qyuBgAAADivYmexVu9bLUmKj2FGBQAAgItBo4IPWuJawpfZFAAAAODzclzhltkUAAAA4CM2/7JZx4qOKTQgVO2btre6HAAAAJ9Eo4IPSnMt4ZvMEr4AAADwdTmucOsg3AIAAMA3pP9csuxDj+ge8rf7W1wNAACAb6JRwcf88ou0bl3J7euvt7QUAAAAoGoKf5EOryu57SDcAgAAwDdkZGVIkuKjWfYBAADgYtGo4GOWLi35t2NHyeGwthYAAACgSnJc4TaioxRCuAUAAIBvSM8qmVEhoXmCxZUAAAD4LhoVfMwS1xK+SSzhCwAAAF+X4wq3DsItAAAAfMOJUye0IWeDJCk+hhkVAAAALhaNCj4mzbWEbzJL+AIAAMDXZbvCbRThFgAAAL5hbfZaFZtiOcIcig2PtbocAAAAn0Wjgg/5+WdpyxbJbpf69LG6GgAAAKAKjv8sHdsi2exSJOEWAAAAviH951+XfbDZbBZXAwAA4LtoVPAhpcs+9OghNWhgaSkAAABA1WS7wm2jHlJgA0tLAQAAAC5Uxr4MSVJ8NMs+AAAAVAWNCj6ktFEhiSV8AQAA4OtyXOHWQbgFAACA78jIcjUqxNCoAAAAUBU0KvgIY6Q01xK+ySzhCwAAAF9mjJTjCrdRhFsAAAD4hgMFB7Tj8A5JUs+YnhZXAwAA4NtoVPAR27ZJP/8sBQZKvXpZXQ0AAABQBce2Scd/luyBUhPCLQAAAHzDqn2rJEltG7dVg+AG1hYDAADg42hU8BGlsyn06iWFhlpbCwAAAFAlpbMpNOkl+RNuAQAAatPMmTMVFxen4OBgJSQkKCMjo9xt3377bdlsNo+v4ODgWqzWu6T/nC5JSmieYHElAAAAvo9GBR+xxLWEbxJL+AIAAMDX5bjCrYNwCwAAUJvmzp2rsWPHasqUKVqzZo06d+6s/v37Kzc3t9x9wsPDtX//fvfX7t27a7Fi75Kxr6SpIz463uJKAAAAfB+NCj7A6fy1USGZJXwBAADgy4zz10aFKMItAABAbZo+fbpGjhypESNGqH379po1a5ZCQ0M1e/bscvex2WyKiopyfzkcjlqs2HsYY5SR5WpUiKFRAQAAoKpoVPABGzdKv/wi1asn9expdTUAAABAFRzZKBX+IvnXkxoTbgEAAGpLUVGRMjMzlZKS4r7PbrcrJSVFK1euLHe//Px8tWzZUrGxsRowYIB++OGHCo9TWFiovLw8j6+6YPvh7Tp04pAC/QLVOaqz1eUAAAD4PBoVfECaawnfPn2kgABrawEAAACqJNsVbiP7SHbCLQAAQG05ePCgiouLz5kRweFwKDs7u8x92rZtq9mzZ+uzzz7Tu+++K6fTqV69eunnn38u9zjTpk1TRESE+ys2NrZaz8MqpbMpdI3qqkC/QIurAQAA8H00KviA0mUfkljCFwAAAL6udNkHB+EWAADA2yUmJmrYsGHq0qWL+vbtq3nz5qlp06Z6/fXXy91n/PjxOnr0qPtr7969tVhxzWHZBwAAgOrlb3UBqNipU9Ly5SW3k1nCFwAAAL7MeUrKdYXbKMItAABAbWrSpIn8/PyUk5PjcX9OTo6ioqIuaIyAgAB17dpV27ZtK3eboKAgBQUFValWb5SelS5JSohJsLgSAACAuoEZFbzc6tVSfr7UuLF01VVWVwMAAABUwS+rpdP5UlBjqQHhFgAAoDYFBgaqe/fuSitdZ1aS0+lUWlqaEhMTL2iM4uJibdy4Uc2aNaupMr1SUXGR1u5fK4kZFQAAAKoLMyp4udL/brj+eslOWwkAAAB8WY4r3EZeL9kItwAAALVt7NixGj58uHr06KH4+HjNmDFDBQUFGjFihCRp2LBhiomJ0bRp0yRJzz//vK6++mpdccUVOnLkiP70pz9p9+7duv/++608jVq3MWejCosL1TC4oa5odIXV5QAAANQJNCp4uSWuJXyTWMIXAAAAvi7HFW6jCLcAAABWGDRokA4cOKDJkycrOztbXbp00aJFi+RwOCRJe/bskf2Mv5Y6fPiwRo4cqezsbDVs2FDdu3fXihUr1L59e6tOwRKlyz7Ex8TLZrNZXA0AAEDdQKOCFztxQlqxouR2Mkv4AgAAwJedPiEdcIVbB+EWAADAKmPGjNGYMWPKfGzZsmUe37/yyit65ZVXaqEq75aRlSGJZR8AAACqE/OterEVK6TCQikmRmrd2upqAAAAgCo4uEJyFkohMVJ9wi0AAAB8R+mMCgkxCRZXAgAAUHfQqODF0lxL+CYnS8woBgAAAJ+W7Qq3UYRbAAAA+I6jJ4/qp4M/SZJ6xvS0uBoAAIC6g0YFL7bEtYRvEkv4AgAAwNfluMKtg3ALAAAA37F632pJUlyDOEWGRVpcDQAAQN1xUY0KM2fOVFxcnIKDg5WQkKCMjIwKt58xY4batm2rkJAQxcbG6vHHH9fJkyfL3PYPf/iDbDabHnvssYsprc44elRatarkNo0KAAAANYdsWwuKjkqHXOGWRgUAAAD4EJZ9AAAAqBmVblSYO3euxo4dqylTpmjNmjXq3Lmz+vfvr9zc3DK3f//99zVu3DhNmTJFmzZt0ltvvaW5c+fqmWeeOWfbVatW6fXXX9dVV11V+TOpY776SnI6pdatpdhYq6sBAACom8i2tST3K8k4pfqtpTDCLQAAAHxHRlZJI3N8TLzFlQAAANQtlW5UmD59ukaOHKkRI0aoffv2mjVrlkJDQzV79uwyt1+xYoV69+6twYMHKy4uTv369dNdd911zl+q5efna8iQIXrzzTfVsGHDizubOiTNtYRvcrK1dQAAANRlZNtakuMKtw7CLQAAAHyHMYYZFQAAAGpIpRoVioqKlJmZqZSUlF8HsNuVkpKilStXlrlPr169lJmZ6f7l7Y4dO7Rw4ULdfPPNHtuNHj1at9xyi8fYFSksLFReXp7HV12yxLWEL8s+AAAA1AyybS3KcYXbKMItAAAAfMfPeT8rOz9bfjY/dW3W1epyAAAA6hT/ymx88OBBFRcXy+FweNzvcDj0008/lbnP4MGDdfDgQV1zzTUyxuj06dN68MEHPabH/eCDD7RmzRqtWrXqgmuZNm2annvuucqU7zNyc6WNG0tuX3+9tbUAAADUVWTbWnIyVzriCreRhFsAAAD4jtJlHzo5Oik0INTiagAAAOqWSi/9UFnLli3T1KlT9dprr2nNmjWaN2+eFixYoBdeeEGStHfvXj366KN67733FBwcfMHjjh8/XkePHnV/7d27t6ZOodYtXVryb+fOUpMm1tYCAACAX5FtL0KOK9w26CwFE24BAADgO1j2AQAAoOZUakaFJk2ayM/PTzk5OR735+TkKCoqqsx9Jk2apKFDh+r++++XJHXq1EkFBQUaNWqUJkyYoMzMTOXm5qpbt27ufYqLi/XVV1/pr3/9qwoLC+Xn53fOuEFBQQoKCqpM+T4jzbWEbzJL+AIAANQYsm0tyXaF2yjCLQAAAHxL6YwK8THxFlcCAABQ91RqRoXAwEB1795daaX/J12S0+lUWlqaEhMTy9zn+PHjsts9D1P6y1ljjJKTk7Vx40atW7fO/dWjRw8NGTJE69atK/MXuXXdEtcSvkks4QsAAFBjyLa1JMcVbh2EWwAAAPiOYmexVu9bLYlGBQAAgJpQqRkVJGns2LEaPny4evToofj4eM2YMUMFBQUaMWKEJGnYsGGKiYnRtGnTJEmpqamaPn26unbtqoSEBG3btk2TJk1Samqq/Pz8VL9+fXXs2NHjGGFhYWrcuPE5918Kdu+Wtm+X/PykPn2srgYAAKBuI9vWsILdUv52yeYnRRJuAQAA4Dt+PPCjCk4VqF5gPV3Z5EqrywEAAKhzKt2oMGjQIB04cECTJ09Wdna2unTpokWLFsnhcEiS9uzZ4/FXZhMnTpTNZtPEiROVlZWlpk2bKjU1VS+++GL1nUUdUjqbQny8VL++tbUAAADUdWTbGpbtCreN46UAwi0AAAB8R+myDz2ie8jPfgnOjAYAAFDDbMYYY3UR1SEvL08RERE6evSowsPDrS7not19t/Tee9LEidILL1hdDQAAgHeqK9mvPHXm/FbcLe16T+owUepMuAUAAChLncl+5fDV83vgXw/ojTVv6KleT+mlG16yuhwAAACfUJnsZ6/wUdQqY36dUSGJJXwBAADgy4yRclzhNopwCwAAAN+SnpUuSUponmBxJQAAAHUTjQpe5KefpP37peBgKTHR6moAAACAKsj7STqxX/ILlpoQbgEAAOA7CooK9H3u95Kk+Jh4i6sBAACom2hU8CKlsyn07l3SrAAAAAD4rNLZFJr0LmlWAAAAAHzEmv1rVGyKFV0/Ws3Dm1tdDgAAQJ1Eo4IXSUsr+Tc52do6AAAAgCrLdoXbKMItAAAAfEtGVoYkZlMAAACoSTQqeIniYmnZspLbSSzhCwAAAF/mLJZyl5XcdhBuAQAA4Fsy9rkaFaJpVAAAAKgpNCp4iXXrpMOHpfBwqXt3q6sBAAAAquDIOqnosBQQLjUi3AIAAMC3pP+cLklKaJ5gcSUAAAB1F40KXmKJawnfvn0lf39rawEAAACqJNsVbiP7SnbCLQAAAHxHTn6Odh/dLZts6t6MplsAAICaQqOCl0hzLeGbzBK+AAAA8HU5rnDrINwCAADAt6zat0qS1K5JO0UER1hcDQAAQN1Fo4IXKCqSvv665HYSS/gCAADAlxUXSbmucBtFuAUAAIBvYdkHAACA2kGjghdIT5eOH5eaNpU6drS6GgAAAKAKfkmXio9LQU2lCMItAAAAfEvGvgxJUnx0vMWVAAAA1G00KniBJa4lfJOSJJvN2loAAACAKslxhVsH4RYAAAC+xWmcysgqaVRgRgUAAICaRaOCF0hzLeGbzBK+AAAA8HXZrnAbRbgFAACAb9l2aJuOnDyiIL8gdYrsZHU5AAAAdRqNChYrKJC++67kdhJL+AIAAMCXnS6QfnGFWwfhFgAAAL6ldDaFbs26KcAvwOJqAAAA6jYaFSz2zTfSqVNSy5bSZZdZXQ0AAABQBbnfSM5TUlhLqR7hFgAAAL4l/ed0SVJCDMs+AAAA1DQaFSy2xLWEbxJL+AIAAMDX5bjCrYNwCwAAAN+Tsa9kRoX4mHiLKwEAAKj7aFSwWJprCd9klvAFAACAr8txhVsH4RYAAAC+pfB0odZlr5NEowIAAEBtoFHBQocPS2vWlNy+/nprawEAAACqpOiwdMgVbh2EWwAAAPiW9TnrVVRcpMYhjXVZQ5YxAwAAqGk0Klho2TLJGOnKK6XoaKurAQAAAKogZ5kkI4VfKYUSbgEAAOBbMrJ+XfbBxjJmAAAANY5GBQstcS3hm5RkbR0AAABAleW4wq2DcAsAAADfU9qokBCTYHElAAAAlwYaFSyU5lrCN5klfAEAAODrsl3hNopwCwAAAN+TnpUuqWRGBQAAANQ8GhUssn+/tGmTZLNJfftaXQ0AAABQBSf2S3mbJNmkSMItAAAAfMvhE4e15ZctkqSeMT0trgYAAODSQKOCRUqXfejWTWrUyNpaAAAAgCrJdoXbRt2kIMItAAAAfMuqfaskSZc3vFxNQptYXA0AAMClgUYFi5Q2KiSxhC8AAAB8XY4r3DoItwAAAPA9GVkZklj2AQAAoDbRqGABY6Q01xK+ySzhCwAAAF9mjJTjCrcOwi0AAAB8D40KAAAAtY9GBQvs3Cnt3i0FBEjXXGN1NQAAAEAVFOyUCnZL9gApknALAAAA32KMUXpWuiQpISbB4moAAAAuHTQqWKB0NoWrr5bCwqytBQAAAKiSbFe4bXy15E+4BQAAgG/Zc3SPcgty5W/3V5eoLlaXAwAAcMmgUcECS1xL+CaxhC8AAAB8XY4r3DoItwAAAPA9pcs+dHZ0VkhAiMXVAAAAXDpoVKhlxvzaqJDMEr4AAADwZcb82qgQRbgFAACA7yld9iE+Jt7iSgAAAC4tNCrUsh9+kHJzpdBQKYElzwAAAODLjv4gncyV/EKlxoRbAAAA+J7SGRVoVAAAAKhdNCrUsjTXEr7XXisFBlpbCwAAAFAl2a5wG3mt5Ee4BQAAgG857TytzP2ZkqSEGBpvAQAAahONCrWsdNmHJJbwBQAAgK8rXfbBQbgFAACA7/kh9wcdP3Vc9QPrq22TtlaXAwAAcEmhUaEWnT4tLVtWcjuZJXwBAADgy5ynpdxlJbejCLcAAADwPaXLPvSM6Sm7jV+VAwAA1CbSVy1as0bKy5MaNJC6dLG6GgAAAKAKDq2RTuVJAQ2kBl2srgYAAACotPSsdEks+wAAAGAFGhVqUZprCd/rr5f8/KytBQAAAKiSHFe4dVwv2Qm3AAAA8D2lMyrEx8RbXAkAAMClh0aFWrTEtYRvEkv4AgAAwNfluMKtg3ALAAAA35NflK8fDvwgiUYFAAAAK1xUo8LMmTMVFxen4OBgJSQkKCMjo8LtZ8yYobZt2yokJESxsbF6/PHHdfLkSffj06ZNU8+ePVW/fn1FRkZq4MCB2rx588WU5rVOnpS++abkdjJL+AIAAHgNsu1FKD4pHXCF2yjCLQAAAHxP5r5MOY1TzcObK7p+tNXlAAAAXHIq3agwd+5cjR07VlOmTNGaNWvUuXNn9e/fX7m5uWVu//7772vcuHGaMmWKNm3apLfeektz587VM888495m+fLlGj16tL777jstXrxYp06dUr9+/VRQUHDxZ+ZlvvuupFmhWTOpXTurqwEAAIBEtr1oB78raVYIaSaFE24BAADge1j2AQAAwFqVblSYPn26Ro4cqREjRqh9+/aaNWuWQkNDNXv27DK3X7FihXr37q3BgwcrLi5O/fr101133eXxl2qLFi3SPffcow4dOqhz5856++23tWfPHmVmZl78mXmZNNcSvklJks1mbS0AAAAoQba9SNmucOsg3AIAAPiays4oVuqDDz6QzWbTwIEDa7bAWpKelS5JSohJsLgSAACAS1OlGhWKioqUmZmplJSUXwew25WSkqKVK1eWuU+vXr2UmZnpDrw7duzQwoULdfPNN5d7nKNHj0qSGjVqVO42hYWFysvL8/jyZktcS/gmsYQvAACAVyDbVkGOK9w6CLcAAAC+pLIzipXatWuXnnjiCV177bW1VGnNY0YFAAAAa1WqUeHgwYMqLi6Ww+HwuN/hcCg7O7vMfQYPHqznn39e11xzjQICAnT55Zfruuuu85ge90xOp1OPPfaYevfurY4dO5Zby7Rp0xQREeH+io2Nrcyp1Kpjx6TSxuRklvAFAADwCmTbi3TqmPSLK9xGEW4BAAB8SWVnFJOk4uJiDRkyRM8995wuu+yyWqy25uw/tl978/bKJpu6N+tudTkAAACXpEov/VBZy5Yt09SpU/Xaa69pzZo1mjdvnhYsWKAXXnihzO1Hjx6t77//Xh988EGF444fP15Hjx51f+3du7cmyq8WX38tnT4tXXaZ1LKl1dUAAADgYpFtJeV+LZnTUr3LpDDCLQAAgK+4mBnFJOn5559XZGSk7rvvvgs6ji/MFlY6m0KHyA6qH1Tf4moAAAAuTf6V2bhJkyby8/NTTk6Ox/05OTmKiooqc59JkyZp6NChuv/++yVJnTp1UkFBgUaNGqUJEybIbv+1V2LMmDH697//ra+++krNmzevsJagoCAFBQVVpnzLpLmW8GU2BQAAAO9Btr1IOa5w6yDcAgAA+JKKZhT76aefytznm2++0VtvvaV169Zd8HGmTZum5557riql1jj3sg/RLPsAAABglUrNqBAYGKju3bsrrfT/vKtkOtu0tDQlJiaWuc/x48c9fmErSX5+fpIkY4z73zFjxuiTTz7RkiVL1KpVq0qdhLdb4lrCN4klfAEAALwG2fYi5bjCrYNwCwAAUJcdO3ZMQ4cO1ZtvvqkmTZpc8H6+MFtYxj5Xo0IMjQoAAABWqdSMCpI0duxYDR8+XD169FB8fLxmzJihgoICjRgxQpI0bNgwxcTEaNq0aZKk1NRUTZ8+XV27dlVCQoK2bdumSZMmKTU11f1L3dGjR+v999/XZ599pvr167vXBI6IiFBISEh1naslDh6UShuOr7/e0lIAAABwFrJtJZ08KB1eV3LbQbgFAADwJZWdUWz79u3atWuXUlNT3fc5nU5Jkr+/vzZv3qzLL7/8nP28fbYwp3G6Z1RIaJ5gcTUAAACXrko3KgwaNEgHDhzQ5MmTlZ2drS5dumjRokXuKcP27Nnj8VdmEydOlM1m08SJE5WVlaWmTZsqNTVVL774onubv/3tb5Kk6667zuNYc+bM0T333HMRp+U9li0r+bdjR+msWdUAAABgMbJtJeUuK/k3oqMUQrgFAADwJWfOKDZw4EBJv84oNmbMmHO2b9eunTZu3Ohx38SJE3Xs2DG9+uqrio2NrY2yq92WX7YorzBPIf4h6hjZ0epyAAAALlk2UzpHrY/Ly8tTRESEjh49qvDwcKvLcXvoIWnWLOnRR6UZM6yuBgAAoG7w1uxXXbz2/DIekrbNkto+KnWfYXU1AAAAdUJtZr+5c+dq+PDhev31190zin344Yf66aef5HA4zplR7Gz33HOPjhw5ok8//fSCj+lt2fadde/ons/u0TUtrtHXI762uhwAAIA6pTLZr9IzKqBylriW8E1iCV8AAAD4uhxXuHUQbgEAAHxRZWcUq4tKl32Ij463uBIAAIBLG40KNejnn6UtWyS7Xerb1+pqAAAAgCo4/rN0bItks0uRhFsAAABfNWbMmDKXepCkZaXr2Jbj7bffrv6CalnGPlejQgyNCgAAAFaq2+2xFiudTaFHDykiwtpaAAAAgCrJdoXbRj2kQMItAAAAfM/J0ye1Pnu9JCmheYLF1QAAAFzaaFSoQWlpJf8mJ1tbBwAAAFBlOa5w6yDcAgAAwDety16nU85TahraVC0jWlpdDgAAwCWNRoUaYsyvMyoksYQvAAAAfJkxUo4r3EYRbgEAAOCbMrJ+XfbBZrNZXA0AAMCljUaFGrJ1q/Tzz1JgoNS7t9XVAAAAAFVwbKt0/GfJHig1IdwCAADAN6VnpUuSEmJY9gEAAMBqNCrUkNLZFHr1kkJCrK0FAAAAqJLS2RSa9JL8CbcAAADwTWfOqAAAAABr0ahQQ9JcS/gms4QvAAAAfF22K9xGEW4BAADgmw6dOKRth7ZJknrG9LS4GgAAANCoUAOcTmnp0pLbSSzhCwAAAF9mnFKuK9w6CLcAAADwTaWzKbRu1FqNQhpZXA0AAABoVKgBGzZIv/wi1asn9aQ5FwAAAL7syAap8BfJv57UmHALAAAA38SyDwAAAN6FRoUasMS1hG+fPlJAgLW1AAAAAFWS7Qq3kX0kO+EWAAAAvik9K12SlBCTYHElAAAAkGhUqBFpriV8k1nCFwAAAL4uxxVuHYRbAAAA+CZjDDMqAAAAeBkaFarZqVPSV1+V3E5iCV8AAAD4MucpKdcVbqMItwAAAPBNu47s0sHjBxVgD1DnqM5WlwMAAADRqFDtVq2S8vOlxo2lq66yuhoAAACgCn5ZJZ3Ol4IaSw0ItwAAAPBNpcs+dInqomD/YIurAQAAgESjQrVb4lrC9/rrJTtXFwAAAL4sxxVuI6+XbIRbAAAA+CaWfQAAAPA+/LaxmqW5lvBNZglfAAAA+LpsV7iNItwCAADAd5U2KiTEJFhcCQAAAErRqFCNTpyQVqwouZ3EEr4AAADwZadPSAdd4dZBuAUAAIBvOlV8Spn7MyUxowIAAIA3oVGhGn37rVRUJDVvLrVubXU1AAAAQBUc/FZyFkmhzaX6hFsAAAD4pu9zv9fJ0ycVERSh1o3JtQAAAN6CRoVqtMS1hG9SkmSzWVsLAAAAUCXZrnDrINwCAADAd6VnpUsqmU3BbuPX4QAAAN6CZFaN0lxL+CazhC8AAAB8XY4r3DoItwAAAPBdGVkZklj2AQAAwNvQqFBNjh6VVq8uuZ3EEr4AAADwZUVHpUOucBtFuAUAAIDvolEBAADAO9GoUE2WL5ecTqlNG6l5c6urAQAAAKogd7lknFL9NlIo4RYAAAC+Ka8wTz8e+FESjQoAAADehkaFarLEtYQvsykAAADA5+W4wq2DcAsAAADflbkvU0ZGLSJaKKpelNXlAAAA4Aw0KlSTNNcSvsks4QsAAABfl+0Kt1GEWwAAAPguln0AAADwXjQqVIOcHOn770tuX3edpaUAAAAAVXMiRzrqCreR11laCgAAAFAV6VnpkqSEmASLKwEAAMDZaFSoBkuXlvzbpYvUpImlpQAAAABVk+MKtw27SMGEWwAAAPguZlQAAADwXjQqVIMlriV8k1jCFwAAAL4uxxVuHYRbAAAA+K6svCxlHcuS3WZX92bdrS4HAAAAZ6FRoRqkuZbwpVEBAAAAPi/HFW5pVAAAAIAPK51NoWNkR4UFhllcDQAAAM5Go0IV7dol7dgh+flJffpYXQ0AAABQBfm7pPwdks1PiiTcAgAAwHe5l32IZtkHAAAAb0SjQhWVLvsQHy/Vr29tLQAAAECVlC770DheCiDcAgAAwHelZ6VLkhKaJ1hcCQAAAMpCo0IVlTYqJCdbWwcAAABQZaWNCg7CLQAAAHxXsbNYq/etliTFxzCjAgAAgDeiUaEKjJHSXEv4JrGELwAAAHyZMVK2K9xGEW4BAADguzb/slnHio4pNCBU7Zu2t7ocAAAAlIFGhSr46ScpO1sKDpYSE62uBgAAAKiCvJ+kk9mSX7DUhHALAAAA35X+c8myDz2ie8jf7m9xNQAAACgLjQpVUDqbQu/eJc0KAAAAgM8qnU2hSe+SZgUAAADAR2VkZUiS4qNZ9gEAAMBb0ahQBUtcS/gms4QvAAAAfF2OK9xGEW4BAADg29KzSmZUSGieYHElAAAAKM9FNSrMnDlTcXFxCg4OVkJCgjIyMircfsaMGWrbtq1CQkIUGxurxx9/XCdPnqzSmFYrLpaWLi25ncQSvgAAAD6LbCvJWSzluMKtg3ALAAAA33Xi1AltyNkgSYqPYUYFAAAAb1XpRoW5c+dq7NixmjJlitasWaPOnTurf//+ys3NLXP7999/X+PGjdOUKVO0adMmvfXWW5o7d66eeeaZix7TG6xbJx05IoWHS927W10NAAAALgbZ1uXIOunUESkgXGpEuAUAAIDvWpu9VsWmWI4wh2LDY60uBwAAAOWodKPC9OnTNXLkSI0YMULt27fXrFmzFBoaqtmzZ5e5/YoVK9S7d28NHjxYcXFx6tevn+666y6Pvyqr7JjeIM21hG/fvpK/v7W1AAAA4OKQbV2yXeE2sq9kJ9wCAADAd6X//OuyDzabzeJqAAAAUJ5KNSoUFRUpMzNTKSkpvw5gtyslJUUrV64sc59evXopMzPT/cvbHTt2aOHChbr55psvekxJKiwsVF5ensdXbbr7buntt6UxY2r1sAAAAKgmZNszxN0tXf221IZwCwAAAN/2m/a/0dsD3tZDPR6yuhQAAABUoFJ/LnXw4EEVFxfL4XB43O9wOPTTTz+Vuc/gwYN18OBBXXPNNTLG6PTp03rwwQfd0+NezJiSNG3aND333HOVKb9aRUdLw4dbdngAAABUEdn2DKHR0mWEWwAAAPi+FhEtNLwL2RYAAMDbVXrph8patmyZpk6dqtdee01r1qzRvHnztGDBAr3wwgtVGnf8+PE6evSo+2vv3r3VVDEAAABQNrItAAAAAAAAAFRdpWZUaNKkifz8/JSTk+Nxf05OjqKiosrcZ9KkSRo6dKjuv/9+SVKnTp1UUFCgUaNGacKECRc1piQFBQUpKCioMuUDAAAAbmRbAAAAAAAAALBGpWZUCAwMVPfu3ZWWlua+z+l0Ki0tTYmJiWXuc/z4cdntnofx8/OTJBljLmpMAAAAoKrItgAAAAAAAABgjUrNqCBJY8eO1fDhw9WjRw/Fx8drxowZKigo0IgRIyRJw4YNU0xMjKZNmyZJSk1N1fTp09W1a1clJCRo27ZtmjRpklJTU92/1D3fmAAAAEBNINsCAAAAAAAAQO2rdKPCoEGDdODAAU2ePFnZ2dnq0qWLFi1aJIfDIUnas2ePx1+ZTZw4UTabTRMnTlRWVpaaNm2q1NRUvfjiixc8JgAAAFATyLYAAAAAAAAAUPtsxhhjdRHVIS8vTxERETp69KjCw8OtLgcAAAA1qK5nv7p+fgAAAPhVXc9+df38AAAA8KvKZD97hY8CAAAAAAAAAAAAAABUIxoVAAAAAAAAAAAAAABAraFRAQAAAAAAAAAAAAAA1BoaFQAAAAAAAAAAAAAAQK2hUQEAAAAAAAAAAAAAANQaGhUAAAAAAAAAAAAAAECtoVEBAAAAAAAAAAAAAADUGhoVAAAAAAAAAAAAAABAraFRAQAAAAAAAAAAAAAA1Bp/qwuoLsYYSVJeXp7FlQAAAKCmlWa+0gxY15BtAQAALh1kWwAAANQVlcm2daZR4dixY5Kk2NhYiysBAABAbTl27JgiIiKsLqPakW0BAAAuPWRbAAAA1BUXkm1tpo606jqdTu3bt0/169eXzWarlWPm5eUpNjZWe/fuVXh4eK0c0wp17Tx9/Xx8pX5vrdOb6rKylto+dlWPV9P11sT41T3mxYxXXTV40zjVeV3LGsubztUbxylvLCvez4wxOnbsmKKjo2W3173VzMi2Naeunaevn4+v1O+tdXpTXWTb2tvfivHJtjUzjq9ktLo6TnljkW2rH9m25tS18/T18/GV+r21Tm+qi2xbe/tbMT7ZtmbG8ZWMVlfHKW8sb8+2dWZGBbvdrubNm1ty7PDwcMs/OGtDXTtPXz8fX6nfW+v0prqsrKW2j13V49V0vTUxfnWPeTHjVVcN3jROdV7XssbypnP1xnHKG6u231Pq4l+blSLb1ry6dp6+fj6+Ur+31ulNdZFta29/K8Yn29bMOL6S0erqOOWNRbatPmTbmlfXztPXz8dX6vfWOr2pLrJt7e1vxfhk25oZx1cyWl0dp7yxvDXb1r0WXQAAAAAAAAAAAAAA4LVoVAAAAAAAAAAAAAAAALWGRoUqCAoK0pQpUxQUFGR1KTWqrp2nr5+Pr9TvrXV6U11W1lLbx67q8Wq63poYv7rHvJjxqqsGbxqnOq9rWWN507l64zjljeVN7624eJfKz7Gunaevn4+v1O+tdXpTXWTb2tvfivHJtjUzjq9ktLo6TnljedN7Ky7epfJzrGvn6evn4yv1e2ud3lQX2bb29rdifLJtzYzjKxmtro5T3lje9N5aFpsxxlhdBAAAAAAAAAAAAAAAuDQwowIAAAAAAAAAAAAAAKg1NCoAAAAAAAAAAAAAAIBaQ6MCAAAAAAAAAAAAAACoNTQqlOPZZ5+VzWbz+GrXrl2F+3z00Udq166dgoOD1alTJy1cuLCWqr1wX331lVJTUxUdHS2bzaZPP/3U/dipU6f09NNPq1OnTgoLC1N0dLSGDRumffv2VTjmxVyr6lTROUlSTk6O7rnnHkVHRys0NFQ33nijtm7dWuGY8+bNU48ePdSgQQOFhYWpS5cu+r//+79qrXvatGnq2bOn6tevr8jISA0cOFCbN2/22Oa6664759o++OCDF3yMBx98UDabTTNmzLjoOv/2t7/pqquuUnh4uMLDw5WYmKjPP//c/fjJkyc1evRoNW7cWPXq1dNvfvMb5eTkVDhmfn6+xowZo+bNmyskJETt27fXrFmzqr22i7l+1VXbH/7wB9lsNj322GPu+y7mWj377LNq166dwsLC1LBhQ6WkpCg9Pb3Sxy5ljNFNN91U5mvlYo599rF27dp1zjUv/froo4/c4579WOvWrd2v05CQELVo0UINGza84OtkjNHkyZPVrFkz+fv7V/ie9MADD+jyyy9XSEiImjZtqgEDBuinn36qcPxBgwZVOGZlnmtlnb/dbnc/17KzszV06FBFRUUpLCxM3bp108cffyxJysrK0t13363GjRsrJCREnTp10urVq92vhfr16ysoKEiBgYEKCgpSSkrKOe93ZY3x1FNPKS4uTkFBQYqOjtYVV1xx3s+BM8cJDAxUcHCwwsLCynwtVvRedHY97dq100033eRR30cffaRbb71VERERCgsLU8+ePbVnz54KxwoICCj3uRgWFqbQ0FDdcMMNGjJkSIWvyXnz5ikoKKjMcfz9/dW3b18NHTpUbdu2dT93H3nkER09evSc+uLi4socp/RnVfr6Ot/rtLxxAgMD3dfnk08+UVJSkvtn0qdPH504ceKCxvHz81Pz5s3lcDjk5+cnPz8/BQUF6Y477nBfnzNfcyEhIe7n2vnel2fOnKm4uDgFBwcrISFBGRkZ55wfagbZlmxLti1BtiXbkm3JtmRbsi3Z1veRbcm2ZNsSZFuyLdmWbEu2Jdv6eralUaECHTp00P79+91f33zzTbnbrlixQnfddZfuu+8+rV27VgMHDtTAgQP1/fff12LF51dQUKDOnTtr5syZ5zx2/PhxrVmzRpMmTdKaNWs0b948bd68Wbfeeut5x63MtapuFZ2TMUYDBw7Ujh079Nlnn2nt2rVq2bKlUlJSVFBQUO6YjRo10oQJE7Ry5Upt2LBBI0aM0IgRI/TFF19UW93Lly/X6NGj9d1332nx4sU6deqU+vXrd05dI0eO9Li2f/zjHy9o/E8++UTfffedoqOjq1Rn8+bN9Yc//EGZmZlavXq1kpKSNGDAAP3www+SpMcff1z/+te/9NFHH2n58uXat2+fbr/99grHHDt2rBYtWqR3331XmzZt0mOPPaYxY8Zo/vz51VqbVPnrVx21rVq1Sq+//rquuuoqj/sv5lq1adNGf/3rX7Vx40Z98803iouLU79+/XTgwIFKHbvUjBkzZLPZLug8znfsso4VGxvrcb3379+v5557TvXq1dNNN93k3u7M94x9+/YpIiLC/TodOHCgDh06pMDAQC1atOiCrtMf//hH/c///I9mzZqlkSNHqn79+oqNjdXOnTvPeU/q3r275syZo02bNumLL76QMUb9+vVTcXFxueMXFRUpMjJSL7/8siRp8eLF57zPVea51qFDBw0ZMkQtW7bUxx9/rNWrV7ufazfddJM2b96s+fPna+PGjbr99tt15513avny5erdu7cCAgL0+eef68cff9Sf//xnNWzY0P1aePDBBxUUFKQBAwbI6XTK6XSqf//+OnnypCTp8OHD54yRmpqqGTNmaMqUKfrqq69kt9u1f/9+LV68uNzPgbPHmTlzpiZOnKj58+ef81qs6L3o7HFWrlypw4cPKzQ01F3f73//e40aNUrt2rXTsmXLtGHDBk2aNEnBwcHljnXLLbeoUaNGGjdunP75z39q2rRpCgwMVKtWrSRJf/7zn7V27VplZWVp7ty5+vvf/17ua7JRo0Z6/fXXtXz5cq1cuVIpKSnux15//XXZ7XbNmzdPU6dO1ffff6+3335bixYt0n333XfO+a5atcr9/Jg5c6ZeeuklSdKsWbM8Xl/ne52eOc7KlStVv359SSVhcsOGDbrjjjs0fPhw9evXTxkZGVq1apXGjBkju91e7jipqalq0aKFJOk3v/mNDh06pNzcXF1zzTX64x//KH9/f/30009KTU2V0+n0eM2lp6crLCxM/fv3V2RkZLnvy3PnztXYsWM1ZcoUrVmzRp07d1b//v2Vm5tb7rmiepFtybZkW7It2ZZsK5FtybZkW7Jt3UC2JduSbcm2ZFuyrUS2JduSbX0+2xqUacqUKaZz584XvP2dd95pbrnlFo/7EhISzAMPPFDNlVUfSeaTTz6pcJuMjAwjyezevbvcbSp7rWrS2ee0efNmI8l8//337vuKi4tN06ZNzZtvvlmpsbt27WomTpxYXaWeIzc310gyy5cvd9/Xt29f8+ijj1Z6rJ9//tnExMSY77//3rRs2dK88sor1VeoMaZhw4bmf//3f82RI0dMQECA+eijj9yPbdq0yUgyK1euLHf/Dh06mOeff97jvm7dupkJEyZUW23GXNz1q2ptx44dM61btzaLFy/2OP7FXquzHT161EgyX3755QUfu9TatWtNTEyM2b9//wW9/is69vmOdaYuXbqYe++91/392e8ZZ75OS6/T3Llz3a/T810np9NpoqKizJ/+9Cf3+B07djRBQUHmH//4x3nPa/369UaS2bZtW7nblNa8c+dOI8msXbvW4/HKPNdKxyrvuRYQEGD+/ve/e9zfqFEjc+ONN5prrrmm3HHPvg4NGzY0//M//+NxHZ5++ulzxoiPjzejR492f19cXGyio6PNtGnTjDFlfw6UNc7ZGjZsaP70pz9V+F509jhljTto0CBz9913V3iss/dt1qyZ+etf/+rx+A033GAkmdjYWON0Ot3PtfDwcPfnwYU+18LCwkzDhg3d45z9XPvwww9NYGCgOXXqVIU1P/roo+byyy83TqfT/fqaNWtWpV6ngwYNMu3atXOPY0xJ/qjM59Xx48eNn5+fufXWW83ll19ubrnlFtO/f38jyTzxxBPGGGNuv/12c+eddxqbzWb+85//eDzXjDFlXodSpe/L53uuoWaRbUuQbX9Ftv0V2bZ8ZNtzkW3LHotsS7Yl25JtaxPZtgTZ9ldk21+RbctHtj0X2bbssci2ZFuybe1lW2ZUqMDWrVsVHR2tyy67TEOGDClzupJSZ3frSFL//v21cuXKmi6zRh09elQ2m00NGjSocLvKXKvaVFhYKEkeHVx2u11BQUEX3D1sjFFaWpo2b96sPn361EidktzTzTRq1Mjj/vfee09NmjRRx44dNX78eB0/frzCcZxOp4YOHaonn3xSHTp0qNYai4uL9cEHH6igoECJiYnKzMzUqVOnPJ777dq1U4sWLSp87vfq1Uvz589XVlaWjDFaunSptmzZon79+lVbbaUqe/2qWtvo0aN1yy23nPN+cLHX6kxFRUV64403FBERoc6dO1/wsaWSzvvBgwdr5syZioqKuqDjVXTsio51pszMTK1bt+6cLsUz3zMef/xxSSWv09Lr1K9fP/fr9HzXaefOncrOzvaoZceOHTLG6IEHHqjwPamgoEBz5sxRq1atFBsbW+G5bN26VQkJCZKkZ5555pwxK/Nc27p1q3bu3Kn/9//+n2677Tbt3r3b/Vzr3Lmz5s6dq0OHDsnpdOqDDz7QyZMntXXrVvXo0UN33HGHIiMj1bVrV7355pvnXIfrr7/e/VpITk5WQkKC+9rNnz/fY4wuXbpo1apVHtfObrcrJSXFvU9ZnwNnj3NmLaWvxfz8fH300UcVvhedPc6MGTPcU1WV1vfpp5+qTZs27q7PhISEMqfVOnOs7OxsvfTSSx7Xx8/PT5J0xx13yGazuZ9r9erVc38enO+5tmPHDmVnZ6ugoEADBw6UzWZTRESExzUuvWbh4eHy9/cv9zlQVFSkd999V/fee69OnTqlN954Q+Hh4Zo+ffoFv06dTqf+/e9/a8+ePbLZbHI4HOrWrZvS09MVGRmpXr16yeFwqG/fvhV+5p0+fVrFxcVatmyZ7r33XvXq1Utr166VJKWnp2v9+vX65ptvdNNNN8lut+vf//73Oa+5sq7Dme/L3bt3V2ZmZoXPNdQ8si3ZViLbnolse35kW09k2/LHItuSbcm2ZNvaRrYl20pk2zORbc+PbOuJbFv+WGRbsi3ZthazbY23QviohQsXmg8//NCsX7/eLFq0yCQmJpoWLVqYvLy8MrcPCAgw77//vsd9M2fONJGRkbVR7kXReTp+Tpw4Ybp162YGDx5c4TiVvVY16exzKioqMi1atDB33HGHOXTokCksLDR/+MMfjCTTr1+/Csc6cuSICQsLM/7+/iYoKMi89dZbNVZ3cXGxueWWW0zv3r097n/99dfNokWLzIYNG8y7775rYmJizG233VbhWFOnTjU33HCDu0OrOjpzN2zYYMLCwoyfn5+JiIgwCxYsMMYY895775nAwMBztu/Zs6d56qmnyh3v5MmTZtiwYUaS8ff3N4GBgeadd96p1tqMubjrV5Xa/vGPf5iOHTuaEydOGGM8uzUv9loZY8y//vUvExYWZmw2m4mOjjYZGRmVOrYxxowaNcrcd9997u/P9/qv6NjnO9aZHnroIXPllVd63Hf2e8bVV19t/Pz8zMCBA80bb7xhAgMDz3mdVnSdvv32WyPJ7Nu3z2P8G264wfTp06fM96SZM2easLAwI8m0bdu2wq7cM8dcuHChkWSuuuoqjzEr81wrHWvVqlUmOTnZSDKSTEBAgHnnnXfM4cOHTb9+/dzPwfDwcPPFF1+YoKAgExQUZMaPH2/WrFljXn/9dRMcHGzefvttY4wxf//7340kY7fbPV4Ld9xxh7nzzjuNMeacMV566SUj6ZwuzieffNLEx8eX+zlQVi1BQUEmMDDQ/VocPnz4ed+Lzh7H39/fSDK33HKLWbNmjfnjH/9oJJnAwEAzffp0s3btWjNt2jRjs9nMsmXLyh2rf//+plmzZiYoKMjMnj3b/Oc//zEBAQFGkvmv//ovc+jQIfPOO+8YPz+/cz4PynqulX4elG5vt9tNVlaW+/Ezr/GBAwdMixYtzDPPPFPOs6nE3Llzjd1uNyEhIe7X12233Vap12lp964kM2XKFLN27Vrz0EMPGUkmPDzczJ4926xZs8Y89thjJjAw0GzZsqXcsVq3bm0kmczMTFNUVOTuZJZkbDabefbZZ82YMWOMJHPrrbd6vObOvg5lvS9nZWUZSWbFihUe+5Q+11DzyLZkW7Ltr8i2ZFuyLdn2TGRbsi3Z1veQbcm2ZNtfkW3JtmRbsu2ZyLZkW1/LtjQqXKDDhw+b8PBw99REZ6trgbeoqMikpqaarl27mqNHj1Zq3PNdq5pU1jmtXr3adO7c2Ugyfn5+pn///uamm24yN954Y4VjFRcXm61bt5q1a9eal19+2URERJilS5fWSN0PPvigadmypdm7d2+F26WlpVU41dHq1auNw+HweCOujsBbWFhotm7dalavXm3GjRtnmjRpYn744YeLDnF/+tOfTJs2bcz8+fPN+vXrzV/+8hdTr149s3jx4mqrrSznu35VqW3Pnj0mMjLSrF+/3n1fdQXe/Px8s3XrVrNy5Upz7733mri4OJOTk3PBx/7ss8/MFVdcYY4dO+Z+/EID79nHbt68uWnSpEm5xzrT8ePHTUREhHn55ZcrPMbhw4dNWFiYad68ufsD9uzXaWUCb6nSD9+y3pOOHDlitmzZYpYvX25SU1NNt27d3AG+IqVTiH311VcVvs9V5rn2/vvvm3r16pnBgwebevXqmQEDBpj4+Hjz5ZdfmnXr1plnn33WREREGH9/f5OYmOgxxn//93+bq6++2hhjzLJly4wks2jRIo/XwplhLCAgwGOM0hDSoUMHj3GffPJJ06NHj3I/B84exxhjHn74YdOlSxezevVqc8899xibzebxnlnWe9HZ4wQEBJioqCj3OZXW17hxY4/9UlNTze9+97tyx8rNzTUDBgxwP5/atGljYmNjjc1mc38e2Gw2Y7PZzvk8KOu5Vvp5MGfOHPdnyZnnVnqNjx49auLj482NN95oioqKTEX69etnbrrpJvfrKyUlxfj7+5sdO3a4tznf67T0+kRHR7vvK309nP0fmp06dTLjxo0rd6xrrrnGNGrUyH1tAgICTIcOHdz/ESLJJCYmmm7dupmBAwdW+Jor63156dKl/DLXy5BtLxzZtvLItmTbipBtybZkW7JtWci2qAqy7YUj21Ye2ZZsWxGyLdmWbEu2LQvZ9sLRqFAJPXr0KPfJEhsbe84LefLkyeaqq66qhcouTnkvpKKiIjNw4EBz1VVXmYMHD17U2BVdq5pU0ZvDkSNHTG5urjGmZG2fhx9+uFJj33fffeft5r0Yo0ePNs2bN/d4kytPfn6++wOtLK+88oqx2WzGz8/P/VXaRdayZctqqzk5OdmMGjXK/aF++PBhj8dbtGhhpk+fXua+x48fNwEBAebf//63x/333Xef6d+/f7XVVpbzXb+q1PbJJ5+4PwjPvPalP48vv/yy0teqPFdccYWZOnXqBR97zJgx5T4v+vbtW6ljR0VFVXis06dPu7f9+9//bgICAtyvu4qUvmd89tln7ut05uu0ouu0fft2I527/lifPn3MI4884jF+WQoLC01oaOg5v7Qoy5lrnVU0ZmWfa6Vj3XHHHUbyXJ/RmJLndb169Ty6No0x5rXXXnOHnbOvQ+lr4czr0KJFC48xCgsLjc1mM40aNfIY9+677zZRUVHlfg6cPc7Ztbzyyisez4vy3ovOHqdFixamV69e7nEKCwuN3W439evX9zjWU089ZXr16nXeml599VXjcDjMzp07jc1mM7GxscaYks+Djz/+2Egy3bp18/g8qOi59tVXXxlJJiEhwePzoE+fPubBBx80iYmJJjk5+bz/8bRr1y5jt9vNp59+6r7v0UcfdV+jC32dbtmyxUjy6JzesWOHkWRat27tse2dd95Z7l/anFlPfn6+e624O++809x8883mwIEDZsKECaZt27bG4XCYp59++ryvuTMlJyeb++67z/j5+Z3zGT1s2DBz6623VnC1UJPItheObHvhyLYlyLYXjmzriWxLti2vJrLtr8i2KAvZ9sKRbS8c2bYE2fbCkW09kW3JtuXVRLb91aWebe3CBcnPz9f27dvVrFmzMh9PTExUWlqax32LFy/2WHPJF5w6dUp33nmntm7dqi+//FKNGzeu9Bjnu1ZWiYiIUNOmTbV161atXr1aAwYMqNT+TqfTvXZadTDGaMyYMfrkk0+0ZMkStWrV6rz7rFu3TpLKvbZDhw7Vhg0btG7dOvdXdHS0nnzySX3xxRfVVnvptejevbsCAgI8nvubN2/Wnj17yn3unzp1SqdOnZLd7vn24+fnJ6fTWW21leV8168qtSUnJ2vjxo0e175Hjx4aMmSI+3Zlr1V5zj7H8x17woQJ5zwvJOmVV17RnDlzKnXs4OBgPfTQQ+Ueq3Q9KUl66623dOutt6pp06YVjnnme0bfvn0VEBCgd9991/06Pd91atWqlaKiojyubV5entLT05WYmHje9yRT0rRXqdf38ePHKxyzMs+1M+szxkhSmc9Bh8OhzZs3e9y/ZcsWtWzZUtK518HpdOrYsWPu6yBJvXv39hgjMDBQkZGRCgwMdN9XWFiof/7znzLGlPs5cPY4Z9cydOhQ9ezZU6mpqRW+F509Tu/evbVr1y73OIGBgXI4HAoKCir3WBXVtHPnTl122WV66623ZLfbNXjwYEklnwfJyckKCAjQ2rVr3Z8H53uuffnll7Lb7SouLnY/X/Ly8vTdd98pLS1NgYGBmj9/vsf6mmWZM2eOIiMjdcstt7jvGzdunJo3b64HHnjggl+n7733ngICAjzui4uLU3BwsMfPVCr7mpVVT1hYmAoLC3Xy5El98cUXGjBggJo0aaKwsDDl5+crNzdX99xzT4WvubM5nU6dPn1a3bt399jH6XQqLS3N57JSXUG2vXBk2wtDtiXbkm1LkG3Jtmd+T7Yl26J2kG0vHNn2wpBtybZk2xJkW7Ltmd+Tbcm2NaLGWyF81O9//3uzbNkys3PnTvPtt9+alJQU06RJE3eH2dChQz06sr799lvj7+9vXn75ZbNp0yYzZcoUExAQYDZu3GjVKZTp2LFjZu3atWbt2rVGknvtmN27d5uioiJz6623mubNm5t169aZ/fv3u78KCwvdYyQlJZm//OUv7u/Pd62sPCdjjPnwww/N0qVLzfbt282nn35qWrZsaW6//XaPMc7+eU6dOtX85z//Mdu3bzc//vijefnll42/v7958803q63uhx56yERERJhly5Z5XOvjx48bY4zZtm2bef75583q1avNzp07zWeffWYuu+wy06dPH49x2rZta+bNm1fucao6hdi4cePM8uXLzc6dO82GDRvMuHHjjM1mM//5z3+MMSXTn7Vo0cIsWbLErF692iQmJp4ztdDZNfbt29d06NDBLF261OzYscPMmTPHBAcHm9dee63aarvY61ddtZWOdebUWpW9Vvn5+Wb8+PFm5cqVZteuXWb16tVmxIgRJigo6JzOzfMd+2wqo4v9Yo9d1rG2bt1qbDab+fzzz8859u9//3sTGxtrZs2a5X7PqF+/vvnkk0/M9u3bzY033mj8/PzMtddee8HPqT/84Q+mQYMG5rPPPjPDhg0zvXv3Ns2bNzdLlizxeE/avn27mTp1qlm9erXZvXu3+fbbb01qaqpp1KiRx7RsZ48/evRo8+abb5rZs2cbSaZTp06mQYMGZuPGjZV+rpW+ZyYkJJhWrVqZ7t27m0aNGplXX33VBAUFmaZNm5prr73WpKenm23btpmXX37Z2Gw288orrxh/f3/z4osvmquvvtoMHz7chIaGmnfffdf9Wnj66adN/fr1zW9+8xv3lE+tWrVyd4pmZGQYm81m/uu//sts3brVvPfeeyYoKMj4+/ubt99+26xfv960bNnS2Gw2k5aWVu7nQI8ePYzdbjcvvvii2bp1q0lNTTXBwcHmlVdeKfN9wpiy34vOHuf55583kswdd9zhrq90/bQ33njDbN261fzlL38xfn5+5uuvv3aPM3ToUDN8+HD39fnoo4/MY489ZkJCQsyECRNMUFCQiYiIMHPmzPH4PKhXr54JCQnxeE02bdrU4/OgSZMmZvLkyWbr1q2mWbNm5rLLLjOSzOjRo82GDRvMzTffbIKCgkzHjh3Ntm3bPK7ZmZ3qpT//4uJiExsba66++urzvr4qep0WFxebFi1amNtuu80EBAR4XB+bzWbCwsLMRx99ZLZu3WomTpxogoODPaa0K/0sLx3nzjvvNJ9//rnZsWOHueGGG9zTuX344YfmtddeM/Xr1zfBwcFm7NixHq+5Tp06mfHjx5sBAwaYVq1amSeeeML9vhwfH29uuOEG93Phgw8+MEFBQebtt982P/74oxk1apRp0KCByc7ONqh5ZFuyLdm2BNmWbEu2JduSbcm2ZFvfR7Yl25JtS5BtybZkW7It2ZZs6+vZlkaFcgwaNMg0a9bMBAYGmpiYGDNo0CCPJ0rfvn3N8OHDPfb58MMPTZs2bUxgYKDp0KGDWbBgQS1XfX6la42c/TV8+HD31DhlfZ29Xs2UKVPc35/vWll5TsaUTCHTvHlzExAQYFq0aGEmTpzo8cZtzLk/zwkTJpgrrrjCBAcHm4YNG5rExETzwQcfVGvd5V3rOXPmGGNK1q/q06ePadSokQkKCjJXXHGFefLJJ89Zc+jMfcpS1cB77733mpYtW5rAwEDTtGlTk5yc7PEhduLECfPwww+bhg0bmtDQUHPbbbeZ/fv3V1jj/v37zT333GOio6NNcHCwadu2rfnzn/9snE5ntdV2sdevumoz5twgWNlrdeLECXPbbbeZ6OhoExgYaJo1a2ZuvfVWk5GRUeljn62sD9KLPXZZxxo/fryJjY01xcXF52w/aNAgI8n4+/u73zMmTZrkfp3Gxsaa7t27V+o55XQ6zaRJk4zD4TB2u90EBgaagICAc96TsrKyzE033WQiIyNNQECAad68uRk8eLD56aefKhw/Pj6+zNfrlClTKv1cO/M9MzQ01AQHB5vAwED3c23z5s3m9ttvN5GRkSY0NNRcddVV5u9//7sxxph//etfpmPHjkaSadKkiXnjjTeMMb++FgICAkxoaKj7/JOTk83mzZs96mjatKmJjIw0QUFBpl27duaNN94wf/nLX0yLFi1MQEDABX8O3HXXXaZjx47uMNmoUaNy3ydK9zn7vejscdq1a2fGjBnj8f0bb7xh3nrrLfd7cufOnT2m3jLm1/fw0usTEBBgAgMDjb+/v6lfv76RStanO/vzYNy4ceaBBx7weK4lJiZ6fB5Icj9fJJnOnTub22+/3TgcDhMUFGS6detW7jXbuXPnOT//L774wkgyKSkp5319VfQ6LR1n8+bNZV6fadOmmebNm5vQ0FCTmJjo8R8Ipdd+ypQp7nFeeeUVc9lll5nAwEATGRlprrrqKve1k2QaNmxoXnrpJfd7YelrrnTKs9Ln2pnvy3a73bRq1crjuVD6XAsMDDTx8fHmu+++M6gdZFuyLdm2BNmWbEu2JduSbcm2ZFvfR7Yl25JtS5BtybZkW7It2ZZs6+vZ1ua6eAAAAAAAAAAAAAAAADXOfv5NAAAAAAAAAAAAAAAAqgeNCgAAAAAAAAAAAAAAoNbQqAAAAAAAAAAAAAAAAGoNjQoAAAAAAAAAAAAAAKDW0KgAAAAAAAAAAAAAAABqDY0KAAAAAAAAAAAAAACg1tCoAAAAAAAAAAAAAAAAag2NCgAAAAAAAAAAAAAAoNbQqAAAddyzzz4rh8Mhm82mTz/99IL2WbZsmWw2m44cOVKjtXmTuLg4zZgxw+oyAAAAUAGy7YUh2wIAAHg/su2FIdsCdReNCgBq3T333CObzSabzabAwEBdccUVev7553X69GmrSzuvyoRGb7Bp0yY999xzev3117V//37ddNNNNXas6667To899liNjQ8AAOCNyLa1h2wLAABQs8i2tYdsCwCSv9UFALg03XjjjZozZ44KCwu1cOFCjR49WgEBARo/fnylxyouLpbNZpPdTu/V2bZv3y5JGjBggGw2m8XVAAAA1E1k29pBtgUAAKh5ZNvaQbYFAGZUAGCRoKAgRUVFqWXLlnrooYeUkpKi+fPnS5IKCwv1xBNPKCYmRmFhYUpISNCyZcvc+7799ttq0KCB5s+fr/bt2ysoKEh79uxRYWGhnn76acXGxiooKEhXXHGF3nrrLfd+33//vW666SbVq1dPDodDQ4cO1cGDB92PX3fddXrkkUf01FNPqVGjRoqKitKzzz7rfjwuLk6SdNttt8lms7m/3759uwYMGCCHw6F69eqpZ8+e+vLLLz3Od//+/brlllsUEhKiVq1a6f333z9nyqojR47o/vvvV9OmTRUeHq6kpCStX7++wuu4ceNGJSUlKSQkRI0bN9aoUaOUn58vqWTqsNTUVEmS3W6vMPAuXLhQbdq0UUhIiK6//nrt2rXL4/FffvlFd911l2JiYhQaGqpOnTrpH//4h/vxe+65R8uXL9err77q7rretWuXiouLdd9996lVq1YKCQlR27Zt9eqrr1Z4TqU/3zN9+umnHvWvX79e119/verXr6/w8HB1795dq1evdj/+zTff6Nprr1VISIhiY2P1yCOPqKCgwP14bm6uUlNT3T+P9957r8KaAAAAKkK2JduWh2wLAAB8DdmWbFsesi2A6kajAgCvEBISoqKiIknSmDFjtHLlSn3wwQfasGGD7rjjDt14443aunWre/vjx4/rpZde0v/+7//qhx9+UGRkpIYNG6Z//OMf+p//+R9t2rRJr7/+uurVqyepJEwmJSWpa9euWr16tRYtWqScnBzdeeedHnW88847CgsLU3p6uv74xz/q+eef1+LFiyVJq1atkiTNmTNH+/fvd3+fn5+vm2++WWlpaVq7dq1uvPFGpaamas+ePe5xhw0bpn379mnZsmX6+OOP9cYbbyg3N9fj2HfccYdyc3P1+eefKzMzU926dVNycrIOHTpU5jUrKChQ//791bBhQ61atUofffSRvvzyS40ZM0aS9MQTT2jOnDmSSgL3/v37yxxn7969uv3225Wamqp169bp/vvv17hx4zy2OXnypLp3764FCxbo+++/16hRozR06FBlZGRIkl599VUlJiZq5MiR7mPFxsbK6XSqefPm+uijj/Tjjz9q8uTJeuaZZ/Thhx+WWcuFGjJkiJo3b65Vq1YpMzNT48aNU0BAgKSS/wC58cYb9Zvf/EYbNmzQ3Llz9c0337ivi1QS0Pfu3aulS5fqn//8p1577bVzfh4AAAAXi2xLtq0Msi0AAPBmZFuybWWQbQFUigGAWjZ8+HAzYMAAY4wxTqfTLF682AQFBZknnnjC7N692/j5+ZmsrCyPfZKTk8348eONMcbMmTPHSDLr1q1zP75582YjySxevLjMY77wwgumX79+Hvft3bvXSDKbN282xhjTt29fc80113hs07NnT/P000+7v5dkPvnkk/OeY4cOHcxf/vIXY4wxmzZtMpLMqlWr3I9v3brVSDKvvPKKMcaYr7/+2oSHh5uTJ096jHP55Zeb119/vcxjvPHGG6Zhw4YmPz/ffd+CBQuM3W432dnZxhhjPvnkE3O+t/rx48eb9u3be9z39NNPG0nm8OHD5e53yy23mN///vfu7/v27WseffTRCo9ljDGjR482v/nNb8p9fM6cOSYiIsLjvrPPo379+ubtt98uc//77rvPjBo1yuO+r7/+2tjtdnPixAn3cyUjI8P9eOnPqPTnAQAAcKHItmRbsi0AAKgryLZkW7ItgNrkX+OdEABQhn//+9+qV6+eTp06JafTqcGDB+vZZ5/VsmXLVFxcrDZt2nhsX1hYqMaNG7u/DwwM1FVXXeX+ft26dfLz81Pfvn3LPN769eu1dOlSd6fumbZv3+4+3pljSlKzZs3O27GZn5+vZ599VgsWLND+/ft1+vRpnThxwt2Zu3nzZvn7+6tbt27ufa644go1bNjQo778/HyPc5SkEydOuNcrO9umTZvUuXNnhYWFue/r3bu3nE6nNm/eLIfDUWHdZ46TkJDgcV9iYqLH98XFxZo6dao+/PBDZWVlqaioSIWFhQoNDT3v+DNnztTs2bO1Z88enThxQkVFRerSpcsF1VaesWPH6v7779f//d//KSUlRXfccYcuv/xySSXXcsOGDR7Tghlj5HQ6tXPnTm3ZskX+/v7q3r27+/F27dqdM20ZAADAhSLbkm2rgmwLAAC8CdmWbFsVZFsAlUGjAgBLXH/99frb3/6mwMBARUdHy9+/5O0oPz9ffn5+yszMlJ+fn8c+Z4bVkJAQj7WvQkJCKjxefn6+UlNT9dJLL53zWLNmzdy3S6ehKmWz2eR0Oisc+4knntDixYv18ssv64orrlBISIh++9vfuqdEuxD5+flq1qyZx5pupbwhiP3pT3/Sq6++qhkzZqhTp04KCwvTY489dt5z/OCDD/TEE0/oz3/+sxITE1W/fn396U9/Unp6ern72O12GWM87jt16pTH988++6wGDx6sBQsW6PPPP9eUKVP0wQcf6LbbblN+fr4eeOABPfLII+eM3aJFC23ZsqUSZw4AAHB+ZNtz6yPbliDbAgAAX0O2Pbc+sm0Jsi2A6kajAgBLhIWF6Yorrjjn/q5du6q4uFi5ubm69tprL3i8Tp06yel0avny5UpJSTnn8W7duunjjz9WXFycO1xfjICAABUXF3vc9+233+qee+7RbbfdJqkkvO7atcv9eNu2bXX69GmtXbvW3Q26bds2HT582KO+7Oxs+fv7Ky4u7oJqufLKK/X222+roKDA3Z377bffym63q23bthd8TldeeaXmz5/vcd933313zjkOGDBAd999tyTJ6XRqy5Ytat++vXubwMDAMq9Nr1699PDDD7vvK6/TuFTTpk117Ngxj/Nat27dOdu1adNGbdq00eOPP6677rpLc+bM0W233aZu3brpxx9/LPP5JZV04Z4+fVqZmZnq2bOnpJLu6SNHjlRYFwAAQHnItmTb8pBtAQCAryHbkm3LQ7YFUN3sVhcAAGdq06aNhgwZomHDhmnevHnauXOnMjIyNG3aNC1YsKDc/eLi4jR8+HDde++9+vTTT7Vz504tW7ZMH374oSRp9OjROnTokO666y6tWrVK27dv1xdffKERI0acE9IqEhcXp7S0NGVnZ7sDa+vWrTVv3jytW7dO69ev1+DBgz26edu1a6eUlBSNGjVKGRkZWrt2rUaNGuXRXZySkqLExEQNHDhQ//nPf7Rr1y6tWLFCEyZM0OrVq8usZciQIQoODtbw4cP1/fffa+nSpfrv//5vDR069IKnD5OkBx98UFu3btWTTz6pzZs36/3339fbb7/tsU3r1q21ePFirVixQps2bdIDDzygnJycc65Nenq6du3apYMHD8rpdKp169ZavXq1vvjiC23ZskWTJk3SqlWrKqwnISFBoaGheuaZZ7R9+/Zz6jlx4oTGjBmjZcuWaffu3fr222+1atUqXXnllZKkp59+WitWrNCYMWO0bt06bd26VZ999pnGjBkjqeQ/QG688UY98MADSk9PV2Zmpu6///7zdncDAABUFtmWbEu2BQAAdQXZlmxLtgVQ3WhUAOB15syZo2HDhun3v/+92rZtq4EDB2rVqlVq0aJFhfv97W9/029/+1s9/PDDateunUaOHKmCggJJUnR0tL799lsVFxerX79+6tSpkx577DE1aNBAdvuFvxX++c9/1uLFixUbG6uuXbtKkqZPn66GDRuqV69eSk1NVf/+/T3WNZOkv//973I4HOrTp49uu+02jRw5UvXr11dwcLCkkqnKFi5cqD59+mjEiBFq06aNfve732n37t3lhtfQ0FB98cUXOnTokHr27Knf/va3Sk5O1l//+tcLPh+pZFqtjz/+WJ9++qk6d+6sWbNmaerUqR7bTJw4Ud26dVP//v113XXXKSoqSgMHDvTY5oknnpCfn5/at2+vpk2bas+ePXrggQd0++23a9CgQUpISNAvv/zi0aVblkaNGundd9/VwoUL1alTJ/3jH//Qs88+637cz89Pv/zyi4YNG6Y2bdrozjvv1E033aTnnntOUsl6dcuXL9eWLVt07bXXqmvXrpo8ebKio6PdY8yZM0fR0dHq27evbr/9do0aNUqRkZGVum4AAAAXgmxLtiXbAgCAuoJsS7Yl2wKoTjZz9oIyAIAa9/PPPys2NlZffvmlkpOTrS4HAAAAuGhkWwAAANQVZFsAqD00KgBALViyZIny8/PVqVMn7d+/X0899ZSysrK0ZcsWBQQEWF0eAAAAcMHItgAAAKgryLYAYB1/qwsAgEvBqVOn9Mwzz2jHjh2qX7++evXqpffee4+wCwAAAJ9DtgUAAEBdQbYFAOswowIAAAAAAAAAAAAAAKg1dqsLAAAAAAAAAAAAAAAAlw4aFQAAAAAAAAAAAAAAQK2hUQEAAAAAAAAAAAAAANQaGhUAAAAAAAAAAAAAAECtoVEBAAAAAAAAAAAAAADUGhoVAAAAAAAAAAAAAABAraFRAQAAAAAAAAAAAAAA1BoaFQAAAAAAAAAAAAAAQK2hUQEAAAAAAAAAAAAAANSa/w8SpH7ao8EcuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651126e7",
   "metadata": {
    "papermill": {
     "duration": 0.059352,
     "end_time": "2025-03-23T11:13:22.849383",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.790031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "494cadd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:13:22.876113Z",
     "iopub.status.busy": "2025-03-23T11:13:22.875784Z",
     "iopub.status.idle": "2025-03-23T12:05:00.182920Z",
     "shell.execute_reply": "2025-03-23T12:05:00.182136Z"
    },
    "papermill": {
     "duration": 3097.322098,
     "end_time": "2025-03-23T12:05:00.184388",
     "exception": false,
     "start_time": "2025-03-23T11:13:22.862290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 63.304930686950684 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005745713599026205\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 7.506768226623535 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6203, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5033, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4868, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4617, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4448, Accuracy: 0.7999, F1 Micro: 0.8873, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.399, Accuracy: 0.817, F1 Micro: 0.8958, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3499, Accuracy: 0.8318, F1 Micro: 0.9032, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3249, Accuracy: 0.8438, F1 Micro: 0.9089, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2824, Accuracy: 0.8616, F1 Micro: 0.9183, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2359, Accuracy: 0.8921, F1 Micro: 0.9355, F1 Macro: 0.9344\n",
      "\n",
      "Aspect detection accuracy: 0.8921, F1 Micro: 0.9355, F1 Macro: 0.9344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      1.00      0.96       187\n",
      "     machine       0.81      1.00      0.90       175\n",
      "      others       0.82      0.96      0.88       158\n",
      "        part       0.90      0.98      0.94       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.94      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.99      0.94      1061\n",
      "   macro avg       0.89      0.99      0.93      1061\n",
      "weighted avg       0.89      0.99      0.94      1061\n",
      " samples avg       0.89      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6453, Accuracy: 0.6556, F1 Micro: 0.6556, F1 Macro: 0.396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5042, Accuracy: 0.6556, F1 Micro: 0.6556, F1 Macro: 0.396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4739, Accuracy: 0.6821, F1 Micro: 0.6821, F1 Macro: 0.4739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4082, Accuracy: 0.7616, F1 Micro: 0.7616, F1 Macro: 0.6653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2609, Accuracy: 0.8146, F1 Micro: 0.8146, F1 Macro: 0.7619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8305\n",
      "Epoch 8/10, Train Loss: 0.0981, Accuracy: 0.8079, F1 Micro: 0.8079, F1 Macro: 0.7472\n",
      "Epoch 9/10, Train Loss: 0.1158, Accuracy: 0.8146, F1 Micro: 0.8146, F1 Macro: 0.758\n",
      "Epoch 10/10, Train Loss: 0.0821, Accuracy: 0.8212, F1 Micro: 0.8212, F1 Macro: 0.7722\n",
      "\n",
      "Sentiment analysis accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.63      0.76        52\n",
      "    positive       0.84      0.98      0.90        99\n",
      "\n",
      "    accuracy                           0.86       151\n",
      "   macro avg       0.89      0.81      0.83       151\n",
      "weighted avg       0.87      0.86      0.85       151\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8719, F1 Micro: 0.8719, F1 Macro: 0.6425\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.92      1.00      0.96       181\n",
      "    positive       0.93      0.58      0.72        24\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.95      0.68      0.77       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.12      0.22        16\n",
      "     neutral       0.80      1.00      0.89       167\n",
      "    positive       0.67      0.12      0.21        33\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.82      0.42      0.44       216\n",
      "weighted avg       0.80      0.80      0.74       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.08      0.13        12\n",
      "     neutral       0.82      0.97      0.89       152\n",
      "    positive       0.68      0.44      0.53        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.61      0.50      0.52       216\n",
      "weighted avg       0.76      0.79      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.39      0.56        23\n",
      "     neutral       0.89      0.98      0.93       152\n",
      "    positive       0.72      0.71      0.72        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.87      0.69      0.74       216\n",
      "weighted avg       0.87      0.87      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.15      0.27        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.62      0.59      0.61        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.58      0.61       216\n",
      "weighted avg       0.91      0.91      0.89       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.70      0.78       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Total train time: 72.67481112480164 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0013907131971791387\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.791614532470703 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5963, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4909, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.478, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4552, Accuracy: 0.7932, F1 Micro: 0.884, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.413, Accuracy: 0.8118, F1 Micro: 0.8929, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3767, Accuracy: 0.8594, F1 Micro: 0.9176, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3167, Accuracy: 0.9003, F1 Micro: 0.9398, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2515, Accuracy: 0.9219, F1 Micro: 0.9522, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2244, Accuracy: 0.9368, F1 Micro: 0.9611, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1822, Accuracy: 0.9412, F1 Micro: 0.9638, F1 Macro: 0.9627\n",
      "\n",
      "Aspect detection accuracy: 0.9412, F1 Micro: 0.9638, F1 Macro: 0.9627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.85      0.99      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.94      0.99      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6328, Accuracy: 0.6542, F1 Micro: 0.6542, F1 Macro: 0.3955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5237, Accuracy: 0.7243, F1 Micro: 0.7243, F1 Macro: 0.5947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3153, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.898\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1617, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9197\n",
      "Epoch 6/10, Train Loss: 0.1596, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9135\n",
      "Epoch 7/10, Train Loss: 0.1214, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9135\n",
      "Epoch 8/10, Train Loss: 0.0581, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.9007\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8792\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8849\n",
      "\n",
      "Sentiment analysis accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        74\n",
      "    positive       0.98      0.91      0.94       140\n",
      "\n",
      "    accuracy                           0.93       214\n",
      "   macro avg       0.91      0.93      0.92       214\n",
      "weighted avg       0.93      0.93      0.93       214\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.8343\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.62      0.67        16\n",
      "     neutral       0.93      0.98      0.95       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.76      0.79       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.85      0.99      0.91       152\n",
      "    positive       0.93      0.52      0.67        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.84      0.72      0.76       216\n",
      "weighted avg       0.86      0.86      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.70      0.78        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.84      0.76      0.79        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.74      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 80.71420168876648 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014003454707562923\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.148317813873291 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5933, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5205, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4766, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4462, Accuracy: 0.8103, F1 Micro: 0.8924, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4049, Accuracy: 0.869, F1 Micro: 0.9227, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3354, Accuracy: 0.9241, F1 Micro: 0.9532, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2666, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.211, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1768, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1406, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5739, Accuracy: 0.6774, F1 Micro: 0.6774, F1 Macro: 0.4038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4309, Accuracy: 0.8347, F1 Micro: 0.8347, F1 Macro: 0.7914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2276, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1171, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1003, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.045, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        80\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.93      0.95      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.898\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.78      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.85      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 96.69466090202332 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014694785117171708\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.410380363464355 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5912, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5253, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4969, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4313, Accuracy: 0.8579, F1 Micro: 0.9167, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3603, Accuracy: 0.9167, F1 Micro: 0.9491, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2839, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2202, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "Epoch 8/10, Train Loss: 0.177, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9683\n",
      "Epoch 9/10, Train Loss: 0.1366, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9692\n",
      "Epoch 10/10, Train Loss: 0.1206, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9693\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.97      0.95       175\n",
      "      others       0.87      0.98      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5443, Accuracy: 0.6681, F1 Micro: 0.6681, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3693, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9176\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9353\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9237\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9296\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.93\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        79\n",
      "    positive       0.98      0.93      0.95       159\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.93      0.95      0.94       238\n",
      "weighted avg       0.94      0.94      0.94       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8772\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.96      0.95       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.67      0.55        12\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.91      0.60      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.76      0.74      0.73       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 88.24902701377869 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0009731133468449116\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.53532886505127 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.566, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5311, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4807, Accuracy: 0.8237, F1 Micro: 0.8984, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.392, Accuracy: 0.8899, F1 Micro: 0.9335, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3122, Accuracy: 0.9263, F1 Micro: 0.9542, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2373, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1864, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1479, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1158, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0995, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5365, Accuracy: 0.7183, F1 Micro: 0.7183, F1 Macro: 0.5604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.322, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1166, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1052, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9214\n",
      "Epoch 7/10, Train Loss: 0.1156, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Epoch 8/10, Train Loss: 0.104, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.92        81\n",
      "    positive       0.99      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9005\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.96      0.96       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 102.35205101966858 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010933602461591367\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.068966150283813 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5825, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5159, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4632, Accuracy: 0.8333, F1 Micro: 0.9035, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3802, Accuracy: 0.9092, F1 Micro: 0.9448, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2924, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2172, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1737, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.1378, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Epoch 9/10, Train Loss: 0.1071, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9691\n",
      "Epoch 10/10, Train Loss: 0.0896, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.88      0.97      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.7108, F1 Micro: 0.7108, F1 Macro: 0.5279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2669, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9102\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9378\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        81\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       249\n",
      "   macro avg       0.94      0.95      0.94       249\n",
      "weighted avg       0.95      0.95      0.95       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8878\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.80      0.74       216\n",
      "weighted avg       0.89      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.56977105140686 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0007108735386282206\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.631265878677368 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5817, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5049, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4624, Accuracy: 0.8653, F1 Micro: 0.9204, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3608, Accuracy: 0.9196, F1 Micro: 0.9509, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2731, Accuracy: 0.9449, F1 Micro: 0.9661, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2026, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1576, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.1313, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1026, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0863, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5162, Accuracy: 0.7016, F1 Micro: 0.7016, F1 Macro: 0.5062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.286, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1941, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9276\n",
      "Epoch 4/10, Train Loss: 0.1509, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.937\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9327\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9241\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9203\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.928\n",
      "\n",
      "Sentiment analysis accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        81\n",
      "    positive       0.98      0.94      0.96       167\n",
      "\n",
      "    accuracy                           0.94       248\n",
      "   macro avg       0.93      0.95      0.94       248\n",
      "weighted avg       0.95      0.94      0.94       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8966\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.74752855300903 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.000710057356627658\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.461148023605347 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.561, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4986, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4302, Accuracy: 0.9048, F1 Micro: 0.9418, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3048, Accuracy: 0.9338, F1 Micro: 0.9585, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2258, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9715\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1305, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.1114, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0863, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5463, Accuracy: 0.814, F1 Micro: 0.814, F1 Macro: 0.7506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2716, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 3/10, Train Loss: 0.1557, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.919\n",
      "Epoch 4/10, Train Loss: 0.1114, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1142, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 6/10, Train Loss: 0.1381, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 7/10, Train Loss: 0.0783, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        83\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8864\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.92      0.51        12\n",
      "     neutral       0.95      0.88      0.91       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.85      0.75       216\n",
      "weighted avg       0.90      0.85      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.79422903060913 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006835286854766313\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.69985818862915 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5604, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4963, Accuracy: 0.7932, F1 Micro: 0.8841, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4252, Accuracy: 0.8847, F1 Micro: 0.9303, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3254, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2472, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9711\n",
      "Epoch 6/10, Train Loss: 0.1808, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.139, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.1129, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0802, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2349, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2255, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9281\n",
      "Epoch 4/10, Train Loss: 0.1593, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Epoch 5/10, Train Loss: 0.151, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9202\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 8/10, Train Loss: 0.1079, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8905\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.83      0.76       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.22121477127075 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0005004255537642164\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.143543481826782 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5608, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5029, Accuracy: 0.7946, F1 Micro: 0.8847, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4043, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3073, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2266, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.127, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Epoch 9/10, Train Loss: 0.0891, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0754, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4983, Accuracy: 0.8054, F1 Micro: 0.8054, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2767, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1498, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1257, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0893, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9322\n",
      "Epoch 6/10, Train Loss: 0.0791, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0679, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.86      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.73390531539917 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.000383588281692937\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.6683056354522705 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5654, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4865, Accuracy: 0.8192, F1 Micro: 0.8967, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3936, Accuracy: 0.9025, F1 Micro: 0.9413, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.288, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2116, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1559, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1242, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4924, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.8334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2881, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Epoch 4/10, Train Loss: 0.1392, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0982, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "\n",
      "Sentiment analysis accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        86\n",
      "    positive       0.95      0.95      0.95       182\n",
      "\n",
      "    accuracy                           0.93       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.93      0.93      0.93       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.91\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.91034126281738 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0002816201595123857\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 5.948026657104492 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5667, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4784, Accuracy: 0.8185, F1 Micro: 0.8965, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3679, Accuracy: 0.9278, F1 Micro: 0.9555, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2625, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1966, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1191, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 8/10, Train Loss: 0.0946, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.523, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9272\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1244, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9461\n",
      "Epoch 7/10, Train Loss: 0.117, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 10/10, Train Loss: 0.0809, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.93        84\n",
      "    positive       0.95      0.98      0.97       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.95      0.94      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8974\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.82      0.78       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      1.00      0.81        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.45941185951233 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00029607911128550786\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.579091787338257 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5573, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4726, Accuracy: 0.8289, F1 Micro: 0.9003, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3567, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2417, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9752\n",
      "Epoch 6/10, Train Loss: 0.1299, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4691, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2126, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9215\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9254\n",
      "Epoch 9/10, Train Loss: 0.0898, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9137\n",
      "Epoch 10/10, Train Loss: 0.0863, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9206\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90        86\n",
      "    positive       0.98      0.92      0.95       184\n",
      "\n",
      "    accuracy                           0.93       270\n",
      "   macro avg       0.92      0.94      0.93       270\n",
      "weighted avg       0.94      0.93      0.93       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9104\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.61996793746948 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00015297444770112634\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.2911176681518555 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5499, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4406, Accuracy: 0.869, F1 Micro: 0.9227, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3313, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2317, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Epoch 5/10, Train Loss: 0.1639, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4696, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1911, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9272\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0994, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0904, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 9/10, Train Loss: 0.0816, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 10/10, Train Loss: 0.0834, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9212\n",
      "\n",
      "Sentiment analysis accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        87\n",
      "    positive       0.96      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9016\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.88      0.74        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.85      0.81       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.05870175361633 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00017680745804682374\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.748547077178955 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4536, Accuracy: 0.8765, F1 Micro: 0.9268, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3212, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2277, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9744\n",
      "Epoch 5/10, Train Loss: 0.1636, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.9472, F1 Micro: 0.9662, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1135, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.488, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2436, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.927\n",
      "Epoch 3/10, Train Loss: 0.1616, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.91\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9356\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.927\n",
      "Epoch 9/10, Train Loss: 0.082, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0777, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.95       168\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9071\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.20512008666992 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00011872236791532487\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.338209867477417 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.543, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4464, Accuracy: 0.8839, F1 Micro: 0.9302, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3085, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2156, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1573, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.96      0.94      0.95       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4964, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1752, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9103\n",
      "Epoch 5/10, Train Loss: 0.1081, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Epoch 8/10, Train Loss: 0.0896, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8947\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.96      0.93      0.94       152\n",
      "    positive       0.85      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.82      0.90      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 132.56278920173645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.832601452013478e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.799464464187622 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4196, Accuracy: 0.907, F1 Micro: 0.9437, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2918, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9756\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.496, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.173, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1289, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1077, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Epoch 7/10, Train Loss: 0.107, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9179\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9228\n",
      "\n",
      "Sentiment analysis accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.95       165\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.94      0.93       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8883\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.82      0.78       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 134.43138933181763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.94644316151971e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.4590542316436768 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5362, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.431, Accuracy: 0.8876, F1 Micro: 0.9324, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2914, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1953, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1457, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9788\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4822, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2281, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "Epoch 7/10, Train Loss: 0.0964, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9144\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9292\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.9046\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        87\n",
      "    positive       0.96      0.96      0.96       185\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.93      0.93      0.93       272\n",
      "weighted avg       0.94      0.94      0.94       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8983\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.74      0.85      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.81      0.83       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.88      0.88      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.11487579345703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.5088009937899176e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.17063307762146 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5357, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4258, Accuracy: 0.9144, F1 Micro: 0.948, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2737, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1417, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4544, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1839, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9351\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9259\n",
      "Epoch 10/10, Train Loss: 0.0631, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        85\n",
      "    positive       0.96      0.96      0.96       182\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.94      0.94       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9077\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.85      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 134.98780727386475 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 5.2882370800944047e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.928583860397339 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5373, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4019, Accuracy: 0.9107, F1 Micro: 0.946, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2648, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1794, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1314, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5169, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2347, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0906, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9338\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "    positive       0.94      0.98      0.96       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.94      0.92      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9029\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.92      0.77        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.42631340026855 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.5765068676264492e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.225740909576416 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4043, Accuracy: 0.9174, F1 Micro: 0.9492, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2682, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0787, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4976, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9124\n",
      "Epoch 2/10, Train Loss: 0.2562, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9283\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9026\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.84      0.78       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 143.57160878181458 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.7220805714023298e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9026143550872803 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5282, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3928, Accuracy: 0.9286, F1 Micro: 0.9564, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2389, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 5/10, Train Loss: 0.1264, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.061, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.462, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2107, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9386\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9234\n",
      "Epoch 4/10, Train Loss: 0.1266, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.9248\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.9082\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.9248\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9035\n",
      "Epoch 8/10, Train Loss: 0.0789, Accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0596, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9375\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.9239\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       188\n",
      "\n",
      "    accuracy                           0.95       275\n",
      "   macro avg       0.93      0.94      0.94       275\n",
      "weighted avg       0.95      0.95      0.95       275\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8993\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.82      0.96      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.89       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.95      0.88      0.91       152\n",
      "    positive       0.74      0.83      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.85      0.79       216\n",
      "weighted avg       0.88      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.23532891273499 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.8953931976284364e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3214616775512695 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5203, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3902, Accuracy: 0.9286, F1 Micro: 0.9559, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2352, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5029, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2387, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9105\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9279\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9161\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Epoch 8/10, Train Loss: 0.0909, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9157\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9126\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.56539154052734 s\n",
      "Total runtime: 3096.311123609543 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074dc8b",
   "metadata": {
    "papermill": {
     "duration": 0.199129,
     "end_time": "2025-03-23T12:05:00.538608",
     "exception": false,
     "start_time": "2025-03-23T12:05:00.339479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ce56981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T12:05:00.842923Z",
     "iopub.status.busy": "2025-03-23T12:05:00.842567Z",
     "iopub.status.idle": "2025-03-23T12:58:39.568164Z",
     "shell.execute_reply": "2025-03-23T12:58:39.567271Z"
    },
    "papermill": {
     "duration": 3218.878196,
     "end_time": "2025-03-23T12:58:39.569836",
     "exception": false,
     "start_time": "2025-03-23T12:05:00.691640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 60.92792224884033 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008303248207084835\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.546241998672485 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6059, Accuracy: 0.7887, F1 Micro: 0.8818, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5336, Accuracy: 0.7894, F1 Micro: 0.8821, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4962, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4756, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.459, Accuracy: 0.7999, F1 Micro: 0.8865, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4103, Accuracy: 0.808, F1 Micro: 0.8898, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3772, Accuracy: 0.8237, F1 Micro: 0.8974, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3375, Accuracy: 0.8445, F1 Micro: 0.9087, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2851, Accuracy: 0.8713, F1 Micro: 0.9223, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2508, Accuracy: 0.872, F1 Micro: 0.9226, F1 Macro: 0.9197\n",
      "\n",
      "Aspect detection accuracy: 0.872, F1 Micro: 0.9226, F1 Macro: 0.9197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.90      1.00      0.95       187\n",
      "     machine       0.86      0.98      0.92       175\n",
      "      others       0.84      0.85      0.85       158\n",
      "        part       0.86      0.96      0.91       158\n",
      "       price       0.96      0.98      0.97       192\n",
      "     service       0.87      1.00      0.93       191\n",
      "\n",
      "   micro avg       0.88      0.97      0.92      1061\n",
      "   macro avg       0.88      0.96      0.92      1061\n",
      "weighted avg       0.88      0.97      0.92      1061\n",
      " samples avg       0.89      0.97      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6038, Accuracy: 0.7753, F1 Micro: 0.7753, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5372, Accuracy: 0.7753, F1 Micro: 0.7753, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4926, Accuracy: 0.7753, F1 Micro: 0.7753, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4347, Accuracy: 0.7921, F1 Micro: 0.7921, F1 Macro: 0.5622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3295, Accuracy: 0.8202, F1 Micro: 0.8202, F1 Macro: 0.727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2684, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.7866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1765, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8532\n",
      "Epoch 8/10, Train Loss: 0.1558, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1133, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0953, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8577\n",
      "\n",
      "Sentiment analysis accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.88      0.79        40\n",
      "    positive       0.96      0.90      0.93       138\n",
      "\n",
      "    accuracy                           0.89       178\n",
      "   macro avg       0.84      0.89      0.86       178\n",
      "weighted avg       0.91      0.89      0.90       178\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.6403\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.27      0.43        11\n",
      "     neutral       0.91      1.00      0.95       181\n",
      "    positive       1.00      0.54      0.70        24\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.97      0.60      0.69       216\n",
      "weighted avg       0.92      0.91      0.90       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.06      0.12        16\n",
      "     neutral       0.85      0.98      0.91       167\n",
      "    positive       0.83      0.58      0.68        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.89      0.54      0.57       216\n",
      "weighted avg       0.86      0.85      0.82       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.42      0.40        12\n",
      "     neutral       0.84      0.84      0.84       152\n",
      "    positive       0.63      0.62      0.62        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.62      0.62      0.62       216\n",
      "weighted avg       0.77      0.76      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.61      0.67        23\n",
      "     neutral       0.85      0.96      0.90       152\n",
      "    positive       0.81      0.51      0.63        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.80      0.69      0.73       216\n",
      "weighted avg       0.83      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.96      0.98      0.97       186\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        14\n",
      "     neutral       0.87      1.00      0.93       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.62      0.38      0.39       216\n",
      "weighted avg       0.81      0.87      0.81       216\n",
      "\n",
      "Total train time: 76.20807957649231 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001422121748328209\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.24895691871643 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5908, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5228, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4973, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4793, Accuracy: 0.7954, F1 Micro: 0.8836, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4268, Accuracy: 0.8177, F1 Micro: 0.8955, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3843, Accuracy: 0.8594, F1 Micro: 0.9169, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3163, Accuracy: 0.9025, F1 Micro: 0.9409, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2676, Accuracy: 0.9122, F1 Micro: 0.9461, F1 Macro: 0.9443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2165, Accuracy: 0.9249, F1 Micro: 0.9539, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1847, Accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9562\n",
      "\n",
      "Aspect detection accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.96      0.95       175\n",
      "      others       0.87      0.91      0.89       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.99      0.98      0.98       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5945, Accuracy: 0.6822, F1 Micro: 0.6822, F1 Macro: 0.4055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.502, Accuracy: 0.8008, F1 Micro: 0.8008, F1 Macro: 0.7232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3123, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.196, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8985\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1013, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8985\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9114\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.9016\n",
      "Epoch 10/10, Train Loss: 0.0549, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        75\n",
      "    positive       0.94      0.95      0.94       161\n",
      "\n",
      "    accuracy                           0.92       236\n",
      "   macro avg       0.91      0.91      0.91       236\n",
      "weighted avg       0.92      0.92      0.92       236\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8207\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.81      0.82       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.87      0.91      0.89       152\n",
      "    positive       0.74      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.77      0.76      0.76       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.74      0.77        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.85      0.71      0.77        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.98      0.98       186\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       1.00      0.24      0.38        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.65      0.71       216\n",
      "weighted avg       0.93      0.92      0.90       216\n",
      "\n",
      "Total train time: 79.28256225585938 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015119469026103616\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.49571943283081 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5773, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4997, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4925, Accuracy: 0.7924, F1 Micro: 0.8831, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4568, Accuracy: 0.8155, F1 Micro: 0.8936, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4001, Accuracy: 0.8653, F1 Micro: 0.9199, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3195, Accuracy: 0.9085, F1 Micro: 0.9437, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2692, Accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2095, Accuracy: 0.936, F1 Micro: 0.9599, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1818, Accuracy: 0.9412, F1 Micro: 0.9631, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1508, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9651\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.87      0.97      0.92       158\n",
      "        part       0.98      0.96      0.97       158\n",
      "       price       0.98      0.97      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.6762, F1 Micro: 0.6762, F1 Macro: 0.4034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4578, Accuracy: 0.8525, F1 Micro: 0.8525, F1 Macro: 0.8254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3338, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0762, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9449\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0419, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9321\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        79\n",
      "    positive       0.98      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.95      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8746\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.87      0.97      0.92       152\n",
      "    positive       0.94      0.62      0.74        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.78      0.80       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.95      0.97       152\n",
      "    positive       0.85      0.85      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.94      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.91      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.59      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.77      0.84       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Total train time: 89.13907361030579 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015020604711025957\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.292829275131226 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5847, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5167, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4812, Accuracy: 0.7961, F1 Micro: 0.8838, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4281, Accuracy: 0.8519, F1 Micro: 0.9125, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3498, Accuracy: 0.91, F1 Micro: 0.9448, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2908, Accuracy: 0.9353, F1 Micro: 0.9598, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2292, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1656, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1406, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.114, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5716, Accuracy: 0.682, F1 Micro: 0.682, F1 Macro: 0.4055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3987, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9192\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9197\n",
      "Epoch 6/10, Train Loss: 0.059, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9063\n",
      "Epoch 7/10, Train Loss: 0.0378, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8803\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9117\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9188\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90        83\n",
      "    positive       0.97      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.91      0.93      0.92       261\n",
      "weighted avg       0.93      0.93      0.93       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8738\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.91      0.90      0.91       152\n",
      "    positive       0.75      0.73      0.74        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.82      0.80       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.87      0.78        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.42760038375854 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001196755561977625\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.230507373809814 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5645, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5335, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4765, Accuracy: 0.8095, F1 Micro: 0.891, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3992, Accuracy: 0.8824, F1 Micro: 0.9288, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3123, Accuracy: 0.9271, F1 Micro: 0.9547, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2356, Accuracy: 0.9412, F1 Micro: 0.9629, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.184, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1511, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1156, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5746, Accuracy: 0.668, F1 Micro: 0.668, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4019, Accuracy: 0.8477, F1 Micro: 0.8477, F1 Macro: 0.8385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.186, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1482, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "\n",
      "Sentiment analysis accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        83\n",
      "    positive       0.99      0.92      0.95       173\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.92      0.95      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.909\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.03220558166504 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001121072191745043\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.499120235443115 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5765, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.5007, Accuracy: 0.7902, F1 Micro: 0.8821, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4775, Accuracy: 0.846, F1 Micro: 0.909, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3783, Accuracy: 0.8943, F1 Micro: 0.9343, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3117, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2288, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1749, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1394, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1076, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5521, Accuracy: 0.7423, F1 Micro: 0.7423, F1 Macro: 0.6058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2933, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1499, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.93      0.96      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9109\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.15540504455566 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008036180050112306\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.370396137237549 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5059, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4627, Accuracy: 0.84, F1 Micro: 0.9044, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3675, Accuracy: 0.9003, F1 Micro: 0.9381, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2958, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2304, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1345, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1132, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0905, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.6899, F1 Micro: 0.6899, F1 Macro: 0.4797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3015, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.123, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9215\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9137\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.49499654769897 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006134841532912105\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.524099349975586 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5087, Accuracy: 0.7946, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4354, Accuracy: 0.8802, F1 Micro: 0.927, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3297, Accuracy: 0.933, F1 Micro: 0.9585, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2442, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1834, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1401, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.1034, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5509, Accuracy: 0.668, F1 Micro: 0.668, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3128, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.142, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1643, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9299\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.938\n",
      "Epoch 8/10, Train Loss: 0.0935, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        83\n",
      "    positive       0.99      0.93      0.96       167\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.93      0.95      0.94       250\n",
      "weighted avg       0.95      0.94      0.94       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.83      0.77       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.39414739608765 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005637987283989788\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.610073089599609 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5719, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5041, Accuracy: 0.8013, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4291, Accuracy: 0.8802, F1 Micro: 0.9272, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3365, Accuracy: 0.9368, F1 Micro: 0.9607, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2516, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1912, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1163, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0907, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0758, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5555, Accuracy: 0.7208, F1 Micro: 0.7208, F1 Macro: 0.5637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2967, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1397, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1122, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0916, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        88\n",
      "    positive       0.96      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.93      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9153\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.87      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.06151843070984 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00039205091597978027\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.279946327209473 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5586, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.499, Accuracy: 0.8051, F1 Micro: 0.8883, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4176, Accuracy: 0.8929, F1 Micro: 0.9345, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3094, Accuracy: 0.9412, F1 Micro: 0.9631, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2284, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1695, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1344, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.9576, F1 Micro: 0.9731, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0847, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.515, Accuracy: 0.8447, F1 Micro: 0.8447, F1 Macro: 0.7998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2415, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1888, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Epoch 6/10, Train Loss: 0.1308, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.917\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9008\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.88      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.39801955223083 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0002869531454052776\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.629671812057495 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5653, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.8058, F1 Micro: 0.8891, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4235, Accuracy: 0.8929, F1 Micro: 0.9351, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3062, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2191, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1705, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1378, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0817, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4723, Accuracy: 0.8534, F1 Micro: 0.8534, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2437, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1136, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9124\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9406\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9214\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.91      0.90        33\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.20106768608093 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00029331110999919474\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.112691879272461 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.554, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5041, Accuracy: 0.8185, F1 Micro: 0.8954, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.376, Accuracy: 0.9152, F1 Micro: 0.9474, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2624, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2026, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1449, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 7/10, Train Loss: 0.1155, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.7765, F1 Micro: 0.7765, F1 Macro: 0.68\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2626, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1642, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9333\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9373\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9114\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.87      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.56743097305298 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0001965512245078572\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.5895349979400635 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5421, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4831, Accuracy: 0.8326, F1 Micro: 0.9028, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3685, Accuracy: 0.9278, F1 Micro: 0.9557, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.258, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1815, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.1364, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9643, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4788, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2744, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9147\n",
      "Epoch 3/10, Train Loss: 0.178, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9338\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9299, F1 Micro: 0.9299, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        88\n",
      "    positive       0.97      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.93      0.94      0.93       271\n",
      "weighted avg       0.94      0.94      0.94       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8886\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.88      0.80       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.86      0.90      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.59602904319763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00018552017718320712\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.347259759902954 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5447, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4627, Accuracy: 0.8497, F1 Micro: 0.9114, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3503, Accuracy: 0.9301, F1 Micro: 0.9571, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2367, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1759, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.126, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5428, Accuracy: 0.7887, F1 Micro: 0.7887, F1 Macro: 0.7019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 5/10, Train Loss: 0.1447, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9294\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0978, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9449\n",
      "Epoch 9/10, Train Loss: 0.0772, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9291\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       179\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9122\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.84      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.52198362350464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.479786629322916e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.771061420440674 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4697, Accuracy: 0.8363, F1 Micro: 0.9052, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3355, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2344, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0545, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4841, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2041, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1811, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 4/10, Train Loss: 0.1389, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1123, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9497\n",
      "Epoch 6/10, Train Loss: 0.1014, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1043, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9494\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9366\n",
      "Epoch 9/10, Train Loss: 0.0857, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9359\n",
      "Epoch 10/10, Train Loss: 0.0755, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        87\n",
      "    positive       0.98      0.96      0.97       180\n",
      "\n",
      "    accuracy                           0.96       267\n",
      "   macro avg       0.94      0.95      0.95       267\n",
      "weighted avg       0.96      0.96      0.96       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9084\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.76      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.39023160934448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.000102586331195198\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.408350944519043 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5523, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4676, Accuracy: 0.8274, F1 Micro: 0.9009, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3388, Accuracy: 0.9234, F1 Micro: 0.9521, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2293, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9728\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9487, F1 Micro: 0.9674, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1386, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1095, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5004, Accuracy: 0.8864, F1 Micro: 0.8864, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2567, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1065, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9479\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        87\n",
      "    positive       0.96      0.98      0.97       177\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.95      0.94      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8948\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.83      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.12714052200317 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00011690556857502088\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.936746120452881 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4511, Accuracy: 0.8653, F1 Micro: 0.92, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3095, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2097, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.493, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2291, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "Epoch 4/10, Train Loss: 0.1317, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 5/10, Train Loss: 0.1101, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9305\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9143\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9366\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.909\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.85      0.81       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.66366958618164 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 4.752690074383281e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.4291179180145264 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4506, Accuracy: 0.8676, F1 Micro: 0.9214, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3132, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2062, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1149, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2795, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9132\n",
      "Epoch 3/10, Train Loss: 0.1472, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Epoch 7/10, Train Loss: 0.1026, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.95      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8983\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.92      0.61        12\n",
      "     neutral       0.96      0.86      0.91       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.86      0.77       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.6550431251526 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 5.299469485180452e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.291949510574341 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.531, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4246, Accuracy: 0.9018, F1 Micro: 0.9399, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2757, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.195, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4969, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2314, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.945\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9488\n",
      "\n",
      "Sentiment analysis accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        85\n",
      "    positive       0.98      0.96      0.97       181\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.95      0.95       266\n",
      "weighted avg       0.96      0.95      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9221\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.03335428237915 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.484265518840401e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.99725604057312 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5296, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4252, Accuracy: 0.8921, F1 Micro: 0.9342, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2778, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4917, Accuracy: 0.8649, F1 Micro: 0.8649, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2232, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9429\n",
      "Epoch 3/10, Train Loss: 0.1568, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9478\n",
      "Epoch 7/10, Train Loss: 0.071, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 10/10, Train Loss: 0.0382, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8961\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.92      0.56        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.85      0.76       216\n",
      "weighted avg       0.90      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.66011905670166 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 3.645510150818155e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3179540634155273 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4355, Accuracy: 0.8973, F1 Micro: 0.9373, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2887, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9717, F1 Micro: 0.9821, F1 Macro: 0.9808\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9821, F1 Macro: 0.9808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4652, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2208, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9337\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.942\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9231\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9337\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9193\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9245\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        88\n",
      "    positive       0.97      0.95      0.96       185\n",
      "\n",
      "    accuracy                           0.95       273\n",
      "   macro avg       0.94      0.95      0.94       273\n",
      "weighted avg       0.95      0.95      0.95       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9252\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 147.89534187316895 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.7532426500110888e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9343035221099854 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4191, Accuracy: 0.9115, F1 Micro: 0.9456, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2586, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0972, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0728, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4719, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2434, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 6/10, Train Loss: 0.0917, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9409\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.912\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9447\n",
      "\n",
      "Sentiment analysis accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        87\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.95      0.96      0.95       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.92      0.69        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.87      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 147.3220636844635 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.4967458810133394e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.413839340209961 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7946, F1 Micro: 0.8845, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4197, Accuracy: 0.9055, F1 Micro: 0.9423, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2527, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.0932, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0589, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4315, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9333\n",
      "Epoch 2/10, Train Loss: 0.1979, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9377\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9219\n",
      "Epoch 6/10, Train Loss: 0.0924, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9494\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8949\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.9454\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.96      0.97       184\n",
      "\n",
      "    accuracy                           0.96       270\n",
      "   macro avg       0.94      0.96      0.95       270\n",
      "weighted avg       0.96      0.96      0.96       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9291\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 149.96028590202332 s\n",
      "Total runtime: 3217.9513840675354 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50070ffc",
   "metadata": {
    "papermill": {
     "duration": 0.293985,
     "end_time": "2025-03-23T12:58:40.174051",
     "exception": false,
     "start_time": "2025-03-23T12:58:39.880066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759571f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 67.98799681663513 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006667633366305381\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 8.595411777496338 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6079, Accuracy: 0.7872, F1 Micro: 0.8809, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5171, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4969, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4605, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4237, Accuracy: 0.8051, F1 Micro: 0.8897, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3988, Accuracy: 0.8132, F1 Micro: 0.8935, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3454, Accuracy: 0.8348, F1 Micro: 0.9046, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2925, Accuracy: 0.8423, F1 Micro: 0.9081, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2634, Accuracy: 0.8609, F1 Micro: 0.9173, F1 Macro: 0.9154\n",
      "\n",
      "Aspect detection accuracy: 0.8609, F1 Micro: 0.9173, F1 Macro: 0.9154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.87      1.00      0.93       187\n",
      "     machine       0.80      0.99      0.88       175\n",
      "      others       0.86      0.89      0.87       158\n",
      "        part       0.83      0.99      0.90       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.86      0.98      0.92      1061\n",
      "   macro avg       0.86      0.98      0.92      1061\n",
      "weighted avg       0.87      0.98      0.92      1061\n",
      " samples avg       0.87      0.98      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6512, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6089, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4613, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4275, Accuracy: 0.8489, F1 Micro: 0.8489, F1 Macro: 0.7216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3329, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2587, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1276, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0947, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9325\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9353, F1 Micro: 0.9353, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        32\n",
      "    positive       0.99      0.94      0.97       107\n",
      "\n",
      "    accuracy                           0.95       139\n",
      "   macro avg       0.91      0.96      0.93       139\n",
      "weighted avg       0.96      0.95      0.95       139\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8573, F1 Micro: 0.8573, F1 Macro: 0.608\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.87      1.00      0.93       181\n",
      "    positive       1.00      0.33      0.50        24\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.62      0.44      0.48       216\n",
      "weighted avg       0.84      0.88      0.84       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.06      0.11        16\n",
      "     neutral       0.79      0.99      0.88       167\n",
      "    positive       0.83      0.15      0.26        33\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.71      0.40      0.42       216\n",
      "weighted avg       0.78      0.79      0.73       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.86      0.88      0.87       152\n",
      "    positive       0.72      0.65      0.69        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.72      0.73      0.73       216\n",
      "weighted avg       0.81      0.81      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.35      0.52        23\n",
      "     neutral       0.82      0.99      0.90       152\n",
      "    positive       0.92      0.59      0.72        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.92      0.64      0.71       216\n",
      "weighted avg       0.86      0.84      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.65      0.73       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.54      0.59       216\n",
      "weighted avg       0.87      0.90      0.87       216\n",
      "\n",
      "Total train time: 76.52830600738525 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014112006640061743\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.419966459274292 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5958, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.504, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4738, Accuracy: 0.8028, F1 Micro: 0.8885, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4424, Accuracy: 0.8185, F1 Micro: 0.8964, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3898, Accuracy: 0.8527, F1 Micro: 0.9139, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3386, Accuracy: 0.8876, F1 Micro: 0.9323, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2785, Accuracy: 0.9062, F1 Micro: 0.9426, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2352, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.957\n",
      "Epoch 10/10, Train Loss: 0.1891, Accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9557\n",
      "\n",
      "Aspect detection accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.87      0.96      0.92       158\n",
      "        part       0.93      0.95      0.94       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.94      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6223, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.561, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4271, Accuracy: 0.7956, F1 Micro: 0.7956, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.257, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1868, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.883\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8737\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8583\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1047, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8854\n",
      "Epoch 10/10, Train Loss: 0.0308, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8559\n",
      "\n",
      "Sentiment analysis accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.89      0.85        72\n",
      "    positive       0.95      0.90      0.92       153\n",
      "\n",
      "    accuracy                           0.90       225\n",
      "   macro avg       0.88      0.90      0.89       225\n",
      "weighted avg       0.90      0.90      0.90       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.7834\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.55      0.67        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.83      0.83      0.83        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.88      0.64      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.75      0.80       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.42      0.40        12\n",
      "     neutral       0.88      0.94      0.91       152\n",
      "    positive       0.78      0.62      0.69        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.68      0.66      0.67       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.74      0.71        23\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.76      0.78      0.77        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.81      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.62      0.73        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.84      0.81      0.81       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.57      0.70        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.72      0.79       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 79.73332262039185 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014075053040869534\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.890231847763062 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5921, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5351, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.501, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.451, Accuracy: 0.808, F1 Micro: 0.891, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4154, Accuracy: 0.8668, F1 Micro: 0.9211, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3481, Accuracy: 0.9025, F1 Micro: 0.9406, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2857, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2222, Accuracy: 0.9368, F1 Micro: 0.9607, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1722, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1384, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9658\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.578, Accuracy: 0.6752, F1 Micro: 0.6752, F1 Macro: 0.4031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4373, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2738, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.92\n",
      "Epoch 4/10, Train Loss: 0.1453, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9077\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8706\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8902\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8831\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.9012\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8921\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9106\n",
      "\n",
      "Sentiment analysis accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90        76\n",
      "    positive       0.98      0.91      0.94       158\n",
      "\n",
      "    accuracy                           0.93       234\n",
      "   macro avg       0.91      0.94      0.92       234\n",
      "weighted avg       0.93      0.93      0.93       234\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.8603\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       1.00      0.64      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.79      0.84       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.89      0.96      0.92       152\n",
      "    positive       0.84      0.62      0.71        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.78      0.78       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.94      0.71      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.571204662323 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015592004638165236\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.138539552688599 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5794, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5306, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4968, Accuracy: 0.8036, F1 Micro: 0.8893, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4462, Accuracy: 0.84, F1 Micro: 0.9066, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3752, Accuracy: 0.9003, F1 Micro: 0.9397, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2981, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2238, Accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1765, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.135, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9686\n",
      "Epoch 10/10, Train Loss: 0.1153, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9667\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.99      0.96      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5951, Accuracy: 0.6944, F1 Micro: 0.6944, F1 Macro: 0.4221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3926, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8784\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "Epoch 5/10, Train Loss: 0.1089, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9015\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9084\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9133\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        78\n",
      "    positive       0.99      0.91      0.95       174\n",
      "\n",
      "    accuracy                           0.93       252\n",
      "   macro avg       0.91      0.94      0.92       252\n",
      "weighted avg       0.94      0.93      0.93       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.8573\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.67      0.53        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.76      0.74       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.96      0.79        23\n",
      "     neutral       0.98      0.94      0.96       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.91      0.87       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.96      0.98       186\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.82      0.90      0.85       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 94.3452718257904 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015031752409413457\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.009461402893066 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5232, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4858, Accuracy: 0.8125, F1 Micro: 0.8936, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4175, Accuracy: 0.8899, F1 Micro: 0.9342, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.332, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2447, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1863, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.144, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1119, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0889, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3454, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9377\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9288\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.893\n",
      "Epoch 8/10, Train Loss: 0.1217, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9011\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        81\n",
      "    positive       0.99      0.93      0.96       170\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.95      0.94       251\n",
      "weighted avg       0.95      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.907\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.21567988395691 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0013561213389039041\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.87272334098816 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5797, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5105, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4738, Accuracy: 0.8214, F1 Micro: 0.8979, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4087, Accuracy: 0.8988, F1 Micro: 0.9383, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3126, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2314, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.1836, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1375, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1072, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5395, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3055, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2383, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9353\n",
      "Epoch 4/10, Train Loss: 0.1774, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1802, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9395\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9353\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9284\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        84\n",
      "    positive       0.99      0.93      0.96       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9046\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.25361227989197 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010341104120016097\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.048786878585815 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5735, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5395, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4709, Accuracy: 0.8222, F1 Micro: 0.8978, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3773, Accuracy: 0.9129, F1 Micro: 0.9463, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2964, Accuracy: 0.9249, F1 Micro: 0.9527, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2184, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1706, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.9688\n",
      "Epoch 8/10, Train Loss: 0.1218, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1048, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0888, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6122, Accuracy: 0.6923, F1 Micro: 0.6923, F1 Macro: 0.4625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3537, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8996\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9131\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9195\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9103\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9105\n",
      "Epoch 9/10, Train Loss: 0.075, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8678\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.77      0.70      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.75      0.79       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.58      0.67        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.76      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.86      0.88      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.13060688972473 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0007474470185115933\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.896500825881958 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5071, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4449, Accuracy: 0.8839, F1 Micro: 0.9307, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3492, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2434, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1879, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1444, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1187, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7769, F1 Micro: 0.7769, F1 Macro: 0.6821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3008, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Epoch 6/10, Train Loss: 0.1388, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9255\n",
      "Epoch 7/10, Train Loss: 0.13, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        83\n",
      "    positive       0.99      0.93      0.96       177\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.95      0.94       260\n",
      "weighted avg       0.95      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8891\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.75      0.58        12\n",
      "     neutral       0.93      0.90      0.91       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.81      0.77       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.08602142333984 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005266224499791879\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.111201286315918 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5675, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5157, Accuracy: 0.8036, F1 Micro: 0.8891, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4354, Accuracy: 0.8824, F1 Micro: 0.93, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3319, Accuracy: 0.9353, F1 Micro: 0.96, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.246, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1852, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.139, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.1067, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0749, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5003, Accuracy: 0.8417, F1 Micro: 0.8417, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2164, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1654, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9207\n",
      "Epoch 7/10, Train Loss: 0.1083, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8858\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        83\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8752\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.76      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.81      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.97522568702698 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00045447262236848464\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.538952350616455 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5621, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4955, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.423, Accuracy: 0.9003, F1 Micro: 0.9399, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3086, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2192, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1671, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.1345, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.748, F1 Micro: 0.748, F1 Macro: 0.6131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2733, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2247, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9067\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1411, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9339\n",
      "Epoch 7/10, Train Loss: 0.1096, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9167\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9142\n",
      "Epoch 9/10, Train Loss: 0.1049, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9229\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        84\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9027\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      1.00      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.82424139976501 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00026285130297765136\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.915225028991699 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5608, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5029, Accuracy: 0.8162, F1 Micro: 0.8955, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3972, Accuracy: 0.904, F1 Micro: 0.942, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2072, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1556, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1171, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.94      1.00      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5047, Accuracy: 0.8443, F1 Micro: 0.8443, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2837, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9365\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9397\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9204\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9261\n",
      "Epoch 10/10, Train Loss: 0.0766, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8897\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        81\n",
      "    positive       0.96      0.96      0.96       163\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.8621\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.75      0.73      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.76      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.87      0.78       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.74      0.69        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.86      0.76      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.83      0.82       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.0331518650055 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00031338632106781006\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.273387908935547 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5545, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4781, Accuracy: 0.8199, F1 Micro: 0.8975, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3766, Accuracy: 0.9249, F1 Micro: 0.9536, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2662, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1927, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4783, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2561, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9172\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8954\n",
      "Epoch 4/10, Train Loss: 0.1701, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9172\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9141\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.911\n",
      "Epoch 8/10, Train Loss: 0.1038, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9116\n",
      "\n",
      "Sentiment analysis accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.94      0.89        84\n",
      "    positive       0.97      0.92      0.94       173\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.91      0.93      0.92       257\n",
      "weighted avg       0.93      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8848\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      1.00      0.67        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.89      0.80       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.01699805259705 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00022546340187545882\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.81131386756897 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5437, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4742, Accuracy: 0.8408, F1 Micro: 0.9077, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3623, Accuracy: 0.9323, F1 Micro: 0.9581, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2452, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1711, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.066, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2592, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.916\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9166\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9171\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        85\n",
      "    positive       0.96      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8916\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.85      0.79       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.1292860507965 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00015396359958685935\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.422231912612915 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5572, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4868, Accuracy: 0.8371, F1 Micro: 0.9061, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3439, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2408, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1294, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9785\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9568, F1 Micro: 0.9725, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5095, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.233, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1424, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.096, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9249\n",
      "Epoch 7/10, Train Loss: 0.0883, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       178\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.94       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.914\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.95912790298462 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00010382199980085716\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.9749815464019775 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4641, Accuracy: 0.8571, F1 Micro: 0.9167, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3366, Accuracy: 0.9397, F1 Micro: 0.9625, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2292, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1586, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0544, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5069, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2122, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9395\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9114\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        85\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.94      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9053\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.02543902397156 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.561952821153682e-05\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.49582052230835 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5557, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4563, Accuracy: 0.8817, F1 Micro: 0.9298, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3245, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9606, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5026, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2417, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9332\n",
      "Epoch 5/10, Train Loss: 0.1453, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0885, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 7/10, Train Loss: 0.108, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        86\n",
      "    positive       0.97      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.94      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9093\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.75079250335693 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 4.9349546316079795e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.966219902038574 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5441, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4476, Accuracy: 0.8884, F1 Micro: 0.9335, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3063, Accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2023, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1076, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2251, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "Epoch 3/10, Train Loss: 0.1613, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1125, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9454\n",
      "Epoch 7/10, Train Loss: 0.0715, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9413\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9254\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       182\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.96      0.95       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9033\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.79      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 139.46400666236877 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 4.2176106944680214e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.5202817916870117 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.439, Accuracy: 0.8921, F1 Micro: 0.9351, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2974, Accuracy: 0.9427, F1 Micro: 0.9646, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1968, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5286, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2344, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 3/10, Train Loss: 0.1653, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8998\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       174\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.93      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9018\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.96      0.92      0.94       152\n",
      "    positive       0.88      0.83      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.79      0.89      0.82       216\n",
      "weighted avg       0.92      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 137.30172157287598 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.999147349735722e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.4522435665130615 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4345, Accuracy: 0.9129, F1 Micro: 0.9467, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2785, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4814, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Epoch 8/10, Train Loss: 0.0562, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9444\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.9\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        86\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.915\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.44200205802917 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.9484827468404536e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8646974563598633 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.527, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4231, Accuracy: 0.9174, F1 Micro: 0.9496, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2767, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1039, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4981, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2383, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9262\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9357\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9088\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.917\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9349\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "    positive       0.95      0.96      0.96       176\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.94      0.93      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9032\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.72549843788147 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 3.4360557037871365e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.302995204925537 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5378, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4115, Accuracy: 0.9115, F1 Micro: 0.9465, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2642, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4471, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2141, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9088\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9096\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8965\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        87\n",
      "    positive       0.99      0.92      0.96       173\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.95      0.94       260\n",
      "weighted avg       0.95      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9018\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.87      0.83       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.3682460784912 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.377079363213852e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9214324951171875 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.8028, F1 Micro: 0.8889, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4109, Accuracy: 0.9204, F1 Micro: 0.9512, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2515, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Epoch 6/10, Train Loss: 0.0922, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.433, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2227, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1611, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Epoch 5/10, Train Loss: 0.109, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Epoch 6/10, Train Loss: 0.1052, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9174\n",
      "Epoch 9/10, Train Loss: 0.0825, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9161\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "    positive       0.95      0.97      0.96       175\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8951\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.85      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 148.63786101341248 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.6293237968056926e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3321690559387207 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5286, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4078, Accuracy: 0.9271, F1 Micro: 0.9554, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1693, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0854, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.489, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Epoch 2/10, Train Loss: 0.2191, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8914\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1345, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1108, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9223\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        84\n",
      "    positive       0.96      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.94       255\n",
      "   macro avg       0.93      0.94      0.93       255\n",
      "weighted avg       0.94      0.94      0.94       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9018\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.85      0.80       216\n",
      "weighted avg       0.91      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 147.71439933776855 s\n",
      "Total runtime: 3163.0139989852905 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175447,
     "sourceId": 10843157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6362.996716,
   "end_time": "2025-03-23T12:58:44.308953",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-23T11:12:41.312237",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f2d7706b7c14f9f932d5712806ea023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f909e5979e84919a0357ce6344ffb11",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_42396802c80540d6bea8cb547e02446c",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "13d17800b4914e239835c86fbd2773bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b085b5b9eec4872916525f40d196b97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_766f600ac14d47399bc6aeafebd14983",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a51de2a68e0742bf8d10db01767f1fa4",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "26bc607dad224e1c98f92795688ff7b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "357cb264aa834dc3bda4492e3faf7156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a77418afe3194c7f8410ae90fb6e7da3",
        "IPY_MODEL_0f2d7706b7c14f9f932d5712806ea023",
        "IPY_MODEL_a96e3baefc79402b8a340d368fc5ceb0"
       ],
       "layout": "IPY_MODEL_26bc607dad224e1c98f92795688ff7b6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3625a9894ca949f28a0bd6a59c2a25ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41286d9eff5f4a0b88935be6448cd97b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42396802c80540d6bea8cb547e02446c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4256f103b721413292f01ffb39a26826": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "461b51a056fc4bad8f99ade8944928dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46bc281c38324260bb22de784d9e5ffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "512ddfdfb7674c62b8b2cfed85202887": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "51f5712a6c5349b18a8233e47ed1cd06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_46bc281c38324260bb22de784d9e5ffe",
       "placeholder": "​",
       "style": "IPY_MODEL_b2fd8b26862c4a9eae01617555d5907a",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 656kB/s]"
      }
     },
     "583f184732aa460788ee6ab699d092df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "59b65e8713a94de580e2c2766bdcbaa9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cb1d249339a4190b8acc04ef8b3fe3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5fa4a80aef3243d6af4f2cd3f15b717a",
        "IPY_MODEL_8754d5b6904842a3b1c3b7aad6cc7ee4",
        "IPY_MODEL_697d7a5c160848f9ae8d562180662172"
       ],
       "layout": "IPY_MODEL_4256f103b721413292f01ffb39a26826",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5fa4a80aef3243d6af4f2cd3f15b717a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89c283e7db1b439499bd9bdedd495f94",
       "placeholder": "​",
       "style": "IPY_MODEL_583f184732aa460788ee6ab699d092df",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "68aa91618d694a8d84ec9a8a338cac82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "697d7a5c160848f9ae8d562180662172": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_41286d9eff5f4a0b88935be6448cd97b",
       "placeholder": "​",
       "style": "IPY_MODEL_93e01b755a73413f87d1ac395809fbd3",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 164B/s]"
      }
     },
     "70524553a4444193b27cec173ff8698e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3625a9894ca949f28a0bd6a59c2a25ee",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c55924c9ac164f0ca046e1d708feb97e",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "73628a78fe7f4a678ef19cf881f06ed8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "766f600ac14d47399bc6aeafebd14983": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e9a4614232d478bb7a845250ec49bb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8754d5b6904842a3b1c3b7aad6cc7ee4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7e9a4614232d478bb7a845250ec49bb9",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bd92bf48d2534e63b663c254c450f80a",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "87f9fb678d2046c4bac1e72837674b24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aaab67e1cf884cf9abb7f59d4356d2a9",
       "placeholder": "​",
       "style": "IPY_MODEL_9212e0714b004dada7231d7bd5a5b6fd",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "89c283e7db1b439499bd9bdedd495f94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9212e0714b004dada7231d7bd5a5b6fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9321a8a6be6e491a9f7c847297670354": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13d17800b4914e239835c86fbd2773bb",
       "placeholder": "​",
       "style": "IPY_MODEL_73628a78fe7f4a678ef19cf881f06ed8",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "93e01b755a73413f87d1ac395809fbd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9cdba1212f2743238bd2a62a2d189ad5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_87f9fb678d2046c4bac1e72837674b24",
        "IPY_MODEL_1b085b5b9eec4872916525f40d196b97",
        "IPY_MODEL_51f5712a6c5349b18a8233e47ed1cd06"
       ],
       "layout": "IPY_MODEL_d16c6c8dfc4d4bacb9930fd536e5d4f6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9f909e5979e84919a0357ce6344ffb11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a51de2a68e0742bf8d10db01767f1fa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a77418afe3194c7f8410ae90fb6e7da3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_461b51a056fc4bad8f99ade8944928dd",
       "placeholder": "​",
       "style": "IPY_MODEL_f3521c466a904d14a003498f30e76f19",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "a96e3baefc79402b8a340d368fc5ceb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59b65e8713a94de580e2c2766bdcbaa9",
       "placeholder": "​",
       "style": "IPY_MODEL_68aa91618d694a8d84ec9a8a338cac82",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 10.9kB/s]"
      }
     },
     "aaab67e1cf884cf9abb7f59d4356d2a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aaed654b2b834405910cb972dc6dfe0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9321a8a6be6e491a9f7c847297670354",
        "IPY_MODEL_70524553a4444193b27cec173ff8698e",
        "IPY_MODEL_e164870932ce4db297d62b4c5b0eef14"
       ],
       "layout": "IPY_MODEL_c687435f161e4d35b02e0ee4772708c0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b2fd8b26862c4a9eae01617555d5907a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bd92bf48d2534e63b663c254c450f80a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c55924c9ac164f0ca046e1d708feb97e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c687435f161e4d35b02e0ee4772708c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d16c6c8dfc4d4bacb9930fd536e5d4f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e164870932ce4db297d62b4c5b0eef14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f967d329ef8e4f3a8f14fa889ad86dfb",
       "placeholder": "​",
       "style": "IPY_MODEL_512ddfdfb7674c62b8b2cfed85202887",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 148kB/s]"
      }
     },
     "f3521c466a904d14a003498f30e76f19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f967d329ef8e4f3a8f14fa889ad86dfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
