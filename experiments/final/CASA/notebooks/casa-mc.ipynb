{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e47b2e",
   "metadata": {
    "papermill": {
     "duration": 0.012354,
     "end_time": "2025-03-25T04:41:38.679270",
     "exception": false,
     "start_time": "2025-03-25T04:41:38.666916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4ea27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:41:38.703554Z",
     "iopub.status.busy": "2025-03-25T04:41:38.703260Z",
     "iopub.status.idle": "2025-03-25T04:42:10.519345Z",
     "shell.execute_reply": "2025-03-25T04:42:10.518698Z"
    },
    "papermill": {
     "duration": 31.829312,
     "end_time": "2025-03-25T04:42:10.520856",
     "exception": false,
     "start_time": "2025-03-25T04:41:38.691544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e66b13",
   "metadata": {
    "papermill": {
     "duration": 0.010885,
     "end_time": "2025-03-25T04:42:10.543503",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.532618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcec79d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.567046Z",
     "iopub.status.busy": "2025-03-25T04:42:10.566572Z",
     "iopub.status.idle": "2025-03-25T04:42:10.570045Z",
     "shell.execute_reply": "2025-03-25T04:42:10.569419Z"
    },
    "papermill": {
     "duration": 0.016336,
     "end_time": "2025-03-25T04:42:10.571236",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.554900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe728e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.594000Z",
     "iopub.status.busy": "2025-03-25T04:42:10.593799Z",
     "iopub.status.idle": "2025-03-25T04:42:10.597447Z",
     "shell.execute_reply": "2025-03-25T04:42:10.596683Z"
    },
    "papermill": {
     "duration": 0.016299,
     "end_time": "2025-03-25T04:42:10.598625",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.582326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506bcede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.621423Z",
     "iopub.status.busy": "2025-03-25T04:42:10.621212Z",
     "iopub.status.idle": "2025-03-25T04:42:10.632849Z",
     "shell.execute_reply": "2025-03-25T04:42:10.632261Z"
    },
    "papermill": {
     "duration": 0.024313,
     "end_time": "2025-03-25T04:42:10.634118",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.609805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1c710",
   "metadata": {
    "papermill": {
     "duration": 0.01088,
     "end_time": "2025-03-25T04:42:10.656233",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.645353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc2f5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.678974Z",
     "iopub.status.busy": "2025-03-25T04:42:10.678774Z",
     "iopub.status.idle": "2025-03-25T04:42:10.740590Z",
     "shell.execute_reply": "2025-03-25T04:42:10.739104Z"
    },
    "papermill": {
     "duration": 0.074931,
     "end_time": "2025-03-25T04:42:10.742034",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.667103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-mc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc37c2c",
   "metadata": {
    "papermill": {
     "duration": 0.011012,
     "end_time": "2025-03-25T04:42:10.764309",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.753297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1edc7197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.787510Z",
     "iopub.status.busy": "2025-03-25T04:42:10.787197Z",
     "iopub.status.idle": "2025-03-25T04:42:10.878252Z",
     "shell.execute_reply": "2025-03-25T04:42:10.877377Z"
    },
    "papermill": {
     "duration": 0.104204,
     "end_time": "2025-03-25T04:42:10.879566",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.775362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becce9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.905048Z",
     "iopub.status.busy": "2025-03-25T04:42:10.904812Z",
     "iopub.status.idle": "2025-03-25T04:42:10.914361Z",
     "shell.execute_reply": "2025-03-25T04:42:10.913580Z"
    },
    "papermill": {
     "duration": 0.023958,
     "end_time": "2025-03-25T04:42:10.915797",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.891839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61db3373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.941655Z",
     "iopub.status.busy": "2025-03-25T04:42:10.941395Z",
     "iopub.status.idle": "2025-03-25T04:42:10.950828Z",
     "shell.execute_reply": "2025-03-25T04:42:10.950234Z"
    },
    "papermill": {
     "duration": 0.023464,
     "end_time": "2025-03-25T04:42:10.952246",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.928782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6efdb9e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:10.977026Z",
     "iopub.status.busy": "2025-03-25T04:42:10.976801Z",
     "iopub.status.idle": "2025-03-25T04:42:10.989169Z",
     "shell.execute_reply": "2025-03-25T04:42:10.988546Z"
    },
    "papermill": {
     "duration": 0.026104,
     "end_time": "2025-03-25T04:42:10.990436",
     "exception": false,
     "start_time": "2025-03-25T04:42:10.964332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b9524",
   "metadata": {
    "papermill": {
     "duration": 0.011176,
     "end_time": "2025-03-25T04:42:11.013348",
     "exception": false,
     "start_time": "2025-03-25T04:42:11.002172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe414c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:11.037976Z",
     "iopub.status.busy": "2025-03-25T04:42:11.037729Z",
     "iopub.status.idle": "2025-03-25T04:42:11.043949Z",
     "shell.execute_reply": "2025-03-25T04:42:11.043244Z"
    },
    "papermill": {
     "duration": 0.020206,
     "end_time": "2025-03-25T04:42:11.045126",
     "exception": false,
     "start_time": "2025-03-25T04:42:11.024920",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4c33ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:11.069773Z",
     "iopub.status.busy": "2025-03-25T04:42:11.069555Z",
     "iopub.status.idle": "2025-03-25T04:42:11.076591Z",
     "shell.execute_reply": "2025-03-25T04:42:11.075907Z"
    },
    "papermill": {
     "duration": 0.020627,
     "end_time": "2025-03-25T04:42:11.077723",
     "exception": false,
     "start_time": "2025-03-25T04:42:11.057096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8733703f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:11.102344Z",
     "iopub.status.busy": "2025-03-25T04:42:11.102147Z",
     "iopub.status.idle": "2025-03-25T04:42:11.932639Z",
     "shell.execute_reply": "2025-03-25T04:42:11.931959Z"
    },
    "papermill": {
     "duration": 0.844058,
     "end_time": "2025-03-25T04:42:11.934074",
     "exception": false,
     "start_time": "2025-03-25T04:42:11.090016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6962cf7cc9e44ca090658a98024a1389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9112012d8f7b4bbd8fc12e2d877e3e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b689cc7454c46ff9d4fda6814a02e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722b52af21c64aaba36c806cac2faf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "520be9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:11.964783Z",
     "iopub.status.busy": "2025-03-25T04:42:11.964533Z",
     "iopub.status.idle": "2025-03-25T04:42:11.969109Z",
     "shell.execute_reply": "2025-03-25T04:42:11.968496Z"
    },
    "papermill": {
     "duration": 0.020221,
     "end_time": "2025-03-25T04:42:11.970311",
     "exception": false,
     "start_time": "2025-03-25T04:42:11.950090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da4970f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:11.994905Z",
     "iopub.status.busy": "2025-03-25T04:42:11.994700Z",
     "iopub.status.idle": "2025-03-25T04:42:12.004061Z",
     "shell.execute_reply": "2025-03-25T04:42:12.003433Z"
    },
    "papermill": {
     "duration": 0.022769,
     "end_time": "2025-03-25T04:42:12.005182",
     "exception": false,
     "start_time": "2025-03-25T04:42:11.982413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec037b",
   "metadata": {
    "papermill": {
     "duration": 0.011988,
     "end_time": "2025-03-25T04:42:12.029708",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.017720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dbf2012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.054732Z",
     "iopub.status.busy": "2025-03-25T04:42:12.054458Z",
     "iopub.status.idle": "2025-03-25T04:42:12.058259Z",
     "shell.execute_reply": "2025-03-25T04:42:12.057491Z"
    },
    "papermill": {
     "duration": 0.017539,
     "end_time": "2025-03-25T04:42:12.059519",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.041980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dfd878d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.084281Z",
     "iopub.status.busy": "2025-03-25T04:42:12.084068Z",
     "iopub.status.idle": "2025-03-25T04:42:12.088374Z",
     "shell.execute_reply": "2025-03-25T04:42:12.087742Z"
    },
    "papermill": {
     "duration": 0.018173,
     "end_time": "2025-03-25T04:42:12.089746",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.071573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db5b316c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.113921Z",
     "iopub.status.busy": "2025-03-25T04:42:12.113718Z",
     "iopub.status.idle": "2025-03-25T04:42:12.119422Z",
     "shell.execute_reply": "2025-03-25T04:42:12.118850Z"
    },
    "papermill": {
     "duration": 0.019093,
     "end_time": "2025-03-25T04:42:12.120528",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.101435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2be35f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.146016Z",
     "iopub.status.busy": "2025-03-25T04:42:12.145820Z",
     "iopub.status.idle": "2025-03-25T04:42:12.171626Z",
     "shell.execute_reply": "2025-03-25T04:42:12.170999Z"
    },
    "papermill": {
     "duration": 0.040794,
     "end_time": "2025-03-25T04:42:12.172919",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.132125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4a066",
   "metadata": {
    "papermill": {
     "duration": 0.011449,
     "end_time": "2025-03-25T04:42:12.196097",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.184648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d1e855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.220174Z",
     "iopub.status.busy": "2025-03-25T04:42:12.219957Z",
     "iopub.status.idle": "2025-03-25T04:42:12.224864Z",
     "shell.execute_reply": "2025-03-25T04:42:12.224280Z"
    },
    "papermill": {
     "duration": 0.018248,
     "end_time": "2025-03-25T04:42:12.225957",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.207709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e6390",
   "metadata": {
    "papermill": {
     "duration": 0.011893,
     "end_time": "2025-03-25T04:42:12.249662",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.237769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8af86c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.274694Z",
     "iopub.status.busy": "2025-03-25T04:42:12.274418Z",
     "iopub.status.idle": "2025-03-25T04:42:12.291906Z",
     "shell.execute_reply": "2025-03-25T04:42:12.291256Z"
    },
    "papermill": {
     "duration": 0.031404,
     "end_time": "2025-03-25T04:42:12.293175",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.261771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monte_carlo_dropout_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, mc_passes=3, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.train()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.train()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    aspect_uncertainties = []\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        batch_probs = []\n",
    "        \n",
    "        for i in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()  # Shape: (batch_size, num_classes)\n",
    "                batch_probs.append(probs)\n",
    "                \n",
    "        # Stack the probabilities from multiple MC passes\n",
    "        batch_probs = np.stack(batch_probs, axis=0)  # Shape: (mc_passes, batch_size, num_classes)\n",
    "\n",
    "        # Calculate mean probability and uncertainty for each sample in the batch\n",
    "        mean_probs = np.mean(batch_probs, axis=0)  # Shape: (batch_size, num_classes)\n",
    "        uncertainties = np.mean(np.var(batch_probs, axis=0), axis=1)  # Shape: (batch_size,)\n",
    "        aspect_uncertainties.extend(uncertainties)\n",
    "\n",
    "        for i in range(len(mean_probs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = [np.max(torch.sigmoid(outputs[i]).cpu().numpy())]\n",
    "            \n",
    "            for j in range(len(mean_probs[i])):\n",
    "                if int(mean_probs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    aspect_outputs = {i: aspect_uncertainties[i] for i in range(len(aspect_uncertainties))}\n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        batch_probs = []\n",
    "        for i in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "                for j in range(len(preds)):\n",
    "                    ori_index = batch['ori_indices'][j].item()\n",
    "                    if ori_index in sentiment_outputs.keys():\n",
    "                        sentiment_outputs[ori_index].append(preds[j].cpu().numpy())\n",
    "                    else:\n",
    "                        sentiment_outputs[ori_index] = [preds[j].cpu().numpy()]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    for indices, probs in sentiment_outputs.items():\n",
    "        sentiment_outputs[indices] = [[probs[i], probs[i+1], probs[i+2]] for i in range(int(len(probs) / 3))]\n",
    "        \n",
    "        variance = np.var(sentiment_outputs[indices], axis=1)\n",
    "        mean_aspect_variance = np.mean(variance, axis=1)\n",
    "        mean_data_variance = np.mean(mean_aspect_variance)\n",
    "        \n",
    "        sentiment_outputs[indices] = np.mean(np.mean(np.var(sentiment_outputs[indices], axis=0), axis=0), axis=0)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = (val + aspect_outputs[key]) / 2\n",
    "\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd17be",
   "metadata": {
    "papermill": {
     "duration": 0.011665,
     "end_time": "2025-03-25T04:42:12.316872",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.305207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e8136d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.344703Z",
     "iopub.status.busy": "2025-03-25T04:42:12.344416Z",
     "iopub.status.idle": "2025-03-25T04:42:12.354237Z",
     "shell.execute_reply": "2025-03-25T04:42:12.353574Z"
    },
    "papermill": {
     "duration": 0.025026,
     "end_time": "2025-03-25T04:42:12.355571",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.330545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(monte_carlo_dropout_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbc0d199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.381854Z",
     "iopub.status.busy": "2025-03-25T04:42:12.381642Z",
     "iopub.status.idle": "2025-03-25T04:42:12.384887Z",
     "shell.execute_reply": "2025-03-25T04:42:12.384042Z"
    },
    "papermill": {
     "duration": 0.017792,
     "end_time": "2025-03-25T04:42:12.386221",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.368429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacef9e0",
   "metadata": {
    "papermill": {
     "duration": 0.012463,
     "end_time": "2025-03-25T04:42:12.411440",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.398977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.3199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.13      0.22        23\n",
      "     neutral       0.74      0.98      0.84       152\n",
      "    positive       0.60      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.70      0.42      0.43       216\n",
      "weighted avg       0.71      0.73      0.66       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 52.394439935684204 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008176815987098964\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 7.828569650650024 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6175, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5199, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4808, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.445, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4485, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3903, Accuracy: 0.8147, F1 Micro: 0.8947, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3793, Accuracy: 0.843, F1 Micro: 0.9092, F1 Macro: 0.9085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3259, Accuracy: 0.8579, F1 Micro: 0.9163, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2756, Accuracy: 0.875, F1 Micro: 0.9255, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2484, Accuracy: 0.8966, F1 Micro: 0.9373, F1 Macro: 0.9363\n",
      "\n",
      "Aspect detection accuracy: 0.8966, F1 Micro: 0.9373, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.84      1.00      0.91       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.86      0.93      0.90       158\n",
      "        part       0.90      0.98      0.94       158\n",
      "       price       0.95      0.98      0.97       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.94      1061\n",
      "weighted avg       0.90      0.98      0.94      1061\n",
      " samples avg       0.90      0.98      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.6685, F1 Micro: 0.6685, F1 Macro: 0.4007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5724, Accuracy: 0.6685, F1 Micro: 0.6685, F1 Macro: 0.4007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5082, Accuracy: 0.7072, F1 Micro: 0.7072, F1 Macro: 0.5357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4235, Accuracy: 0.7569, F1 Micro: 0.7569, F1 Macro: 0.647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3107, Accuracy: 0.8177, F1 Micro: 0.8177, F1 Macro: 0.7761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2083, Accuracy: 0.8564, F1 Micro: 0.8564, F1 Macro: 0.8302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.8359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.8674, F1 Micro: 0.8674, F1 Macro: 0.8399\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.7927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.88\n",
      "\n",
      "Sentiment analysis accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        60\n",
      "    positive       0.91      0.93      0.92       121\n",
      "\n",
      "    accuracy                           0.90       181\n",
      "   macro avg       0.89      0.88      0.88       181\n",
      "weighted avg       0.89      0.90      0.89       181\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.7029\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.85      1.00      0.92       181\n",
      "    positive       1.00      0.08      0.15        24\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.62      0.36      0.36       216\n",
      "weighted avg       0.82      0.85      0.79       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.88      0.98      0.93       167\n",
      "    positive       0.77      0.52      0.62        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.68      0.75       216\n",
      "weighted avg       0.87      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.58      0.64        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.74      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.77      0.71      0.74       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.70      0.74        23\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.80      0.59      0.68        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.75      0.79       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.95      0.98      0.97       186\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.77      0.81       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.70      0.77       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Total train time: 73.25267219543457 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001401702687144281\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.154410600662231 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5992, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5225, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4912, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4649, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.429, Accuracy: 0.8177, F1 Micro: 0.8962, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3748, Accuracy: 0.8757, F1 Micro: 0.9267, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3293, Accuracy: 0.9159, F1 Micro: 0.9488, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.271, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2345, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1916, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "\n",
      "Aspect detection accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.99      0.98       187\n",
      "     machine       0.92      0.98      0.95       175\n",
      "      others       0.90      0.93      0.91       158\n",
      "        part       0.92      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6028, Accuracy: 0.6795, F1 Micro: 0.6795, F1 Macro: 0.4046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.526, Accuracy: 0.7094, F1 Micro: 0.7094, F1 Macro: 0.54\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.415, Accuracy: 0.8376, F1 Micro: 0.8376, F1 Macro: 0.7937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2166, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.92\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9083\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9151\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9071\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9077\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9117\n",
      "\n",
      "Sentiment analysis accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        75\n",
      "    positive       0.93      0.96      0.95       159\n",
      "\n",
      "    accuracy                           0.93       234\n",
      "   macro avg       0.92      0.91      0.92       234\n",
      "weighted avg       0.93      0.93      0.93       234\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8516\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.97      0.99      0.98       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.92      0.98      0.95       167\n",
      "    positive       0.74      0.61      0.67        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.74      0.78       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.93      0.91       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.74      0.81        23\n",
      "     neutral       0.92      0.99      0.96       152\n",
      "    positive       0.85      0.68      0.76        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 75.13684844970703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0017040643142536283\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 11.853351593017578 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5895, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5116, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4497, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3999, Accuracy: 0.8609, F1 Micro: 0.9177, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3489, Accuracy: 0.9152, F1 Micro: 0.9476, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2833, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2298, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1764, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1588, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9671\n",
      "\n",
      "Aspect detection accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6064, Accuracy: 0.6923, F1 Micro: 0.6923, F1 Macro: 0.4091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.463, Accuracy: 0.8138, F1 Micro: 0.8138, F1 Macro: 0.7377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2891, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.9033\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8855\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8877\n",
      "Epoch 7/10, Train Loss: 0.1386, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1132, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9107\n",
      "Epoch 9/10, Train Loss: 0.1114, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8924\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.902\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        76\n",
      "    positive       0.95      0.94      0.94       171\n",
      "\n",
      "    accuracy                           0.92       247\n",
      "   macro avg       0.91      0.92      0.91       247\n",
      "weighted avg       0.92      0.92      0.92       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8727\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.78      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 80.4737606048584 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014492561575025326\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 11.970031976699829 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5938, Accuracy: 0.7961, F1 Micro: 0.8854, F1 Macro: 0.8838\n",
      "Epoch 2/10, Train Loss: 0.5331, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5047, Accuracy: 0.8132, F1 Micro: 0.8941, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4332, Accuracy: 0.8571, F1 Micro: 0.9166, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3617, Accuracy: 0.9241, F1 Micro: 0.9532, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2867, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2271, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1827, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1421, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1203, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5843, Accuracy: 0.6776, F1 Micro: 0.6776, F1 Macro: 0.4039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3978, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9147\n",
      "Epoch 5/10, Train Loss: 0.1814, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1918, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9137\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.9016\n",
      "Epoch 10/10, Train Loss: 0.0901, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9089\n",
      "\n",
      "Sentiment analysis accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        79\n",
      "    positive       0.98      0.92      0.95       166\n",
      "\n",
      "    accuracy                           0.93       245\n",
      "   macro avg       0.92      0.94      0.93       245\n",
      "weighted avg       0.94      0.93      0.94       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.78      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 87.90706753730774 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0011264084605500102\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 10.656459093093872 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.575, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4839, Accuracy: 0.8281, F1 Micro: 0.9017, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4064, Accuracy: 0.9062, F1 Micro: 0.9429, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3162, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2478, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1491, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.122, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1067, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5326, Accuracy: 0.689, F1 Micro: 0.689, F1 Macro: 0.519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3423, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1906, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1567, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1145, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8947\n",
      "Epoch 7/10, Train Loss: 0.1478, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 8/10, Train Loss: 0.1044, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.927\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.93      0.95       169\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9119\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 92.65407991409302 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008436530712060634\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.526324987411499 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5759, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5266, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4663, Accuracy: 0.8482, F1 Micro: 0.9121, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3729, Accuracy: 0.9286, F1 Micro: 0.956, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2968, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2395, Accuracy: 0.9494, F1 Micro: 0.9681, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1862, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.1436, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.1218, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1034, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7126, F1 Micro: 0.7126, F1 Macro: 0.5421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2975, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 4/10, Train Loss: 0.2114, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9263\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1196, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "Epoch 8/10, Train Loss: 0.1463, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Epoch 9/10, Train Loss: 0.0996, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "Epoch 10/10, Train Loss: 0.0802, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        84\n",
      "    positive       0.98      0.94      0.95       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9122\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 94.65308403968811 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.000688252120744437\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 8.565399885177612 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5765, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5257, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4599, Accuracy: 0.8594, F1 Micro: 0.9181, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3752, Accuracy: 0.9315, F1 Micro: 0.958, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2856, Accuracy: 0.9487, F1 Micro: 0.9679, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2194, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.163, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.129, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1078, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0899, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4686, Accuracy: 0.8071, F1 Micro: 0.8071, F1 Macro: 0.7528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9158\n",
      "Epoch 4/10, Train Loss: 0.1388, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9051\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8947\n",
      "Epoch 6/10, Train Loss: 0.1442, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1234, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1001, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 9/10, Train Loss: 0.1056, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9071\n",
      "Epoch 10/10, Train Loss: 0.09, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9094\n",
      "\n",
      "Sentiment analysis accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90        84\n",
      "    positive       0.97      0.92      0.95       170\n",
      "\n",
      "    accuracy                           0.93       254\n",
      "   macro avg       0.91      0.94      0.92       254\n",
      "weighted avg       0.93      0.93      0.93       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9079\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 99.70585083961487 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005463595443870872\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.038261413574219 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5082, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4346, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3299, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2397, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1867, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.1098, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0766, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.7308, F1 Micro: 0.7308, F1 Macro: 0.5793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2996, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9195\n",
      "Epoch 3/10, Train Loss: 0.1739, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1533, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1451, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 8/10, Train Loss: 0.0921, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9155\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.915\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        85\n",
      "    positive       0.98      0.93      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.95      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.37173223495483 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005325875361450021\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.270729303359985 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.8155, F1 Micro: 0.8953, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4341, Accuracy: 0.9144, F1 Micro: 0.948, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3219, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2452, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Epoch 6/10, Train Loss: 0.191, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1436, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.1155, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0975, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4881, Accuracy: 0.7695, F1 Micro: 0.7695, F1 Macro: 0.6732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2602, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1721, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1111, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9119\n",
      "Epoch 7/10, Train Loss: 0.1189, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9166\n",
      "Epoch 8/10, Train Loss: 0.1167, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9124\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9148\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        86\n",
      "    positive       0.96      0.94      0.95       170\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.92      0.93      0.93       256\n",
      "weighted avg       0.94      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.914\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.42725419998169 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0003043390257516874\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 6.800199508666992 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5602, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.498, Accuracy: 0.8222, F1 Micro: 0.8985, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.402, Accuracy: 0.9204, F1 Micro: 0.9508, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2979, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2308, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1686, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.1297, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0911, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0706, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5022, Accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "Epoch 3/10, Train Loss: 0.1577, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9228\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1135, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9278\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9162\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9152\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9172\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        85\n",
      "    positive       0.97      0.94      0.95       182\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.92      0.93      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9146\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.4562451839447 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0003250475856475532\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.209640264511108 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5703, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5082, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4079, Accuracy: 0.9189, F1 Micro: 0.9498, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2964, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2272, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1655, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1312, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0861, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4548, Accuracy: 0.8171, F1 Micro: 0.8171, F1 Macro: 0.7616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "Epoch 5/10, Train Loss: 0.1094, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9218\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9214\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9073\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9167\n",
      "Epoch 9/10, Train Loss: 0.0913, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8929\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9027\n",
      "\n",
      "Sentiment analysis accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91        86\n",
      "    positive       0.98      0.92      0.95       171\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.92      0.94      0.93       257\n",
      "weighted avg       0.94      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9152\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.84752655029297 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00021115904382895678\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 5.681354284286499 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5563, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4872, Accuracy: 0.8266, F1 Micro: 0.901, F1 Macro: 0.9001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3554, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2662, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1965, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1407, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1112, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.508, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2337, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1574, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9166\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0398, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.917\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        86\n",
      "    positive       0.98      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9178\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.38687324523926 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00020333983848104287\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.1505537033081055 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5546, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4808, Accuracy: 0.8549, F1 Micro: 0.9153, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.351, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2584, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1793, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1493, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4821, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2691, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9127\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.95      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9166\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.88703322410583 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00013101370132062584\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.014212608337402 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.564, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4802, Accuracy: 0.84, F1 Micro: 0.9075, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3559, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2413, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1674, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1334, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1063, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0867, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4683, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2549, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 4/10, Train Loss: 0.1471, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1335, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9256\n",
      "Epoch 7/10, Train Loss: 0.0968, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9245\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.08812427520752 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00010496540926396847\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.55861234664917 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.466, Accuracy: 0.8497, F1 Micro: 0.9129, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3336, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2232, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1629, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2581, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9311\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9163\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9203\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1257, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        85\n",
      "    positive       0.98      0.93      0.96       180\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.919\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      1.00      0.90        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.88240957260132 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 7.401363109238446e-05\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.250437498092651 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5497, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4608, Accuracy: 0.9137, F1 Micro: 0.9477, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3102, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5082, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9338\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1186, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9423\n",
      "Epoch 5/10, Train Loss: 0.0835, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9303\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0579, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9376\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9368\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.72195982933044 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00014161912258714437\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.6432199478149414 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5455, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4527, Accuracy: 0.8996, F1 Micro: 0.9398, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3066, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1519, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5044, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9141\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9212\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0895, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "    positive       0.94      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.93       263\n",
      "   macro avg       0.92      0.92      0.92       263\n",
      "weighted avg       0.93      0.93      0.93       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.4256899356842 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.0086820920114405e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.3313653469085693 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5454, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4369, Accuracy: 0.9144, F1 Micro: 0.9482, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2081, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4773, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2178, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9026\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9291\n",
      "\n",
      "Sentiment analysis accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        87\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9213\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.81      0.85      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.87612533569336 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 3.001175027748104e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.109501600265503 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5289, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4409, Accuracy: 0.9301, F1 Micro: 0.9569, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2809, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4632, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9263\n",
      "Epoch 3/10, Train Loss: 0.208, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9124\n",
      "Epoch 4/10, Train Loss: 0.1455, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9279\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9216\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9142\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        87\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9256\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.94      0.95       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.90      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.11031103134155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.061998988618142e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.6923749446868896 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4085, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2715, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4717, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2173, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 3/10, Train Loss: 0.1619, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8975\n",
      "Epoch 4/10, Train Loss: 0.1578, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9271\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9487\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.95       262\n",
      "weighted avg       0.96      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9653, F1 Micro: 0.9653, F1 Macro: 0.9339\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.93509030342102 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.6841603246575692e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1932690143585205 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5412, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4163, Accuracy: 0.9226, F1 Micro: 0.9526, F1 Macro: 0.9511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2684, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.183, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0839, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9643, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4428, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2472, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9206\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9219\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.887\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        85\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9234\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.47564816474915 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.992001743928995e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.864917278289795 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3908, Accuracy: 0.9301, F1 Micro: 0.9566, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2456, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.98      0.95       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5001, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9341\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1313, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9341\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9245\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9215\n",
      "Epoch 9/10, Train Loss: 0.0794, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9215\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9202\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        83\n",
      "    positive       0.99      0.93      0.96       167\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.93      0.95      0.94       250\n",
      "weighted avg       0.95      0.94      0.94       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9218\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.93      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.61405754089355 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.703367776528466e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.349768877029419 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3999, Accuracy: 0.9301, F1 Micro: 0.957, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2439, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4673, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2246, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9298\n",
      "Epoch 3/10, Train Loss: 0.1576, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Epoch 5/10, Train Loss: 0.1102, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9223\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8993\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9289\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.0919, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        86\n",
      "    positive       0.98      0.93      0.96       187\n",
      "\n",
      "    accuracy                           0.94       273\n",
      "   macro avg       0.92      0.95      0.93       273\n",
      "weighted avg       0.95      0.94      0.94       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9268\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.47000122070312 s\n",
      "Total runtime: 2791.353596687317 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba2d97",
   "metadata": {
    "papermill": {
     "duration": 0.011748,
     "end_time": "2025-03-25T04:42:12.463964",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.452216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da332f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 55.68444538116455 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006264137045945973\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 8.265932321548462 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6022, Accuracy: 0.7917, F1 Micro: 0.8827, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.4997, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4948, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4575, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4221, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3712, Accuracy: 0.8371, F1 Micro: 0.9061, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3461, Accuracy: 0.8757, F1 Micro: 0.9263, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3188, Accuracy: 0.8899, F1 Micro: 0.9335, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.259, Accuracy: 0.9003, F1 Micro: 0.9393, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2231, Accuracy: 0.9137, F1 Micro: 0.9473, F1 Macro: 0.9453\n",
      "\n",
      "Aspect detection accuracy: 0.9137, F1 Micro: 0.9473, F1 Macro: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.85      0.92      0.89       158\n",
      "        part       0.88      0.97      0.92       158\n",
      "       price       0.92      1.00      0.96       192\n",
      "     service       0.96      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.91      0.98      0.95      1061\n",
      "   macro avg       0.91      0.98      0.95      1061\n",
      "weighted avg       0.92      0.98      0.95      1061\n",
      " samples avg       0.92      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6035, Accuracy: 0.6869, F1 Micro: 0.6869, F1 Macro: 0.4072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5774, Accuracy: 0.6869, F1 Micro: 0.6869, F1 Macro: 0.4072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.546, Accuracy: 0.6869, F1 Micro: 0.6869, F1 Macro: 0.4072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4752, Accuracy: 0.6919, F1 Micro: 0.6919, F1 Macro: 0.4386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3119, Accuracy: 0.7172, F1 Micro: 0.7172, F1 Macro: 0.5909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2564, Accuracy: 0.7929, F1 Micro: 0.7929, F1 Macro: 0.7537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.148, Accuracy: 0.7929, F1 Micro: 0.7929, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.8081, F1 Micro: 0.8081, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.8333, F1 Micro: 0.8333, F1 Macro: 0.8054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8481\n",
      "\n",
      "Sentiment analysis accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.95      0.81        62\n",
      "    positive       0.97      0.82      0.89       136\n",
      "\n",
      "    accuracy                           0.86       198\n",
      "   macro avg       0.84      0.88      0.85       198\n",
      "weighted avg       0.89      0.86      0.86       198\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.7757\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       1.00      0.58      0.74        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.80      0.87       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.87      0.61      0.71        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.80      0.84       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.50      0.34        12\n",
      "     neutral       0.85      0.92      0.89       152\n",
      "    positive       0.83      0.46      0.59        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.65      0.63      0.61       216\n",
      "weighted avg       0.81      0.79      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.65      0.71        23\n",
      "     neutral       0.88      0.97      0.92       152\n",
      "    positive       0.86      0.59      0.70        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.74      0.78       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.46      0.57        13\n",
      "     neutral       0.92      1.00      0.96       186\n",
      "    positive       1.00      0.35      0.52        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.60      0.68       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.96      0.99      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 70.99307084083557 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0012020639376714827\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 12.46504521369934 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5302, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5061, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4823, Accuracy: 0.8095, F1 Micro: 0.8922, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4292, Accuracy: 0.8482, F1 Micro: 0.9113, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3626, Accuracy: 0.8936, F1 Micro: 0.9358, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.317, Accuracy: 0.9249, F1 Micro: 0.9538, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2579, Accuracy: 0.9278, F1 Micro: 0.9554, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2186, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.186, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9612\n",
      "\n",
      "Aspect detection accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.96      0.95       175\n",
      "      others       0.85      0.97      0.90       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.6711, F1 Micro: 0.6711, F1 Macro: 0.4016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4301, Accuracy: 0.6711, F1 Micro: 0.6711, F1 Macro: 0.4016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3891, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2341, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2309, Accuracy: 0.9422, F1 Micro: 0.9422, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8831\n",
      "Epoch 7/10, Train Loss: 0.1163, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9237\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9147\n",
      "Epoch 9/10, Train Loss: 0.0945, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9195\n",
      "Epoch 10/10, Train Loss: 0.1456, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9168\n",
      "\n",
      "Sentiment analysis accuracy: 0.9422, F1 Micro: 0.9422, F1 Macro: 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        74\n",
      "    positive       0.95      0.96      0.96       151\n",
      "\n",
      "    accuracy                           0.94       225\n",
      "   macro avg       0.94      0.93      0.93       225\n",
      "weighted avg       0.94      0.94      0.94       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.8666\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.77      0.70      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.90      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.58      0.70        12\n",
      "     neutral       0.85      0.97      0.91       152\n",
      "    positive       0.85      0.54      0.66        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.86      0.70      0.75       216\n",
      "weighted avg       0.85      0.85      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.70      0.78        23\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.80      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 75.42493748664856 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014250980457291007\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.030675172805786 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5941, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5423, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5074, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4658, Accuracy: 0.8586, F1 Micro: 0.9174, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3771, Accuracy: 0.9025, F1 Micro: 0.9409, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3132, Accuracy: 0.9196, F1 Micro: 0.9504, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2594, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2082, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1742, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1444, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9688\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.97      0.96      0.96       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5495, Accuracy: 0.6774, F1 Micro: 0.6774, F1 Macro: 0.4038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4665, Accuracy: 0.7056, F1 Micro: 0.7056, F1 Macro: 0.5088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2689, Accuracy: 0.871, F1 Micro: 0.871, F1 Macro: 0.8524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1917, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9052\n",
      "Epoch 5/10, Train Loss: 0.097, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1248, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.91\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.8629, F1 Micro: 0.8629, F1 Macro: 0.8387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0915, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Epoch 10/10, Train Loss: 0.0962, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8913\n",
      "\n",
      "Sentiment analysis accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.95      0.89        80\n",
      "    positive       0.97      0.91      0.94       168\n",
      "\n",
      "    accuracy                           0.92       248\n",
      "   macro avg       0.90      0.93      0.92       248\n",
      "weighted avg       0.93      0.92      0.92       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8871\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.91      0.64      0.75        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.77      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.91      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 86.07385182380676 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001502620242536068\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.248112201690674 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5867, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5349, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5062, Accuracy: 0.817, F1 Micro: 0.8961, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4259, Accuracy: 0.8869, F1 Micro: 0.9317, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3585, Accuracy: 0.9137, F1 Micro: 0.9474, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2913, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2336, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1931, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1508, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1209, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5237, Accuracy: 0.6745, F1 Micro: 0.6745, F1 Macro: 0.4028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4485, Accuracy: 0.6745, F1 Micro: 0.6745, F1 Macro: 0.4028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.319, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0924, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1351, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       255\n",
      "   macro avg       0.93      0.94      0.93       255\n",
      "weighted avg       0.94      0.94      0.94       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9009\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.96      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.8274519443512 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010901810601353645\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.072760820388794 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5743, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5081, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4591, Accuracy: 0.8571, F1 Micro: 0.9162, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3846, Accuracy: 0.9122, F1 Micro: 0.9466, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.306, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2385, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1831, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1425, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.121, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0983, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5536, Accuracy: 0.6758, F1 Micro: 0.6758, F1 Macro: 0.4033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3643, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2173, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "Epoch 6/10, Train Loss: 0.1324, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9229\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 9/10, Train Loss: 0.1231, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 10/10, Train Loss: 0.0919, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9325\n",
      "\n",
      "Sentiment analysis accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        83\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.95       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9174\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 94.64506959915161 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010199714917689562\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.682742834091187 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5745, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5212, Accuracy: 0.7991, F1 Micro: 0.8868, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4419, Accuracy: 0.8713, F1 Micro: 0.9228, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3613, Accuracy: 0.9152, F1 Micro: 0.948, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2844, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2258, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.182, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1472, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.1177, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0975, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5168, Accuracy: 0.6705, F1 Micro: 0.6705, F1 Macro: 0.4014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3347, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1573, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "Epoch 4/10, Train Loss: 0.1346, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9444\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 96.5010712146759 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005910211126320063\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 8.874150514602661 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5136, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4378, Accuracy: 0.8891, F1 Micro: 0.933, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3386, Accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2623, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2278, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1626, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1357, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.1081, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 10/10, Train Loss: 0.0909, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5025, Accuracy: 0.6732, F1 Micro: 0.6732, F1 Macro: 0.4023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3518, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1571, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1374, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9437\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9184\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.91      0.94      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 99.97754502296448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005274599243421108\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 7.89479660987854 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4932, Accuracy: 0.8237, F1 Micro: 0.8993, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3873, Accuracy: 0.8929, F1 Micro: 0.9344, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3158, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2335, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1905, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1504, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1187, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.096, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0783, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.579, Accuracy: 0.682, F1 Micro: 0.682, F1 Macro: 0.4055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3345, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2103, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1673, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Epoch 7/10, Train Loss: 0.1256, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Epoch 8/10, Train Loss: 0.117, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0977, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 10/10, Train Loss: 0.1054, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9215\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.13734936714172 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005333866574801507\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.132815837860107 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5532, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5037, Accuracy: 0.8125, F1 Micro: 0.8939, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4043, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3133, Accuracy: 0.9338, F1 Micro: 0.959, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2506, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1518, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1239, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0987, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0818, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.7843, F1 Micro: 0.7843, F1 Macro: 0.7086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2749, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0781, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9069\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9235\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.16534280776978 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0003663053415948525\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 6.873921632766724 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5536, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4809, Accuracy: 0.8519, F1 Micro: 0.914, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3792, Accuracy: 0.9211, F1 Micro: 0.9512, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2883, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2252, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1696, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.129, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.109, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.539, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.8278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2677, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.196, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1121, Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9457\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0872, Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9451\n",
      "Epoch 10/10, Train Loss: 0.0921, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.95      0.95       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9257\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.9502284526825 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0002508923935238272\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.184702634811401 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5507, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4689, Accuracy: 0.8795, F1 Micro: 0.9283, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3566, Accuracy: 0.9174, F1 Micro: 0.9496, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2651, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2085, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1517, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.6692, F1 Micro: 0.6692, F1 Macro: 0.4009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3238, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9227\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9291\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        87\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.927\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 113.36635875701904 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00020688785298261791\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 5.6145312786102295 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.552, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4461, Accuracy: 0.878, F1 Micro: 0.9278, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3375, Accuracy: 0.9263, F1 Micro: 0.9548, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2564, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1899, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.146, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1106, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.813, F1 Micro: 0.813, F1 Macro: 0.7601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2077, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1587, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9398\n",
      "Epoch 5/10, Train Loss: 0.1528, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9439\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9349\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9198\n",
      "Epoch 9/10, Train Loss: 0.0816, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Epoch 10/10, Train Loss: 0.0548, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        84\n",
      "    positive       0.98      0.95      0.96       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9247\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.82288908958435 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00016147472488228234\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.305429935455322 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4519, Accuracy: 0.8899, F1 Micro: 0.9339, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3362, Accuracy: 0.9286, F1 Micro: 0.9555, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2426, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1776, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1355, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8411, F1 Micro: 0.8411, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2915, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9243\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0834, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9284\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9017\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9194\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.93      0.77      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.45620942115784 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.421714665018953e-05\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.688485383987427 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4253, Accuracy: 0.8921, F1 Micro: 0.9342, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3103, Accuracy: 0.9301, F1 Micro: 0.9559, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2297, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9816\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.497, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2248, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2051, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1369, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1174, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.086, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        88\n",
      "    positive       0.96      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.94      0.94      0.94       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9279\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.89      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.84321999549866 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 9.31748072616756e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.573812961578369 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5543, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4325, Accuracy: 0.8988, F1 Micro: 0.9382, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3042, Accuracy: 0.9427, F1 Micro: 0.9643, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2147, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "Epoch 9/10, Train Loss: 0.0669, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.7041, F1 Micro: 0.7041, F1 Macro: 0.5177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2551, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1363, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.93\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0727, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        88\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9306\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.88      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.56184673309326 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.545504533685744e-05\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.2252466678619385 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4284, Accuracy: 0.9025, F1 Micro: 0.9411, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3033, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2158, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.97      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.7196, F1 Micro: 0.7196, F1 Macro: 0.534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2725, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9186\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1242, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0942, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9378\n",
      "\n",
      "Sentiment analysis accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       184\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.93      0.95      0.94       271\n",
      "weighted avg       0.95      0.94      0.95       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9246\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.98      0.97      0.97       167\n",
      "    positive       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.84      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.5143337249756 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.6755594414426014e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7646644115448 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.8996, F1 Micro: 0.9372, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2897, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2073, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.482, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "Epoch 3/10, Train Loss: 0.2219, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9408\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9157\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 10/10, Train Loss: 0.0798, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9295\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.07500433921814 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 3.225389991712291e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.2765629291534424 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5335, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4121, Accuracy: 0.904, F1 Micro: 0.9406, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2904, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0592, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.95      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5496, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2434, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.935\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.136, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.099, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9425\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9382\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9225\n",
      "\n",
      "Sentiment analysis accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.92        88\n",
      "    positive       0.98      0.94      0.96       184\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.93      0.95      0.94       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.93\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.90      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.33325028419495 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 5.6163001863751555e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.2967963218688965 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5399, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3855, Accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2648, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.977\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4926, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1891, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Epoch 6/10, Train Loss: 0.0994, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "Epoch 8/10, Train Loss: 0.062, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9042\n",
      "Epoch 9/10, Train Loss: 0.0864, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9111\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8994\n",
      "\n",
      "Sentiment analysis accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        85\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.94      0.93       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9184\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.97560167312622 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.036119426018558e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.73834228515625 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3867, Accuracy: 0.9211, F1 Micro: 0.9509, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0755, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4742, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1884, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9268\n",
      "Epoch 3/10, Train Loss: 0.1871, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9222\n",
      "Epoch 4/10, Train Loss: 0.1243, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9261\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9233\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9456\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.93        88\n",
      "    positive       0.97      0.96      0.96       184\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.94      0.95      0.95       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9282\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.06507992744446 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.1180823387112473e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1953206062316895 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3777, Accuracy: 0.9263, F1 Micro: 0.9545, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2554, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.529, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2675, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 3/10, Train Loss: 0.1568, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9287\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1226, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9405\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9235\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.943\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9207\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.97       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9286\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.42581701278687 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.3680803385796026e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7793278694152832 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3604, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2273, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1162, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.071, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0511, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4793, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9258\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1338, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9073\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0834, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9107\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9337\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9145\n",
      "\n",
      "Sentiment analysis accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        87\n",
      "    positive       0.95      0.97      0.96       183\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.94      0.93      0.94       270\n",
      "weighted avg       0.94      0.94      0.94       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.4868643283844 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 9.808790491661056e-06\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.5733256340026855 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.519, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3719, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2259, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.0903, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4785, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 2/10, Train Loss: 0.1975, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9302\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9185\n",
      "Epoch 4/10, Train Loss: 0.1136, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\n",
      "Epoch 5/10, Train Loss: 0.0909, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9189\n",
      "Epoch 10/10, Train Loss: 0.0714, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9295\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.8411636352539 s\n",
      "Total runtime: 2866.563265800476 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636007ed",
   "metadata": {
    "papermill": {
     "duration": 0.051241,
     "end_time": "2025-03-25T04:42:12.559454",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.508213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10d0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 69.68354439735413 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005745713599026205\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 7.4465765953063965 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6203, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5033, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4868, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4617, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4448, Accuracy: 0.7999, F1 Micro: 0.8873, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.399, Accuracy: 0.817, F1 Micro: 0.8958, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3499, Accuracy: 0.8318, F1 Micro: 0.9032, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3249, Accuracy: 0.8438, F1 Micro: 0.9089, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2824, Accuracy: 0.8616, F1 Micro: 0.9183, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2359, Accuracy: 0.8921, F1 Micro: 0.9355, F1 Macro: 0.9344\n",
      "\n",
      "Aspect detection accuracy: 0.8921, F1 Micro: 0.9355, F1 Macro: 0.9344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      1.00      0.96       187\n",
      "     machine       0.81      1.00      0.90       175\n",
      "      others       0.82      0.96      0.88       158\n",
      "        part       0.90      0.98      0.94       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.94      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.99      0.94      1061\n",
      "   macro avg       0.89      0.99      0.93      1061\n",
      "weighted avg       0.89      0.99      0.94      1061\n",
      " samples avg       0.89      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6453, Accuracy: 0.6556, F1 Micro: 0.6556, F1 Macro: 0.396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5042, Accuracy: 0.6556, F1 Micro: 0.6556, F1 Macro: 0.396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4739, Accuracy: 0.6821, F1 Micro: 0.6821, F1 Macro: 0.4739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4082, Accuracy: 0.7616, F1 Micro: 0.7616, F1 Macro: 0.6653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2609, Accuracy: 0.8146, F1 Micro: 0.8146, F1 Macro: 0.7619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8305\n",
      "Epoch 8/10, Train Loss: 0.0981, Accuracy: 0.8079, F1 Micro: 0.8079, F1 Macro: 0.7472\n",
      "Epoch 9/10, Train Loss: 0.1158, Accuracy: 0.8146, F1 Micro: 0.8146, F1 Macro: 0.758\n",
      "Epoch 10/10, Train Loss: 0.0821, Accuracy: 0.8212, F1 Micro: 0.8212, F1 Macro: 0.7722\n",
      "\n",
      "Sentiment analysis accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.63      0.76        52\n",
      "    positive       0.84      0.98      0.90        99\n",
      "\n",
      "    accuracy                           0.86       151\n",
      "   macro avg       0.89      0.81      0.83       151\n",
      "weighted avg       0.87      0.86      0.85       151\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.6692\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.92      1.00      0.96       181\n",
      "    positive       0.88      0.58      0.70        24\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.65      0.73       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.12      0.22        16\n",
      "     neutral       0.80      1.00      0.89       167\n",
      "    positive       0.67      0.12      0.21        33\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.82      0.42      0.44       216\n",
      "weighted avg       0.80      0.80      0.74       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.25      0.35        12\n",
      "     neutral       0.82      0.97      0.89       152\n",
      "    positive       0.72      0.44      0.55        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.71      0.55      0.60       216\n",
      "weighted avg       0.78      0.80      0.78       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.52      0.69        23\n",
      "     neutral       0.89      0.98      0.93       152\n",
      "    positive       0.78      0.71      0.74        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.89      0.74      0.79       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.23      0.38        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.60      0.65       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.72      0.81       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 72.2947187423706 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0013907131971791387\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.46117353439331 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5963, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4909, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.478, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4552, Accuracy: 0.7932, F1 Micro: 0.884, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.413, Accuracy: 0.8118, F1 Micro: 0.8929, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3767, Accuracy: 0.8594, F1 Micro: 0.9176, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3167, Accuracy: 0.9003, F1 Micro: 0.9398, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2515, Accuracy: 0.9219, F1 Micro: 0.9522, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2244, Accuracy: 0.9368, F1 Micro: 0.9611, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1822, Accuracy: 0.9412, F1 Micro: 0.9638, F1 Macro: 0.9627\n",
      "\n",
      "Aspect detection accuracy: 0.9412, F1 Micro: 0.9638, F1 Macro: 0.9627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.85      0.99      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.94      0.99      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6328, Accuracy: 0.6542, F1 Micro: 0.6542, F1 Macro: 0.3955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5237, Accuracy: 0.7243, F1 Micro: 0.7243, F1 Macro: 0.5947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3153, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.898\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1617, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9197\n",
      "Epoch 6/10, Train Loss: 0.1596, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9135\n",
      "Epoch 7/10, Train Loss: 0.1214, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9135\n",
      "Epoch 8/10, Train Loss: 0.0581, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.9007\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8792\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8849\n",
      "\n",
      "Sentiment analysis accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        74\n",
      "    positive       0.98      0.91      0.94       140\n",
      "\n",
      "    accuracy                           0.93       214\n",
      "   macro avg       0.91      0.93      0.92       214\n",
      "weighted avg       0.93      0.93      0.93       214\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.8539\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71        16\n",
      "     neutral       0.93      0.98      0.95       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.78      0.81       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.85      0.99      0.91       152\n",
      "    positive       0.93      0.50      0.65        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.82      0.72      0.74       216\n",
      "weighted avg       0.86      0.85      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.97      0.71      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.87      0.88       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.77      0.84       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Total train time: 78.08930468559265 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014003454707562923\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.99328351020813 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5933, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5205, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4766, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4462, Accuracy: 0.8103, F1 Micro: 0.8924, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4049, Accuracy: 0.869, F1 Micro: 0.9227, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3354, Accuracy: 0.9241, F1 Micro: 0.9532, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2666, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.211, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1768, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1406, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5739, Accuracy: 0.6774, F1 Micro: 0.6774, F1 Macro: 0.4038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4309, Accuracy: 0.8347, F1 Micro: 0.8347, F1 Macro: 0.7914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2276, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1171, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1003, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.045, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        80\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.93      0.95      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.898\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.78      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.85      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 97.2597725391388 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014694785117171708\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.884810209274292 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5912, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5253, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4969, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4313, Accuracy: 0.8579, F1 Micro: 0.9167, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3603, Accuracy: 0.9167, F1 Micro: 0.9491, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2839, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2202, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "Epoch 8/10, Train Loss: 0.177, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9683\n",
      "Epoch 9/10, Train Loss: 0.1366, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9692\n",
      "Epoch 10/10, Train Loss: 0.1206, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9693\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.97      0.95       175\n",
      "      others       0.87      0.98      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5443, Accuracy: 0.6681, F1 Micro: 0.6681, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3693, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9176\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9353\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9237\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9296\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.93\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        79\n",
      "    positive       0.98      0.93      0.95       159\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.93      0.95      0.94       238\n",
      "weighted avg       0.94      0.94      0.94       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8916\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.82      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.87      0.98      0.92       152\n",
      "    positive       0.91      0.60      0.72        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.86      0.75      0.79       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.29659724235535 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0009731133468449116\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.478921890258789 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.566, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5311, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4807, Accuracy: 0.8237, F1 Micro: 0.8984, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.392, Accuracy: 0.8899, F1 Micro: 0.9335, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3122, Accuracy: 0.9263, F1 Micro: 0.9542, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2373, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1864, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1479, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1158, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0995, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5365, Accuracy: 0.7183, F1 Micro: 0.7183, F1 Macro: 0.5604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.322, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1166, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1052, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9214\n",
      "Epoch 7/10, Train Loss: 0.1156, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Epoch 8/10, Train Loss: 0.104, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.92        81\n",
      "    positive       0.99      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.81      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 106.68393611907959 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010933602461591367\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.628739356994629 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5825, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5159, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4632, Accuracy: 0.8333, F1 Micro: 0.9035, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3802, Accuracy: 0.9092, F1 Micro: 0.9448, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2924, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2172, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1737, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.1378, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Epoch 9/10, Train Loss: 0.1071, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9691\n",
      "Epoch 10/10, Train Loss: 0.0896, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.88      0.97      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.7108, F1 Micro: 0.7108, F1 Macro: 0.5279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2669, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9102\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9378\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        81\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       249\n",
      "   macro avg       0.94      0.95      0.94       249\n",
      "weighted avg       0.95      0.95      0.95       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9084\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.88      0.97      0.93       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.02568078041077 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0007108735386282206\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.857564210891724 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5817, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5049, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4624, Accuracy: 0.8653, F1 Micro: 0.9204, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3608, Accuracy: 0.9196, F1 Micro: 0.9509, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2731, Accuracy: 0.9449, F1 Micro: 0.9661, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2026, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1576, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.1313, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1026, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0863, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5162, Accuracy: 0.7016, F1 Micro: 0.7016, F1 Macro: 0.5062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.286, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1941, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9276\n",
      "Epoch 4/10, Train Loss: 0.1509, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.937\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9327\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9241\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9203\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.928\n",
      "\n",
      "Sentiment analysis accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        81\n",
      "    positive       0.98      0.94      0.96       167\n",
      "\n",
      "    accuracy                           0.94       248\n",
      "   macro avg       0.93      0.95      0.94       248\n",
      "weighted avg       0.95      0.94      0.94       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9105\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.92      0.69      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.62015199661255 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.000710057356627658\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.867181777954102 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.561, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4986, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4302, Accuracy: 0.9048, F1 Micro: 0.9418, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3048, Accuracy: 0.9338, F1 Micro: 0.9585, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2258, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9715\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1305, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.1114, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0863, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5463, Accuracy: 0.814, F1 Micro: 0.814, F1 Macro: 0.7506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2716, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 3/10, Train Loss: 0.1557, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.919\n",
      "Epoch 4/10, Train Loss: 0.1114, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1142, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 6/10, Train Loss: 0.1381, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 7/10, Train Loss: 0.0783, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        83\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9071\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.63891386985779 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006835286854766313\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.9766106605529785 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5604, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4963, Accuracy: 0.7932, F1 Micro: 0.8841, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4252, Accuracy: 0.8847, F1 Micro: 0.9303, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3254, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2472, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9711\n",
      "Epoch 6/10, Train Loss: 0.1808, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.139, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.1129, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0802, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2349, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2255, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9281\n",
      "Epoch 4/10, Train Loss: 0.1593, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Epoch 5/10, Train Loss: 0.151, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9202\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 8/10, Train Loss: 0.1079, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9052\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 113.50691866874695 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0005004255537642164\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.399838924407959 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5608, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5029, Accuracy: 0.7946, F1 Micro: 0.8847, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4043, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3073, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2266, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.127, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Epoch 9/10, Train Loss: 0.0891, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0754, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4983, Accuracy: 0.8054, F1 Micro: 0.8054, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2767, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1498, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1257, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0893, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9322\n",
      "Epoch 6/10, Train Loss: 0.0791, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0679, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.913\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.95      0.96      0.95       152\n",
      "    positive       0.86      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 121.92016220092773 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.000383588281692937\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.8946311473846436 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5654, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4865, Accuracy: 0.8192, F1 Micro: 0.8967, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3936, Accuracy: 0.9025, F1 Micro: 0.9413, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.288, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2116, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1559, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1242, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4924, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.8334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2881, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Epoch 4/10, Train Loss: 0.1392, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0982, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "\n",
      "Sentiment analysis accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        86\n",
      "    positive       0.95      0.95      0.95       182\n",
      "\n",
      "    accuracy                           0.93       268\n",
      "   macro avg       0.92      0.92      0.92       268\n",
      "weighted avg       0.93      0.93      0.93       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9151\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.27269101142883 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0002816201595123857\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.130702018737793 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5667, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4784, Accuracy: 0.8185, F1 Micro: 0.8965, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3679, Accuracy: 0.9278, F1 Micro: 0.9555, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2625, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1966, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1191, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 8/10, Train Loss: 0.0946, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.523, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9272\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1244, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9461\n",
      "Epoch 7/10, Train Loss: 0.117, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 10/10, Train Loss: 0.0809, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.93        84\n",
      "    positive       0.95      0.98      0.97       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.95      0.94      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9181\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 123.69373774528503 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00029607911128550786\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.722234725952148 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5573, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4726, Accuracy: 0.8289, F1 Micro: 0.9003, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3567, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2417, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9752\n",
      "Epoch 6/10, Train Loss: 0.1299, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4691, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2126, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9215\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9254\n",
      "Epoch 9/10, Train Loss: 0.0898, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9137\n",
      "Epoch 10/10, Train Loss: 0.0863, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9206\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90        86\n",
      "    positive       0.98      0.92      0.95       184\n",
      "\n",
      "    accuracy                           0.93       270\n",
      "   macro avg       0.92      0.94      0.93       270\n",
      "weighted avg       0.94      0.93      0.93       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9151\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.84      0.83       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 134.23233294487 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00015297444770112634\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.37779974937439 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5499, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4406, Accuracy: 0.869, F1 Micro: 0.9227, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3313, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2317, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Epoch 5/10, Train Loss: 0.1639, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4696, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1911, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9272\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0994, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0904, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 9/10, Train Loss: 0.0816, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 10/10, Train Loss: 0.0834, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9212\n",
      "\n",
      "Sentiment analysis accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        87\n",
      "    positive       0.96      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9143\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.0624577999115 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00017680745804682374\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.067354679107666 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4536, Accuracy: 0.8765, F1 Micro: 0.9268, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3212, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2277, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9744\n",
      "Epoch 5/10, Train Loss: 0.1636, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.9472, F1 Micro: 0.9662, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1135, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.488, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2436, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.927\n",
      "Epoch 3/10, Train Loss: 0.1616, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.91\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9356\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.927\n",
      "Epoch 9/10, Train Loss: 0.082, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0777, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.95       168\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.8578999042511 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00011872236791532487\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.457341432571411 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.543, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4464, Accuracy: 0.8839, F1 Micro: 0.9302, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3085, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2156, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1573, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.96      0.94      0.95       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4964, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1752, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9103\n",
      "Epoch 5/10, Train Loss: 0.1081, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Epoch 8/10, Train Loss: 0.0896, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9271\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86        12\n",
      "     neutral       0.96      0.95      0.95       152\n",
      "    positive       0.86      0.83      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.92      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.5246605873108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.832601452013478e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.9779739379882812 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4196, Accuracy: 0.907, F1 Micro: 0.9437, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2918, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9756\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.496, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.173, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1289, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1077, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Epoch 7/10, Train Loss: 0.107, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9179\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9228\n",
      "\n",
      "Sentiment analysis accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.95       165\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.94      0.93       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.51696491241455 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.94644316151971e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.540287733078003 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5362, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.431, Accuracy: 0.8876, F1 Micro: 0.9324, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2914, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1953, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1457, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9788\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4822, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2281, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "Epoch 7/10, Train Loss: 0.0964, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9144\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9292\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.9046\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        87\n",
      "    positive       0.96      0.96      0.96       185\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.93      0.93      0.93       272\n",
      "weighted avg       0.94      0.94      0.94       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.915\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 141.74983024597168 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.5088009937899176e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.3743627071380615 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5357, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4258, Accuracy: 0.9144, F1 Micro: 0.948, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2737, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1417, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4544, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1839, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9351\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9259\n",
      "Epoch 10/10, Train Loss: 0.0631, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        85\n",
      "    positive       0.96      0.96      0.96       182\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.94      0.94       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9214\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.76727986335754 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 5.2882370800944047e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8893537521362305 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5373, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4019, Accuracy: 0.9107, F1 Micro: 0.946, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2648, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1794, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1314, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5169, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2347, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0906, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9338\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "    positive       0.94      0.98      0.96       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.94      0.92      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9157\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 145.3516821861267 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.5765068676264492e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.380985736846924 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4043, Accuracy: 0.9174, F1 Micro: 0.9492, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2682, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0787, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4976, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9124\n",
      "Epoch 2/10, Train Loss: 0.2562, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9283\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9284\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.83479189872742 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.7220805714023298e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1540637016296387 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5282, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3928, Accuracy: 0.9286, F1 Micro: 0.9564, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2389, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 5/10, Train Loss: 0.1264, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.061, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.462, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2107, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9386\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9234\n",
      "Epoch 4/10, Train Loss: 0.1266, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.9248\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.9082\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.9248\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9035\n",
      "Epoch 8/10, Train Loss: 0.0789, Accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0596, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9375\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.9239\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       188\n",
      "\n",
      "    accuracy                           0.95       275\n",
      "   macro avg       0.93      0.94      0.94       275\n",
      "weighted avg       0.95      0.95      0.95       275\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9239\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.85      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.64864826202393 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.8953931976284364e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3597450256347656 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5203, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3902, Accuracy: 0.9286, F1 Micro: 0.9559, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2352, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5029, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2387, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9105\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9279\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9161\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Epoch 8/10, Train Loss: 0.0909, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9157\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9248\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.33677124977112 s\n",
      "Total runtime: 3193.0706157684326 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fe63a",
   "metadata": {
    "papermill": {
     "duration": 0.013009,
     "end_time": "2025-03-25T04:42:12.616871",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.603862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 67.69088625907898 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008303248207084835\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.348589658737183 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6059, Accuracy: 0.7887, F1 Micro: 0.8818, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5336, Accuracy: 0.7894, F1 Micro: 0.8821, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4962, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4756, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.459, Accuracy: 0.7999, F1 Micro: 0.8865, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4103, Accuracy: 0.808, F1 Micro: 0.8898, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3772, Accuracy: 0.8237, F1 Micro: 0.8974, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3375, Accuracy: 0.8445, F1 Micro: 0.9087, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2851, Accuracy: 0.8713, F1 Micro: 0.9223, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2508, Accuracy: 0.872, F1 Micro: 0.9226, F1 Macro: 0.9197\n",
      "\n",
      "Aspect detection accuracy: 0.872, F1 Micro: 0.9226, F1 Macro: 0.9197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.90      1.00      0.95       187\n",
      "     machine       0.86      0.98      0.92       175\n",
      "      others       0.84      0.85      0.85       158\n",
      "        part       0.86      0.96      0.91       158\n",
      "       price       0.96      0.98      0.97       192\n",
      "     service       0.87      1.00      0.93       191\n",
      "\n",
      "   micro avg       0.88      0.97      0.92      1061\n",
      "   macro avg       0.88      0.96      0.92      1061\n",
      "weighted avg       0.88      0.97      0.92      1061\n",
      " samples avg       0.89      0.97      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6038, Accuracy: 0.7753, F1 Micro: 0.7753, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5372, Accuracy: 0.7753, F1 Micro: 0.7753, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4926, Accuracy: 0.7753, F1 Micro: 0.7753, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4347, Accuracy: 0.7921, F1 Micro: 0.7921, F1 Macro: 0.5622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3295, Accuracy: 0.8202, F1 Micro: 0.8202, F1 Macro: 0.727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2684, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.7866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1765, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8532\n",
      "Epoch 8/10, Train Loss: 0.1558, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1133, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0953, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8577\n",
      "\n",
      "Sentiment analysis accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.88      0.79        40\n",
      "    positive       0.96      0.90      0.93       138\n",
      "\n",
      "    accuracy                           0.89       178\n",
      "   macro avg       0.84      0.89      0.86       178\n",
      "weighted avg       0.91      0.89      0.90       178\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.6403\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.27      0.43        11\n",
      "     neutral       0.91      1.00      0.95       181\n",
      "    positive       1.00      0.54      0.70        24\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.97      0.60      0.69       216\n",
      "weighted avg       0.92      0.91      0.90       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.06      0.12        16\n",
      "     neutral       0.85      0.98      0.91       167\n",
      "    positive       0.83      0.58      0.68        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.89      0.54      0.57       216\n",
      "weighted avg       0.86      0.85      0.82       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.42      0.40        12\n",
      "     neutral       0.84      0.84      0.84       152\n",
      "    positive       0.63      0.62      0.62        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.62      0.62      0.62       216\n",
      "weighted avg       0.77      0.76      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.61      0.67        23\n",
      "     neutral       0.85      0.96      0.90       152\n",
      "    positive       0.81      0.51      0.63        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.80      0.69      0.73       216\n",
      "weighted avg       0.83      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.96      0.98      0.97       186\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        14\n",
      "     neutral       0.87      1.00      0.93       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.62      0.38      0.39       216\n",
      "weighted avg       0.81      0.87      0.81       216\n",
      "\n",
      "Total train time: 79.4930989742279 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001422121748328209\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.282034397125244 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5908, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5228, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4973, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4793, Accuracy: 0.7954, F1 Micro: 0.8836, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4268, Accuracy: 0.8177, F1 Micro: 0.8955, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3843, Accuracy: 0.8594, F1 Micro: 0.9169, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3163, Accuracy: 0.9025, F1 Micro: 0.9409, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2676, Accuracy: 0.9122, F1 Micro: 0.9461, F1 Macro: 0.9443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2165, Accuracy: 0.9249, F1 Micro: 0.9539, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1847, Accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9562\n",
      "\n",
      "Aspect detection accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.96      0.95       175\n",
      "      others       0.87      0.91      0.89       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.99      0.98      0.98       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5945, Accuracy: 0.6822, F1 Micro: 0.6822, F1 Macro: 0.4055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.502, Accuracy: 0.8008, F1 Micro: 0.8008, F1 Macro: 0.7232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3123, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.196, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8985\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1013, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8985\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9114\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.9016\n",
      "Epoch 10/10, Train Loss: 0.0549, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        75\n",
      "    positive       0.94      0.95      0.94       161\n",
      "\n",
      "    accuracy                           0.92       236\n",
      "   macro avg       0.91      0.91      0.91       236\n",
      "weighted avg       0.92      0.92      0.92       236\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8326\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.79      0.79      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.87      0.91      0.89       152\n",
      "    positive       0.73      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.78      0.76      0.77       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.74      0.81        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.86      0.76      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.98      0.98       186\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       1.00      0.29      0.45        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.97      0.67      0.75       216\n",
      "weighted avg       0.93      0.93      0.91       216\n",
      "\n",
      "Total train time: 80.93688201904297 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015119469026103616\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.140210390090942 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5773, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4997, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4925, Accuracy: 0.7924, F1 Micro: 0.8831, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4568, Accuracy: 0.8155, F1 Micro: 0.8936, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4001, Accuracy: 0.8653, F1 Micro: 0.9199, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3195, Accuracy: 0.9085, F1 Micro: 0.9437, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2692, Accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2095, Accuracy: 0.936, F1 Micro: 0.9599, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1818, Accuracy: 0.9412, F1 Micro: 0.9631, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1508, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9651\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.87      0.97      0.92       158\n",
      "        part       0.98      0.96      0.97       158\n",
      "       price       0.98      0.97      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.6762, F1 Micro: 0.6762, F1 Macro: 0.4034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4578, Accuracy: 0.8525, F1 Micro: 0.8525, F1 Macro: 0.8254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3338, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0762, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9449\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0419, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9321\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        79\n",
      "    positive       0.98      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.95      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8833\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.87      0.97      0.92       152\n",
      "    positive       0.94      0.62      0.74        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.78      0.80       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.95      0.97       152\n",
      "    positive       0.86      0.88      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.91      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.79      0.86       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 92.59644675254822 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015020604711025957\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.917480707168579 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5847, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5167, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4812, Accuracy: 0.7961, F1 Micro: 0.8838, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4281, Accuracy: 0.8519, F1 Micro: 0.9125, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3498, Accuracy: 0.91, F1 Micro: 0.9448, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2908, Accuracy: 0.9353, F1 Micro: 0.9598, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2292, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1656, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1406, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.114, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5716, Accuracy: 0.682, F1 Micro: 0.682, F1 Macro: 0.4055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3987, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9192\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9197\n",
      "Epoch 6/10, Train Loss: 0.059, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9063\n",
      "Epoch 7/10, Train Loss: 0.0378, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8803\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9117\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9188\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90        83\n",
      "    positive       0.97      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.91      0.93      0.92       261\n",
      "weighted avg       0.93      0.93      0.93       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8943\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.88      0.91      0.90        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.73      0.69      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.81      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 91.90008759498596 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001196755561977625\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.944561958312988 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5645, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5335, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4765, Accuracy: 0.8095, F1 Micro: 0.891, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3992, Accuracy: 0.8824, F1 Micro: 0.9288, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3123, Accuracy: 0.9271, F1 Micro: 0.9547, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2356, Accuracy: 0.9412, F1 Micro: 0.9629, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.184, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1511, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1156, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5746, Accuracy: 0.668, F1 Micro: 0.668, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4019, Accuracy: 0.8477, F1 Micro: 0.8477, F1 Macro: 0.8385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.186, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1482, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "\n",
      "Sentiment analysis accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        83\n",
      "    positive       0.99      0.92      0.95       173\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.92      0.95      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.909\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.12393260002136 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.001121072191745043\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.600102186203003 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5765, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.5007, Accuracy: 0.7902, F1 Micro: 0.8821, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4775, Accuracy: 0.846, F1 Micro: 0.909, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3783, Accuracy: 0.8943, F1 Micro: 0.9343, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3117, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2288, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1749, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1394, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1076, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5521, Accuracy: 0.7423, F1 Micro: 0.7423, F1 Macro: 0.6058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2933, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1499, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9245\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.93      0.96      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9146\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.51780915260315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0008036180050112306\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.693414211273193 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5059, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4627, Accuracy: 0.84, F1 Micro: 0.9044, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3675, Accuracy: 0.9003, F1 Micro: 0.9381, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2958, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2304, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1345, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1132, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0905, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.6899, F1 Micro: 0.6899, F1 Macro: 0.4797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3015, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.123, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9215\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9137\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.91027355194092 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006134841532912105\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.843992948532104 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5087, Accuracy: 0.7946, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4354, Accuracy: 0.8802, F1 Micro: 0.927, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3297, Accuracy: 0.933, F1 Micro: 0.9585, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2442, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1834, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1401, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.1034, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5509, Accuracy: 0.668, F1 Micro: 0.668, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3128, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.142, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1643, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9299\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.938\n",
      "Epoch 8/10, Train Loss: 0.0935, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        83\n",
      "    positive       0.99      0.93      0.96       167\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.93      0.95      0.94       250\n",
      "weighted avg       0.95      0.94      0.94       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.61800599098206 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005637987283989788\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.941364765167236 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5719, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5041, Accuracy: 0.8013, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4291, Accuracy: 0.8802, F1 Micro: 0.9272, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3365, Accuracy: 0.9368, F1 Micro: 0.9607, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2516, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1912, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1163, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0907, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0758, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5555, Accuracy: 0.7208, F1 Micro: 0.7208, F1 Macro: 0.5637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2967, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1397, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1122, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0916, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        88\n",
      "    positive       0.96      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.93      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9171\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.87      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.75117897987366 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00039205091597978027\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.479145526885986 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5586, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.499, Accuracy: 0.8051, F1 Micro: 0.8883, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4176, Accuracy: 0.8929, F1 Micro: 0.9345, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3094, Accuracy: 0.9412, F1 Micro: 0.9631, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2284, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1695, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1344, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.9576, F1 Micro: 0.9731, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0847, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.515, Accuracy: 0.8447, F1 Micro: 0.8447, F1 Macro: 0.7998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2415, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1888, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Epoch 6/10, Train Loss: 0.1308, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.917\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9203\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.81643009185791 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0002869531454052776\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.017374515533447 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5653, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.8058, F1 Micro: 0.8891, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4235, Accuracy: 0.8929, F1 Micro: 0.9351, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3062, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2191, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1705, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1378, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0817, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4723, Accuracy: 0.8534, F1 Micro: 0.8534, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2437, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1136, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9124\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9406\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9214\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.91      0.90        33\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.9789502620697 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00029331110999919474\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.21099591255188 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.554, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5041, Accuracy: 0.8185, F1 Micro: 0.8954, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.376, Accuracy: 0.9152, F1 Micro: 0.9474, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2624, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2026, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1449, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 7/10, Train Loss: 0.1155, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.7765, F1 Micro: 0.7765, F1 Macro: 0.68\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2626, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1642, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9333\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9373\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9208\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.87      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.39148712158203 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0001965512245078572\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.815133571624756 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5421, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4831, Accuracy: 0.8326, F1 Micro: 0.9028, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3685, Accuracy: 0.9278, F1 Micro: 0.9557, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.258, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1815, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.1364, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9643, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4788, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2744, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9147\n",
      "Epoch 3/10, Train Loss: 0.178, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9338\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9299, F1 Micro: 0.9299, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        88\n",
      "    positive       0.97      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.93      0.94      0.93       271\n",
      "weighted avg       0.94      0.94      0.94       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9181\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.88      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.927636384964 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00018552017718320712\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.463561534881592 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5447, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4627, Accuracy: 0.8497, F1 Micro: 0.9114, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3503, Accuracy: 0.9301, F1 Micro: 0.9571, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2367, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1759, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.126, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5428, Accuracy: 0.7887, F1 Micro: 0.7887, F1 Macro: 0.7019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 5/10, Train Loss: 0.1447, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9294\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0978, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9449\n",
      "Epoch 9/10, Train Loss: 0.0772, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9291\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       179\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9191\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.76      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.32691431045532 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 8.479786629322916e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.233440160751343 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4697, Accuracy: 0.8363, F1 Micro: 0.9052, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3355, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2344, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0545, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4841, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2041, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1811, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 4/10, Train Loss: 0.1389, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1123, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9497\n",
      "Epoch 6/10, Train Loss: 0.1014, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1043, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9494\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9366\n",
      "Epoch 9/10, Train Loss: 0.0857, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9359\n",
      "Epoch 10/10, Train Loss: 0.0755, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        87\n",
      "    positive       0.98      0.96      0.97       180\n",
      "\n",
      "    accuracy                           0.96       267\n",
      "   macro avg       0.94      0.95      0.95       267\n",
      "weighted avg       0.96      0.96      0.96       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9302\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.87      0.85       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.18897891044617 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.000102586331195198\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.615495681762695 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5523, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4676, Accuracy: 0.8274, F1 Micro: 0.9009, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3388, Accuracy: 0.9234, F1 Micro: 0.9521, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2293, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9728\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9487, F1 Micro: 0.9674, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1386, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1095, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5004, Accuracy: 0.8864, F1 Micro: 0.8864, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2567, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1065, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9479\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        87\n",
      "    positive       0.96      0.98      0.97       177\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.95      0.94      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9264\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.0505805015564 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00011690556857502088\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.139827489852905 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4511, Accuracy: 0.8653, F1 Micro: 0.92, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3095, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2097, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.493, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2291, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "Epoch 4/10, Train Loss: 0.1317, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 5/10, Train Loss: 0.1101, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9305\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9143\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9366\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9172\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.47758603096008 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 4.752690074383281e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.5966122150421143 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4506, Accuracy: 0.8676, F1 Micro: 0.9214, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3132, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2062, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1149, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2795, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9132\n",
      "Epoch 3/10, Train Loss: 0.1472, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Epoch 7/10, Train Loss: 0.1026, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.95      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9257\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.88      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.8149836063385 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 5.299469485180452e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.345614433288574 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.531, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4246, Accuracy: 0.9018, F1 Micro: 0.9399, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2757, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.195, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4969, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2314, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.945\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9488\n",
      "\n",
      "Sentiment analysis accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        85\n",
      "    positive       0.98      0.96      0.97       181\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.95      0.95       266\n",
      "weighted avg       0.96      0.95      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9287\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 147.5208556652069 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.484265518840401e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.990555763244629 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5296, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4252, Accuracy: 0.8921, F1 Micro: 0.9342, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2778, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4917, Accuracy: 0.8649, F1 Micro: 0.8649, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2232, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9429\n",
      "Epoch 3/10, Train Loss: 0.1568, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9478\n",
      "Epoch 7/10, Train Loss: 0.071, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 10/10, Train Loss: 0.0382, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9276\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.31160283088684 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 3.645510150818155e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4639241695404053 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4355, Accuracy: 0.8973, F1 Micro: 0.9373, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2887, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9717, F1 Micro: 0.9821, F1 Macro: 0.9808\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9821, F1 Macro: 0.9808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4652, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2208, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9337\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.942\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9231\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9337\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9193\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9245\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        88\n",
      "    positive       0.97      0.95      0.96       185\n",
      "\n",
      "    accuracy                           0.95       273\n",
      "   macro avg       0.94      0.95      0.94       273\n",
      "weighted avg       0.95      0.95      0.95       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9336\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.88      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.6011607646942 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.7532426500110888e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0205788612365723 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4191, Accuracy: 0.9115, F1 Micro: 0.9456, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2586, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0972, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0728, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4719, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2434, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 6/10, Train Loss: 0.0917, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9409\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.912\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9447\n",
      "\n",
      "Sentiment analysis accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        87\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.95      0.96      0.95       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9345\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.88      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 148.3667414188385 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.4967458810133394e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.4265007972717285 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7946, F1 Micro: 0.8845, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4197, Accuracy: 0.9055, F1 Micro: 0.9423, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2527, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.0932, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0589, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4315, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9333\n",
      "Epoch 2/10, Train Loss: 0.1979, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9377\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9219\n",
      "Epoch 6/10, Train Loss: 0.0924, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9494\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8949\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.9454\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.96      0.97       184\n",
      "\n",
      "    accuracy                           0.96       270\n",
      "   macro avg       0.94      0.96      0.95       270\n",
      "weighted avg       0.96      0.96      0.96       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9328\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 149.08322668075562 s\n",
      "Total runtime: 3245.425366163254 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594eceeb",
   "metadata": {
    "papermill": {
     "duration": 0.013191,
     "end_time": "2025-03-25T04:42:12.674899",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.661708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8395ca1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T04:42:12.701680Z",
     "iopub.status.busy": "2025-03-25T04:42:12.701426Z",
     "iopub.status.idle": "2025-03-25T05:28:58.134096Z",
     "shell.execute_reply": "2025-03-25T05:28:58.133343Z"
    },
    "papermill": {
     "duration": 2805.447458,
     "end_time": "2025-03-25T05:28:58.135489",
     "exception": false,
     "start_time": "2025-03-25T04:42:12.688031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 65.11259698867798 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0006667633366305381\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 8.323540210723877 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6079, Accuracy: 0.7872, F1 Micro: 0.8809, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5171, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4969, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4605, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4237, Accuracy: 0.8051, F1 Micro: 0.8897, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3988, Accuracy: 0.8132, F1 Micro: 0.8935, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3454, Accuracy: 0.8348, F1 Micro: 0.9046, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2925, Accuracy: 0.8423, F1 Micro: 0.9081, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2634, Accuracy: 0.8609, F1 Micro: 0.9173, F1 Macro: 0.9154\n",
      "\n",
      "Aspect detection accuracy: 0.8609, F1 Micro: 0.9173, F1 Macro: 0.9154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.87      1.00      0.93       187\n",
      "     machine       0.80      0.99      0.88       175\n",
      "      others       0.86      0.89      0.87       158\n",
      "        part       0.83      0.99      0.90       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.86      0.98      0.92      1061\n",
      "   macro avg       0.86      0.98      0.92      1061\n",
      "weighted avg       0.87      0.98      0.92      1061\n",
      " samples avg       0.87      0.98      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6512, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6089, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4613, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4275, Accuracy: 0.8489, F1 Micro: 0.8489, F1 Macro: 0.7216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3329, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2587, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1276, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0947, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9325\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9353, F1 Micro: 0.9353, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        32\n",
      "    positive       0.99      0.94      0.97       107\n",
      "\n",
      "    accuracy                           0.95       139\n",
      "   macro avg       0.91      0.96      0.93       139\n",
      "weighted avg       0.96      0.95      0.95       139\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.6156\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.87      1.00      0.93       181\n",
      "    positive       1.00      0.33      0.50        24\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.62      0.44      0.48       216\n",
      "weighted avg       0.84      0.88      0.84       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.06      0.11        16\n",
      "     neutral       0.79      0.99      0.88       167\n",
      "    positive       0.83      0.15      0.26        33\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.71      0.40      0.42       216\n",
      "weighted avg       0.78      0.79      0.73       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.86      0.88      0.87       152\n",
      "    positive       0.73      0.67      0.70        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.74      0.74      0.74       216\n",
      "weighted avg       0.82      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.35      0.52        23\n",
      "     neutral       0.82      0.99      0.90       152\n",
      "    positive       0.92      0.59      0.72        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.92      0.64      0.71       216\n",
      "weighted avg       0.86      0.84      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.46      0.63        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.68      0.76       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.54      0.59       216\n",
      "weighted avg       0.87      0.90      0.87       216\n",
      "\n",
      "Total train time: 73.85097360610962 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014112006640061743\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 10.718860149383545 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5958, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.504, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4738, Accuracy: 0.8028, F1 Micro: 0.8885, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4424, Accuracy: 0.8185, F1 Micro: 0.8964, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3898, Accuracy: 0.8527, F1 Micro: 0.9139, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3386, Accuracy: 0.8876, F1 Micro: 0.9323, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2785, Accuracy: 0.9062, F1 Micro: 0.9426, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2352, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.957\n",
      "Epoch 10/10, Train Loss: 0.1891, Accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9557\n",
      "\n",
      "Aspect detection accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.87      0.96      0.92       158\n",
      "        part       0.93      0.95      0.94       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.94      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6223, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.561, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4271, Accuracy: 0.7956, F1 Micro: 0.7956, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.257, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1868, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.883\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8737\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8583\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1047, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8854\n",
      "Epoch 10/10, Train Loss: 0.0308, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8559\n",
      "\n",
      "Sentiment analysis accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.89      0.85        72\n",
      "    positive       0.95      0.90      0.92       153\n",
      "\n",
      "    accuracy                           0.90       225\n",
      "   macro avg       0.88      0.90      0.89       225\n",
      "weighted avg       0.90      0.90      0.90       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8273\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.91      0.99      0.95       167\n",
      "    positive       0.95      0.58      0.72        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.77      0.81       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.87      0.96      0.92       152\n",
      "    positive       0.83      0.58      0.68        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.77      0.73      0.75       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.78      0.77        23\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.85      0.83      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       1.00      0.59      0.74        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.74      0.83       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Total train time: 75.473219871521 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0014075053040869534\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 11.410805463790894 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5921, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5351, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.501, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.451, Accuracy: 0.808, F1 Micro: 0.891, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4154, Accuracy: 0.8668, F1 Micro: 0.9211, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3481, Accuracy: 0.9025, F1 Micro: 0.9406, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2857, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2222, Accuracy: 0.9368, F1 Micro: 0.9607, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1722, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1384, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9658\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.578, Accuracy: 0.6752, F1 Micro: 0.6752, F1 Macro: 0.4031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4373, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2738, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.92\n",
      "Epoch 4/10, Train Loss: 0.1453, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9077\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8706\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8902\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8831\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.9012\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8921\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9106\n",
      "\n",
      "Sentiment analysis accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90        76\n",
      "    positive       0.98      0.91      0.94       158\n",
      "\n",
      "    accuracy                           0.93       234\n",
      "   macro avg       0.91      0.94      0.92       234\n",
      "weighted avg       0.93      0.93      0.93       234\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.87\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       0.95      0.64      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.77      0.82       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.89      0.96      0.92       152\n",
      "    positive       0.84      0.62      0.71        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.78      0.78       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.94      0.71      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 78.86271166801453 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015592004638165236\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 11.100661993026733 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5794, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5306, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4968, Accuracy: 0.8036, F1 Micro: 0.8893, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4462, Accuracy: 0.84, F1 Micro: 0.9066, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3752, Accuracy: 0.9003, F1 Micro: 0.9397, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2981, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2238, Accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1765, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.135, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9686\n",
      "Epoch 10/10, Train Loss: 0.1153, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9667\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.99      0.96      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5951, Accuracy: 0.6944, F1 Micro: 0.6944, F1 Macro: 0.4221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3926, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8784\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "Epoch 5/10, Train Loss: 0.1089, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9015\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9084\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9133\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        78\n",
      "    positive       0.99      0.91      0.95       174\n",
      "\n",
      "    accuracy                           0.93       252\n",
      "   macro avg       0.91      0.94      0.92       252\n",
      "weighted avg       0.94      0.93      0.93       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8824\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.90      0.67      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.80      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.96      0.98       186\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.81      0.90      0.85       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 83.91508221626282 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0015031752409413457\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 10.392054557800293 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5232, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4858, Accuracy: 0.8125, F1 Micro: 0.8936, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4175, Accuracy: 0.8899, F1 Micro: 0.9342, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.332, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2447, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1863, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.144, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1119, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0889, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3454, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9377\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9288\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.893\n",
      "Epoch 8/10, Train Loss: 0.1217, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9011\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        81\n",
      "    positive       0.99      0.93      0.96       170\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.95      0.94       251\n",
      "weighted avg       0.95      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.907\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 94.21943831443787 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0013561213389039041\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.424079895019531 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5797, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5105, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4738, Accuracy: 0.8214, F1 Micro: 0.8979, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4087, Accuracy: 0.8988, F1 Micro: 0.9383, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3126, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2314, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.1836, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1375, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1072, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5395, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3055, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2383, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9353\n",
      "Epoch 4/10, Train Loss: 0.1774, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1802, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9395\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9353\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9284\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        84\n",
      "    positive       0.99      0.93      0.96       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9139\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.81      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 99.09622168540955 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0010341104120016097\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 8.653039693832397 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5735, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5395, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4709, Accuracy: 0.8222, F1 Micro: 0.8978, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3773, Accuracy: 0.9129, F1 Micro: 0.9463, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2964, Accuracy: 0.9249, F1 Micro: 0.9527, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2184, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1706, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.9688\n",
      "Epoch 8/10, Train Loss: 0.1218, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1048, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0888, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6122, Accuracy: 0.6923, F1 Micro: 0.6923, F1 Macro: 0.4625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3537, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8996\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9131\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9195\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9103\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9105\n",
      "Epoch 9/10, Train Loss: 0.075, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9109\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 96.15606999397278 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0007474470185115933\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 7.946946382522583 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5071, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4449, Accuracy: 0.8839, F1 Micro: 0.9307, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3492, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2434, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1879, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1444, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1187, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7769, F1 Micro: 0.7769, F1 Macro: 0.6821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3008, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Epoch 6/10, Train Loss: 0.1388, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9255\n",
      "Epoch 7/10, Train Loss: 0.13, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        83\n",
      "    positive       0.99      0.93      0.96       177\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.95      0.94       260\n",
      "weighted avg       0.95      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9071\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.96      0.67      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.06550216674805 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0005266224499791879\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.233517408370972 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5675, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5157, Accuracy: 0.8036, F1 Micro: 0.8891, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4354, Accuracy: 0.8824, F1 Micro: 0.93, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3319, Accuracy: 0.9353, F1 Micro: 0.96, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.246, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1852, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.139, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.1067, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0749, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5003, Accuracy: 0.8417, F1 Micro: 0.8417, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2164, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1654, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9207\n",
      "Epoch 7/10, Train Loss: 0.1083, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8858\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        83\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9106\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 100.88498425483704 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00045447262236848464\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 6.833533048629761 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5621, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4955, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.423, Accuracy: 0.9003, F1 Micro: 0.9399, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3086, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2192, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1671, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.1345, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.748, F1 Micro: 0.748, F1 Macro: 0.6131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2733, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2247, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9067\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1411, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9339\n",
      "Epoch 7/10, Train Loss: 0.1096, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9167\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9142\n",
      "Epoch 9/10, Train Loss: 0.1049, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9229\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        84\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9107\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      1.00      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.96156215667725 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00026285130297765136\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.346508979797363 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5608, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5029, Accuracy: 0.8162, F1 Micro: 0.8955, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3972, Accuracy: 0.904, F1 Micro: 0.942, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2072, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1556, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1171, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.94      1.00      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5047, Accuracy: 0.8443, F1 Micro: 0.8443, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2837, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9365\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9397\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9204\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9261\n",
      "Epoch 10/10, Train Loss: 0.0766, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8897\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        81\n",
      "    positive       0.96      0.96      0.96       163\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9055\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        23\n",
      "     neutral       0.94      1.00      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.47215557098389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00031338632106781006\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 5.612687587738037 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5545, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4781, Accuracy: 0.8199, F1 Micro: 0.8975, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3766, Accuracy: 0.9249, F1 Micro: 0.9536, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2662, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1927, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4783, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2561, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9172\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8954\n",
      "Epoch 4/10, Train Loss: 0.1701, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9172\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9141\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.911\n",
      "Epoch 8/10, Train Loss: 0.1038, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9116\n",
      "\n",
      "Sentiment analysis accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.94      0.89        84\n",
      "    positive       0.97      0.92      0.94       173\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.91      0.93      0.92       257\n",
      "weighted avg       0.93      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.52436518669128 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00022546340187545882\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.229524374008179 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5437, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4742, Accuracy: 0.8408, F1 Micro: 0.9077, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3623, Accuracy: 0.9323, F1 Micro: 0.9581, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2452, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1711, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.066, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2592, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.916\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9166\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9171\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        85\n",
      "    positive       0.96      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9157\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.16065812110901 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00015396359958685935\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.890037298202515 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5572, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4868, Accuracy: 0.8371, F1 Micro: 0.9061, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3439, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2408, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1294, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9785\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9568, F1 Micro: 0.9725, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5095, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.233, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1424, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.096, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9249\n",
      "Epoch 7/10, Train Loss: 0.0883, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       178\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.94       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9184\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.04191374778748 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00010382199980085716\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.417881727218628 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4641, Accuracy: 0.8571, F1 Micro: 0.9167, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3366, Accuracy: 0.9397, F1 Micro: 0.9625, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2292, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1586, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0544, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5069, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2122, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9395\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9114\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        85\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.94      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9167\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 117.66150712966919 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 5.561952821153682e-05\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.090154647827148 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5557, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4563, Accuracy: 0.8817, F1 Micro: 0.9298, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3245, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9606, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5026, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2417, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9332\n",
      "Epoch 5/10, Train Loss: 0.1453, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0885, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 7/10, Train Loss: 0.108, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        86\n",
      "    positive       0.97      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.94      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9192\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.14419031143188 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 4.9349546316079795e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.610199213027954 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5441, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4476, Accuracy: 0.8884, F1 Micro: 0.9335, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3063, Accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2023, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1076, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2251, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "Epoch 3/10, Train Loss: 0.1613, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1125, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9454\n",
      "Epoch 7/10, Train Loss: 0.0715, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9413\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9254\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.9454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       182\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.96      0.95       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9247\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.7336151599884 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 4.2176106944680214e-05\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.4437315464019775 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.439, Accuracy: 0.8921, F1 Micro: 0.9351, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2974, Accuracy: 0.9427, F1 Micro: 0.9646, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1968, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5286, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2344, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "Epoch 3/10, Train Loss: 0.1653, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8998\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       174\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.93      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9135\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.54844546318054 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.999147349735722e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.060375452041626 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4345, Accuracy: 0.9129, F1 Micro: 0.9467, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2785, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4814, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Epoch 8/10, Train Loss: 0.0562, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9444\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.9\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        86\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9294\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.883061170578 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 4.9484827468404536e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7213470935821533 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.527, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4231, Accuracy: 0.9174, F1 Micro: 0.9496, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2767, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1039, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4981, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2383, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9262\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9357\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9088\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.917\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9349\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "    positive       0.95      0.96      0.96       176\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.94      0.93      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9184\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.27732181549072 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 3.4360557037871365e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.249534845352173 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5378, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4115, Accuracy: 0.9115, F1 Micro: 0.9465, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2642, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4471, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2141, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9088\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9096\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8965\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        87\n",
      "    positive       0.99      0.92      0.96       173\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.95      0.94       260\n",
      "weighted avg       0.95      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9224\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.23606204986572 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 2.377079363213852e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9274682998657227 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.8028, F1 Micro: 0.8889, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4109, Accuracy: 0.9204, F1 Micro: 0.9512, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2515, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Epoch 6/10, Train Loss: 0.0922, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.433, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2227, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1611, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Epoch 5/10, Train Loss: 0.109, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Epoch 6/10, Train Loss: 0.1052, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9174\n",
      "Epoch 9/10, Train Loss: 0.0825, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9161\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "    positive       0.95      0.97      0.96       175\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9213\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.86      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.70710778236389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 1.6293237968056926e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3589231967926025 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5286, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4078, Accuracy: 0.9271, F1 Micro: 0.9554, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1693, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0854, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.489, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Epoch 2/10, Train Loss: 0.2191, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8914\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1345, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1108, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9223\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        84\n",
      "    positive       0.96      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.94       255\n",
      "   macro avg       0.93      0.94      0.93       255\n",
      "weighted avg       0.94      0.94      0.94       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.915\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.89      0.81      0.85        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.36517667770386 s\n",
      "Total runtime: 2804.2992684841156 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175447,
     "sourceId": 10843157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2845.793791,
   "end_time": "2025-03-25T05:29:00.980564",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-25T04:41:35.186773",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0da84b0aa1794c669d924b3d3b286945": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0f07fef078d3407496122355d80b4502": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f22a88b475f449dba90ff11af534ab1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13e40afe981645869d18eb3fc9dbb4cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ef5801397334b93a9fee36b6a82692b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25bd48509fd74fd4ba3d0c5c8c4c858f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "27ce3c346eb44e2abb3f8bf2b29684e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b8f27d74f7c4abb9cf5470ef280cfcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89051d212ed84876aed416a16830c76f",
       "placeholder": "​",
       "style": "IPY_MODEL_94aba9293a4d4a05bab0c68fa3a851f7",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 165B/s]"
      }
     },
     "2e664575546d40e680e88b4369519bf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4974f4e3404d4993963fbecfcf41331f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4eb3d82b075d4408bc33ebc37f7c7e16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a4a4f8765cd64b61a87e139c8c0991b4",
       "placeholder": "​",
       "style": "IPY_MODEL_ffc1a9660cbc4e278cf5e60fc243fc37",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.59MB/s]"
      }
     },
     "50115963fd8d4248acd174510bc65eaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51b71085fe584329840cbdd9c9157a42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57ab6042235a4b4e9c0a76ccfd49e84d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5ab71bb79c2140879eb114e81b7e9723": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "643d356e386747588a75269af6716c44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64a2f730ec014bee8302f03d6ddc867e",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4974f4e3404d4993963fbecfcf41331f",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "64a2f730ec014bee8302f03d6ddc867e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6691ec2a83ba4db9bf31f5391c7ff607": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_51b71085fe584329840cbdd9c9157a42",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_57ab6042235a4b4e9c0a76ccfd49e84d",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "6962cf7cc9e44ca090658a98024a1389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c417482d28b44086ae268fbf41f4ce6d",
        "IPY_MODEL_e7222c2bb9574149b757c069c73d8211",
        "IPY_MODEL_2b8f27d74f7c4abb9cf5470ef280cfcc"
       ],
       "layout": "IPY_MODEL_27ce3c346eb44e2abb3f8bf2b29684e2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "722b52af21c64aaba36c806cac2faf71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9c32b1bbea8a4eb2959ecf1aa8a27349",
        "IPY_MODEL_643d356e386747588a75269af6716c44",
        "IPY_MODEL_9079f7f3aaab4037abd5487268d92654"
       ],
       "layout": "IPY_MODEL_87c20b8ecd9242d486c82bc44b795dce",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7a10d98e7ad849ab987c389c0f5e307a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7b689cc7454c46ff9d4fda6814a02e5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e3bac63eae3c40b7967c98323ec34939",
        "IPY_MODEL_6691ec2a83ba4db9bf31f5391c7ff607",
        "IPY_MODEL_8b52c16a05e24cc9b302816f348766db"
       ],
       "layout": "IPY_MODEL_e5ccd6538da84e3892134a334939841d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "87c20b8ecd9242d486c82bc44b795dce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89051d212ed84876aed416a16830c76f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b52c16a05e24cc9b302816f348766db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1ef5801397334b93a9fee36b6a82692b",
       "placeholder": "​",
       "style": "IPY_MODEL_df07b1cd5b554b31b664ce24a6e50707",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.9kB/s]"
      }
     },
     "9079f7f3aaab4037abd5487268d92654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7ba74857bbf4d0f93cb6b9fbcef8863",
       "placeholder": "​",
       "style": "IPY_MODEL_fcc939c7c2fc4019a6c788a0a6c95272",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 154kB/s]"
      }
     },
     "9112012d8f7b4bbd8fc12e2d877e3e3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e9e4f77be3e9440488379c325af1aed1",
        "IPY_MODEL_a0f48581b96c4daca5f5002fa960382d",
        "IPY_MODEL_4eb3d82b075d4408bc33ebc37f7c7e16"
       ],
       "layout": "IPY_MODEL_d1168b04599b4a158d49476419b2f1aa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "94aba9293a4d4a05bab0c68fa3a851f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "97619e73d8904a3aa639d08bbd446466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9c32b1bbea8a4eb2959ecf1aa8a27349": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f07fef078d3407496122355d80b4502",
       "placeholder": "​",
       "style": "IPY_MODEL_7a10d98e7ad849ab987c389c0f5e307a",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "a0f48581b96c4daca5f5002fa960382d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bccc42e2c3ab4ac0bdca10a725554c04",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ccd3c9f708454696bc19d12c062858f1",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "a4a4f8765cd64b61a87e139c8c0991b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7ba74857bbf4d0f93cb6b9fbcef8863": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bccc42e2c3ab4ac0bdca10a725554c04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c417482d28b44086ae268fbf41f4ce6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2e664575546d40e680e88b4369519bf3",
       "placeholder": "​",
       "style": "IPY_MODEL_97619e73d8904a3aa639d08bbd446466",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "ccd3c9f708454696bc19d12c062858f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d1168b04599b4a158d49476419b2f1aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df07b1cd5b554b31b664ce24a6e50707": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e3bac63eae3c40b7967c98323ec34939": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13e40afe981645869d18eb3fc9dbb4cf",
       "placeholder": "​",
       "style": "IPY_MODEL_25bd48509fd74fd4ba3d0c5c8c4c858f",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "e5ccd6538da84e3892134a334939841d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7222c2bb9574149b757c069c73d8211": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f22a88b475f449dba90ff11af534ab1",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_50115963fd8d4248acd174510bc65eaa",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "e9e4f77be3e9440488379c325af1aed1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5ab71bb79c2140879eb114e81b7e9723",
       "placeholder": "​",
       "style": "IPY_MODEL_0da84b0aa1794c669d924b3d3b286945",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "fcc939c7c2fc4019a6c788a0a6c95272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ffc1a9660cbc4e278cf5e60fc243fc37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
