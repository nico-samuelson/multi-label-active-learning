{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec329c1",
   "metadata": {
    "papermill": {
     "duration": 0.011702,
     "end_time": "2025-03-29T04:18:30.409880",
     "exception": false,
     "start_time": "2025-03-29T04:18:30.398178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5193a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:30.433387Z",
     "iopub.status.busy": "2025-03-29T04:18:30.433122Z",
     "iopub.status.idle": "2025-03-29T04:18:56.195382Z",
     "shell.execute_reply": "2025-03-29T04:18:56.194467Z"
    },
    "papermill": {
     "duration": 25.775718,
     "end_time": "2025-03-29T04:18:56.197050",
     "exception": false,
     "start_time": "2025-03-29T04:18:30.421332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37965498",
   "metadata": {
    "papermill": {
     "duration": 0.010845,
     "end_time": "2025-03-29T04:18:56.219420",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.208575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22055f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.242244Z",
     "iopub.status.busy": "2025-03-29T04:18:56.241763Z",
     "iopub.status.idle": "2025-03-29T04:18:56.245176Z",
     "shell.execute_reply": "2025-03-29T04:18:56.244410Z"
    },
    "papermill": {
     "duration": 0.016142,
     "end_time": "2025-03-29T04:18:56.246553",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.230411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561ede68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.269350Z",
     "iopub.status.busy": "2025-03-29T04:18:56.269082Z",
     "iopub.status.idle": "2025-03-29T04:18:56.272883Z",
     "shell.execute_reply": "2025-03-29T04:18:56.272098Z"
    },
    "papermill": {
     "duration": 0.016685,
     "end_time": "2025-03-29T04:18:56.274153",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.257468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367750f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.296939Z",
     "iopub.status.busy": "2025-03-29T04:18:56.296742Z",
     "iopub.status.idle": "2025-03-29T04:18:56.305868Z",
     "shell.execute_reply": "2025-03-29T04:18:56.305312Z"
    },
    "papermill": {
     "duration": 0.021313,
     "end_time": "2025-03-29T04:18:56.306981",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.285668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8ed8c",
   "metadata": {
    "papermill": {
     "duration": 0.010904,
     "end_time": "2025-03-29T04:18:56.328795",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.317891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eca895c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.352091Z",
     "iopub.status.busy": "2025-03-29T04:18:56.351876Z",
     "iopub.status.idle": "2025-03-29T04:18:56.414771Z",
     "shell.execute_reply": "2025-03-29T04:18:56.413238Z"
    },
    "papermill": {
     "duration": 0.076742,
     "end_time": "2025-03-29T04:18:56.416847",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.340105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-random'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a649658",
   "metadata": {
    "papermill": {
     "duration": 0.011267,
     "end_time": "2025-03-29T04:18:56.439884",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.428617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3009a848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.466216Z",
     "iopub.status.busy": "2025-03-29T04:18:56.465960Z",
     "iopub.status.idle": "2025-03-29T04:18:56.544662Z",
     "shell.execute_reply": "2025-03-29T04:18:56.543793Z"
    },
    "papermill": {
     "duration": 0.093024,
     "end_time": "2025-03-29T04:18:56.545987",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.452963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727a5e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.569098Z",
     "iopub.status.busy": "2025-03-29T04:18:56.568876Z",
     "iopub.status.idle": "2025-03-29T04:18:56.577004Z",
     "shell.execute_reply": "2025-03-29T04:18:56.576407Z"
    },
    "papermill": {
     "duration": 0.020956,
     "end_time": "2025-03-29T04:18:56.578267",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.557311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb51863c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.601246Z",
     "iopub.status.busy": "2025-03-29T04:18:56.601024Z",
     "iopub.status.idle": "2025-03-29T04:18:56.613821Z",
     "shell.execute_reply": "2025-03-29T04:18:56.613127Z"
    },
    "papermill": {
     "duration": 0.02587,
     "end_time": "2025-03-29T04:18:56.615148",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.589278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b804a",
   "metadata": {
    "papermill": {
     "duration": 0.010848,
     "end_time": "2025-03-29T04:18:56.637964",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.627116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b8c72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.660849Z",
     "iopub.status.busy": "2025-03-29T04:18:56.660617Z",
     "iopub.status.idle": "2025-03-29T04:18:56.666199Z",
     "shell.execute_reply": "2025-03-29T04:18:56.665621Z"
    },
    "papermill": {
     "duration": 0.018406,
     "end_time": "2025-03-29T04:18:56.667455",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.649049",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39394de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.690274Z",
     "iopub.status.busy": "2025-03-29T04:18:56.690043Z",
     "iopub.status.idle": "2025-03-29T04:18:56.696890Z",
     "shell.execute_reply": "2025-03-29T04:18:56.696093Z"
    },
    "papermill": {
     "duration": 0.019608,
     "end_time": "2025-03-29T04:18:56.698081",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.678473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94572e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:56.722106Z",
     "iopub.status.busy": "2025-03-29T04:18:56.721884Z",
     "iopub.status.idle": "2025-03-29T04:18:57.933306Z",
     "shell.execute_reply": "2025-03-29T04:18:57.932320Z"
    },
    "papermill": {
     "duration": 1.225737,
     "end_time": "2025-03-29T04:18:57.934999",
     "exception": false,
     "start_time": "2025-03-29T04:18:56.709262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb90d3ae0294bb6b5549b4b7e6de5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd89fa61b324133a2886db8c3c8bbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994d5145a7ab4c52b0002ddcba445ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f097eda218b4cffbe6f1f32738b7845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b6131b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:57.968915Z",
     "iopub.status.busy": "2025-03-29T04:18:57.968592Z",
     "iopub.status.idle": "2025-03-29T04:18:57.973322Z",
     "shell.execute_reply": "2025-03-29T04:18:57.972642Z"
    },
    "papermill": {
     "duration": 0.019641,
     "end_time": "2025-03-29T04:18:57.974688",
     "exception": false,
     "start_time": "2025-03-29T04:18:57.955047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6285cdd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.000461Z",
     "iopub.status.busy": "2025-03-29T04:18:58.000115Z",
     "iopub.status.idle": "2025-03-29T04:18:58.011016Z",
     "shell.execute_reply": "2025-03-29T04:18:58.010334Z"
    },
    "papermill": {
     "duration": 0.025346,
     "end_time": "2025-03-29T04:18:58.012425",
     "exception": false,
     "start_time": "2025-03-29T04:18:57.987079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc1ead",
   "metadata": {
    "papermill": {
     "duration": 0.011743,
     "end_time": "2025-03-29T04:18:58.036314",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.024571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1688ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.061579Z",
     "iopub.status.busy": "2025-03-29T04:18:58.061224Z",
     "iopub.status.idle": "2025-03-29T04:18:58.065194Z",
     "shell.execute_reply": "2025-03-29T04:18:58.064474Z"
    },
    "papermill": {
     "duration": 0.017683,
     "end_time": "2025-03-29T04:18:58.066340",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.048657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bf03c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.090781Z",
     "iopub.status.busy": "2025-03-29T04:18:58.090494Z",
     "iopub.status.idle": "2025-03-29T04:18:58.095421Z",
     "shell.execute_reply": "2025-03-29T04:18:58.094691Z"
    },
    "papermill": {
     "duration": 0.018532,
     "end_time": "2025-03-29T04:18:58.096622",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.078090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d658bd9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.121597Z",
     "iopub.status.busy": "2025-03-29T04:18:58.121250Z",
     "iopub.status.idle": "2025-03-29T04:18:58.128126Z",
     "shell.execute_reply": "2025-03-29T04:18:58.127252Z"
    },
    "papermill": {
     "duration": 0.020921,
     "end_time": "2025-03-29T04:18:58.129494",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.108573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "475fa1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.155004Z",
     "iopub.status.busy": "2025-03-29T04:18:58.154710Z",
     "iopub.status.idle": "2025-03-29T04:18:58.181801Z",
     "shell.execute_reply": "2025-03-29T04:18:58.181040Z"
    },
    "papermill": {
     "duration": 0.041539,
     "end_time": "2025-03-29T04:18:58.183254",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.141715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465baa9c",
   "metadata": {
    "papermill": {
     "duration": 0.011602,
     "end_time": "2025-03-29T04:18:58.207525",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.195923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c6aaf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.232236Z",
     "iopub.status.busy": "2025-03-29T04:18:58.231929Z",
     "iopub.status.idle": "2025-03-29T04:18:58.237721Z",
     "shell.execute_reply": "2025-03-29T04:18:58.236990Z"
    },
    "papermill": {
     "duration": 0.019618,
     "end_time": "2025-03-29T04:18:58.239008",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.219390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02d4a0",
   "metadata": {
    "papermill": {
     "duration": 0.011973,
     "end_time": "2025-03-29T04:18:58.263315",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.251342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8a9a5e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.288777Z",
     "iopub.status.busy": "2025-03-29T04:18:58.288449Z",
     "iopub.status.idle": "2025-03-29T04:18:58.296217Z",
     "shell.execute_reply": "2025-03-29T04:18:58.295316Z"
    },
    "papermill": {
     "duration": 0.022169,
     "end_time": "2025-03-29T04:18:58.297597",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.275428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_sampling(current_train_size, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    nearest_cp = 0\n",
    "    arrived_at_cp = False\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "\n",
    "    num_of_candidates = math.ceil(0.1 * len(remaining_indices))\n",
    "\n",
    "    if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "        num_of_candidates = n_samples\n",
    "    elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "        num_of_candidates = max(n_samples, num_of_candidates)\n",
    "    else:\n",
    "        num_of_candidates = nearest_cp - current_train_size\n",
    "        arrived_at_cp = True\n",
    "\n",
    "    random_indices = random.sample(range(len(X_pool)), num_of_candidates)\n",
    "\n",
    "    if arrived_at_cp:\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend([remaining_indices[i] for i in random_indices])\n",
    "            \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'fuel': [y_train[i][0] for i in temp],\n",
    "            'machine': [y_train[i][1] for i in temp],\n",
    "            'others': [y_train[i][2] for i in temp],\n",
    "            'part': [y_train[i][3] for i in temp],\n",
    "            'price': [y_train[i][4] for i in temp],\n",
    "            'service': [y_train[i][5] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "    end_time = time.time() \n",
    "    duration = end_time - start_time\n",
    "\n",
    "    sampling_dur.append(duration)\n",
    "    for i in random_indices:\n",
    "        new_samples.append(remaining_indices[i])\n",
    "        \n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Acquired samples:\", len(random_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e24387",
   "metadata": {
    "papermill": {
     "duration": 0.011808,
     "end_time": "2025-03-29T04:18:58.321540",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.309732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f890e5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.347126Z",
     "iopub.status.busy": "2025-03-29T04:18:58.346803Z",
     "iopub.status.idle": "2025-03-29T04:18:58.356948Z",
     "shell.execute_reply": "2025-03-29T04:18:58.356001Z"
    },
    "papermill": {
     "duration": 0.024476,
     "end_time": "2025-03-29T04:18:58.358398",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.333922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        random_sampling(\n",
    "            current_train_size, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e15567c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.384509Z",
     "iopub.status.busy": "2025-03-29T04:18:58.384144Z",
     "iopub.status.idle": "2025-03-29T04:18:58.387587Z",
     "shell.execute_reply": "2025-03-29T04:18:58.386870Z"
    },
    "papermill": {
     "duration": 0.017928,
     "end_time": "2025-03-29T04:18:58.388961",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.371033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68b5a5",
   "metadata": {
    "papermill": {
     "duration": 0.011623,
     "end_time": "2025-03-29T04:18:58.412772",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.401149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95da011e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T04:18:58.437894Z",
     "iopub.status.busy": "2025-03-29T04:18:58.437597Z",
     "iopub.status.idle": "2025-03-29T05:02:12.843317Z",
     "shell.execute_reply": "2025-03-29T05:02:12.842327Z"
    },
    "papermill": {
     "duration": 2594.420091,
     "end_time": "2025-03-29T05:02:12.844927",
     "exception": false,
     "start_time": "2025-03-29T04:18:58.424836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.3199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.13      0.22        23\n",
      "     neutral       0.74      0.98      0.84       152\n",
      "    positive       0.60      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.70      0.42      0.43       216\n",
      "weighted avg       0.71      0.73      0.66       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 51.41648197174072 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 0.00021076202392578125 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425275665dde42f2b9284a4907bf6052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6145, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.527, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Epoch 3/10, Train Loss: 0.5011, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4653, Accuracy: 0.7976, F1 Micro: 0.8862, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4397, Accuracy: 0.8006, F1 Micro: 0.8874, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4048, Accuracy: 0.8088, F1 Micro: 0.8912, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.382, Accuracy: 0.8274, F1 Micro: 0.9004, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3359, Accuracy: 0.8438, F1 Micro: 0.9084, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3035, Accuracy: 0.8631, F1 Micro: 0.9189, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2645, Accuracy: 0.8832, F1 Micro: 0.9292, F1 Macro: 0.927\n",
      "\n",
      "Aspect detection accuracy: 0.8832, F1 Micro: 0.9292, F1 Macro: 0.927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.87      1.00      0.93       187\n",
      "     machine       0.87      0.98      0.92       175\n",
      "      others       0.85      0.94      0.89       158\n",
      "        part       0.87      0.91      0.89       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.93      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.89      0.97      0.93      1061\n",
      "   macro avg       0.89      0.97      0.93      1061\n",
      "weighted avg       0.89      0.97      0.93      1061\n",
      " samples avg       0.89      0.97      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6382, Accuracy: 0.7135, F1 Micro: 0.7135, F1 Macro: 0.4164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5829, Accuracy: 0.7191, F1 Micro: 0.7191, F1 Macro: 0.437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4985, Accuracy: 0.882, F1 Micro: 0.882, F1 Macro: 0.8566\n",
      "Epoch 4/10, Train Loss: 0.3899, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.8095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.882, F1 Micro: 0.882, F1 Macro: 0.8639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1926, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0942, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8987\n",
      "\n",
      "Sentiment analysis accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.86        51\n",
      "    positive       0.95      0.93      0.94       127\n",
      "\n",
      "    accuracy                           0.92       178\n",
      "   macro avg       0.89      0.91      0.90       178\n",
      "weighted avg       0.92      0.92      0.92       178\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.6975\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.18      0.31        11\n",
      "     neutral       0.87      1.00      0.93       181\n",
      "    positive       0.80      0.17      0.28        24\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.89      0.45      0.50       216\n",
      "weighted avg       0.87      0.87      0.82       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.55        16\n",
      "     neutral       0.87      0.98      0.92       167\n",
      "    positive       0.82      0.55      0.65        33\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.90      0.63      0.71       216\n",
      "weighted avg       0.87      0.87      0.85       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.85      0.93      0.89       152\n",
      "    positive       0.74      0.48      0.58        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.74      0.72      0.72       216\n",
      "weighted avg       0.81      0.81      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.65      0.71        23\n",
      "     neutral       0.87      0.91      0.89       152\n",
      "    positive       0.63      0.59      0.61        41\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.76      0.72      0.74       216\n",
      "weighted avg       0.81      0.82      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.46      0.63        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.74      0.80       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        14\n",
      "     neutral       0.93      1.00      0.96       185\n",
      "    positive       0.78      0.41      0.54        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.64      0.72       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Total train time: 71.39136004447937 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 0.00011706352233886719 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6067, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5114, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4724, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.457, Accuracy: 0.8155, F1 Micro: 0.8951, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.407, Accuracy: 0.8475, F1 Micro: 0.9109, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3598, Accuracy: 0.8638, F1 Micro: 0.9188, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3055, Accuracy: 0.901, F1 Micro: 0.9402, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2536, Accuracy: 0.9219, F1 Micro: 0.9515, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.207, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1829, Accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.955\n",
      "\n",
      "Aspect detection accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.86      0.87       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6095, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5637, Accuracy: 0.834, F1 Micro: 0.834, F1 Macro: 0.7729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4015, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2282, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9252\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.918\n",
      "Epoch 6/10, Train Loss: 0.1389, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9135\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9162\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9135\n",
      "Epoch 9/10, Train Loss: 0.0857, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9001\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.918\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        74\n",
      "    positive       0.99      0.92      0.95       167\n",
      "\n",
      "    accuracy                           0.93       241\n",
      "   macro avg       0.91      0.94      0.93       241\n",
      "weighted avg       0.94      0.93      0.93       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.854\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.98       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.88      0.86      0.87       152\n",
      "    positive       0.61      0.58      0.59        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.68      0.76      0.71       216\n",
      "weighted avg       0.80      0.79      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.93      0.68      0.79        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.79      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.83      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 74.36257529258728 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 0.00011324882507324219 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5892, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4962, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4736, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.408, Accuracy: 0.8333, F1 Micro: 0.9035, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3655, Accuracy: 0.8772, F1 Micro: 0.9269, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3006, Accuracy: 0.9226, F1 Micro: 0.9523, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2398, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1865, Accuracy: 0.9397, F1 Micro: 0.9625, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1609, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9644\n",
      "Epoch 10/10, Train Loss: 0.144, Accuracy: 0.9412, F1 Micro: 0.9631, F1 Macro: 0.9602\n",
      "\n",
      "Aspect detection accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.85      0.95      0.90       158\n",
      "        part       0.95      0.98      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5839, Accuracy: 0.6652, F1 Micro: 0.6652, F1 Macro: 0.3995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4649, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2958, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1368, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9233\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9229\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9162\n",
      "Epoch 8/10, Train Loss: 0.0461, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9348, F1 Micro: 0.9348, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9348, F1 Micro: 0.9348, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        77\n",
      "    positive       0.94      0.96      0.95       153\n",
      "\n",
      "    accuracy                           0.93       230\n",
      "   macro avg       0.93      0.92      0.93       230\n",
      "weighted avg       0.93      0.93      0.93       230\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.8678\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.85      0.95      0.90       152\n",
      "    positive       0.81      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.85      0.73      0.78       216\n",
      "weighted avg       0.84      0.85      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.95      0.98      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 82.92715716362 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 0.00010991096496582031 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.579, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.484, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4641, Accuracy: 0.8222, F1 Micro: 0.8984, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3896, Accuracy: 0.8765, F1 Micro: 0.9267, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3223, Accuracy: 0.9129, F1 Micro: 0.947, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2416, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1972, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1536, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1252, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9677\n",
      "Epoch 10/10, Train Loss: 0.1038, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.9643\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.93      0.91       158\n",
      "        part       0.94      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5544, Accuracy: 0.6765, F1 Micro: 0.6765, F1 Macro: 0.4157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4017, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9085\n",
      "Epoch 4/10, Train Loss: 0.1864, Accuracy: 0.8866, F1 Micro: 0.8866, F1 Macro: 0.8774\n",
      "Epoch 5/10, Train Loss: 0.1141, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1306, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9192\n",
      "Epoch 7/10, Train Loss: 0.1001, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9033\n",
      "Epoch 8/10, Train Loss: 0.1211, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0877, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9337\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        78\n",
      "    positive       0.96      0.95      0.96       160\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.93      0.94      0.93       238\n",
      "weighted avg       0.94      0.94      0.94       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8869\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.80      0.71      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.82      0.80      0.81       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 86.16461992263794 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 0.00010395050048828125 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5592, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Epoch 2/10, Train Loss: 0.4927, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4358, Accuracy: 0.8423, F1 Micro: 0.9089, F1 Macro: 0.9082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.34, Accuracy: 0.9189, F1 Micro: 0.9501, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2715, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1913, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1527, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1213, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Epoch 10/10, Train Loss: 0.0876, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.94      0.99      0.96       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5875, Accuracy: 0.7166, F1 Micro: 0.7166, F1 Macro: 0.5402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3365, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9113\n",
      "Epoch 3/10, Train Loss: 0.1423, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.894\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8976\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9069\n",
      "Epoch 7/10, Train Loss: 0.117, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.9066\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.9033\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9029\n",
      "Epoch 10/10, Train Loss: 0.0805, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.905\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        81\n",
      "    positive       0.93      0.95      0.94       166\n",
      "\n",
      "    accuracy                           0.92       247\n",
      "   macro avg       0.91      0.90      0.91       247\n",
      "weighted avg       0.92      0.92      0.92       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8801\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.86      0.73      0.79        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.83      0.86       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 87.53356623649597 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 0.00010323524475097656 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5601, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4909, Accuracy: 0.8103, F1 Micro: 0.8923, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4126, Accuracy: 0.8698, F1 Micro: 0.9224, F1 Macro: 0.9211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3191, Accuracy: 0.9338, F1 Micro: 0.9591, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2388, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1761, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1401, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9705\n",
      "Epoch 8/10, Train Loss: 0.114, Accuracy: 0.9494, F1 Micro: 0.9681, F1 Macro: 0.965\n",
      "Epoch 9/10, Train Loss: 0.0949, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.8106, F1 Micro: 0.8106, F1 Macro: 0.75\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3106, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1981, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9143\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.931\n",
      "Epoch 7/10, Train Loss: 0.1217, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9043\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0799, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9314\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        83\n",
      "    positive       0.98      0.93      0.95       181\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9063\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.84      0.82       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 94.22147274017334 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 0.00010323524475097656 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5518, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4772, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.394, Accuracy: 0.9092, F1 Micro: 0.9447, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3123, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2126, Accuracy: 0.9435, F1 Micro: 0.9646, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1719, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9683\n",
      "Epoch 7/10, Train Loss: 0.1267, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1118, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5469, Accuracy: 0.7952, F1 Micro: 0.7952, F1 Macro: 0.7247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2594, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.175, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9075\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9012\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0934, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9091\n",
      "Epoch 7/10, Train Loss: 0.0783, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9033\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9048\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.9007\n",
      "Epoch 10/10, Train Loss: 0.0683, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9006\n",
      "\n",
      "Sentiment analysis accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        82\n",
      "    positive       0.94      0.94      0.94       167\n",
      "\n",
      "    accuracy                           0.92       249\n",
      "   macro avg       0.91      0.91      0.91       249\n",
      "weighted avg       0.92      0.92      0.92       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8854\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.94      0.92       152\n",
      "    positive       0.84      0.71      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.80      0.80       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.61251759529114 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.489059448242188e-05 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5432, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4579, Accuracy: 0.8155, F1 Micro: 0.8951, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3783, Accuracy: 0.9256, F1 Micro: 0.9543, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2587, Accuracy: 0.9449, F1 Micro: 0.966, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1994, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1431, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.555, Accuracy: 0.8047, F1 Micro: 0.8047, F1 Macro: 0.7396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2635, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 5/10, Train Loss: 0.0962, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Epoch 6/10, Train Loss: 0.1241, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "\n",
      "Sentiment analysis accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.95       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9196\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 101.96011543273926 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 0.016658544540405273 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5493, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4626, Accuracy: 0.8259, F1 Micro: 0.9005, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3771, Accuracy: 0.9196, F1 Micro: 0.9509, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2775, Accuracy: 0.936, F1 Micro: 0.9598, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.199, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1481, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0957, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0839, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0683, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.534, Accuracy: 0.8327, F1 Micro: 0.8327, F1 Macro: 0.7976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2944, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9279\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1318, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9416\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.913\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9465\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9425\n",
      "Epoch 10/10, Train Loss: 0.0833, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9297\n",
      "\n",
      "Sentiment analysis accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       161\n",
      "\n",
      "    accuracy                           0.95       245\n",
      "   macro avg       0.94      0.95      0.95       245\n",
      "weighted avg       0.95      0.95      0.95       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9217\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.58361268043518 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 0.00010013580322265625 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.463, Accuracy: 0.8266, F1 Micro: 0.9008, F1 Macro: 0.9002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3585, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2503, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1727, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 6/10, Train Loss: 0.1354, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 10/10, Train Loss: 0.0598, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5136, Accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2768, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1256, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1146, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9127\n",
      "Epoch 8/10, Train Loss: 0.0992, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9069\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9244\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.50491738319397 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 0.00015282630920410156 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4486, Accuracy: 0.8616, F1 Micro: 0.9189, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3427, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2336, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1797, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1075, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 9/10, Train Loss: 0.074, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5653, Accuracy: 0.8167, F1 Micro: 0.8167, F1 Macro: 0.7537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2417, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1297, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0989, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9388\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.919\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9185\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.91\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        83\n",
      "    positive       0.96      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.94      0.94       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9158\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 106.16848587989807 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 8.702278137207031e-05 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5497, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4742, Accuracy: 0.8452, F1 Micro: 0.9103, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3419, Accuracy: 0.9271, F1 Micro: 0.955, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2424, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1646, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1236, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 7/10, Train Loss: 0.1001, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0588, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5052, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8907\n",
      "Epoch 2/10, Train Loss: 0.2354, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1289, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 4/10, Train Loss: 0.1355, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.0913, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9201\n",
      "\n",
      "Sentiment analysis accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.95      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9244\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.11022567749023 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 0.006467580795288086 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5281, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.445, Accuracy: 0.875, F1 Micro: 0.9251, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3158, Accuracy: 0.9397, F1 Micro: 0.9621, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2182, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1527, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.487, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2192, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1536, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Epoch 9/10, Train Loss: 0.0876, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9079\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9205\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.42993688583374 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.869171142578125e-05 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5513, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4411, Accuracy: 0.8876, F1 Micro: 0.933, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.301, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2089, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1536, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 6/10, Train Loss: 0.1169, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9819\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.97      0.96       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4978, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2481, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.904\n",
      "Epoch 4/10, Train Loss: 0.1301, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9106\n",
      "Epoch 5/10, Train Loss: 0.1124, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8917\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9075\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8961\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        85\n",
      "    positive       0.99      0.92      0.96       173\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.95      0.94       258\n",
      "weighted avg       0.95      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9267\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.97      0.96       152\n",
      "    positive       0.93      0.81      0.87        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.02886700630188 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.00011038780212402344 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5383, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4357, Accuracy: 0.8787, F1 Micro: 0.928, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3059, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2025, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9802\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5206, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1557, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9166\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1275, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9333\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 9/10, Train Loss: 0.0804, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9068\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        86\n",
      "    positive       0.98      0.93      0.95       181\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.92      0.95      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9212\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.44388771057129 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.250640869140625e-05 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5425, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4336, Accuracy: 0.8862, F1 Micro: 0.9318, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2927, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1929, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0859, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.91      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5221, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2381, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1084, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9342\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9138\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9085\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9074\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9114\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8985\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9283\n",
      "\n",
      "Sentiment analysis accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.91        86\n",
      "    positive       0.99      0.92      0.96       185\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.92      0.95      0.93       271\n",
      "weighted avg       0.95      0.94      0.94       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9207\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.88      0.84       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.16630387306213 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.463859558105469e-05 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5336, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4132, Accuracy: 0.9182, F1 Micro: 0.9505, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2703, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1772, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0793, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0672, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4768, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2425, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 3/10, Train Loss: 0.1466, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 6/10, Train Loss: 0.0967, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9298\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.927\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8912\n",
      "Epoch 9/10, Train Loss: 0.0738, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        87\n",
      "    positive       0.97      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.925\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.79      0.87      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.67167949676514 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.006763458251953125 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4272, Accuracy: 0.8966, F1 Micro: 0.9378, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2723, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4965, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2236, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2011, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9204\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0992, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 7/10, Train Loss: 0.0856, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9125\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9305\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9085\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       179\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9201\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.24571371078491 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.392333984375e-05 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4236, Accuracy: 0.9152, F1 Micro: 0.9477, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2744, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1773, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4488, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2548, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 4/10, Train Loss: 0.1207, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9132\n",
      "Epoch 5/10, Train Loss: 0.0964, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8981\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9319\n",
      "Epoch 7/10, Train Loss: 0.0662, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Epoch 8/10, Train Loss: 0.0633, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9149\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9194\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9207\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9235\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.25491404533386 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.416175842285156e-05 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5282, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4041, Accuracy: 0.9263, F1 Micro: 0.9551, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2579, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 5/10, Train Loss: 0.1147, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0512, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4325, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1962, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1151, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1468, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0974, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9215\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9161\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "\n",
      "Sentiment analysis accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       177\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.95      0.96      0.95       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9286\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.86      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.43129110336304 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.225440979003906e-05 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5288, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3977, Accuracy: 0.9211, F1 Micro: 0.9521, F1 Macro: 0.9505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2561, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1735, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 8/10, Train Loss: 0.0669, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.95      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.457, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 2/10, Train Loss: 0.2136, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 3/10, Train Loss: 0.1298, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 6/10, Train Loss: 0.1407, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        85\n",
      "    positive       0.97      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9188\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.95      0.94      0.95       152\n",
      "    positive       0.81      0.85      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.68195867538452 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.106231689453125e-05 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5177, Accuracy: 0.8036, F1 Micro: 0.8893, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3837, Accuracy: 0.9368, F1 Micro: 0.961, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2495, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 6/10, Train Loss: 0.0899, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.0789, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0511, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4762, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1637, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Epoch 3/10, Train Loss: 0.1522, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1242, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9271\n",
      "Epoch 6/10, Train Loss: 0.0805, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9113\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9226\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.86      0.83      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.02385520935059 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.007424831390380859 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.523, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3879, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2426, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 7/10, Train Loss: 0.0765, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9732, F1 Micro: 0.9832, F1 Macro: 0.9823\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "\n",
      "Aspect detection accuracy: 0.9732, F1 Micro: 0.9832, F1 Macro: 0.9823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.98      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4531, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.243, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1504, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 4/10, Train Loss: 0.1056, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1206, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9442\n",
      "Epoch 6/10, Train Loss: 0.0754, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9333\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9653, F1 Micro: 0.9653, F1 Macro: 0.9304\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.64624977111816 s\n",
      "Total runtime: 2593.480860710144 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b481c99",
   "metadata": {
    "papermill": {
     "duration": 0.130782,
     "end_time": "2025-03-29T05:02:13.110047",
     "exception": false,
     "start_time": "2025-03-29T05:02:12.979265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b10e2cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:02:13.418102Z",
     "iopub.status.busy": "2025-03-29T05:02:13.417772Z",
     "iopub.status.idle": "2025-03-29T05:45:37.062167Z",
     "shell.execute_reply": "2025-03-29T05:45:37.061171Z"
    },
    "papermill": {
     "duration": 2603.780192,
     "end_time": "2025-03-29T05:45:37.063804",
     "exception": false,
     "start_time": "2025-03-29T05:02:13.283612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 57.04911732673645 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 0.00013899803161621094 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.613, Accuracy: 0.7932, F1 Micro: 0.8831, F1 Macro: 0.881\n",
      "Epoch 2/10, Train Loss: 0.5142, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.5203, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4604, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4419, Accuracy: 0.8013, F1 Micro: 0.8881, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3975, Accuracy: 0.8244, F1 Micro: 0.8992, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3614, Accuracy: 0.8743, F1 Micro: 0.9253, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3128, Accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2722, Accuracy: 0.9174, F1 Micro: 0.9492, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2322, Accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.951\n",
      "\n",
      "Aspect detection accuracy: 0.9241, F1 Micro: 0.9531, F1 Macro: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.89      0.94      0.91       158\n",
      "        part       0.88      0.94      0.91       158\n",
      "       price       0.94      0.99      0.97       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.95      1061\n",
      " samples avg       0.93      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5932, Accuracy: 0.6968, F1 Micro: 0.6968, F1 Macro: 0.4107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5525, Accuracy: 0.6968, F1 Micro: 0.6968, F1 Macro: 0.4107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4473, Accuracy: 0.6968, F1 Micro: 0.6968, F1 Macro: 0.4107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4084, Accuracy: 0.6968, F1 Micro: 0.6968, F1 Macro: 0.4107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2759, Accuracy: 0.7511, F1 Micro: 0.7511, F1 Macro: 0.6195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2567, Accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8318\n",
      "Epoch 7/10, Train Loss: 0.1806, Accuracy: 0.8552, F1 Micro: 0.8552, F1 Macro: 0.8189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.212, Accuracy: 0.8778, F1 Micro: 0.8778, F1 Macro: 0.8548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0847, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8929\n",
      "\n",
      "Sentiment analysis accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        67\n",
      "    positive       0.94      0.94      0.94       154\n",
      "\n",
      "    accuracy                           0.91       221\n",
      "   macro avg       0.89      0.89      0.89       221\n",
      "weighted avg       0.91      0.91      0.91       221\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8139\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.93      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.80      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.85      0.63      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.78      0.77       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.43      0.54        23\n",
      "     neutral       0.88      0.93      0.90       152\n",
      "    positive       0.72      0.71      0.72        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.69      0.72       216\n",
      "weighted avg       0.83      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.94      0.99      0.97       186\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.71      0.78       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.75      0.81       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 69.46449613571167 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 0.00011205673217773438 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6039, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5116, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4975, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4419, Accuracy: 0.8065, F1 Micro: 0.8907, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3977, Accuracy: 0.8661, F1 Micro: 0.9212, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3165, Accuracy: 0.904, F1 Micro: 0.9413, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2683, Accuracy: 0.9219, F1 Micro: 0.9521, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.234, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9605\n",
      "Epoch 9/10, Train Loss: 0.1898, Accuracy: 0.9382, F1 Micro: 0.9618, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1588, Accuracy: 0.939, F1 Micro: 0.9623, F1 Macro: 0.9605\n",
      "\n",
      "Aspect detection accuracy: 0.939, F1 Micro: 0.9623, F1 Macro: 0.9605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.87      0.93      0.90       158\n",
      "        part       0.91      1.00      0.95       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.99      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6221, Accuracy: 0.6816, F1 Micro: 0.6816, F1 Macro: 0.4053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4725, Accuracy: 0.6816, F1 Micro: 0.6816, F1 Macro: 0.4053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4587, Accuracy: 0.8341, F1 Micro: 0.8341, F1 Macro: 0.7781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3369, Accuracy: 0.8879, F1 Micro: 0.8879, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1925, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1517, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1339, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8982\n",
      "Epoch 8/10, Train Loss: 0.1118, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.9056\n",
      "Epoch 10/10, Train Loss: 0.0901, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.888\n",
      "\n",
      "Sentiment analysis accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.9056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        71\n",
      "    positive       0.93      0.95      0.94       152\n",
      "\n",
      "    accuracy                           0.92       223\n",
      "   macro avg       0.91      0.90      0.91       223\n",
      "weighted avg       0.92      0.92      0.92       223\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9282, F1 Micro: 0.9282, F1 Macro: 0.8384\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.80      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.58      0.61        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.83      0.67      0.74        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.78      0.73      0.75       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.70      0.78        23\n",
      "     neutral       0.90      1.00      0.95       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.81      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.73      0.79       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 77.00628161430359 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 0.00011348724365234375 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5765, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5075, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4862, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3967, Accuracy: 0.8795, F1 Micro: 0.9279, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3165, Accuracy: 0.9167, F1 Micro: 0.9486, F1 Macro: 0.9468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2641, Accuracy: 0.9315, F1 Micro: 0.958, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2068, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1705, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1346, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "Epoch 10/10, Train Loss: 0.1155, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9677\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.94      0.95       175\n",
      "      others       0.88      0.97      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      0.99      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.6857, F1 Micro: 0.6857, F1 Macro: 0.4068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5038, Accuracy: 0.8041, F1 Micro: 0.8041, F1 Macro: 0.715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3242, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.9009\n",
      "Epoch 4/10, Train Loss: 0.2322, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8925\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1389, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.106, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9306\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9189\n",
      "\n",
      "Sentiment analysis accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        77\n",
      "    positive       0.98      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.94       245\n",
      "   macro avg       0.93      0.95      0.94       245\n",
      "weighted avg       0.95      0.94      0.94       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.899\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.94      0.95       167\n",
      "    positive       0.76      0.85      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.87      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.95      0.67      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.77      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      0.99      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 83.15919661521912 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 0.00010561943054199219 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5702, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4806, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4455, Accuracy: 0.8318, F1 Micro: 0.9037, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3684, Accuracy: 0.907, F1 Micro: 0.9431, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.285, Accuracy: 0.9219, F1 Micro: 0.9513, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2302, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1748, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1524, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.116, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Epoch 10/10, Train Loss: 0.0938, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5966, Accuracy: 0.6748, F1 Micro: 0.6748, F1 Macro: 0.4029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5294, Accuracy: 0.7033, F1 Micro: 0.7033, F1 Macro: 0.4903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3747, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2478, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9242\n",
      "Epoch 6/10, Train Loss: 0.1421, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1707, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0939, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1094, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.99      0.92        80\n",
      "    positive       0.99      0.93      0.96       166\n",
      "\n",
      "    accuracy                           0.95       246\n",
      "   macro avg       0.93      0.96      0.94       246\n",
      "weighted avg       0.95      0.95      0.95       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9097\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.77      0.78       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 86.80578351020813 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 0.00010609626770019531 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5599, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4711, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3997, Accuracy: 0.8951, F1 Micro: 0.9361, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3022, Accuracy: 0.9204, F1 Micro: 0.9507, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.248, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1767, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1523, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.1124, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.1, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0812, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5637, Accuracy: 0.6708, F1 Micro: 0.6708, F1 Macro: 0.4015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4311, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.255, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9206\n",
      "Epoch 4/10, Train Loss: 0.1538, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9166\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9089\n",
      "Epoch 6/10, Train Loss: 0.1478, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9103\n",
      "Epoch 7/10, Train Loss: 0.1331, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.096, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.99      0.91        79\n",
      "    positive       0.99      0.91      0.95       161\n",
      "\n",
      "    accuracy                           0.93       240\n",
      "   macro avg       0.92      0.95      0.93       240\n",
      "weighted avg       0.94      0.93      0.93       240\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9005\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.92      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.76      0.77       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 88.0688214302063 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 0.00010824203491210938 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5446, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4879, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3949, Accuracy: 0.901, F1 Micro: 0.9396, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2997, Accuracy: 0.9382, F1 Micro: 0.9618, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2215, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1749, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.139, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0766, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.90      0.99      0.94       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5734, Accuracy: 0.6911, F1 Micro: 0.6911, F1 Macro: 0.4645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3786, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9111\n",
      "Epoch 3/10, Train Loss: 0.2239, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1471, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9312\n",
      "Epoch 5/10, Train Loss: 0.1756, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1377, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9364\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9204\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9285\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.932\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        81\n",
      "    positive       0.97      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.94       246\n",
      "   macro avg       0.93      0.94      0.94       246\n",
      "weighted avg       0.94      0.94      0.94       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9065\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.96      0.96       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.99      0.94       152\n",
      "    positive       0.95      0.71      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 89.37190270423889 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 0.00010371208190917969 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5461, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4767, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.378, Accuracy: 0.9033, F1 Micro: 0.9396, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2832, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.205, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.168, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1304, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1065, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5742, Accuracy: 0.7194, F1 Micro: 0.7194, F1 Macro: 0.5472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3647, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.203, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9257\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.914\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9317\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0847, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9108\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.38706231117249 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.560585021972656e-05 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5537, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4653, Accuracy: 0.8259, F1 Micro: 0.9005, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3538, Accuracy: 0.9204, F1 Micro: 0.9506, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.253, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1882, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Epoch 6/10, Train Loss: 0.1538, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.111, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0793, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.58, Accuracy: 0.7385, F1 Micro: 0.7385, F1 Macro: 0.6131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.372, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8969\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9075\n",
      "Epoch 6/10, Train Loss: 0.1304, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8998\n",
      "Epoch 7/10, Train Loss: 0.1424, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.907\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9109\n",
      "Epoch 9/10, Train Loss: 0.0914, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0686, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        84\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9125\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 97.85390567779541 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 0.005715847015380859 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4606, Accuracy: 0.8408, F1 Micro: 0.9082, F1 Macro: 0.9074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3356, Accuracy: 0.9286, F1 Micro: 0.9553, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2379, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1891, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1374, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1052, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0966, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5889, Accuracy: 0.7273, F1 Micro: 0.7273, F1 Macro: 0.5667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2985, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2161, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9468\n",
      "Epoch 4/10, Train Loss: 0.1724, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Epoch 5/10, Train Loss: 0.1316, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9226\n",
      "Epoch 6/10, Train Loss: 0.1198, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Epoch 7/10, Train Loss: 0.0656, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9166\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9299\n",
      "Epoch 10/10, Train Loss: 0.0667, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9224\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        84\n",
      "    positive       0.97      0.96      0.96       169\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.95       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 99.0643720626831 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.393692016601562e-05 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5431, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4508, Accuracy: 0.8601, F1 Micro: 0.9182, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3335, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.237, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1842, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1413, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5442, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3065, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2157, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9444\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9378\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9247\n",
      "Epoch 6/10, Train Loss: 0.1585, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 7/10, Train Loss: 0.0969, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0926, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.948\n",
      "Epoch 9/10, Train Loss: 0.0893, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9318\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.97       177\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.95       261\n",
      "weighted avg       0.96      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9259\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.88      0.83      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 102.59279870986938 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 0.0001342296600341797 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4387, Accuracy: 0.8802, F1 Micro: 0.929, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3153, Accuracy: 0.9353, F1 Micro: 0.9599, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2238, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9783\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.7444, F1 Micro: 0.7444, F1 Macro: 0.5936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2817, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9248\n",
      "Epoch 4/10, Train Loss: 0.1324, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9212\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9409\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9276\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.89      0.85       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.9353518486023 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 9.059906005859375e-05 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5347, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4378, Accuracy: 0.8958, F1 Micro: 0.9371, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3135, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.221, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.162, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.1309, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5101, Accuracy: 0.8707, F1 Micro: 0.8707, F1 Macro: 0.8504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2451, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1702, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9433\n",
      "Epoch 4/10, Train Loss: 0.1481, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9144\n",
      "Epoch 5/10, Train Loss: 0.1135, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9085\n",
      "Epoch 6/10, Train Loss: 0.0849, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.918\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9384\n",
      "Epoch 9/10, Train Loss: 0.0738, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0838, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9479\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        84\n",
      "    positive       0.97      0.96      0.97       179\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.95      0.95      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9257\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.85      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.04489612579346 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 0.006578207015991211 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4092, Accuracy: 0.9062, F1 Micro: 0.9429, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2946, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2084, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.4505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2984, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Epoch 4/10, Train Loss: 0.148, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Epoch 7/10, Train Loss: 0.1308, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8735\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9282\n",
      "Epoch 10/10, Train Loss: 0.0888, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9165\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.91        85\n",
      "    positive       0.99      0.92      0.95       174\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.95      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9181\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.84      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 106.60600590705872 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.463859558105469e-05 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4167, Accuracy: 0.8996, F1 Micro: 0.9375, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2828, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1437, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5296, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.8405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "Epoch 3/10, Train Loss: 0.1741, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 4/10, Train Loss: 0.1241, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9188\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9185\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9289\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.71558499336243 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.416175842285156e-05 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5313, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4238, Accuracy: 0.8899, F1 Micro: 0.9317, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2896, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2048, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9785\n",
      "Epoch 6/10, Train Loss: 0.1194, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5504, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2343, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1895, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1421, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9373\n",
      "Epoch 5/10, Train Loss: 0.0901, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9202\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9417\n",
      "Epoch 8/10, Train Loss: 0.0716, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.916\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9457\n",
      "\n",
      "Sentiment analysis accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.97      0.95      0.96       160\n",
      "\n",
      "    accuracy                           0.95       243\n",
      "   macro avg       0.94      0.95      0.95       243\n",
      "weighted avg       0.95      0.95      0.95       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9178\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.6367347240448 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.559226989746094e-05 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5265, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4016, Accuracy: 0.8996, F1 Micro: 0.9368, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2629, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1372, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1048, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5214, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2573, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 3/10, Train Loss: 0.1642, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1472, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.107, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9531\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.94        88\n",
      "    positive       0.96      0.98      0.97       180\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.96      0.95      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9289\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.7997190952301 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.320808410644531e-05 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3946, Accuracy: 0.9219, F1 Micro: 0.9515, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2601, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1815, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0994, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 7/10, Train Loss: 0.0813, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4934, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2259, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9283\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9167\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0545, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9194\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.923\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.34417653083801 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.006860256195068359 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5231, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4024, Accuracy: 0.9219, F1 Micro: 0.9519, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2648, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.19, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2178, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1722, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9317\n",
      "Epoch 5/10, Train Loss: 0.1457, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1354, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       172\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.95      0.94       258\n",
      "weighted avg       0.95      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9211\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.81297302246094 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.249282836914062e-05 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5185, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.382, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2485, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.175, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5051, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2565, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1617, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9519\n",
      "Epoch 7/10, Train Loss: 0.0899, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9516\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9519\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        83\n",
      "    positive       0.99      0.95      0.97       172\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9309\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.93      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.99362754821777 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.202957153320312e-05 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5242, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3838, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2498, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0573, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0422, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5301, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9393\n",
      "Epoch 6/10, Train Loss: 0.0785, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0763, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9393\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9472\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        85\n",
      "    positive       0.97      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.95       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9283\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.99420976638794 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.679794311523438e-05 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3825, Accuracy: 0.9338, F1 Micro: 0.9589, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2416, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4733, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2424, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9447\n",
      "Epoch 6/10, Train Loss: 0.0827, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9284\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9324\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9213\n",
      "\n",
      "Sentiment analysis accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9261\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.94531989097595 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.940696716308594e-05 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5249, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.352, Accuracy: 0.939, F1 Micro: 0.9622, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2356, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9782\n",
      "Epoch 5/10, Train Loss: 0.1139, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0728, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4711, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2338, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.905\n",
      "Epoch 4/10, Train Loss: 0.1296, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1169, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9284\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        87\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9231\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.94978713989258 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.007537364959716797 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5225, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3686, Accuracy: 0.9308, F1 Micro: 0.9571, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.234, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9759\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0487, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5003, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2438, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1858, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9302\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.07, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.929\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        84\n",
      "    positive       0.97      0.96      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9246\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.76397252082825 s\n",
      "Total runtime: 2602.884182691574 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca736a",
   "metadata": {
    "papermill": {
     "duration": 0.257547,
     "end_time": "2025-03-29T05:45:37.584247",
     "exception": false,
     "start_time": "2025-03-29T05:45:37.326700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 62.73601317405701 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 0.00017714500427246094 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6303, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5033, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4778, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4662, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4217, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4115, Accuracy: 0.8125, F1 Micro: 0.8935, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3785, Accuracy: 0.8237, F1 Micro: 0.8979, F1 Macro: 0.8955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3174, Accuracy: 0.8497, F1 Micro: 0.9108, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2773, Accuracy: 0.8891, F1 Micro: 0.9333, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2378, Accuracy: 0.8988, F1 Micro: 0.9383, F1 Macro: 0.9355\n",
      "\n",
      "Aspect detection accuracy: 0.8988, F1 Micro: 0.9383, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      1.00      0.98       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.87      0.87      0.87       158\n",
      "        part       0.83      1.00      0.91       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.93      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.97      0.94      1061\n",
      "weighted avg       0.91      0.98      0.94      1061\n",
      " samples avg       0.91      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6228, Accuracy: 0.6984, F1 Micro: 0.6984, F1 Macro: 0.4112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4821, Accuracy: 0.6984, F1 Micro: 0.6984, F1 Macro: 0.4112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4524, Accuracy: 0.8148, F1 Micro: 0.8148, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.252, Accuracy: 0.8466, F1 Micro: 0.8466, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2047, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.8096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1335, Accuracy: 0.8677, F1 Micro: 0.8677, F1 Macro: 0.8243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.8836, F1 Micro: 0.8836, F1 Macro: 0.8574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8688\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.8075\n",
      "Epoch 10/10, Train Loss: 0.0738, Accuracy: 0.8466, F1 Micro: 0.8466, F1 Macro: 0.7901\n",
      "\n",
      "Sentiment analysis accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        57\n",
      "    positive       0.92      0.92      0.92       132\n",
      "\n",
      "    accuracy                           0.89       189\n",
      "   macro avg       0.87      0.87      0.87       189\n",
      "weighted avg       0.89      0.89      0.89       189\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8866, F1 Micro: 0.8866, F1 Macro: 0.7402\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.97      1.00      0.98       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.89      0.98      0.93       167\n",
      "    positive       0.85      0.52      0.64        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.69      0.75       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.87      0.87      0.87       152\n",
      "    positive       0.67      0.58      0.62        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.69      0.76      0.71       216\n",
      "weighted avg       0.80      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.52      0.69        23\n",
      "     neutral       0.82      1.00      0.90       152\n",
      "    positive       0.89      0.41      0.57        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.91      0.65      0.72       216\n",
      "weighted avg       0.85      0.84      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.23      0.38        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.64      0.53      0.58        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.58      0.64       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.93      1.00      0.96       185\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.65      0.74       216\n",
      "weighted avg       0.93      0.93      0.91       216\n",
      "\n",
      "Total train time: 74.13586902618408 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 0.0001544952392578125 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5997, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5048, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5071, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4529, Accuracy: 0.8051, F1 Micro: 0.8901, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3959, Accuracy: 0.8341, F1 Micro: 0.9044, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3383, Accuracy: 0.8638, F1 Micro: 0.9198, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2899, Accuracy: 0.9033, F1 Micro: 0.9411, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2365, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1935, Accuracy: 0.933, F1 Micro: 0.9588, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1642, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9585\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.92      0.99      0.96       175\n",
      "      others       0.90      0.90      0.90       158\n",
      "        part       0.89      1.00      0.94       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.6756, F1 Micro: 0.6756, F1 Macro: 0.4032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4966, Accuracy: 0.76, F1 Micro: 0.76, F1 Macro: 0.6577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3499, Accuracy: 0.8267, F1 Micro: 0.8267, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2118, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9135\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9231\n",
      "Epoch 7/10, Train Loss: 0.066, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8378\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9081\n",
      "Epoch 9/10, Train Loss: 0.0983, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9122\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8654\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90        73\n",
      "    positive       0.94      0.96      0.95       152\n",
      "\n",
      "    accuracy                           0.93       225\n",
      "   macro avg       0.93      0.92      0.92       225\n",
      "weighted avg       0.93      0.93      0.93       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.929, F1 Micro: 0.929, F1 Macro: 0.8565\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.97      0.99      0.98       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.91      0.64      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.79      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.90      0.90      0.90       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.82      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.65      0.79        23\n",
      "     neutral       0.88      1.00      0.94       152\n",
      "    positive       0.93      0.66      0.77        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.94      0.77      0.83       216\n",
      "weighted avg       0.91      0.90      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 74.58822011947632 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 0.00011372566223144531 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5847, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4983, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4647, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4134, Accuracy: 0.8222, F1 Micro: 0.8978, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3692, Accuracy: 0.8631, F1 Micro: 0.9188, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2893, Accuracy: 0.9211, F1 Micro: 0.9511, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2305, Accuracy: 0.939, F1 Micro: 0.9622, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1799, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9624\n",
      "Epoch 9/10, Train Loss: 0.1493, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.118, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9674\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.94      0.97      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5784, Accuracy: 0.684, F1 Micro: 0.684, F1 Macro: 0.4062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4326, Accuracy: 0.768, F1 Micro: 0.768, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2909, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.905\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1216, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9093\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9146\n",
      "\n",
      "Sentiment analysis accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.94      0.89        79\n",
      "    positive       0.97      0.92      0.94       171\n",
      "\n",
      "    accuracy                           0.92       250\n",
      "   macro avg       0.91      0.93      0.91       250\n",
      "weighted avg       0.93      0.92      0.93       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8842\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.86      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.94      0.97      0.96       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 82.38141584396362 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 0.0001087188720703125 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5667, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4769, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4504, Accuracy: 0.8073, F1 Micro: 0.8911, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3905, Accuracy: 0.869, F1 Micro: 0.9221, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2878, Accuracy: 0.9249, F1 Micro: 0.9535, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2299, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1838, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1517, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1214, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9684\n",
      "Epoch 10/10, Train Loss: 0.1066, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.90      0.93      0.91       158\n",
      "        part       0.95      0.97      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6254, Accuracy: 0.6855, F1 Micro: 0.6855, F1 Macro: 0.4067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4492, Accuracy: 0.7782, F1 Micro: 0.7782, F1 Macro: 0.6887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2807, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1548, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0611, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9077\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.879, F1 Micro: 0.879, F1 Macro: 0.8507\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8942\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9041\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.88        78\n",
      "    positive       0.95      0.93      0.94       170\n",
      "\n",
      "    accuracy                           0.92       248\n",
      "   macro avg       0.90      0.91      0.91       248\n",
      "weighted avg       0.92      0.92      0.92       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.82      0.69      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.79      0.79       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 84.64105582237244 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 0.00011110305786132812 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5449, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4957, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4219, Accuracy: 0.849, F1 Micro: 0.9115, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3349, Accuracy: 0.9189, F1 Micro: 0.95, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.259, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2008, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1556, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1187, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1028, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9708\n",
      "Epoch 10/10, Train Loss: 0.0829, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9677\n",
      "\n",
      "Aspect detection accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.88      0.99      0.93       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.6623, F1 Micro: 0.6623, F1 Macro: 0.4329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3398, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2455, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1366, Accuracy: 0.9298, F1 Micro: 0.9298, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1244, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9426\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8946\n",
      "Epoch 7/10, Train Loss: 0.1205, Accuracy: 0.9386, F1 Micro: 0.9386, F1 Macro: 0.9337\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9193\n",
      "Epoch 9/10, Train Loss: 0.0663, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9158\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9164\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        79\n",
      "    positive       0.97      0.95      0.96       149\n",
      "\n",
      "    accuracy                           0.95       228\n",
      "   macro avg       0.94      0.95      0.94       228\n",
      "weighted avg       0.95      0.95      0.95       228\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.88      0.99      0.93       152\n",
      "    positive       0.97      0.62      0.75        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.79      0.82       216\n",
      "weighted avg       0.90      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.97      0.71      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 87.81625485420227 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 0.0001614093780517578 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5616, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4788, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4135, Accuracy: 0.8698, F1 Micro: 0.9231, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3248, Accuracy: 0.9241, F1 Micro: 0.9529, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2359, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1745, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1378, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9691\n",
      "Epoch 8/10, Train Loss: 0.1126, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9695\n",
      "Epoch 9/10, Train Loss: 0.0892, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.971\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9693\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5947, Accuracy: 0.7012, F1 Micro: 0.7012, F1 Macro: 0.5164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3375, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1988, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1317, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9309\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8987\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9237\n",
      "Epoch 7/10, Train Loss: 0.0969, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8812\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.9386\n",
      "\n",
      "Sentiment analysis accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        78\n",
      "    positive       0.96      0.96      0.96       163\n",
      "\n",
      "    accuracy                           0.95       241\n",
      "   macro avg       0.94      0.94      0.94       241\n",
      "weighted avg       0.95      0.95      0.95       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.95      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 87.76423335075378 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 0.00010633468627929688 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4794, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4012, Accuracy: 0.8884, F1 Micro: 0.9324, F1 Macro: 0.9303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2931, Accuracy: 0.9338, F1 Micro: 0.9587, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2158, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Epoch 6/10, Train Loss: 0.1602, Accuracy: 0.9479, F1 Micro: 0.9671, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.136, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5456, Accuracy: 0.772, F1 Micro: 0.772, F1 Macro: 0.67\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2942, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9236\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1452, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1238, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9419\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1072, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9462\n",
      "Epoch 9/10, Train Loss: 0.0451, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9462\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        81\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9085\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 95.17596888542175 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.775161743164062e-05 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5593, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4757, Accuracy: 0.8162, F1 Micro: 0.8954, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3686, Accuracy: 0.9196, F1 Micro: 0.9507, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2696, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1818, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1132, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0975, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0644, Accuracy: 0.9576, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5442, Accuracy: 0.7188, F1 Micro: 0.7188, F1 Macro: 0.523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2995, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9093\n",
      "Epoch 6/10, Train Loss: 0.1285, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9462\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9258\n",
      "Epoch 10/10, Train Loss: 0.0693, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        80\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.95       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9142\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.85      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.79334807395935 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 0.013980388641357422 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4738, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.376, Accuracy: 0.9144, F1 Micro: 0.9477, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2634, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1891, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1438, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.538, Accuracy: 0.7097, F1 Micro: 0.7097, F1 Macro: 0.5196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2687, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9334\n",
      "Epoch 4/10, Train Loss: 0.1032, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9065\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9315\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9071\n",
      "Epoch 8/10, Train Loss: 0.1002, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9362\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        81\n",
      "    positive       0.96      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.94       248\n",
      "   macro avg       0.93      0.94      0.94       248\n",
      "weighted avg       0.94      0.94      0.94       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.81      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 101.8484616279602 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 0.00010180473327636719 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4662, Accuracy: 0.8259, F1 Micro: 0.8997, F1 Macro: 0.8982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3524, Accuracy: 0.9196, F1 Micro: 0.9512, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2501, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9705\n",
      "Epoch 5/10, Train Loss: 0.1868, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1388, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Epoch 7/10, Train Loss: 0.1039, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0945, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.073, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.95      0.96       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5788, Accuracy: 0.7083, F1 Micro: 0.7083, F1 Macro: 0.5058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.274, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9233\n",
      "Epoch 3/10, Train Loss: 0.1757, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1408, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.129, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.86      0.88       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.95      0.96       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.94      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.88      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.893061876297 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 0.00010609626770019531 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5404, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4486, Accuracy: 0.8408, F1 Micro: 0.9075, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3516, Accuracy: 0.9249, F1 Micro: 0.9539, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2321, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Epoch 5/10, Train Loss: 0.1637, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9568, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5402, Accuracy: 0.8722, F1 Micro: 0.8722, F1 Macro: 0.853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.259, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1637, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9024\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9151\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9146\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9181\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9176\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9111\n",
      "\n",
      "Sentiment analysis accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.90        82\n",
      "    positive       0.97      0.93      0.95       184\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.94      0.93       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9075\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.87      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.42030572891235 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 9.298324584960938e-05 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5461, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4515, Accuracy: 0.8452, F1 Micro: 0.91, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3328, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2285, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1724, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5547, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2475, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9271\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9024\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9118\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8983\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9221\n",
      "Epoch 9/10, Train Loss: 0.0624, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.041, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.90        85\n",
      "    positive       0.97      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.94      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9085\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.85      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 106.23050427436829 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 0.006319761276245117 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4373, Accuracy: 0.8735, F1 Micro: 0.9239, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3179, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2212, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1548, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9745\n",
      "Epoch 6/10, Train Loss: 0.1246, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.8199, F1 Micro: 0.8199, F1 Macro: 0.758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.305, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1525, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1503, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9318\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9386\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9237\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        85\n",
      "    positive       0.96      0.97      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9224\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.61575245857239 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.775161743164062e-05 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.429, Accuracy: 0.8929, F1 Micro: 0.936, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2928, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.90      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5158, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.264, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1517, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9339\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.919\n",
      "Epoch 9/10, Train Loss: 0.0772, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.88\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9179\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        86\n",
      "    positive       0.98      0.93      0.96       186\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.92      0.95      0.93       272\n",
      "weighted avg       0.95      0.94      0.94       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9149\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.88      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.19660973548889 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.00011205673217773438 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4348, Accuracy: 0.8728, F1 Micro: 0.9249, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3033, Accuracy: 0.9487, F1 Micro: 0.9683, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0957, Accuracy: 0.9546, F1 Micro: 0.9711, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4606, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2287, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1622, Accuracy: 0.9572, F1 Micro: 0.9572, F1 Macro: 0.9515\n",
      "Epoch 4/10, Train Loss: 0.1368, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "Epoch 6/10, Train Loss: 0.0857, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9293\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.908\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9373\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9322\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "\n",
      "Sentiment analysis accuracy: 0.9572, F1 Micro: 0.9572, F1 Macro: 0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        85\n",
      "    positive       0.97      0.97      0.97       172\n",
      "\n",
      "    accuracy                           0.96       257\n",
      "   macro avg       0.95      0.95      0.95       257\n",
      "weighted avg       0.96      0.96      0.96       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9273\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.68863368034363 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.96453857421875e-05 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4196, Accuracy: 0.9003, F1 Micro: 0.9392, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.28, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2005, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0865, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.91      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5013, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2267, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1109, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "Epoch 7/10, Train Loss: 0.1208, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.94\n",
      "Epoch 8/10, Train Loss: 0.0878, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9278\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.95      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9281\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.86      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.05850267410278 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.678436279296875e-05 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4203, Accuracy: 0.9167, F1 Micro: 0.949, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2626, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2752, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 3/10, Train Loss: 0.1666, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1401, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1115, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1082, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9586, F1 Micro: 0.9586, F1 Macro: 0.9526\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "\n",
      "Sentiment analysis accuracy: 0.9586, F1 Micro: 0.9586, F1 Macro: 0.9526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        85\n",
      "    positive       0.97      0.97      0.97       181\n",
      "\n",
      "    accuracy                           0.96       266\n",
      "   macro avg       0.95      0.95      0.95       266\n",
      "weighted avg       0.96      0.96      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9272\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.79433679580688 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.006803274154663086 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4188, Accuracy: 0.8787, F1 Micro: 0.9275, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2788, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1844, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.974\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 7/10, Train Loss: 0.0838, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.97      0.92      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5295, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2536, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1444, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Epoch 6/10, Train Loss: 0.0797, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9227\n",
      "Epoch 7/10, Train Loss: 0.0734, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9276\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9227\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9112\n",
      "Epoch 10/10, Train Loss: 0.0722, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9308\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9133\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.97      0.92      0.95       152\n",
      "    positive       0.79      0.87      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.90      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 112.78284811973572 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.489059448242188e-05 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5163, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4107, Accuracy: 0.904, F1 Micro: 0.9412, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2595, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1798, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1042, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0685, Accuracy: 0.9665, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5069, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9064\n",
      "Epoch 2/10, Train Loss: 0.2148, Accuracy: 0.8794, F1 Micro: 0.8794, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1153, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9312\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9141\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9255\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        84\n",
      "    positive       0.96      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.59523510932922 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.845329284667969e-05 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5318, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3916, Accuracy: 0.9174, F1 Micro: 0.9498, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2539, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1223, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0764, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0515, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.98      0.97      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5017, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2315, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9272\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9177\n",
      "Epoch 4/10, Train Loss: 0.1306, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9055\n",
      "Epoch 5/10, Train Loss: 0.0959, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1246, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "Epoch 7/10, Train Loss: 0.1067, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8984\n",
      "Epoch 8/10, Train Loss: 0.0653, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9134\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9217\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9248\n",
      "\n",
      "Sentiment analysis accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.91        87\n",
      "    positive       0.97      0.94      0.95       179\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.93      0.93       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9221\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.98      0.97      0.97       167\n",
      "    positive       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.29957890510559 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.274482727050781e-05 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5272, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3984, Accuracy: 0.9182, F1 Micro: 0.9496, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2541, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0735, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9809\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4711, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9328\n",
      "Epoch 2/10, Train Loss: 0.2254, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9065\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1349, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9328\n",
      "Epoch 5/10, Train Loss: 0.1207, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9052\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9276\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Epoch 8/10, Train Loss: 0.0855, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9252\n",
      "Epoch 9/10, Train Loss: 0.0524, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9277\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.87      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.7694845199585 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.00010561943054199219 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5216, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4004, Accuracy: 0.9226, F1 Micro: 0.9522, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2488, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.0759, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4825, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.148, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Epoch 4/10, Train Loss: 0.1147, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9227\n",
      "Epoch 5/10, Train Loss: 0.1136, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0967, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0738, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9227\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        85\n",
      "    positive       0.96      0.96      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9213\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.6323630809784 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.00733494758605957 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5271, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3958, Accuracy: 0.9226, F1 Micro: 0.9526, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2482, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0519, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4808, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2266, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1441, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.945\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9263\n",
      "Epoch 6/10, Train Loss: 0.1309, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Epoch 7/10, Train Loss: 0.0865, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9412\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9134\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9267\n",
      "\n",
      "Sentiment analysis accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9317\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.81471943855286 s\n",
      "Total runtime: 2587.051504611969 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADd/ElEQVR4nOzdd3TV9f3H8Wd2wgorjEAARWUPZUSWW1GsE3dbnFgHVqW2ouJupepPilUs1t0K4sBZt6hUC4ICMlS2svdIWNn398dNAiFhZN6M5+Oce3LH9977/kaPfTX3dT+fsEAgEECSJEmSJEmSJEmSJKkChId6AEmSJEmSJEmSJEmSVHNYVJAkSZIkSZIkSZIkSRXGooIkSZIkSZIkSZIkSaowFhUkSZIkSZIkSZIkSVKFsaggSZIkSZIkSZIkSZIqjEUFSZIkSZIkSZIkSZJUYSwqSJIkSZIkSZIkSZKkCmNRQZIkSZIkSZIkSZIkVRiLCpIkSZIkSZIkSZIkqcJYVJAkSZIkSVXOFVdcQZs2bUI9hiRJkiRJKgGLCpJUhp566inCwsJITk4O9SiSJElSqbz44ouEhYUVeRkxYkT+cZ988glXX301nTt3JiIiotjlgbzXvOaaa4p8/K677so/ZtOmTaU5JUmSJNUg5llJqtwiQz2AJFUn48ePp02bNsyYMYMlS5ZwxBFHhHokSZIkqVQeeOABDjvssAL3de7cOf/6hAkTePXVVznmmGNITEws0XvExsYyadIknnrqKaKjows89sorrxAbG0taWlqB+5955hlycnJK9H6SJEmqOSprnpWkms4VFSSpjPz8889MnTqV0aNHk5CQwPjx40M9UpF27twZ6hEkSZJUhZxxxhn85je/KXDp3r17/uMPPfQQqamp/O9//6Nbt24leo/TTz+d1NRUPvzwwwL3T506lZ9//pkzzzyz0HOioqKIiYkp0fvtLScnxz8aS5IkVWOVNc+WN/8OLKmys6ggSWVk/PjxNGjQgDPPPJMLLrigyKLCtm3buPXWW2nTpg0xMTG0bNmSIUOGFFjyKy0tjfvuu4+jjjqK2NhYmjdvzvnnn8/SpUsB+PLLLwkLC+PLL78s8Nq//PILYWFhvPjii/n3XXHFFdSpU4elS5cyaNAg6taty69//WsAvvrqKy688EJatWpFTEwMSUlJ3HrrrezevbvQ3AsWLOCiiy4iISGBuLg42rVrx1133QXAF198QVhYGG+99Vah502YMIGwsDCmTZtW7N+nJEmSqobExESioqJK9RotWrTguOOOY8KECQXuHz9+PF26dCnwjbc8V1xxRaFleXNycnj88cfp0qULsbGxJCQkcPrpp/Pdd9/lHxMWFsawYcMYP348nTp1IiYmho8++giA2bNnc8YZZ1CvXj3q1KnDySefzDfffFOqc5MkSVLlFqo8W1Z/nwW47777CAsL48cff+Syyy6jQYMG9O/fH4CsrCwefPBB2rZtS0xMDG3atOHOO+8kPT29VOcsSaXl1g+SVEbGjx/P+eefT3R0NJdeein/+Mc/+Pbbb+nVqxcAO3bsYMCAAfz0009cddVVHHPMMWzatIl3332XVatW0bhxY7Kzs/nVr37F5MmTueSSS7j55pvZvn07n376KfPnz6dt27bFnisrK4uBAwfSv39//u///o9atWoB8Prrr7Nr1y6uv/56GjVqxIwZM3jiiSdYtWoVr7/+ev7z586dy4ABA4iKiuLaa6+lTZs2LF26lPfee4+//OUvnHDCCSQlJTF+/HjOO++8Qr+Ttm3b0qdPn1L8ZiVJkhRKKSkphfbSbdy4cZm/z2WXXcbNN9/Mjh07qFOnDllZWbz++usMHz78kFc8uPrqq3nxxRc544wzuOaaa8jKyuKrr77im2++oWfPnvnHff7557z22msMGzaMxo0b06ZNG3744QcGDBhAvXr1+NOf/kRUVBRPP/00J5xwAlOmTCE5ObnMz1mSJEnlr7Lm2bL6++zeLrzwQo488kgeeughAoEAANdccw0vvfQSF1xwAX/4wx+YPn06o0aN4qeffiryy2eSVFEsKkhSGZg5cyYLFizgiSeeAKB///60bNmS8ePH5xcVHn30UebPn8+bb75Z4AP9kSNH5ofGf/3rX0yePJnRo0dz66235h8zYsSI/GOKKz09nQsvvJBRo0YVuP/hhx8mLi4u//a1117LEUccwZ133smKFSto1aoVADfddBOBQIBZs2bl3wfw17/+FQh+I+03v/kNo0ePJiUlhfj4eAA2btzIJ598UqDZK0mSpKrnlFNOKXRfSbPpgVxwwQUMGzaMt99+m9/85jd88sknbNq0iUsvvZQXXnjhoM//4osvePHFF/n973/P448/nn//H/7wh0LzLly4kHnz5tGxY8f8+8477zwyMzP5+uuvOfzwwwEYMmQI7dq1409/+hNTpkwpozOVJElSRaqsebas/j67t27duhVY1WHOnDm89NJLXHPNNTzzzDMA3HDDDTRp0oT/+7//44svvuDEE08ss9+BJBWHWz9IUhkYP348TZs2zQ91YWFhXHzxxUycOJHs7GwAJk2aRLdu3QqtOpB3fN4xjRs35qabbtrvMSVx/fXXF7pv7xC8c+dONm3aRN++fQkEAsyePRsIlg3++9//ctVVVxUIwfvOM2TIENLT03njjTfy73v11VfJysriN7/5TYnnliRJUuiNHTuWTz/9tMClPDRo0IDTTz+dV155BQhuI9a3b19at259SM+fNGkSYWFh3HvvvYUe2zdLH3/88QVKCtnZ2XzyySece+65+SUFgObNm3PZZZfx9ddfk5qaWpLTkiRJUohV1jxbln+fzXPdddcVuP3BBx8AMHz48AL3/+EPfwDg/fffL84pSlKZckUFSSql7OxsJk6cyIknnsjPP/+cf39ycjKPPfYYkydP5rTTTmPp0qUMHjz4gK+1dOlS2rVrR2Rk2f3nOTIykpYtWxa6f8WKFdxzzz28++67bN26tcBjKSkpACxbtgygyD3U9ta+fXt69erF+PHjufrqq4FgeePYY4/liCOOKIvTkCRJUoj07t27wLYJ5emyyy7jt7/9LStWrODtt9/mkUceOeTnLl26lMTERBo2bHjQYw877LACtzdu3MiuXbto165doWM7dOhATk4OK1eupFOnToc8jyRJkiqHyppny/Lvs3n2zbnLly8nPDy80N9omzVrRv369Vm+fPkhva4klQeLCpJUSp9//jlr165l4sSJTJw4sdDj48eP57TTTiuz99vfygp5KzfsKyYmhvDw8ELHnnrqqWzZsoXbb7+d9u3bU7t2bVavXs0VV1xBTk5OsecaMmQIN998M6tWrSI9PZ1vvvmGJ598stivI0mSpJrr7LPPJiYmhssvv5z09HQuuuiicnmfvb+9JkmSJJWVQ82z5fH3Wdh/zi3Nar2SVF4sKkhSKY0fP54mTZowduzYQo+9+eabvPXWW4wbN462bdsyf/78A75W27ZtmT59OpmZmURFRRV5TIMGDQDYtm1bgfuL036dN28eixYt4qWXXmLIkCH59++77FnesrcHmxvgkksuYfjw4bzyyivs3r2bqKgoLr744kOeSZIkSYqLi+Pcc8/l5Zdf5owzzqBx48aH/Ny2bdvy8ccfs2XLlkNaVWFvCQkJ1KpVi4ULFxZ6bMGCBYSHh5OUlFSs15QkSVLNc6h5tjz+PluU1q1bk5OTw+LFi+nQoUP+/evXr2fbtm2HvM2aJJWH8IMfIknan927d/Pmm2/yq1/9igsuuKDQZdiwYWzfvp13332XwYMHM2fOHN56661CrxMIBAAYPHgwmzZtKnIlgrxjWrduTUREBP/9738LPP7UU08d8twREREFXjPv+uOPP17guISEBI477jief/55VqxYUeQ8eRo3bswZZ5zByy+/zPjx4zn99NOL9YdlSZIkCeC2227j3nvv5e677y7W8wYPHkwgEOD+++8v9Ni+2XVfERERnHbaabzzzjv88ssv+fevX7+eCRMm0L9/f+rVq1eseSRJklQzHUqeLY+/zxZl0KBBAIwZM6bA/aNHjwbgzDPPPOhrSFJ5cUUFSSqFd999l+3bt3P22WcX+fixxx5LQkIC48ePZ8KECbzxxhtceOGFXHXVVfTo0YMtW7bw7rvvMm7cOLp168aQIUP417/+xfDhw5kxYwYDBgxg586dfPbZZ9xwww2cc845xMfHc+GFF/LEE08QFhZG27Zt+c9//sOGDRsOee727dvTtm1bbrvtNlavXk29evWYNGlSob3QAP7+97/Tv39/jjnmGK699loOO+wwfvnlF95//32+//77AscOGTKECy64AIAHH3zw0H+RkiRJqrLmzp3Lu+++C8CSJUtISUnhz3/+MwDdunXjrLPOKtbrdevWjW7duhV7jhNPPJHf/va3/P3vf2fx4sWcfvrp5OTk8NVXX3HiiScybNiwAz7/z3/+M59++in9+/fnhhtuIDIykqeffpr09PQD7i0sSZKkqi0Ueba8/j5b1CyXX345//znP9m2bRvHH388M2bM4KWXXuLcc8/lxBNPLNa5SVJZsqggSaUwfvx4YmNjOfXUU4t8PDw8nDPPPJPx48eTnp7OV199xb333stbb73FSy+9RJMmTTj55JNp2bIlEGzSfvDBB/zlL39hwoQJTJo0iUaNGtG/f3+6dOmS/7pPPPEEmZmZjBs3jpiYGC666CIeffRROnfufEhzR0VF8d577/H73/+eUaNGERsby3nnncewYcMKhehu3brxzTffcPfdd/OPf/yDtLQ0WrduXeT+ameddRYNGjQgJydnv+UNSZIkVS+zZs0q9G2xvNuXX355sf+wWxovvPACXbt25bnnnuOPf/wj8fHx9OzZk759+x70uZ06deKrr77ijjvuYNSoUeTk5JCcnMzLL79McnJyBUwvSZKkUAhFni2vv88W5dlnn+Xwww/nxRdf5K233qJZs2bccccd3HvvvWV+XpJUHGGBQ1kbRpKkQ5CVlUViYiJnnXUWzz33XKjHkSRJkiRJkiRJUiUUHuoBJEnVx9tvv83GjRsZMmRIqEeRJEmSJEmSJElSJeWKCpKkUps+fTpz587lwQcfpHHjxsyaNSvUI0mSJEmSJEmSJKmSckUFSVKp/eMf/+D666+nSZMm/Otf/wr1OJIkSZIkSZIkSarEXFFBkiRJkiRJkiRJkiRVGFdUkCRJkiRJkiRJkiRJFcaigiRJkiRJkiRJkiRJqjCRoR6gouTk5LBmzRrq1q1LWFhYqMeRJElSKQQCAbZv305iYiLh4TWve2u2lSRJqj7MtmZbSZKk6qI42bbGFBXWrFlDUlJSqMeQJElSGVq5ciUtW7YM9RgVzmwrSZJU/ZhtJUmSVF0cSratMUWFunXrAsFfSr169UI8jSRJkkojNTWVpKSk/IxX05htJUmSqg+zrdlWkiSpuihOtq0xRYW8ZcPq1atn4JUkSaomaurSsGZbSZKk6sdsa7aVJEmqLg4l29a8Tc8kSZIkSZIkSZIkSVLIWFSQJEmSJEmSJEmSJEkVxqKCJEmSJEmSJEmSJEmqMBYVJEmSJEmSJEmSJElShbGoIEmSJEmSJEmSJEmSKoxFBUmSJEmSJEmSJEmSVGEsKkiSJEmSJEmSJEmSpApjUUGSJEmSJEmSJEmSJFUYiwqSJEmSJEmSJEmSJKnCWFSQJEmSJEmSJEmSJEkVxqKCJEmSJEmSJEmSJEmqMBYVJEmSJEmSJEmSJElShbGoIEmSJEmSJEmSJEmSKoxFBUmSJEmSJEmSJEmSVGEsKkiSJKlUVqyARx+FnJxQTyJJkiSV0s4V8OOjEDDcSpIkqWpbnbqav379VwKBQKhHKVJkqAeQJElS1bVrF5x7LsyeDVu3wkMPhXoiSZIkqYSydsF/z4WtsyFjK3Q33EqSJKlqSklL4YzxZzBvwzx2ZOzgzyf9OdQjFWJRQZIkqRoKBGDVKvj+++Bl0SJo3x5OPRV69ICIiLJ5j6uvDpYUEhLguutK/5qSJElSIYEA7FoFW78PXrYvgnrtoNmp0LAnhJdRuJ1+dbCkEJMARxpuJUmS9icrJ4v0rHTSs9PJyM4ocD0nkEN0RDQxETHBn5Ex+dejI6IJCwsL9fjVXkZ2Bue/dj7zNsyjWZ1mXHPMNaEeqUgWFSRJUoUKBMAsWrYyM2HBgj2lhLzLli2Fjx05Eho0gJNOCpYWTj0VDj+8ZO/7yCMwcSJERsIbb0CrViU/B0mSpCrJcFv2cjIhdcGeUkLeJaOIcDv3boiqD81OCpYWmp0KdduW7H1/egSWT4SwSBjwBtQ23EqSpJphV+YuXvvhNd786U1S0lP2W0DYt4xQUlHhUQXKC/u7XjemLvefcD/dm3Uvu5MNsZS0FOaun8uc9XOYs24Oc9bPYdHmRbSKb0WPxB70bN6THok96Na0G3FRcSV6j5xADle9cxWf//w5daLr8MFlH9CmfpuyPZEyYlFBkiRViJwcGDUK/vxn6NkTrrgCLroI6tYN9WRVS2oqzJlTsJAwfz5kZBQ+NjISOnSA7t3hqKOCKx98/nlwi4ZJk4IXCBYV8koLJ50ULDIczAcfwB13BK8/8QQcd1zZnJ8kSVKVEMiBH0bBD38OfqP/8Cug1UUQZbgtlsxU2DqnYCEhZT7kFBFuwyIhvgPU7w71jgqufLDuc8jcBivfDF4Aah8GzXNLC01PgpiGB59j9QfwfW647fkENDHcSpKk6u+njT/x9MyneWnOS2xL21aq14qJiMkvGYSFhZGRnZFfbsgOZBc4NjMnk8yMTHaw46Cvu2DTAr7/3fcl/tA+VHICOSzbuiy/jJBXTvhl2y9FHj9vwzzmbZjHi9+/CEBEWASdmnTKLy70TOxJ16ZdiY2MPeh73zn5TsbPG09keCSTLprE0c2PLsMzK1thgUAgEOohKkJqairx8fGkpKRQr169UI8jSVKF2bEDpkyBk0+G2IPnmHKxYQP89rfwyScF769VCwYPDpYWTjgBwsMrbqZAABYvDn7IP2hQ6H43+woEYPt2WLduz2Xhwj2lhGXLin5e3brBQsLel44dC59XVhbMnAmffhq8TJ0avC9PeHiwSJJXXOjTB6KjC77GwoWQnAwpKXDttfD002V19oeupme7mn7+kqQaLHMHbJgCzU6GiBAFuLQNMPW3sG6fcBtRC5IGB0sLTU+AsAoOt9sXBz/kTxwUut/NvgIByNoOu9dB2rrgz9SFsO37YClhx37CbWRdaNC94CW+Y+HzysmCLTNh3afBy8apENgr3IaFQ4Mee4oLjftCxD7hNnUhfJwMmSlwxLXQu+LDbU3PdjX9/CVJqkgZ2Rm89dNbjJs5ji9/+TL//jb123D10VfTrlE7YiJj8rduOJTrkeGRB9zOITsne09xITud9Kz0/OtFrdqQkZ1BWlYat316G2u2r+G2Prfx6GmPVsBvp2R2ZOxg3vp5BVZJmLdhHjsyii5itIpvRbem3YKXZt1o16gdv2z7he/WfMfMtTP5bs13rN+5vtDzIsMj6dykMz2aB4sLPRN70qVJF2IiY/KPGTtjLMM+HAbAi+e8yOXdLy+fkz6A4mQ7iwqSJFVjGRlw4onBD6PbtYPnn4e+fSt2hilT4NJLYe1aiIuDxx4LfsD94ovBD7zztGoFl18evLQt4WqtB7NpE0yevOdD+hUrgvdfcgm88kr5vGee9HRYv75gAWF/l927D/xaSUmFSwlt2pSs6JFXZMn7nfz4Y8HHa9eG44/fU1xo0QKOPTb4z65fv+AKDfsWGSpCTc92Nf38JUk1VHYGTD4RNk2Feu0g+XlIqOBwu34KTL0Udq+FiDg45jHISIGfXwx+4J2nVis4/HI47PKSb0VwMGmbYP3k4Af0az+FXbnhtvUl0K+cw212OqSt31NAyCshFPUz+yDhtlZS4VJC7TYlK3rkFVnyigsp+4TbyNrQ5Pg920TUagGfHBv8Z5fQD076vHCRoQLU9GxX089fklQz7czYyQNTHuDdRe/SvnF7jm99PMe3Pp6uTbsSER5R5u+3bOsynpn5DM/Nfo6NuzYCEB4Wzq+O+hXX9biO09qeVi7vWxr/WfQfznrlLMLDwvnfVf/j2JbHlvo1F29ezIdLPmT66un5W1gEAgECBAgEAsHbxbi+evtqlm5ZSoDCH7fHRMTQuUnn/EJCt6bd6Nq0Kw3iDrycbd7rzlwzs0B5Ie+f296iwqPo3KQzPRN70rR2U/7y1V8IEODBEx9k5HEjS/37KgmLCkUw8EqSaqJhw2Ds2D23w8Lg97+Hv/wl+AF0ecrb6uGee4LXO3aE116DTp2CjwcCMH16sLAwcWKwvJBnwIDgKgsXXli6rSHS0uB//9vzIfzs2cH3zRMVBdnZwfneeQfOPrvk77W3detg/Hj48ENYsyZ4e+vW4r1G3brQrFnw0qbNnkJCt27QqFHZzFmU1avhs8+Cq1989llwNYy9xcYGf68tW8J330HTpuU3y4HU9GxX089fklRDfTsMFu8VbgmDdr+Hbn8JfgBdnvK2eph3T/B6fEfo9xrU3yvcbp4Oy16E5ROD387PkzAgd2uIC0u3NUR2Gmz8355iwtbZsPcfRMOjIJAdnO+4d6BlGYXb3evgl/Gw5kPYvSZYPsgoZriNrAtxzSC2WbCEkF9K6AYx5Rhud62GdZ/B2k9g/WfB1TD2FhEb/L3WagkDv4O40ITbmp7tavr5S5JqnncXvstNH97EipQVhR6rH1ufAa0GBIsLbY6ne7PuRIZHluh9snKyeH/R+4ybOY6Pl3yc/2F68zrNGXrMUK455hqS4pNKdS7lbchbQ/j33H/TvnF7Zv9u9iFtfbC33Zm7+fKXL/lg8Qd8uORDlm5dWi5zNq/TPL+MkFdMOKrRUSX+Z7evQCDAqtRVBYoL3635js27Nxc6dugxQ3n6V08fcJWL8mRRoQgGXklSTfPSS8EP+wH+/e/gN99feCF4+/DD4dlng6stlId9t3q4/PJgYWJ/5Yjdu4NFgRdfDD4nL50Ud2uInByYN29PMeGrrwqvTtCly57VAQYMgAcfhIcfhsRE+OEHqF+/ZOecng7/+U/wHD78MFiA2Fd09J7ywb6Xpk0LXi/vIsmh2Pf3+d//BksKsbHw9dfQo0foZqvp2a6mn78kqQZa9hJ8c0Xwep9/w/rPYVluuK1zOCQ/C03LKdzuu9XDYZdDr7H7L0dk7YZV7wRXWVj7CfllguJuDRHIgW3z9hQTNn5VeHWC+l32rA7QZADMfxB+fBjiEuHMHyC6fsnOOTsdVv8nWLxY+2GwALGv8Ohg8SCvgFDgZ9OC18u7SHIoCv0+/xssKUTEwqlfQ8PQhduanu1q+vlLkmqOlSkr+f1Hv+ftBW8D0Dq+NfefcD/rdqzjy+Vf8vWKrwttF1A3ui79W/XPLy70aN6DqIioA77P6tTVPDvrWZ6Z9Qyrt6/Ov/+0tqdxXY/r+NVRvzroa1QWW3ZvodNTnVi3Yx0j+o1g1CmjDvqcvFUTPlzyIV/+8iVpWWn5j0WFRzGg9QBOPuxk4mPiCQ8LJywsjDDCDul6WFju7dzrDeMa0q1pNxJqJ5Tnr6FIgUCAFSkr8ssLM9fO5IgGR/D4GY+XWUGiJCwqFMHAK0mqSWbNCi7Ln5YG994L990XvP/jj2HoUFi5Mnj7uuuCH9KX5f807rvVw1NP7SlMHIpVq+Dllw99a4jVq/d8kF7UCgDNm8Mpp8BppwV/NmtW8PHdu4OrFCxeHPzd/POfhz5rIBD8Xb/4IkyYAFu27Hns2GPhN78JriSRV0CoXz+4qkVVlZYG33wTPJf27UM7S03PdjX9/CVJNcyWWfBpv+CHyp3vha73Be9f8zHMGAq7csPtEdfB0Q9DVBn+b+O+Wz30eipYNDhUu1bBzy8f+tYQu1bv+SC9qBUA4ppD01Og+WnQ7JRgEWBvWbvhw26wfTG0HQrJxQy3W2cFywm/TICMvcJto2PhsN8EV5LIKyBE1a/a4TY7DTZ9Ezyf+NCG25qe7Wr6+UuSDt3W3VupG1M3pB/ClkRWThZ/n/537vniHnZm7iQyPJI/9PkDdx93N7Wjaxc4bvba2UxZPoUpy6fw1fKvSElPKfBataNq0zepL8e3Pp4T2pxArxa9iI6IJieQw6dLP2XczHG8t/A9snOLpo1rNeaq7ldxbY9raduwnLYkK2fvLHiHc189l/CwcL65+ht6tehV4PG8VRM+XPIhHyz+oNCqCUn1khh05CDOOOIMTjrsJOrGlGKVMx2URYUiGHglSTXF5s3Bb7ovXw6DBsF77xVciSA1FUaMgH/8I3g7KSn44fzpp5fufQ+21UNxHWxriC5d4Isv4KefCj6vVi04/vg9qyZ06nTwv59+9RUcd1zw+uTJcNJJBz4+b2uHF1+E+fP33J+YCEOGBMsUof4gv7qr6dmupp+/JKkGSd8MH/WAncshcRAc/17BlQgyU+H7EbA4N9zWSoLe/4TEUobbg231UOzXO8jWEPW7wPovIHWfcBtRC5ocD81zV02IP4Rwu+Er+Cw33J40GZodJNzmbe2w7EVI2SvcxiXCYUOCZYoQf5Bf3dX0bFfTz1+SKoucQA4bd26kQVwDoiOiQz1Ovl2Zu3j9h9d5bvZzfLXiK+pE16FvUl/6J/VnQOsBJLdIJi4qLtRj7tf0VdP53X9+x5z1cwDol9SPf5z5D7o07XLQ52bnZDN3/VymLJ/Cl798yX+X/5etaQW34IqLjKNPUh9+3vozP2/7Of/+41ofx3U9ruP8DucTExlTticVApdNuoxX5r9Cp4ROzLx2JitSVhx01YQzjjiDM444g44JHUO2DUJNZFGhCAZeSVJNkJ0dLCd88klw1YFvv4UGDYo+9osv4JprYNmy4O0rroDRo/d//IEUd6uH4trf1hAQ/Dttz557igl9+kBMCbL3jTcGV384/HCYO7fw7Pvb2iEmBs47L/j7O+UUiIgo4UmqWGp6tqvp5y9JqiFysuHLQcEtF+q0hdO/hej9hNX1X8D0a2BHbrg9/Ao4ZvT+jz+Q4m71UFz72xoCgDBo2HNPMaFxH4goQbj99kZY/FRwW4xBcwvPvr+tHcJjIOk8OOyK4IoN4YbbilDTs11NP39JqijpWemsTF3J8m3LWZGyguUpy1meknt923JWpq4kIzuDhFoJ3N7vdm7odUPICgCBQIBZa2fx7KxnmTB/Aqnpqfs9Nio8ih6JPRjQagADWg2gX6t+NIxrWIHTFm3r7q3cOflOnp75NAECNIxryCOnPMKVR19J+MG2ANuPnEAO8zfMZ8ovwRUX/rv8v2zctTH/8fiYeC7vdjm/6/k7OiZ0LKtTqRQ27dpEp6c6sWHnBhrFNWLz7s0FHk+qlxQsJhx5BicfdrKrJoSQRYUiGHglSTXBXXfBQw8FVxWYNg26dj3w8Tt3wt13w5gxwQ//mzWDcePgnHMO/T1Lu9VDca1aFVzNYM2a4MoKJ50EDcvg/3ukpkLnzsFtMYYPh8ceO/jWDldcARdfHNzSQRWrpme7mn7+kqQaYs5d8MNDwVUFTpsGDQ4SbrN2wpy7YeEYIBBc0r/3OGhZjHBb2q0eimvXquBqBrvWQJMB0PQkiCmDcJuZCu93Dm6L0X44HPPYwbd2OPwKaH0xRNcv/furWGp6tqvp5y9JZWVb2rb80kF+ASFleX4xYe2OtcV6veZ1mnPngDsZeszQCvtG/tbdWxk/bzzPzno2fwUCgMMbHM7VR1/Nb7v+li27t/D1iq/5asVXfLXiK9ZsX1PodToldAoWF1oPoH+r/rSKb1Uh80OwZPHK/Fe49eNb2bAzuI3X5d0u59FTHyWhdkKZv9dPm37iq+XBlSbO63AetaJqlel7VCaTfpzEBa9fAEBkeCQDWg3ILyd0SujkqgmVhEWFIhh4JUnV3VtvwfnnB69PmBAsDxyqadPgqqtgwYLg7Usugb//HRIOkJ3LequHyuCDD+DMM4NbZfzxj/D++27tUFnV9GxX089fklQDrHwLvsoNt30nQJtihNuN02D6VZCaG25bXwI9/g6xBwi3Zb3VQ2Ww+gOYcmZwq4wOf4TV77u1QyVV07NdTT9/SToUOYEc1u1YV3A1hH0KCQdadSBPXGQcreu3pnV8a1rFt6J1fGta199zvWmdpkyYN4EHpjzA8pTlQPCb6ncfdzdXdL+CqIiocjm3Kb9M4dnZzzLpx0mkZ6cDEBMRw+COg7nm6Gs4vs3xRa5CEAgE+Hnbz8HiwvJgcWHh5oWFjmsV34oBrYKlhQGtBtAhoUOJVzU4kMWbF3PDBzfw2bLPAGjXqB3jfjWOE9qcUObvVVO9v+h9MnMyOemwk6gXY26ojCwqFMHAK0mqzhYsgN69Yft2uOUW+Nvfiv8aaWnwwAPwyCPBbQ0aN4Ynn4SLLiq8DW55b/UQSr/9Lbz88p7bbu1QOdX0bFfTz1+SVM2lLICPe0PWdmh3C/QoQbjNToN5D8BPjwS3NYhpDD2fhFZFhNvy3uohlKb+Fn7ZK9y6tUOlVNOzXU0/f0kqyq7MXXy69FPeWfgO/13+X1akrCAzJ/Ogz2sU16jIIkLe7ca1Gh/St84zsjN4btZz/PmrP+evWHB4g8O59/h7+XWXXxNRBhlizfY1vPT9Szw3+zmWbl2af3/Xpl255uhr+HXXX5doC4eNOzfmr7jw9YqvmbV2Ftl521zlahjXkP6t+tM/qT9HNz+a7JxsdmftJi0rjd2ZuT/3ul3gseyCx+x9/Zdtv5CRnUFsZCwjB4zktr63VdhqFFJlYVGhCAZeSVJ1tX17sKSwYAEcdxx89hlElaLcPHNmcHWFuXODt889N7idQ/PmwdsVvdVDRdu8GX71q+CqCkOGuLVDZVXTs11NP39JUjWWuT1YUkhdAE2Og5M+g/BShNstM+Gbq2BbbrhteW5wO4e43HBb0Vs9VLT0zfDlr4KrKhw2xK0dKqmanu1q+vlLUp4NOzfwn0X/4Z2F7/Dp0k/ZnbW7wOPhYeG0rNdyTwEhr4ywVxGhdnTZFi13Z+7m6ZlPM+rrUfnbGLRr1I77TriPizpdVOxVCbJysvhg8Qc8O+tZPlj8QX6BoG50XS7rchnXHHMNPZr3KNMl/Hdk7OCbVd/w1fKv+Hrl13yz6ht2Ze4qs9ff12ltT+OpQU/RtmHbcnsPqTKzqFAEA68kqToKBODCC2HSpOC2BLNmQdOmpX/djAz461/hz3+GzMzgB/V/+xusXl29tnpQ1VXTs11NP39JUjUVCMDXF8LKScFtCU6fBXFlEG6zM+DHv8IPf4acTIiqH1ylYdfq6rXVg6qsypbtxo4dy6OPPsq6devo1q0bTzzxBL179y7y2MzMTEaNGsVLL73E6tWradeuHQ8//DCnn376Ib9fZTt/SapIizYv4p0F7/DOwneYunIqAfZ8ZNc6vjXntDuHM486k3aN2tGiXgsiwyNDMufOjJ2M/XYsD//vYbbs3gJAlyZdeODEBzin3TkHLRYs3ryY52c/z4tzXmTdjnX59/dv1Z9rjr6GCzpeUOYli/3JzM5k1tpZ+asuLNq8iJjIGOIi44iNjCUuKvdn5D4/97q/0DG5txvFNaJjQscyLVpIVY1FhSIYeCUpdLZsCX47P+/yww/QqBGcdRacffaeb+qHSno6zJkD334bvMyfD23awIABwRUKunatvMv9P/II3H57cAWF//4Xjj22bF9/3rzg6grffVfw/uq01YOqppqe7Wr6+UtSSKVvCX47P//yA8Q0ghZnQcuz93xTP1Sy02HrHNjyLWz+FlLmQ+02kDAguEJB/a6Vd7n/Hx+B728PrqBwyn+hcRmH223zgqsrbNkn3FanrR5UJVWmbPfqq68yZMgQxo0bR3JyMmPGjOH1119n4cKFNGnSpNDxt99+Oy+//DLPPPMM7du35+OPP2b48OFMnTqVo48++pDeszKdvySVt5xADtNXTeedhcFywoJNCwo8fkzzYzin3Tmc0+4cujbtWuk+8E5NT+Xxbx7nsWmPkZKeAkCP5j144MQHOOOIMwrMuztzN5N+msSzs55lyvIp+fcn1Ergiu5XcNXRV9G+cfsKPwdJ5cuiQhEMvJJU/jIzYeHCgqWEuXOD38I/kN694ZxzgpeOHQtvGVuWsrODWyTklRJmzAiWFDIPsMVbvXrQt2+wtDBgAPTqBTGVYGuxzz6DgQODqxuMGwe/+135vE9WFoweHVxJITy8+m31oKqppme7mn7+klQhcjIhdeGeQsLW3J+7DxJuG/WGludAi3OC39Ivz3Cbkx3cIiGvlLB5BmybE5x9f6LqQeO+wdJCwgBo1AsiKkG4XfcZfDEwuLpBr3FwZDmF25wsWDAa5t4T3A6hum31oCqpMmW75ORkevXqxZNPPglATk4OSUlJ3HTTTYwYMaLQ8YmJidx1113ceOON+fcNHjyYuLg4Xn755UN6z8p0/pJUHtKy0pi8bDJvL3ib9xa9x/qd6/MfiwyP5MQ2J3JOu3M4u93ZJMUnhXDSQ7d191Yem/YYj09/nB0ZOwDo07IPD574IA3jGvLc7Od4ee7L+WWG8LBwBrYdyDXHXMOvjvoV0RHRoRxfUjmyqFAEA68klZ1AANavL1xI+PHH/X/gf9hhwZUJunaFzp1hyRJ4912YPr3gcW3bBgsLZ58N/fpBZClWMwsEYMWKYBkhr5Qwcybs2FH42EaNgoWJXr2CMy5aBF99Bf/7H6SmFjw2JgaSk/esuNCnD9StW/I5S2L5cujRAzZvDq548Oyz5fs3cIB1uauyNWtWvu8jHYqanu1q+vlLUpkKBCBtfeFCQuqP+//Av/Zh0KBrcHWC+M6wYwmsehc27xNu67TNLS2cDQn9oDRL9QYCsGtFsIyQV0rYMhOyigi3MY2gYe9gCaF+V9i+CDZ8BZv+B5n7hNvwGGicvGfFhcZ9IKqCw+3O5fBRD0jfDIdfBckVEG5354bbOMOtQq+yZLuMjAxq1arFG2+8wbnnnpt//+WXX862bdt45513Cj2nUaNGPPLII1x99dX59/3mN7/h66+/5pdffinyfdLT00lPT8+/nZqaSlJSUsjPX5LK0uZdm3l/8fu8s/AdPl7yMTszd+Y/Vi+mHoOOHMQ57c7hjCPOID42PoSTls6mXZt45H+P8OSMJ9mdtbvQ463jW3P10VdzRfcrqkwJQ1LpWFQoQmUJ/JJU1aSlBQsI+5YSNm4s+vi6dfcUEvYuJuzvP71r18J778E778DkycFtGPI0agRnnhksLpx2GtSpc+BZN24suFLCt98WPWft2sEP+Xv12lNOaNOm6L+FZmcHz/err4KX//4XNmwoeExEBHTvvmfFhf79ISHhwLOWRlpa8D1mzoSePYNzxcaW3/tJlVFNz3Y1/fwlqcSy0yDlx4KFhG1zIX0/4Tay7p5CQv6lc3BVgqLsXgur34NV78C6yZCzV7iNaQSJZwaLC81Og6iDhNu0jcFCwpZv95QTipozsjY07AENewVXc2jUK7jVQ1HhNic7eL4bvwoWFzb+F9L2CbdhEdCgOyQcB00GQEJ/iC3HcJudBp/2D5YuGvaEU7+CCMOtapbKku3WrFlDixYtmDp1Kn369Mm//09/+hNTpkxh+r7fNAAuu+wy5syZw9tvv03btm2ZPHky55xzDtnZ2QXKCHu77777uP/++wvdH+rzl6TSWrZ1Ge8sCG7p8PWKr8kOZOc/1rJeS84+6mzObX8ux7c5vtqtKLBuxzpGfTWKcTPHAXBe+/O45phrOOmwkwgPCw/xdJIqkkWFIlSWwC9JlVUgACtXFi4kLFoU/LB+X+HhcOSRhUsJrVuX/MtPO3bAxx8HSwvvvw9btux5LCYGTjklWFo466xgaWHmzIKlhKK+rBEZCd26FSwldOgQLBeURCAAixcHCwt55YWffy58XIcOwdJC3qoLrVqV7P2Kev+rr4YXXggWOWbODP7OpZqmpme7mn7+knRQgQDsWll4lYTtiyBQRLgNC4e6R+5TSOgKtUsRbjN3wNqPg6WFNe9Dxl7hNjwGmp2Su9rCWRBZJ/hB/d6lhJ2/FDFnJDToVrCUUK8DhJci3G5fDBv+u6e8sLOIcFuvQ25pIXfVhdplGG6nXw3LXggWOU6fGfydSzVMZcl2JSkqbNy4kaFDh/Lee+8RFhZG27ZtOeWUU3j++efZvbvwN2vBFRUkVR85gRxmrpnJOwuD5YT5G+YXeLxb026c3e5szml3Dsc0P4aw8l4xqhLYnr4dgLoxFbxCl6RKw6JCESpL4JekyiIQgJ9+gk8/DV7+9z/Ytq3oYxs2DH7Yv3choWNHqFWr/ObLygrO9M47wcuyZQUfDw+HnJzCz2vfvmApoVu38l9tYNWqgisu/PBD4WMaN4boMihK5+QEt2AIDw+WOk45pfSvKVVFNT3b1fTzl6RCAgFI/QnWfgrrPoWN/4PMbUUfG90w+GH/3oWE+I4QWY7hNicrONOqd2D1O7Bjn3AbFg6BIsJtvfYFSwkNupX/agO7VuWutvBVsMCQUkS4jWkM4WUQbgM5kLYueP4nfhwsb0g1UGXJdiXZ+iFPWloamzdvJjExkREjRvCf//yHH4r6P8dFqCznL0mHIj0rnS9++YJ3FrzDu4veZc32NfmPRYRFcFzr4zin3Tmc0/4c2tRvE7pBJSlEipPtSrE5oiSpqlm/Hj77LFhM+OwzWL264OORkcGVAPZdJaF58/LfInZfkZFw/PHBy2OPBT/8f+cdePfd4AoKOTnQsuWeQkLv3sHtHOJDsKVby5Zw6aXBC8DmzcGSRd6qCzNnwqZNZfd+YWHw6KOWFCRJUg23ez2s+yxYTFj3GezeJ9yGRUJ8h8KrJMSFINyGR0LT44OXYx4Lfvi/6h1Y/W5wBYVADtRqGSwk5BUTGvaA6BCE21otoc2lwQtA+uZgySJv1YUtMyG9DMMtYdD9UUsKUiUQHR1Njx49mDx5cn5RIScnh8mTJzNs2LADPjc2NpYWLVqQmZnJpEmTuOiiiypgYknV2ba0bcxaO4vFmxeTU1ShM9eBVikIo+jHSvKczJxMvvzlSz5a8hHbM7bn318nug6nH3E657Q7h0FHDqJhXMP9vrYkqSBXVJCkamzXruAH5XmrJsydW/DxmJjg1gSnngonnwxdupTNt/7L24YNwaJCs2ahnuTQ7NgBS5cGv+hXFho2LLutJKSqqqZnu5p+/pJqqKxdwW/6r8tdNWHbPuE2PCa4PUGzU6HZyRDfBarC3r9pG4JFhbgqEm4zd8COpUAZhdvohmW3lYRURVWmbPfqq69y+eWX8/TTT9O7d2/GjBnDa6+9xoIFC2jatClDhgyhRYsWjBo1CoDp06ezevVqunfvzurVq7nvvvv4+eefmTVrFvXr1z+k96xM5y8pNPJKCTPXzGTm2pl8t+Y7lm5dGuqx9qt5neb5WzqcdNhJxETGhHokSao0yn1FhbFjx/Loo4+ybt06unXrxhNPPEHv3r2LPDYzM5NRo0bx0ksvsXr1atq1a8fDDz/M6aefnn/Mfffdx/3331/gee3atWPBggX5t9PS0vjDH/7AxIkTSU9PZ+DAgTz11FM0bdq0JKcgSdVSTg7Mnl1wO4e9tn0EoHv3YDHh1FOhf3+IiwvJqKXSpEmoJyieOnWCW1BIqpzMtpJUSQVyYOvsgts55OwTbht0zy0mnAoJ/SGyCobb2CoWbqPqBLegkFQtXXzxxWzcuJF77rmHdevW0b17dz766KP8nLpixQrCw8Pzj09LS2PkyJEsW7aMOnXqMGjQIP79738fcklBUs2TkpYSLCXkFhJmrp3Jki1Lijy2Tf02dG7SmZiIoosAgQMUJw/0Hd39Pe9g3+vtlNCJc9qfQ8/EnoSHhR/wWEnSwRW7qPDqq68yfPhwxo0bR3JyMmPGjGHgwIEsXLiQJkV8cjRy5EhefvllnnnmGdq3b8/HH3/Meeedx9SpUzn66KPzj+vUqROfffbZnsEiC45266238v777/P6668THx/PsGHDOP/88/nf//5X3FOQpGpl+fI9xYTJk4PbDuytZcs9xYSTT656H/JLUnky20pSJbNz+Z5iwvrJwW0H9lar5Z5iQrOTq96H/JJUBQwbNmy/Wz18+eWXBW4ff/zx/PjjjxUwlaSqaO9SQl4x4UClhB7Ne9AzsSc9mvfgmObH0KhWowqeWJJUkYq99UNycjK9evXiySefBIL7lCUlJXHTTTcxYsSIQscnJiZy1113ceONN+bfN3jwYOLi4nj55ZeB4LfO3n77bb7//vsi3zMlJYWEhAQmTJjABRdcAMCCBQvo0KED06ZN49hjjz3o3C4hJqm6SEmBL77YU05YvLjg43XqwIkn7ikntGtX8VvwSlJ5K6tsZ7aVpBDLSIH1X+zZzmH7PuE2sg40PXFPOaGe4VZS9VPTs11NP3+pukhNT83fvuG7td8xc81MFm9ZXOSxeaWEHs170CMx+NNSgiRVD+W29UNGRgYzZ87kjjvuyL8vPDycU045hWnTphX5nPT0dGJjYwvcFxcXx9dff13gvsWLF5OYmEhsbCx9+vRh1KhRtMrdgHvmzJlkZmZyyimn5B/fvn17WrVqtd8/5qanp5O+13rnqampxTlVSao0MjNh+vQ9xYQZMyA7e8/jERHQu/eeYkJyMkRFhW5eSaoqzLaSFAI5mbBp+p5iwuYZENgr3IZFQKPee4oJjZMh3HArSZKqnrSsND5c/CFvLniTHRk7aBjbkIZxDWlUq1HwZ1yjQrfjoqrGNlZ7lxLyVkrYXymhdXxreiT2oGfznvRIDK6U0LhW4wqeWJJUGRWrqLBp0yays7ML7Z3btGnTAnvu7m3gwIGMHj2a4447jrZt2zJ58mTefPNNsvf6lC05OZkXX3yRdu3asXbtWu6//34GDBjA/PnzqVu3LuvWrSM6OrrQ3mZNmzZl3bp1Rb7vqFGjCu0NLElVQSAACxfuKSZ8+SVs317wmCOP3FNMOPFEiI8PyaiSVKWZbSWpAgQCkLpwTzFh/ZeQtU+4rXvknmJC0xMh2nArSZKqpszsTD5b9hkTf5jIWz+9xfaM7Qd/0l5iI2PzCwz5JYbY/Zcb8u6LiYwppzMKlhJmr52dX0iYuXYmizYvKvLYvFLC3qslWEqQJO1PsYoKJfH4448zdOhQ2rdvT1hYGG3btuXKK6/k+eefzz/mjDPOyL/etWtXkpOTad26Na+99hpXX311id73jjvuYPjw4fm3U1NTSUpKKvmJSFI5SU2FOXNg9myYORM+/xxWrSp4TKNGcPLJe8oJrVuHZlZJqunMtpJ0EJmpsHUObJ0NW2bC+s9h1z7hNqYRND05WExofirUNtxKkqSqKzsnm69WfMXE+RN548c32Lx7c/5jLeu15JJOl9C2YVu27N7C5l2b2ZKW+3P3luB9u4PXs3KySMtKY/X21azevrpYM9SKqlXkCg17lxn2faxBXAOiI6ILvM7epYS8YsL+Sgmt4lvRo3kPeib2tJQgSSqRYhUVGjduTEREBOvXry9w//r162nWrFmRz0lISODtt98mLS2NzZs3k5iYyIgRIzj88MP3+z7169fnqKOOYsmSJQA0a9aMjIwMtm3bVuCbZwd635iYGGJiyq9FKEklsX59sJCw9yX3P3UFREdD//57iglHHw3h4RU/ryRVZ2ZbSSql3euDhYS8y5bZsKOIcBseDQn99xQTGhwNYYZbSZJUdQUCAWasnsEr81/htR9eY+2OtfmPNandhAs7XsglnS+hb1Jfwg8h9wQCAbZnbN9TZtinxHCggkNOIIddmbvYlbmLlakri3UedaPr5pcZdmXuYtHmRQQIFDour5SQV0jo0bwHCbUTivVekiTtq1hFhejoaHr06MHkyZM599xzAcjJyWHy5MkMGzbsgM+NjY2lRYsWZGZmMmnSJC666KL9Hrtjxw6WLl3Kb3/7WwB69OhBVFQUkydPZvDgwQAsXLiQFStW0KdPn+KcgiRViEAAfv65cClh7dqij2/RIlhGOPpo6NcPBgyAWrUqdmZJqmnMtpJ0iAIB2PlzsIiwdzFh937CbVyLYBmh4dHQuB80GQCRhltJklS1BQIB5q6fy8T5E5n4w0R+2fZL/mP1Y+szuMNgLul8CSe0OYHI8OItZh0WFka9mHrUi6lHm/ptDvl5OYEcUtNTi11w2Lp7KwGC5YjtGdtZnrI8/zWT6iXRI7EHPZv3tJQgSSpXxd76Yfjw4Vx++eX07NmT3r17M2bMGHbu3MmVV14JwJAhQ2jRogWjRo0CYPr06axevZru3buzevVq7rvvPnJycvjTn/6U/5q33XYbZ511Fq1bt2bNmjXce++9REREcOmllwIQHx/P1VdfzfDhw2nYsCH16tXjpptuok+fPhx77LFl8XuQpBLLyoIFCwoWEr7/HrZtK3xsWBgceeSeUkLeJcGsL0khYbaVpH3kZEHqgj0rJGydDVu/h8xtRRwcBnWP3FNKaJB7iTXcSpKk6mPR5kXBcsL8ify06af8+2tH1eac9udwSadLOK3tacREVvwqeOFh4dSPrU/92Poc3mD/K/3tKyeQw7a0bQUKDuFh4Rzd/Gia1G5SjhNLkrRHsYsKF198MRs3buSee+5h3bp1dO/enY8++oimTZsCsGLFCsL3Wp88LS2NkSNHsmzZMurUqcOgQYP497//XWCZ21WrVnHppZeyefNmEhIS6N+/P9988w0Je31y97e//Y3w8HAGDx5Meno6AwcO5KmnnirFqUtS8e3eDXPnFiwlzJsHaWmFj42Kgs6dCxYSunWDOnUqfm5JUtHMtpJqtKzdsG1uwa0bUuZBdhHhNjwK4jvvKSM0PBrqd4Mow60kSap+lm9bzms/vMYr819h9rrZ+ffHRMQw6MhBXNr5Us486kxqRVXNVaPCw8Lzt3w4ouERoR5HklRDhQUCgcIbDlVDqampxMfHk5KSQr169UI9jqQqYOvW4MoIs2fDrFnBnwsWQE5O4WPr1AmWEI45Zk8poWNHiI6u8LElqUao6dmupp+/pBLI2BpcGWHLbNg6K1hMSF0AgSLCbWQdaNANGhyzp5RQryNEGG4lqTzU9GxX089flce6Het4/YfXmfjDRKaunJp/f0RYBKe1PY1LOl/COe3OIT42PoRTSpJUuRUn2xV7RQVJqm4CAVizpuAqCbNnwy+/FH18QkLhrRuOOAL2+sKtJEmSFBqBAOxes8/WDbNh5y9FHx+TUHjrhrpHQJjhVpIkVX9bdm/hzZ/eZOL8iXzxyxfk5JY4wwjj+DbHc0mnSxjccTCNazUO8aSSJFU/FhUk1Tg7dsB338H06fDNN8Gfa9cWfWybNoVLCYmJEBZWoSNLkiRJRcvcAVu+g83TYdM3wZ+79xNua7cpuHVDg6MhznArSZJqlu3p23ln4TtMnD+Rj5d+TFZOVv5jx7Y8lks6XcKFnS4ksW5iCKeUJKn6s6ggqVrLzoaffgqWEfKKCT/8UHj7hvBw6NChYCGhe3do0CAkY0uSJEmF5WRD6k+5pYTpsPkbSPmh8PYNYeFQr8M+pYTuEG24lSRJNdPuzN18sPgDJv4wkf8s+g9pWWn5j3Vr2o1LOl/CxZ0u5rAGh4VwSkmSahaLCpKqlXXrCpYSvvsOtm8vfFzLlpCcDMceG/x5zDFQu3bFzytJkiTt1+51BUsJm7+DrCLCba2W0CgZGh8b/NnwGIg03EqSpJotIzuDz5Z9xivzX+HtBW+zI2NH/mNHNTqKSztfysWdLqZDQocQTilJUs1lUUFSlbV7N8yaVXALhxUrCh9Xuzb06hUsJORdEl25TZIkSZVJ1m7YOmtPKWHTdNhVRLiNrA0Ne0Hj5GApoVEy1DLcSpIkAWTnZDNl+RQmzp/IpJ8msWX3lvzHWsW34pJOl3BJ50vo3qw7YW5/JUlSSFlUkFQl5OTA4sUFV0uYOxeysgoeFxYGnToVLCV06gQREaGZW5IkSSokkAPbF+eWEqbDpm9g21wI7BNuCYP4TgVLCfGdINxwK0mSlCcQCPDNqm+YOH8ir/34Gut2rMt/rGntplzU6SIu7XwpyS2TCQ8LD+GkkiRpbxYVJFVKmzbBjBl7SgkzZsC2bYWPa9asYCmhZ0+oV6/Cx5UkSZL2L20TbJ6xp5SweQZkbit8XGyzgqWERj0hynArSZK0r0AgwJz1c3hl3iu8+sOrLE9Znv9Yg9gGXNDxAi7pfAnHtz6eCEuekiRVShYVpGogOxsmTYJVq4LbHNSqteey7+28++LiILySFIjT02HOnIJbOCxdWvi42Fjo0aNgMaFVq+AqCpIkSaomcrJh5STYtSq4zUFkLYioFfwZWXvP9QL3xUFl+XZcdjpsnbNXKWE67Cgi3EbEQsMee0oJjZOhluFWkiTpQBZsWsDE+ROZOH8iCzcvzL+/TnQdzm1/Lpd0uoRT255KdER0CKeUJEmHwqKCVMXNmwdDhwY/3C+u2Niiywz7KzcU53beZd8yRCAAP/9csJQwezZkZBSer127PYWEY4+FLl0gKqpkvydJkiRVAdvmwfShwQ/3iysiNre8sE+5IWLf20UcU6gAUdRzahUuQwQCsPPn4BYOeaWErbMhp4hwW6/dXqWEY6F+Fwg33EqSJB2K9xa+x91f3M2c9XPy74uNjOXMI8/k0s6XMujIQcRFxYVwQkmSVFwWFaQqKi0NHnwQHnkEsrKC2x0MGhRcnWDnTti1a89l79u7dxd8jbQ02LKl/ObMK0PklRm2bIGNGwsf16jRnkJCcjL06gUNGpTfXJIkSapEstNg/oPw4yMQyApud5A4KLg6QdZOyN4FWbtyf+59e3fB18hOg4xyDLf5ZYjcMkP6FkgvItzGNMotJRybu5VDL4g23EqSJJXEt6u/5YLXLyAjO4PI8EgGth3IJZ0v4ex2Z1Mvxm2yJEmqqiwqSFXQl1/CtdfC4sXB2+edB088AS1aHPy5OTnBcsKBygxF3T6UY/JuH6wMER0N3bvvKSUkJ8Phh7vKrSRJUo20/kuYcS1szw23Lc+Dnk9ArUMIt4GcYDmhqDJD/vV9yw37u2+f52TvPLQyRHg0NOi+VykhGeoYbiVJksrC5l2b80sKZ7c7m+fPfp5GtRqFeixJklQGLCpIVcjWrfDHP8JzzwVvN28OY8cGiwqHKjx8zwoH5SWvDFFUmSE2Frp2hZiY8nt/SZIkVQEZW2H2H2FpbriNaw49x0JSMcJtWHju6gblGG7zyxB7lxdyywwRsVC/K0QYbiVJkspaTiCH37z1G1akrOCIhkfwr3P/RXxsfKjHkiRJZcSiglQFBALw2mtw882wfn3wvuuvh1GjIL4SZvO9yxCNG4d6GkmSJFUqgQCseA1m3gxpueH2yOuh2yiIroThtkAZwnArSZJUUf783z/z0ZKPiIuMY9JFkywpSJJUzVhUkCq5FSvghhvg/feDtzt0gGeegX79QjuXJEmSVGw7V8C3N8Ca3HBbrwMkPwMJhltJkiTt8cnST7jvy/sA+MeZ/6Br066hHUiSJJU5iwpSJZWdHdzW4a67YMcOiI6GO++EESPcNkGSJElVTE42LB4Lc+6CrB0QHg2d7oSOI9w2QZIkSQWsSFnBZZMuI0CAoccM5fLul4d6JEmSVA4sKkiV0Lx5MHQoTJ8evN2vX3AVhQ4dQjuXJEmSVGzb5sH0obA5N9wm9IPez0C84VaSJEkFpWelc+HrF7J592aOaX4Mfz/j76EeSZIklROLClIlkpYGDz4IjzwCWVlQrx48/DBcey2Eh4d6OkmSJKkYstNg/oPw4yMQyIKoetD9YTjiWggz3EqSJKmwP3zyB2asnkGD2Aa8ceEbxEbGhnokSZJUTiwqSJXEF1/A734HixcHb59/Pvz979CiRWjnkiRJkopt/Rcw43ewPTfcJp0PPf4OtQy3kiRJKtqEeRMY++1YAP593r85rMFhIZ5IkiSVJ4sKUoht2QJ//CM8/3zwdmIijB0L554b0rEkSZKk4kvfArP/CMtyw21cIvQcC0nnhnQsSZIkVW4/bPiBoe8NBeCuAXdx5lFnhngiSZJU3iwqSCESCMBrr8Hvfw8bNgTvu/56GDUK4uNDO5skSZJULIEArHgNZv4e0nLD7ZHXQ7dREG24lSRJ0v5tT9/O4NcGsytzFycfdjL3n3B/qEeSJEkVwKKCFAIrVsANN8D77wdvd+gAzzwD/fqFdi5JkiSp2HaugG9vgDW54bZeB0h+BhIMt5IkSTqwQCDANe9dw8LNC2lRtwWvDH6FiPCIUI8lSZIqgEUFqQJlZ8OTT8Jdd8HOnRAdDXfeCSNGQExMqKeTJEmSiiEnGxY9CXPvgqydEB4Nne6EjiMgwnArSZKkg/v79L/z2g+vERkeyesXvk5C7YRQjyRJkiqIRQWpgsydC0OHwowZwdv9+gVXUejQIbRzSZIkScW2dS7MGAqbc8NtQj/o/QzEG24lSZJ0aKaunMptn94GwGOnPUafpD4hnkiSJFUkiwpSOdu9Gx58EB59FLKyoF49eOSRYGkhPDzU00mSJEnFkLUb5j8IPz0KgSyIqgfdH4EjhkKY4VaSJEmHZsPODVz4+oVk5WRxUaeLuKn3TaEeSZIkVTCLClI5+uILuPZaWLIkePv88+GJJyAxMbRzSZIkScW2/guYfi3syA23SedDjyegluFWkiRJhy47J5vLJl3Gmu1raN+4Pc+e9SxhYWGhHkuSJFUwiwpSOdiyBf74R3j++eDtxEQYOxbOPTekY0mSJEnFl74FZv8RluWG27hE6DkWks4N6ViSJEmqmu798l4m/zyZ2lG1mXTRJOrG1A31SJIkKQQsKkhlKBCAV1+Fm2+GDRuC911/PYwaBfHxoZ1NkiRJKpZAAJa/CrNuhrTccHvk9dBtFEQbbiVJklR8/1n0H/7y1V8AeOasZ+iY0DHEE0mSpFCxqCCVkRUr4IYb4P33g7c7dIBnnoF+/UI7lyRJklRsO1fAtzfAmtxwW68DJD8DCYZbSZIklczPW3/mt2/9FoBhvYZxaZdLQzyRJEkKJYsKUillZ8OTT8Jdd8HOnRAdDXfeCSNGQExMqKeTJEmSiiEnGxY9CXPvgqydEB4Nne6EjiMgwnArSZKkkknLSuOC1y9gW9o2klsk89jAx0I9kiRJCjGLClIpzJ0LQ4fCjBnB2/37wz//GVxNQZIkSapSts6FGUNhc264TegPvf8J8YZbSZIklc7vP/w9s9bOolFcI16/8HWiI6JDPZIkSQoxiwpSCezeDQ8+CI8+CllZUK8ePPJIsLQQHh7q6SRJkqRiyNoN8x+Enx6FQBZE1YPuj8ARQyHMcCtJkqTSefH7F3lm1jOEEcYrg18hKT4p1CNJkqRKwKKCVEyffw6/+x0sWRK8ff758MQTkJgY2rkkSZKkYlv3Ocz4HezIDbdJ50OPJ6CW4VaSJEmlN2fdHK5//3oA7j/hfk5te2qIJ5IkSZWFRQXpEG3ZArfdBi+8ELydmAhjx8K554Z0LEmSJKn40rfA7NtgWW64jUuEnmMh6dyQjiVJkqTqY1vaNga/Npi0rDTOOOIM7jrurlCPJEmSKhGLCtJBBALw6qtw882wYUPwvuuvh1GjID4+tLNJkiRJxRIIwPJXYdbNkJYbbo+8HrqNgmjDrSRJkspGIBDgyneuZOnWpbSKb8W/z/s34W4rJkmS9mJRQTqAFSuCpYQPPgje7tABnnkG+vUL7VySJElSse1cAd9eD2tyw229DpD8DCQYbiVJklS2/m/q//H2greJjojmjQvfoFGtRqEeSZIkVTIWFaQiZGfDk0/CXXfBzp0QHR28fvvtEBMT6ukkSZKkYsjJhkVPwty7IGsnhEdDp7ug4+0QYbiVJElS2ZryyxRGTB4BwOOnP06vFr1CPJEkSaqMLCpI+5gzB4YOhW+/Dd7u3x/++c/gagqSJElSlbJ1DkwfCltyw21Cf+j9T4g33EqSJKnsrd2+lovfuJicQA6/7fpbftfjd6EeSZIkVVIWFaS9PPkk3HorZGVBvXrwyCPB0kK426dJkiSpqln4JMy6FQJZEFUPuj8CRwwF9waWJElSOcjMzuTiNy5m/c71dG7SmXG/GkdYWFiox5IkSZWUf6GSci1eDMOHB0sK558PP/0Ev/udJQVJkiRVQamLYfbwYEkh6Xw48yc48neWFCRJ0kGNHTuWNm3aEBsbS3JyMjNmzDjg8WPGjKFdu3bExcWRlJTErbfeSlpaWgVNq8rkzsl38tWKr6gbXZdJF02iVlStUI8kSZIqMVdUkHLddhtkZsIZZ8CkSaGeRpIkSSqF2bdBTiY0PwMGGG4lSdKhefXVVxk+fDjjxo0jOTmZMWPGMHDgQBYuXEiTJk0KHT9hwgRGjBjB888/T9++fVm0aBFXXHEFYWFhjB49OgRnoFB586c3+b9p/wfAi+e+yFGNjgrxRJIkqbLz6zQS8Nln8O67EBEBjz0W6mkkSZKkUlj3Gax+F8Ii4BjDrSRJOnSjR49m6NChXHnllXTs2JFx48ZRq1Ytnn/++SKPnzp1Kv369eOyyy6jTZs2nHbaaVx66aUHXYVB1cvizYu58p0rARh+7HDO73B+iCeSJElVgUUF1XhZWXDLLcHrN94IHTqEdBxJkiSp5HKyYOYtwetH3gjxhltJknRoMjIymDlzJqecckr+feHh4ZxyyilMmzatyOf07duXmTNn5hcTli1bxgcffMCgQYP2+z7p6emkpqYWuKjq2pW5i8GvDSY1PZX+rfrz11P+GuqRJElSFVGiokJx9inLzMzkgQceoG3btsTGxtKtWzc++uijAseMGjWKXr16UbduXZo0acK5557LwoULCxxzwgknEBYWVuBy3XXXlWR8qYBnnoEffoCGDeHee0M9jSRJqmhmW1UrS5+BlB8guiF0MdxKkqRDt2nTJrKzs2natGmB+5s2bcq6deuKfM5ll13GAw88QP/+/YmKiqJt27accMIJ3Hnnnft9n1GjRhEfH59/SUpKKtPzUMUJBAJc//71zNswj6a1m/LqBa8SFREV6rEkSVIVUeyiQt4+Zffeey+zZs2iW7duDBw4kA0bNhR5/MiRI3n66ad54okn+PHHH7nuuus477zzmD17dv4xU6ZM4cYbb+Sbb77h008/JTMzk9NOO42dO3cWeK2hQ4eydu3a/MsjjzxS3PGlArZuhbvvDl5/4IFgWUGSJNUcZltVKxlbYW5uuO36AMQYbiVJUvn68ssveeihh3jqqaeYNWsWb775Ju+//z4PPvjgfp9zxx13kJKSkn9ZuXJlBU6ssvTMrGf415x/ER4WzsQLJpJYNzHUI0mSpCokLBAIBIrzhOTkZHr16sWTTz4JQE5ODklJSdx0002MGDGi0PGJiYncdddd3Hjjjfn3DR48mLi4OF5++eUi32Pjxo00adKEKVOmcNxxxwHBb511796dMWPGFGfcfKmpqcTHx5OSkkK9evVK9Bqqfm69FcaMgY4dYc4ciIwM9USSJOlQlFW2M9uqWpl5KywcA/Ed4Yw5EG64lSSpKqgs2S4jI4NatWrxxhtvcO655+bff/nll7Nt2zbeeeedQs8ZMGAAxx57LI8++mj+fS+//DLXXnstO3bsIDz84N+Tqyznr+L5bs139Hu+HxnZGfz15L9ye//bQz2SJEmqBIqT7Yq1okJJ9ilLT08nNja2wH1xcXF8/fXX+32flJQUABru8/X28ePH07hxYzp37swdd9zBrl27ijO+VMCCBZD7mQR/+5slBUmSahqzraqVlAWwKDfcHvM3SwqSJKnYoqOj6dGjB5MnT86/Lycnh8mTJ9OnT58in7Nr165CZYSIiAgguC2Aqqctu7dwwWsXkJGdwTntzuFP/f4U6pEkSVIVVKy/Xh1on7IFCxYU+ZyBAwcyevRojjvuONq2bcvkyZN58803yc7OLvL4nJwcbrnlFvr160fnzp3z77/sssto3bo1iYmJzJ07l9tvv52FCxfy5ptvFvk66enppKen599OTU0tzqmqBvjDHyArC371KzjttFBPI0mSKprZVtXK7D9AIAsSfwXNDbeSJKlkhg8fzuWXX07Pnj3p3bs3Y8aMYefOnVx55ZUADBkyhBYtWjBq1CgAzjrrLEaPHs3RRx9NcnIyS5Ys4e677+ass87KLyyoeskJ5PDbt37L8pTltG3QlhfPfZGwsLBQjyVJkqqgcv+azeOPP87QoUNp3749YWFhtG3bliuvvJLnn3++yONvvPFG5s+fX+hbaddee23+9S5dutC8eXNOPvlkli5dStu2bQu9zqhRo7j//vvL9mRUbXz0EXzwAURFwWOPhXoaSZJUVZhtVSmt+QjWfADhUXCM4VaSJJXcxRdfzMaNG7nnnntYt24d3bt356OPPsov965YsaLACgojR44kLCyMkSNHsnr1ahISEjjrrLP4y1/+EqpTUDkb9dUoPlj8AbGRsbxx0RvUj60f6pEkSVIVVaytHxo3bkxERATr168vcP/69etp1qxZkc9JSEjg7bffZufOnSxfvpwFCxZQp04dDj/88ELHDhs2jP/85z988cUXtGzZ8oCzJCcnA7BkyZIiH7/jjjtISUnJv6xcufJQTlE1QGYmDB8evH7TTXDUUaGdR5IkhYbZVtVCTibMyg23R90E9Qy3kiSpdIYNG8by5ctJT09n+vTp+VkV4Msvv+TFF1/Mvx0ZGcm9997LkiVL2L17NytWrGDs2LHUr1+/4gdXufts2Wfc/cXdADw16Cm6N+se2oEkSVKVVqyiQkn2KcsTGxtLixYtyMrKYtKkSZxzzjn5jwUCAYYNG8Zbb73F559/zmGHHXbQWb7//nsAmjdvXuTjMTEx1KtXr8BFAhg3Dn76CRo3hrvvDvU0kiQpVMy2qhYWj4PUnyCmMXQ23EqSJKl8rEpdxaWTLiVAgKuPvporj74y1CNJkqQqrthbPxR3n7Lp06ezevVqunfvzurVq7nvvvvIycnhT3/6U/5r3njjjUyYMIF33nmHunXrsm7dOgDi4+OJi4tj6dKlTJgwgUGDBtGoUSPmzp3LrbfeynHHHUfXrl3L4vegGmLzZrj33uD1Bx8Ey92SJNVsZltVaembYV5uuO36IETXD+k4kiRJqp4ysjO48PUL2bRrE0c3O5onzngi1CNJkqRqoNhFheLuU5aWlsbIkSNZtmwZderUYdCgQfz73/8usPzXP/7xDwBOOOGEAu/1wgsvcMUVVxAdHc1nn32W/4fjpKQkBg8ezMiRI0twyqrJ7rsPtm6FLl3gmmtCPY0kSQo1s62qtHn3QcZWqN8F2hpuJUmSVD7++Mkf+WbVN9SPrc8bF71BXFRcqEeSJEnVQFggEAiEeoiKkJqaSnx8PCkpKS6VW0P9+CN07QrZ2TB5Mpx0UqgnkiRJJVXTs11NP38BKT/CB10hkA0nTYZmhltJkqqqmp7tavr5V3avzn+VSyZdAsC7l7zLWe3OCvFEkiSpMitOtgs/4KNSNREIwPDhwZLCuedaUpAkSVIVFgjArOHBkkLLcy0pSJIkqVz8tPEnrn73agDu6H+HJQVJklSmLCqoRvjgA/j4Y4iKgkcfDfU0kiRJUims+QDWfgzhUXC04VaSJEllb0fGDga/NpidmTs5sc2JPHDiA6EeSZIkVTMWFVTtZWQEV1MAuOUWOOKIkI4jSZIklVx2RnA1BYB2t0Bdw60kSZLKViAQYOh7Q/lp008k1k3klcGvEBkeGeqxJElSNWNRQdXe2LGwaBE0aQIjR4Z6GkmSJKkUFo+F7Ysgtgl0NtxKkiSp7I39diwT508kMjyS1y54jaZ1moZ6JEmSVA1ZVFC1tmkT3H9/8Ppf/gL16oV2HkmSJKnE0jbBvNxw2/UvEGW4lSRJUtn6ZtU3DP84uILXo6c+Sr9W/UI8kSRJqq4sKqhau+ceSEmB7t3hyitDPY0kSZJUCvPugcwUaNAdDjfcSpIkqWxt3LmRC1+/kMycTC7seCE3J98c6pEkSVI1ZlFB1da8efD008HrY8ZARERIx5EkSZJKbts8WJIbbo8ZA+GGW0mSJJWd7Jxsfv3mr1mVuoqjGh3Fs2c/S1hYWKjHkiRJ1ZhFBVVLgQDceivk5MDgwXD88aGeSJIkSSqhQABm3gqBHEgaDE0Nt5IkSSpb90+5n0+XfUqtqFpMumgS9WLcZkySJJUviwqqlt59FyZPhpgYePTRUE8jSZIklcLqd2H9ZAiPgaMNt5IkSSpbHyz+gAf/+yAA//zVP+ncpHOIJ5IkSTWBRQVVO+np8Ic/BK8PHw6HHRbaeSRJkqQSy06HWbnhtv1wqGO4lSRJUtn5Zdsv/ObN3wBwQ88b+HXXX4d4IkmSVFNYVFC188QTsHQpNGsGd9wR6mkkSZKkUlj0BOxYCrHNoJPhVpIkSWUnPSudC1+/kK1pW+ndojejB44O9UiSJKkGsaigamXDBngwuEoZDz0EdeuGdh5JkiSpxNI2wPzccNvtIYgy3EqSJKns3PLRLXy35jsaxTXi9QtfJyYyJtQjSZKkGsSigqqVkSMhNRV69IDLLw/1NJIkSVIpzBkJmanQsAccbriVJElS2fn3nH8zbuY4wghj/PnjaRXfKtQjSZKkGsaigqqN77+HZ58NXh8zBsL9t1uSJElV1dbvYWluuD1mDIQZbiVJklQ25q2fx+/+8zsA7jn+HgYeMTDEE0mSpJrIv3apWggE4JZbgj8vvhj69w/1RJIkSVIJBQIw8xYgAK0uhiaGW0mSJJWNlLQUBr82mN1ZuxnYdiB3H3d3qEeSJEk1lEUFVQtvvQVTpkBsLDz8cKinkSRJkkph1VuwYQpExMLRhltJkiSVjUAgwFXvXsXiLYtJqpfEy+e/TER4RKjHkiRJNZRFBVV5aWlw223B67fdBq1bh3YeSZIkqcSy02BWbrhtfxvUNtxKkiSpbPztm7/x5k9vEhUexRsXvUHjWo1DPZIkSarBLCqoyhszBn7+GRIT4fbbQz2NJEmSVAoLxsDOnyEuEToabiVJklQ2vlr+FX/69E8AjDl9DL1b9A7xRJIkqaazqKAqbe1a+Mtfgtf/+leoUye080iSJEkltnst/JAbbrv/FaIMt5IkSSq9dTvWcfEbF5MdyOayLpdxfc/rQz2SJEmSRQVVbSNHwo4d0Ls3/PrXoZ5GkiRJKoU5IyFrBzTqDW0Mt5IkSSq9rJwsLnnjEtbuWEunhE7881f/JCwsLNRjSZIkWVRQ1TVrFrzwQvD6mDEQ7r/NkiRJqqq2zIJlueH2mDEQZriVJElS6Y38fCRTlk+hTnQdJl00idrRtUM9kiRJEmBRQVVUIAA33xz8edll0KdPqCeSJEmSSigQgJk3AwFofRkkGG4lSZJUeu8seIeH//cwAM+f/TztGrcL8USSJEl7WFRQlfT66/D11xAXB3/9a6inkSRJkkphxeuw8WuIiIPuhltJkiSV3tItS7n87csBuCX5Fi7sdGGIJ5IkSSrIooKqnN274Y9/DF6//XZISgrtPJIkSVKJZe2G2bnhtuPtUNtwK0mSpNK78YMbSUlPoV9SPx459ZFQjyNJklSIRQVVOaNHw4oV0LLlnsKCJEmSVCUtGA27VkCtltDBcCtJkqTSy8jO4MtfvgTg6V89TVREVGgHkiRJKoJFBVUpa9bAqFHB6w8/DLVqhXYeSZIkqcR2rYEfc8Nt94ch0nArSZKk0vt+3fekZ6fTKK4RHRM6hnocSZKkIllUUJVyxx2wcyf06QOXXhrqaSRJkqRSmHMHZO2Exn2gteFWkiRJZWPaymkAHNvyWMLCwkI8jSRJUtEsKqjKmDED/vWv4PXHHwcztiRJkqqsTTPg59xw28NwK0mSpLIzbVWwqNA3qW+IJ5EkSdo/iwqqEgIBuOWW4PUhQ6BXr5COI0mSJJVcIACzbgleP2wINDLcSpIkqexMXTkVgD4t+4R4EkmSpP2zqKAqYeJEmDYNatWChx4K9TSSJElSKSyfCJumQUQt6Ga4lSRJUtlZnbqalakrCQ8Lp1cLC7GSJKnysqigSm/XLvjTn4LX77gDWrQI7TySJElSiWXtgu9zw22nO6CW4VaSJEllJ2/bh65Nu1Inuk6Ip5EkSdo/iwqq9B59FFatgtat4Q9/CPU0kiRJUin89CjsWgW1W0N7w60kSZLK1rSVwaJC35Z9QzyJJEnSgVlUUKW2ciU8/HDw+iOPQFxcaOeRJEmSSmznSvgxN9x2fwQiDbeSJEkqW3krKvRJ6hPiSSRJkg7MooIqtREjYPdu6N8fLrww1NNIkiRJpfD9CMjeDQn9oZXhVpIkSWUrPSudmWtnAtCnpUUFSZJUuVlUUKU1bRpMmABhYTBmTPCnJEmSVCVtnAbLJwBh0GOM4VaSJEllbtbaWWRkZ5BQK4HDGxwe6nEkSZIOyKKCKqWcHLjlluD1K66AHj1COY0kSZJUCoEcmHVL8PrhV0BDw60kSZLK3t7bPoRZjJUkSZWcRQVVSuPHw4wZUKcOPPRQqKeRJEmSSuGX8bB5BkTWgW6GW0mSJJWPvKJC35Z9QzyJJEnSwVlUUKWzYweMGBG8ftdd0KxZaOeRJEmSSixzB3yfG2473QVxhltJkiSVvUAgwNSVU4HgigqSJEmVnUUFVToPPwxr1sBhh+3Z/kGSJEmqkn58GHavgdqHQftbQj2NJEmSqqmVqStZs30NkeGR9EzsGepxJEmSDsqigiqV5cvh//4veP3RRyE2NrTzSJIkSSW2czksyA23Rz8KEYZbSZIklY9pK4PbPnRr2o1aUbVCPI0kSdLBWVRQpXL77ZCWBscfD+efH+ppJEmSpFKYfTtkp0GT4yHJcCtJkqTyM21VsKjQN6lviCeRJEk6NBYVVGl8/TW8+iqEhcGYMcGfkiRJUpW04WtY8SoQBj3GGG4lSZJUrqaunApAn5Z9QjyJJEnSobGooEohJwduuSV4/ZproHv3UE4jSZIklUIgB2bdErze9hpo0D2U00iSJKma2525m9nrZgPQJ8migiRJqhpKVFQYO3Ysbdq0ITY2luTkZGbMmLHfYzMzM3nggQdo27YtsbGxdOvWjY8++qjYr5mWlsaNN95Io0aNqFOnDoMHD2b9+vUlGV+V0EsvwcyZULcuPPhgqKeRJEk1idlWZW7ZS7BlJkTWha6GW0mSVLUUJx+fcMIJhIWFFbqceeaZFTixZq6dSVZOFs3qNKN1fOtQjyNJknRIil1UePXVVxk+fDj33nsvs2bNolu3bgwcOJANGzYUefzIkSN5+umneeKJJ/jxxx+57rrrOO+885g9e3axXvPWW2/lvffe4/XXX2fKlCmsWbOG8893n9fqYPt2uPPO4PW774amTUM7jyRJqjnMtipzmdthTm647Xw3xBluJUlS1VHcfPzmm2+ydu3a/Mv8+fOJiIjgwgsvrODJa7ZpK6cBwW0fwtxyTJIkVRFhgUAgUJwnJCcn06tXL5588kkAcnJySEpK4qabbmLEiBGFjk9MTOSuu+7ixhtvzL9v8ODBxMXF8fLLLx/Sa6akpJCQkMCECRO44IILAFiwYAEdOnRg2rRpHHvssQedOzU1lfj4eFJSUqhXr15xTlnl7M47YdQoaNsWfvgBYmJCPZEkSarsyirbmW1V5r6/E34cBXXawpk/QIThVpIkHVhlynbFzcf7GjNmDPfccw9r166ldu3ah/Selen8q6rzXz2ftxa8xaOnPsptfW8L9TiSJKkGK062K9aKChkZGcycOZNTTjllzwuEh3PKKacwbdq0Ip+Tnp5ObGxsgfvi4uL4+uuvD/k1Z86cSWZmZoFj2rdvT6tWrQ74vqmpqQUuqnx+/hlGjw5ef+wxSwqSJKnimG1V5nb8DAtyw+0xj1lSkCRJVUpJ8vG+nnvuOS655JIDlhTMtmUrEAgwdeVUILiigiRJUlVRrKLCpk2byM7Opuk+a/M3bdqUdevWFfmcgQMHMnr0aBYvXkxOTg6ffvpp/pJgh/qa69atIzo6mvr16x/y+44aNYr4+Pj8S1JSUnFOVRXkj3+E9HQ4+WQ4++xQTyNJkmoSs63K3Ow/Qk46ND0ZWhhuJUlS1VKSfLy3GTNmMH/+fK655poDHme2LVu/bPuF9TvXExUeRY/EHqEeR5Ik6ZAVq6hQEo8//jhHHnkk7du3Jzo6mmHDhnHllVcSHl6+b33HHXeQkpKSf1m5cmW5vp+Kb8oUmDQJwsPhb38Dt0+TJEmVndlW+7V+CqycBGHh0MNwK0mSap7nnnuOLl260Lt37wMeZ7YtW9NWBVe7OLr50cRGxh7kaEmSpMqjWH9Rbdy4MREREaxfv77A/evXr6dZs2ZFPichIYG3336bnTt3snz5chYsWECdOnU4/PDDD/k1mzVrRkZGBtu2bTvk942JiaFevXoFLqo8srPhlluC16+9Frp0Cek4kiSpBjLbqszkZMOsW4LX214L9Q23kiSp6ilJPs6zc+dOJk6cyNVXX33Q9zHblq1pK4NFhb4t+4Z4EkmSpOIpVlEhOjqaHj16MHny5Pz7cnJymDx5Mn36HHj/q9jYWFq0aEFWVhaTJk3inHPOOeTX7NGjB1FRUQWOWbhwIStWrDjo+6pyeuEF+P57iI+HBx4I9TSSJKkmMtuqzCx7AbZ+D1Hx0NVwK0mSqqbS5OPXX3+d9PR0fvOb35T3mNrH1FVTAeiT5P+XkCRJVUtkcZ8wfPhwLr/8cnr27Env3r0ZM2YMO3fu5MorrwRgyJAhtGjRglGjRgEwffp0Vq9eTffu3Vm9ejX33XcfOTk5/OlPfzrk14yPj+fqq69m+PDhNGzYkHr16nHTTTfRp08fjj322LL4PagCpabCXXcFr997LyQkhHYeSZJUc5ltVWqZqTA3N9x2uRdiDbeSJKnqKm4+zvPcc89x7rnn0qhRo1CMXWPtzNjJnHVzAOjT0qKCJEmqWopdVLj44ovZuHEj99xzD+vWraN79+589NFHNG3aFIAVK1YU2KM3LS2NkSNHsmzZMurUqcOgQYP497//Tf369Q/5NQH+9re/ER4ezuDBg0lPT2fgwIE89dRTpTh1hcqf/wwbNsBRR8GNN4Z6GkmSVJOZbVVq8/8MaRug7lFwpOFWkiRVbcXNxxBcHezrr7/mk08+CcXINdp3a74jO5BNi7otSIpPCvU4kiRJxRIWCAQCoR6iIqSmphIfH09KSor7noXQkiXQsSNkZsJ778GvfhXqiSRJUlVU07NdTT//SmP7Eni/I+RkwvHvQQvDrSRJKr6anu1q+vmXxl+//it3TL6DCzpewOsXvh7qcSRJkoqV7cIP+KhUxv74x2BJ4bTT4MwzQz2NJEmSVAqz/xgsKTQ7DRINt5IkSapY01ZNA6Bvy74hnkSSJKn4LCqownz+Obz9NkREwN/+BmFhoZ5IkiRJKqF1n8OqtyEsAnoYbiVJklSxAoEAU1dOBaBPUp8QTyNJklR8FhVUIbKy4JZbgtevvz64/YMkSZJUJeVkwaxbgtePvB7iDbeSJEmqWEu3LmXTrk1ER0RzdLOjQz2OJElSsVlUUIV49lmYNw8aNID77gv1NJIkSVIpLH0Wts2D6AbQ5b5QTyNJkqQaaNrK4LYPPZr3ICYyJsTTSJIkFZ9FBZW7bdvg7ruD1++7Dxo1CuU0kiRJUilkbIO5ueG2y30QY7iVJElSxZu2KlhU6JvUN8STSJIklYxFBZW7Bx+ETZugQ4fgtg+SJElSlTX/QUjfBPU6BLd9kCRJkkJg6sqpAPRp2SfEk0iSJJWMRQWVq0WL4O9/D14fPRqiokI7jyRJklRiqYtgYW64PWY0hBtuJUmSVPG2p29n3oZ5APRJsqggSZKqJosKKld/+ANkZcGgQXD66aGeRpIkSSqFWX+AQBYkDoJEw60kSZJC49s135ITyKFVfCsS6yaGehxJkqQSsaigcvPJJ/Cf/0BkJDz2WKinkSRJkkph7Sew5j8QFglHG24lSZIUOtNWTgPc9kGSJFVtFhVULrKy4NZbg9dvvBHatw/tPJIkSVKJ5WTBrNxwe9SNEG+4lSRJUuhMXTUVgL5JfUM8iSRJUslZVFC5ePpp+PFHaNQI7r031NNIkiRJpbDkaUj5EWIaQRfDrSRJkkInEAjwzapvAFdUkCRJVZtFBZW5LVvgnnuC1x94ABo0CO08kiRJUomlb4G5ueG2ywMQbbiVJElS6CzavIgtu7cQGxlLt2bdQj2OJElSiVlUUJm7//5gWaFTJ7j22lBPI0mSJJXCvPshYwvEd4IjDLeSJEkKrWmrpgHQM7En0RHRIZ5GkiSp5CwqqEz99BOMHRu8/re/QWRkaOeRJEmSSizlJ1icG26P+RuEG24lSZIUWtNWBosKfVv2DfEkkiRJpWNRQWVq+HDIzoazzoJTTw31NJIkSVIpzBoOgWxocRY0N9xKkiQp9KaumgpAn6Q+IZ5EkiSpdCwqqMx8+CF89BFERcFjj4V6GkmSJKkU1nwIaz+C8Cg42nArSZKk0EtJS+GHDT8A0KelRQVJklS1WVRQmcjMDK6mAPD738ORR4Z2HkmSJKnEcjKDqykAHPV7qGe4lSRJUujNWD2DAAEOq38YTes0DfU4kiRJpWJRQWXiqadgwQJo3BhGjgz1NJIkSVIpLHoKUhdATGPobLiVJElS5TBt1TTAbR8kSVL1YFFBpbZpE9x3X/D6n/8M9euHchpJkiSpFNI2wbz7gte7/hmi64dyGkmSJCnf1JVTAejbsm+IJ5EkSSo9iwoqtXvvhW3boGtXuOaaUE8jSZIklcK8eyFzG9TvCm0Nt5IkSaoccgI5fLPqG8AVFSRJUvVgUUGlMn8+jBsXvD5mDEREhHQcSZIkqeS2zYclueG2xxgIN9xKkiSpcliwaQEp6SnUiqpF16ZdQz2OJElSqVlUUKmMHAk5OXDeeXDiiaGeRpIkSSqFuSMhkAMtz4OmhltJkiRVHtNWTgOgV2IvIsMjQzyNJElS6VlUUInt3Akffhi8fv/9oZ1FkiRJKpWsnbAmN9x2NdxKkiSpcpm2KlhU6JvUN8STSJIklQ2LCiqxKVMgIwNat4bOnUM9jSRJklQK66dATgbUbg3xhltJkiRVLlNXTgWgT8s+IZ5EkiSpbFhUUIl99FHw58CBEBYW2lkkSZKkUlmbG26bG24lSZJUuWzdvZWfNv0EwLEtjw3xNJIkSWXDooJKLK+ocPrpoZ1DkiRJKrX8ooLhVpIkSZXL9NXTATii4REk1E4I8TSSJEllw6KCSmTZMli8GCIj4aSTQj2NJEmSVAo7lsH2xRAWCU0Nt5IkSapcpq2cBrjtgyRJql4sKqhEPv44+LNvX4iPD+0skiRJUqmszQ23CX0h2nArSZKkymXqqqkA9E3qG+JJJEmSyo5FBZWI2z5IkiSp2ljjtg+SJEmqnLJzspm+Krj1gysqSJKk6sSigootIwMmTw5eHzgwtLNIkiRJpZKdAetzw21zw60kSZIqlx83/sj2jO3Uia5D5yadQz2OJElSmbGooGL73/9g505o0gS6dw/1NJIkSVIpbPofZO2E2CbQoHuop5EkSZIKmLZqGgC9W/QmIjwixNNIkiSVHYsKKra8bR8GDoRw/w2SJElSVZa37UOzgRBmuJUkSVLlMnXlVAD6tuwb4kkkSZLKln+JU7F9/HHw5+lu4StJkqSqbm1uuE003EqSJKnyyVtRoU9SnxBPIkmSVLYsKqhY1qyBOXMgLAxOPTXU00iSJEmlsGsNbJsDhEEzw60kSZIql827NrNo8yIAjm15bIinkSRJKlsWFVQsn3wS/NmzJyQkhHYWSZIkqVTW5Ybbhj0h1nArSZKkyuWbVd8A0K5ROxrGNQzxNJIkSWXLooKK5aPcLXwHDgztHJIkSVKprckNt80Nt5IkSap83PZBkiRVZxYVdMiys/esqHC6W/hKkiSpKsvJ3rOiQqLhVpIkSZXP1JVTAejbsm+IJ5EkSSp7FhV0yL79FrZuhfh4SE4O9TSSJElSKWz5FjK2QlQ8NDLcSpIkqXLJyslixuoZgCsqSJKk6smigg7Zxx8Hf556KkRGhnYWSZIkqVTW5obbZqdCuOFWkiRJlcv8DfPZmbmTejH16JjQMdTjSJIklTmLCjpkH+Vu4eu2D5IkSary1uSGW7d9kCRJUiU0beU0AJJbJBMe5p/xJUlS9WPC0SHZvBlmBFcaY+DA0M4iSZIklUr6ZtiSG26bG24lSZJU+UxdNRWAvkl9QzyJJElS+bCooEPy2WeQkwOdOkHLlqGeRpIkSSqFdZ9BIAfiO0Etw60kSZIqn7wVFfq07BPiSSRJkspHiYoKY8eOpU2bNsTGxpKcnMyMvK/a78eYMWNo164dcXFxJCUlceutt5KWlpb/eJs2bQgLCyt0ufHGG/OPOeGEEwo9ft1115VkfJWA2z5IkqTqymxbA63NDbfNDbeSJEmqfDbs3MDSrUsBSG6ZHOJpJEmSykdkcZ/w6quvMnz4cMaNG0dycjJjxoxh4MCBLFy4kCZNmhQ6fsKECYwYMYLnn3+evn37smjRIq644grCwsIYPXo0AN9++y3Z2dn5z5k/fz6nnnoqF154YYHXGjp0KA888ED+7Vq1ahV3fJVAIAAffxy8blFBkiRVJ2bbGigQgLW54TbRcCtJkqTK55tV3wDQMaEj9WPrh3YYSZKkclLsosLo0aMZOnQoV155JQDjxo3j/fff5/nnn2fEiBGFjp86dSr9+vXjsssuA4LfMLv00kuZPn16/jEJCQkFnvPXv/6Vtm3bcvzxxxe4v1atWjRr1qy4I6uU5s2DtWuhVi3o3z/U00iSJJUds20NtG0e7F4LEbUgwXArSZKkysdtHyRJUk1QrK0fMjIymDlzJqeccsqeFwgP55RTTmHatGlFPqdv377MnDkzfwndZcuW8cEHHzBo0KD9vsfLL7/MVVddRVhYWIHHxo8fT+PGjencuTN33HEHu3btKs74KqG8bR9OOAFiY0M6iiRJUpkx29ZQeds+ND0BIgy3kiRJqnymrpoKQN+kviGeRJIkqfwUa0WFTZs2kZ2dTdOmTQvc37RpUxYsWFDkcy677DI2bdpE//79CQQCZGVlcd1113HnnXcWefzbb7/Ntm3buOKKKwq9TuvWrUlMTGTu3LncfvvtLFy4kDfffLPI10lPTyc9PT3/dmpqajHOVHvLKyq47YMkSapOzLY1VF5RobnhVpIkSZVPZnYm367+FnBFBUmSVL0Va0WFkvjyyy956KGHeOqpp5g1axZvvvkm77//Pg8++GCRxz/33HOcccYZJCYmFrj/2muvZeDAgXTp0oVf//rX/Otf/+Ktt95i6dKlRb7OqFGjiI+Pz78kJSWV+bnVBDt2wNdfB69bVJAkSTWd2baKy9wBG3PDrUUFSZKkIo0dO5Y2bdoQGxtLcnJy/mpi+7Nt2zZuvPFGmjdvTkxMDEcddRQffPBBBU1b/cxdP5fdWbupH1ufdo3bhXocSZKkclOsokLjxo2JiIhg/fr1Be5fv379fvfXvfvuu/ntb3/LNddcQ5cuXTjvvPN46KGHGDVqFDk5OQWOXb58OZ999hnXXHPNQWdJTk4GYMmSJUU+fscdd5CSkpJ/Wbly5aGcovbxxReQmQmHHw5HHBHqaSRJksqO2bYGWv8F5GRCncOhruFWkiRpX6+++irDhw/n3nvvZdasWXTr1o2BAweyYcOGIo/PyMjg1FNP5ZdffuGNN95g4cKFPPPMM7Ro0aKCJ68+pq0KbkN3bMtjCQ8r9+8ZSpIkhUyxkk50dDQ9evRg8uTJ+ffl5OQwefJk+vQpehmqXbt2ER5e8G0iIiIACAQCBe5/4YUXaNKkCWeeeeZBZ/n+++8BaN68eZGPx8TEUK9evQIXFd/e2z7ss62yJElSlWa2rYH23vbBcCtJklTI6NGjGTp0KFdeeSUdO3Zk3Lhx1KpVi+eff77I459//nm2bNnC22+/Tb9+/WjTpg3HH3883bp1q+DJq4+pK6cC0Ldl3xBPIkmSVL4ii/uE4cOHc/nll9OzZ0969+7NmDFj2LlzJ1deeSUAQ4YMoUWLFowaNQqAs846i9GjR3P00UeTnJzMkiVLuPvuuznrrLPy/6gLwT8Kv/DCC1x++eVERhYca+nSpUyYMIFBgwbRqFEj5s6dy6233spxxx1H165dS3P+OoBAAD78MHjdbR8kSVJ1ZLatQQIBWJMbbt32QZIkqZCMjAxmzpzJHXfckX9feHg4p5xyCtOmTSvyOe+++y59+vThxhtv5J133iEhIYHLLruM22+/vUA+3lt6ejrp6en5t1NTU8v2RKq4vBUV+iQVXZ6WJEmqLopdVLj44ovZuHEj99xzD+vWraN79+589NFHNG3aFIAVK1YU+JbZyJEjCQsLY+TIkaxevZqEhATOOuss/vKXvxR43c8++4wVK1Zw1VVXFXrP6OhoPvvss/w/HCclJTF48GBGjhxZ3PFVDEuWwM8/Q1QUnHhiqKeRJEkqe2bbGmT7Etj5M4RHQVPDrSRJ0r42bdpEdnZ2fhbO07RpUxYsWFDkc5YtW8bnn3/Or3/9az744AOWLFnCDTfcQGZmJvfee2+Rzxk1ahT3339/mc9fHazbsY5ftv1CGGH0btE71ONIkiSVq7DAvmvUVlOpqanEx8eTkpLiUrmH6Ikn4Pe/D5YUPv881NNIkiTtUdOzXU0//xJZ+ATM/H2wpHCy4VaSJFUelSXbrVmzhhYtWjB16tQCW6H96U9/YsqUKUyfPr3Qc4466ijS0tL4+eef81dQGD16NI8++ihr164t8n2KWlEhKSkp5OdfGbz101uc/9r5dGnShbnXzw31OJIkScVWnGxb7BUVVHN8lLuFr9s+SJIkqcpbmxtu3fZBkiSpSI0bNyYiIoL169cXuH/9+vU0a9asyOc0b96cqKioAts8dOjQgXXr1pGRkUF0dHSh58TExBATE1O2w1cTU1dOBaBPS7d9kCRJ1V/4wQ9RTZSWBl9+GbxuUUGSJElVWnYarP8yeN2igiRJUpGio6Pp0aMHkydPzr8vJyeHyZMnF1hhYW/9+vVjyZIl5OTk5N+3aNEimjdvXmRJQQc2bdU0APom9Q3xJJIkSeXPooKK9PXXsGsXNG8OXbqEehpJkiSpFDZ+Ddm7IK451DfcSpIk7c/w4cN55plneOmll/jpp5+4/vrr2blzJ1deeSUAQ4YM4Y477sg//vrrr2fLli3cfPPNLFq0iPfff5+HHnqIG2+8MVSnUGVlZGfw3ZrvAOiT5IoKkiSp+nPrBxUpb9uHgQMhLCy0s0iSJEmlsiZv2wfDrSRJ0oFcfPHFbNy4kXvuuYd169bRvXt3PvroI5o2bQrAihUrCA/f8923pKQkPv74Y2699Va6du1KixYtuPnmm7n99ttDdQpV1vfrvic9O51GcY04suGRoR5HkiSp3FlUUJHyigpu+yBJkqQqb21eUcFwK0mSdDDDhg1j2LBhRT72Zd5esXvp06cP33zzTTlPVf1NWxnc9uHYlscSZrlWkiTVAG79oEJWroQffoDwcDjllFBPI0mSJJXCzpWQ8gOEhUMzw60kSZIqp6mrpgLQN6lviCeRJEmqGBYVVMgnnwR/9u4NjRqFdhZJkiSpVNblhtuGvSHGcCtJkqTKKW9FhT4t+4R4EkmSpIphUUGFuO2DJEmSqo01ueE20XArSZKkyml16mpWpq4kPCycXi16hXocSZKkCmFRQQVkZcGnnwavDxwY2lkkSZKkUsnJgnW54ba54VaSJEmV07RVwdUUujbtSp3oOiGeRpIkqWJYVFAB06dDSgo0aAC9LO9KkiSpKts8HTJTILoBNDTcSpIkqXKaunIq4LYPkiSpZrGooALytn047TSIiAjtLJIkSVKp5G370Ow0CDfcSpIkqXLKW1Ghb1LfEE8iSZJUcSwqqICPPw7+PN0tfCVJklTVrc0Nt4mGW0mSJFVO6VnpzFo7C3BFBUmSVLNYVFC+jRvhu++C1we6ha8kSZKqsrSNsCU33DY33EqSJKlymrV2FhnZGSTUSuDwBoeHehxJkqQKY1FB+T79FAIB6NYNmjcP9TSSJElSKaz7FAhA/W4QZ7iVJElS5ZS37UOfpD6EhYWFeBpJkqSKY1FB+T7K3cLX1RQkSZJU5a3JDbeupiBJkqRKbOrKqQD0bdk3xJNIkiRVLIsKAiAnBz7O3cL3dLfwlSRJUlUWyIF1ueE20XArSZKkyikQCBRYUUGSJKkmsaggAL7/HjZsgNq1oV+/UE8jSdL/t3fn4VGV9/vH75nsCwlbyELCIsim7EtIUFCIBLRRwCIVC4oK2IIb2goKgvortGoRq1jUr0JbRdGKW0UQUFAh7JsLhoAgAZKwBwiQQPL8/khmZMhCQpYzk7xf15Urk5lznvM5JzOHW/zwPABQAce2SGcPSt5BUkPCLQAAANxT2ok0HTh5QN52b3WL6mZ1OQAAANWKRgVI+nU2hX79JF9fa2sBAAAAKiS9MNyG95O8CLcAAABwT8lpBbMpdAzvqECfQIurAQAAqF40KkCStLhwCV+WfQAAAIDHSy8Mtyz7AAAAADe2Om21JCkummUfAABA7UOjApSVJa0uyMRKTLS2FgAAAKBCcrOkQ4XhNpJwCwAAAPeVvK9gRoX4mHiLKwEAAKh+NCpAX34pnT8vXXmldMUVVlcDAAAAVEDml5I5L9W5Ugom3AIAAMA9nTl3RpszNkuS4mKYUQEAANQ+NCqAZR8AAABQcziWfYgk3AIAAMB9bUzfqPP55xURHKGmoU2tLgcAAKDa0ahQyxkjLVlS8JhGBQAAAHg0Y6T0wnBLowIAAADc2Oq0guXK4qLjZLPZLK4GAACg+tGoUMulpEi//CL5+Ul9+lhdDQAAAFABJ1Kk7F8ku58UTrgFAACA+0relyxJio+Jt7gSAAAAa9CoUMs5ln249lopKMjaWgAAAIAKcSz70OhayZtwCwAAAPdkjFFyWkGjQlx0nMXVAAAAWINGhVrO0ajAsg8AAADweI5GBZZ9AAAAgBvbc3yPMrMz5WP3UdeorlaXAwAAYAkaFWqxM2eklSsLHtOoAAAAAI92/ox0sDDc0qgAAAAAN+ZY9qFzZGf5e/tbXA0AAIA1aFSoxb7+Wjp7VoqOltq1s7oaAAAAoAIOfi3lnZUCo6VQwi0AAADc1+q01ZJY9gEAANRuNCrUYhcu+2CzWVsLAAAAUCEXLvtAuAUAAIAbc8yoEB8Tb3ElAAAA1qFRoRa7sFEBAAAA8GgXNioAAAAAbio7N1tbM7ZKYkYFAABQu9GoUEvt2SP99JPk5SX162d1NQAAAEAFnNojnfhJsnlJEYRbAAAAuK8NBzYoz+SpcZ3GigmNsbocAAAAy9CoUEstWVLwvWdPqW5dS0sBAAAAKia9MNw27Cn51rW0FAAAAKA0q9NWS5LiYphNAQAA1G40KtRSLPsAAACAGoNlHwAAAOAhkvclS5Lio+MtrgQAAMBaNCrUQufOScuXFzymUQEAAAAeLf+clFEYbmlUAAAAgBszxjgbFZhRAQAA1HY0KtRCycnSyZNSw4ZSly5WVwMAAABUwOFk6fxJya+hVJ9wCwAAAPe169guHT59WL5evuoc0dnqcgAAACxFo0It5Fj2oX9/yc47AAAAAJ7sQGG4jegv2Qi3AAAAcF/JaQWzKXSN7Co/bz+LqwEAALAWf5NXCzkaFVj2AQAAAB4vvTDcRhFuAQAA4N5Wp62WJMVFs+wDAAAAjQq1TGamtHlzweP+/a2tBQAAAKiQM5nSscJwG0G4BQAAgHtL3lcwo0J8TLzFlQAAAFiPRoVa5osvCr536SKFh1tbCwAAAFAhGYXhtl4XKYBwCwAAAPd1Muekvjv4nSQpLoYZFQAAAGhUqGVY9gEAAAA1xgGWfQAAAIBnWH9gvfJNvpqENlFUnSirywEAALAcjQq1SF6etGRJwePERGtrAQAAACokP0/KKAy3kYRbAAAAuLfVaaslSXHRzKYAAAAg0ahQq2zaJB05ItWpI8WRhwEAAODJjm2Sco5I3nWkhoRbAAAAuLfkfcmSpPiYeIsrAQAAcA80KtQijmUfEhIkHx9rawEAAAAqxLHsQ0SCZCfcAgAAwH0ZY7Rm3xpJzKgAAADgcFmNCrNnz1azZs3k7++v2NhYrVu3rtTtZ82apdatWysgIEAxMTF6+OGHdfbsWefr06ZNk81mc/lq06aNyxhnz57VuHHj1KBBAwUHB+vWW29VZmbm5ZRfazmWfRjAEr4AAABOZFsP5Vj2IYpwCwAAAPe248gOHT1zVP7e/uoY0dHqcgAAANxCuRsVFixYoAkTJmjq1KnatGmTOnbsqMTERB08eLDY7efPn6+JEydq6tSp2r59u9544w0tWLBAjz/+uMt2V111ldLT051f3377rcvrDz/8sD799FO9//77WrlypQ4cOKAhQ4aUt/xa69gxKblgdjElsoQvAACAJLKtx8o9Jh0uDLeRhFsAAAC4t9VpqyVJ3aK6ydfL1+JqAAAA3IN3eXeYOXOmRo8erVGjRkmS5syZo88++0xvvvmmJk6cWGT71atXq1evXho+fLgkqVmzZrr99tu1du1a10K8vRUREVHsMbOysvTGG29o/vz56tu3ryRp7ty5atu2rdasWaOePXuW9zRqneXLpfx8qW1bqWlTq6sBAABwD2RbD5WxXDL5UkhbKYhwCwAAAPeWvK+gyZZlHwAAAH5VrhkVcnNztXHjRiUkJPw6gN2uhIQEJTv+uf5F4uPjtXHjRucUuj///LMWLVqkG2+80WW71NRURUVF6YorrtAdd9yhvXv3Ol/buHGjzp0753LcNm3aqEmTJiUeNycnRydOnHD5qs0WFy7hy2wKAAAABci2Hiy9MNwymwIAAAA8gKNRIT4m3uJKAAAA3Ee5ZlQ4fPiw8vLyFB4e7vJ8eHi4fvrpp2L3GT58uA4fPqxrrrlGxhidP39e9913n8v0uLGxsZo3b55at26t9PR0PfXUU7r22mv1/fffq06dOsrIyJCvr6/q1q1b5LgZGRnFHnfGjBl66qmnynN6NZYxvzYqDGAJXwAAAElkW49ljHTA0ahAuAUAAIB7yzqbpR8O/iCJGRUAAAAuVK4ZFS7HihUrNH36dL3yyivatGmTFi5cqM8++0zPPPOMc5uBAwdq6NCh6tChgxITE7Vo0SIdP35c77333mUfd9KkScrKynJ+paWlVcbpeKQffpD275f8/aXeva2uBgAAwHORbd1A1g/Smf2Sl7/UiHALAAAA97Zu/zoZGTWv21zhweGX3gEAAKCWKNeMCg0bNpSXl5cyMzNdns/MzCxxDd4pU6ZoxIgRuvfeeyVJ7du3V3Z2tsaMGaMnnnhCdnvRXom6deuqVatW2rlzpyQpIiJCubm5On78uMu/PCvtuH5+fvLz8yvP6dVYS5YUfL/uOikgwNJSAAAA3AbZ1kOlF4bbRtdJ3oRbAAAAuLfVaaslSXExzKYAAABwoXLNqODr66uuXbtq+fLlzufy8/O1fPlyxcUVH7ROnz5d5C9svby8JEnGmGL3OXXqlHbt2qXIyEhJUteuXeXj4+Ny3JSUFO3du7fE4+JXLPsAAABQFNnWQ6Wz7AMAAAA8R/K+ZElSfHS8xZUAAAC4l3LNqCBJEyZM0J133qlu3bqpR48emjVrlrKzszVq1ChJ0siRI9W4cWPNmDFDkpSUlKSZM2eqc+fOio2N1c6dOzVlyhQlJSU5/1L30UcfVVJSkpo2baoDBw5o6tSp8vLy0u233y5JCg0N1T333KMJEyaofv36CgkJ0f3336+4uDj17Nmzsq5FjZSdLX39dcHjxERrawEAAHA3ZFsPcz5bOlgYbiMJtwAAAHBv+SZfa/atkcSMCgAAABcrd6PCsGHDdOjQIT355JPKyMhQp06dtHjxYoWHF6yvtXfvXpd/ZTZ58mTZbDZNnjxZ+/fvV1hYmJKSkvSXv/zFuc2+fft0++2368iRIwoLC9M111yjNWvWKCwszLnNCy+8ILvdrltvvVU5OTlKTEzUK6+8UpFzrxVWrJByc6WmTaXWra2uBgAAwL2QbT1M5gopP1cKaiqFEG4BAACqwuzZs/Xcc88pIyNDHTt21EsvvaQePXoUu+28efOcTb4Ofn5+Onv2bHWU6vZ+OvyTsnKyFOgTqA7hHawuBwAAwK3YTElz1NYwJ06cUGhoqLKyshQSEmJ1OdXm/vull1+Wxo6V5syxuhoAAIDKUVuznUOtPf8N90s7XpZajpV6EG4BAEDN4E7ZbsGCBRo5cqTmzJmj2NhYzZo1S++//75SUlLUqFGjItvPmzdPDz74oFJSUpzP2Ww2Z+NvWbjT+Ve2/9v0fxr96Wj1adpHK+5aYXU5AAAAVa482c5e6qvweEuWFHwfwBK+AAAA8HTpheE2knALAABQFWbOnKnRo0dr1KhRateunebMmaPAwEC9+eabJe5js9kUERHh/CpPk0JNl5yWLEmKi2bZBwAAgIvRqFCD7dolpaZK3t5S375WVwMAAABUwMld0slUyeYtRRBuAQAAKltubq42btyohIQE53N2u10JCQlKTk4ucb9Tp06padOmiomJ0S233KIffvih1OPk5OToxIkTLl81VfK+gusWHxNvcSUAAADuh0aFGswxm0J8vFTDZk0DAABAbeOYTSEsXvIh3AIAAFS2w4cPKy8vr8iMCOHh4crIyCh2n9atW+vNN9/Uxx9/rLfeekv5+fmKj4/Xvn37SjzOjBkzFBoa6vyKiYmp1PNwF8fOHNP2w9slST2je1pcDQAAgPuhUaEGW7y44DvLPgAAAMDjpReGW5Z9AAAAcBtxcXEaOXKkOnXqpD59+mjhwoUKCwvTq6++WuI+kyZNUlZWlvMrLS2tGiuuPmv3r5UktazfUmFBYRZXAwAA4H68rS4AVSM3V/ryy4LHNCoAAADAo+XlSpmF4ZZGBQAAgCrRsGFDeXl5KTMz0+X5zMxMRURElGkMHx8fde7cWTt37ixxGz8/P/n5+VWoVk+wOm21JCkuOs7iSgAAANwTMyrUUKtWSdnZUni41LGj1dUAAAAAFXB4lXQ+W/IPl+oRbgEAAKqCr6+vunbtquXLlzufy8/P1/LlyxUXV7b/2Z6Xl6fvvvtOkZGRVVWmx0jelyxJio+Jt7gSAAAA98SMCjWUY9mHxETJTjsKAAAAPNkBx7IPiZKNcAsAAFBVJkyYoDvvvFPdunVTjx49NGvWLGVnZ2vUqFGSpJEjR6px48aaMWOGJOnpp59Wz5491bJlSx0/flzPPfecfvnlF917771Wnobl8vLztHZfwdIPzKgAAABQPBoVaihHowLLPgAAAMDjpTsaFQi3AAAAVWnYsGE6dOiQnnzySWVkZKhTp05avHixwsPDJUl79+6V/YJ/FXXs2DGNHj1aGRkZqlevnrp27arVq1erXbt2Vp2CW/jx0I86mXtSwb7BurrR1VaXAwAA4JZoVKiBDhyQtm2TbDbphhusrgYAAACogNMHpOPbJNmkCMItAABAVRs/frzGjx9f7GsrVqxw+fmFF17QCy+8UA1VeZbVaaslST0a95CX3cviagAAANwT86bWQEuWFHzv1k1q2NDaWgAAAIAKSS8Mt/W7Sf6EWwAAALi/5H3Jklj2AQAAoDQ0KtRALPsAAACAGsOx7EMU4RYAAACewdGoEB8Tb3ElAAAA7otGhRomL09aurTgMY0KAAAA8Gj5eVJGYbiNJNwCAADA/R0+fVg7juyQJPWM7mlxNQAAAO6LRoUaZv166dgxqW5dqUcPq6sBAAAAKuDoein3mORTV2pAuAUAAID7W7NvjSSpdYPWqh9Q3+JqAAAA3BeNCjWMY9mHhATJ29vaWgAAAIAKOVAYbiMSJDvhFgAAAO4vOa1g2Ye4mDiLKwEAAHBvNCrUMI5GBZZ9AAAAgMdLLwy3UYRbAAAAeIbkfQWNCvHR8RZXAgAA4N5oVKhBjhyR1q0reJyYaG0tAAAAQIXkHJGOFIbbSMItAAAA3N/5/PNat78gwzKjAgAAQOloVKhBli2TjJGuvlqKjra6GgAAAKACMpZJMlLo1VIg4RYAAADu7/uD3yv7XLZC/ELULqyd1eUAAAC4NRoVahCWfQAAAECNwbIPAAAA8DCr01ZLkmIbx8pu46/eAQAASkNaqiGM+bVRgWUfAAAA4NGMkQ4UhluWfQAAAICHSN6XLEmKi2bZBwAAgEuhUaGG2LZNysiQAgOla66xuhoAAACgAo5vk85mSF6BUhjhFgAAAJ4hOa2gUSE+Jt7iSgAAANwfjQo1hGM2heuvl/z9ra0FAAAAqBDHsg/h10tehFsAAAC4v4PZB7Xr2C5JUmx0rMXVAAAAuD8aFWoIR6PCAJbwBQAAgKdzLvtAuAUAAIBncMym0C6sner617W2GAAAAA9Ao0INcPKktGpVwWMaFQAAAODRzp2UDheG2yjCLQAAADxD8r6CRoW46DiLKwEAAPAMNCrUAF99JZ07J7VoIbVsaXU1AAAAQAVkfiXln5OCW0h1CLcAAADwDI5GhfiYeIsrAQAA8Aw0KtQAjmUfEhOtrQMAAACosHTHsg+EWwAAAHiGc3nntH7/eknMqAAAAFBWNCp4OGOkzz8veMyyDwAAAPBoxkgHCsNtJOEWAAAAnmFr5ladOX9Gdf3rqnXD1laXAwAA4BFoVPBwqanSnj2Sj490/fVWVwMAAABUwMlUKXuPZPeRwgm3AAAA8AzJaQXLPvSM7im7jb9yBwAAKAtSk4dbsqTg+7XXSsHB1tYCAAAAVEh6YbgNu1byIdwCAADAMyTvK2hUYNkHAACAsqNRwcMtLlzCl2UfAAAA4PHSC8Mtyz4AAADAgzgaFeJj4i2uBAAAwHPQqODBzp6Vvvqq4HFiorW1AAAAABWSd1bKLAy3kYRbAAAAeIb0k+nac3yPbLKpR+MeVpcDAADgMWhU8GDffCOdOSNFRkrt21tdDQAAAFABB7+R8s5IAZFSXcItAAAAPINjNoWrG12tEL8Qi6sBAADwHDQqeLALl32w2aytBQAAAKiQC5d9INwCAADAQySnFTQqxEXHWVwJAACAZ6FRwYMtWVLwfQBL+AIAAMDTpReG20jCLQAAADyHY0aF+Jh4iysBAADwLDQqeKi0NOmHHyS7XUpIsLoaAAAAoAKy06SsHySbXYog3AIAAMAz5OblasOBDZKkuBhmVAAAACgPGhU8lGM2hdhYqX59a2sBAAAAKsQxm0KDWMmPcAsAAADPsDl9s3LyctQgoIGurH+l1eUAAAB4FBoVPNTiwiV8ExOtrQMAAACosPTCcBtJuAUAAIDncCz70DO6p2w2m8XVAAAAeBYaFTzQuXPS0qUFjwewhC8AAAA8Wf45KaMw3EYSbgEAAOA5HI0KcdEs+wAAAFBeNCp4oLVrpRMnCpZ86NbN6moAAACACji8Vjp3QvKtL9Un3AIAAMBzJKcVNCrEx8RbXAkAAIDnoVHBAy0pXMK3f3/Jy8vaWgAAAIAKSS8Mt5H9JTvhFgAAAJ5h34l9SjuRJrvNru6Nu1tdDgAAgMehUcEDLS5cwpdlHwAAAODx0gvDLcs+AAAAwIM4ZlPoEN5Bwb7BFlcDAADgeWhU8DAHD0obNhQ87t/f2loAAACACjl7UDpaGG4jCbcAAADwHMn7ChoV4qLjLK4EAADAM9Go4GGWLi343rGjFBlpbS0AAABAhaQXhtu6HaUAwi0AAAA8h6NRIT4m3uJKAAAAPNNlNSrMnj1bzZo1k7+/v2JjY7Vu3bpSt581a5Zat26tgIAAxcTE6OGHH9bZs2edr8+YMUPdu3dXnTp11KhRIw0aNEgpKSkuY1x33XWy2WwuX/fdd9/llO/RWPYBAACgcpFtLeRY9iGKcAsAAADPcfb8WW1K3ySJGRUAAAAuV7kbFRYsWKAJEyZo6tSp2rRpkzp27KjExEQdPHiw2O3nz5+viRMnaurUqdq+fbveeOMNLViwQI8//rhzm5UrV2rcuHFas2aNli5dqnPnzql///7Kzs52GWv06NFKT093fj377LPlLd+j5edLX3xR8JhGBQAAgIoj21rI5EsZheE2knALAAAAz7EpfZNy83IVFhimK+pdYXU5AAAAHsm7vDvMnDlTo0eP1qhRoyRJc+bM0WeffaY333xTEydOLLL96tWr1atXLw0fPlyS1KxZM91+++1au3atc5vFjmkCCs2bN0+NGjXSxo0b1bt3b+fzgYGBioiIKG/JNcaWLdLBg1JwsBTPjGIAAAAVRra10LEt0tmDknew1JBwCwAAAM+RnFaw7ENcTJxsNpvF1QAAAHimcs2okJubq40bNyohIeHXAex2JSQkKDk5udh94uPjtXHjRucUuj///LMWLVqkG2+8scTjZGVlSZLq16/v8vzbb7+thg0b6uqrr9akSZN0+vTpEsfIycnRiRMnXL48nePvvPv2lXx9ra0FAADA05FtLeZY9iG8r+RFuAUAAIDnSN5X2KjAsg8AAACXrVwzKhw+fFh5eXkKDw93eT48PFw//fRTsfsMHz5chw8f1jXXXCNjjM6fP6/77rvPZXrcC+Xn5+uhhx5Sr169dPXVV7uM07RpU0VFRWnbtm167LHHlJKSooULFxY7zowZM/TUU0+V5/TcnqNRgWUfAAAAKo5sa7EDheE2inALAAAAz2GMcTYqxMcwMxgAAMDlKvfSD+W1YsUKTZ8+Xa+88opiY2O1c+dOPfjgg3rmmWc0ZcqUItuPGzdO33//vb799luX58eMGeN83L59e0VGRqpfv37atWuXWrRoUWScSZMmacKECc6fT5w4oZiYmEo8s+qVlSWtXl3wODHR2loAAABqK7JtJcnNkg4XhttIwi0AAAA8x96svTpw8oC87d7qFtXN6nIAAAA8VrkaFRo2bCgvLy9lZma6PJ+ZmVni+rpTpkzRiBEjdO+990oq+IvY7OxsjRkzRk888YTs9l9Xnxg/frz+97//6euvv1Z0dHSptcTGxkqSdu7cWexf5vr5+cnPz688p+fWvvxSysuTWrWSrrjC6moAAAA8H9nWQplfSiZPqtNKCibcAgAAwHM4ZlPoGN5RgT6BFlcDAADgueyX3uRXvr6+6tq1q5YvX+58Lj8/X8uXL1dcXPHrcZ0+fdrlL2wlycvLS1LBNFmO7+PHj9eHH36oL7/8Us2bN79kLVu2bJEkRUZGlucUPBbLPgAAAFQusq2F0gvDbSThFgAAAJ4lOa2gUSEuuvj/ZgAAAEDZlHvphwkTJujOO+9Ut27d1KNHD82aNUvZ2dkaNWqUJGnkyJFq3LixZsyYIUlKSkrSzJkz1blzZ+f0uFOmTFFSUpLzL3XHjRun+fPn6+OPP1adOnWUkZEhSQoNDVVAQIB27dql+fPn68Ybb1SDBg20bds2Pfzww+rdu7c6dOhQWdfCbRlDowIAAEBVINtawBjpQGG4jSLcAgAAwLM4ZlSIj4m3uBIAAADPVu5GhWHDhunQoUN68sknlZGRoU6dOmnx4sUKDw+XJO3du9flX5lNnjxZNptNkydP1v79+xUWFqakpCT95S9/cW7zz3/+U5J03XXXuRxr7ty5uuuuu+Tr66tly5Y5/+I4JiZGt956qyZPnnw55+xxfvpJ2rtX8vOT+vSxuhoAAICag2xrgRM/Saf3SnY/qRHhFgAAAJ7jzLkz2pyxWZIUF8OMCgAAABVhM445amu4EydOKDQ0VFlZWQoJCbG6nHJ54QVpwgTphhukL76wuhoAAADreXK2qwweff4/vSBtmiBF3CD1JdwCAAB4dLarBJ50/t/88o16z+utiOAIHZhwQDabzeqSAAAA3Ep5sp291FfhFlj2AQAAADWGY9mHSMItAAAAPItj2Ye46DiaFAAAACqIRgU3d+aM9PXXBY9pVAAAAIBHO39GOlQYbqMItwAAAPAsFzYqAAAAoGJoVHBzK1dKZ89KMTFS27ZWVwMAAABUwMGVUt5ZKTBGCiHcAgAAwHMYY5ScVtCoEB8Tb3E1AAAAno9GBTfnWPYhMVFiNjEAAAB4tHTHsg+EWwAAAHc1e/ZsNWvWTP7+/oqNjdW6devKtN+7774rm82mQYMGVW2BFtl9fLcyszPlY/dR16iuVpcDAADg8WhUcHOORgWWfQAAAIDHczYqEG4BAADc0YIFCzRhwgRNnTpVmzZtUseOHZWYmKiDBw+Wut+ePXv06KOP6tprr62mSqufYzaFzpGd5e/tb3E1AAAAno9GBTe2Z4+UkiJ5eUn9+lldDQAAAFABp/ZIJ1Ikm5cUQbgFAABwRzNnztTo0aM1atQotWvXTnPmzFFgYKDefPPNEvfJy8vTHXfcoaeeekpXXHFFNVZbvZL3FTQqxEXHWVwJAABAzUCjghtbsqTge1ycVLeupaUAAAAAFZNeGG4bxkm+dS0tBQAAAEXl5uZq48aNSkhIcD5nt9uVkJCg5OTkEvd7+umn1ahRI91zzz1lOk5OTo5OnDjh8uUJHI0K8THxFlcCAABQM9Co4MZY9gEAAAA1Bss+AAAAuLXDhw8rLy9P4eHhLs+Hh4crIyOj2H2+/fZbvfHGG3r99dfLfJwZM2YoNDTU+RUTE1OhuqtDdm62tmZslcSMCgAAAJWFRgU3lZsrLV9e8Dgx0dpaAAAAgArJy5UyCsNtJOEWAACgJjh58qRGjBih119/XQ0bNizzfpMmTVJWVpbzKy0trQqrrBzrD6xXnslT4zqNFRPq/o0VAAAAnsDb6gJQvORk6eRJqWFDqUsXq6sBAAAAKuBwsnT+pOTXUKpPuAUAAHBHDRs2lJeXlzIzM12ez8zMVERERJHtd+3apT179igpKcn5XH5+viTJ29tbKSkpatGiRZH9/Pz85OfnV8nVV63ktIJlH+JimE0BAACgsjCjgptyLPuQmCjZ+S0BAADAkzmXfUiUbIRbAAAAd+Tr66uuXbtquWOaVxU0HixfvlxxcUX/B32bNm303XffacuWLc6vm2++Wddff722bNniEUs6lFXyvoJGhfjoeIsrAQAAqDmYUcFNLVlS8H0AS/gCAADA06UXhttIwi0AAIA7mzBhgu68805169ZNPXr00KxZs5Sdna1Ro0ZJkkaOHKnGjRtrxowZ8vf319VXX+2yf926dSWpyPOezBjjbFRgRgUAAIDKQ6OCG8rIkDZvLnjcv7+1tQAAAAAVciZDOlYYbiMJtwAAAO5s2LBhOnTokJ588kllZGSoU6dOWrx4scLDwyVJe/fulb2WTf+68+hOHT59WL5evuoc0dnqcgAAAGoMGhXc0BdfFHzv2lVq1MjaWgAAAIAKSS8Mt/W7Sv6EWwAAAHc3fvx4jR8/vtjXVqxYUeq+8+bNq/yCLOaYTaFrZFf5eftZXA0AAEDNUbvaXz3E4sIlfBMTra0DAAAAqLD0wnAbSbgFAACA50lOK1z2IZplHwAAACoTjQpuJi/v1xkVBrCELwAAADxZfp6UURhuIwm3AAAA8DyOGRXiY+ItrgQAAKBmoVHBzWzcKB05IoWESD17Wl0NAAAAUAFHN0o5RySfEKkh4RYAAACe5WTOSX138DtJUlwMMyoAAABUJhoV3MySJQXfExIkHx9rawEAAAAqJL0w3EYkSHbCLQAAADzLuv3rlG/y1SS0iaLqRFldDgAAQI1Co4KbWVy4hC/LPgAAAMDjpReGW5Z9AAAAgAdyLPsQF81sCgAAAJWNRgU3cuyYtGZNwePERGtrAQAAACok95h0pDDcRhJuAQAA4HkcjQrxMfEWVwIAAFDz0KjgRpYtk/LzpbZtpSZNrK4GAAAAqICMZZLJl0LaSkGEWwAAAHiWfJOvNfsKGm+ZUQEAAKDy0ajgRlj2AQAAADXGAZZ9AAAAgOfacWSHjp45Kn9vf3WM6Gh1OQAAADUOjQpuwhhpyZKCxzQqAAAAwKMZI6UXhtsowi0AAAA8T3JawbIP3aK6ydfL1+JqAAAAah4aFdzEDz9I+/dLAQFS795WVwMAAABUQNYP0pn9kleA1IhwCwAAAM+TvK+gUYFlHwAAAKoGjQpuwrHsQ58+kr+/tbUAAAAAFZJeGG4b9ZG8CLcAAADwPI5GhfiYeIsrAQAAqJloVHATjkYFln0AAACAxztQGG4jCbcAAADwPFlns/TDwR8kMaMCAABAVaFRwQ1kZ0vffFPwmEYFAAAAeLTz2dKhwnAbRbgFAACA51m7f62MjJrXba7w4HCrywEAAKiRaFRwAytWSLm5UrNmUqtWVlcDAAAAVEDmCik/VwpqJtUh3AIAAMDzJKcVLPsQF8NsCgAAAFWFRgU3cOGyDzabtbUAAAAAFZJ+wbIPhFsAAAB4oOR9BY0K8dHxFlcCAABQc9Go4AYubFQAAAAAPNqBwnDLsg8AAADwQPkmX2v2rZHEjAoAAABViUYFi+3cWfDl7S1df73V1QAAAAAVcHKndGqnZPOWwgm3AAAA8DzbD21XVk6WAn0C1SG8g9XlAAAA1Fg0KlhsyZKC7716SSEh1tYCAAAAVEh6YbgN6yX5EG4BAADgeRzLPnSP6i5vu7fF1QAAANRcNCpYjGUfAAAAUGM4ln2IJNwCAADAMyWnFTQqxEWz7AMAAEBVolHBQjk50ldfFTymUQEAAAAeLS9HOlgYbqMItwAAAPBMjhkV4mPiLa4EAACgZqNRwUKrVknZ2VJEhNSxo9XVAAAAABVwaJV0Plvyj5DqEm4BAADgeY6eOarth7dLknpG97S4GgAAgJqNRgULOZZ96N9fstmsrQUAAACokHTHsg+EWwAAAHimtfvWSpJa1m+psKAwi6sBAACo2WhUsJCjUYFlHwAAAODxnI0KhFsAAAB4JseyD3HRcRZXAgAAUPPRqGCR/ful774r+MdmN9xgdTUAAABABZzeLx3/TpJNiiDcAgAAwDM5GhXiY+ItrgQAAKDmo1HBIl98UfC9e3epYUNrawEAAAAqJL0w3DboLvkTbgEAAOB58vLztGbfGknMqAAAAFAdaFSwCMs+AAAAoMZg2QcAAAB4uB8O/aBTuacU7BusqxtdbXU5AAAANR6NChY4f15aurTgcWKitbUAAAAAFZJ/XsooDLeRhFsAAAB4puS0gmUfejTuIS+7l8XVAAAA1Hw0Klhg/Xrp2DGpbl2pRw+rqwEAAAAq4Mh6KfeY5FNXakC4BQAAgGdK3lfQqMCyDwAAANXjshoVZs+erWbNmsnf31+xsbFat25dqdvPmjVLrVu3VkBAgGJiYvTwww/r7Nmz5Rrz7NmzGjdunBo0aKDg4GDdeuutyszMvJzyLedY9uGGGyRvb2trAQAAqO3IthXkXPbhBslOuAUAAIBncjQqxMfEW1wJAABA7VDuRoUFCxZowoQJmjp1qjZt2qSOHTsqMTFRBw8eLHb7+fPna+LEiZo6daq2b9+uN954QwsWLNDjjz9erjEffvhhffrpp3r//fe1cuVKHThwQEOGDLmMU7bekiUF3wewhC8AAIClyLaVIL0w3EYSbgEAAOCZDp8+rB1HdkiSekb3tLgaAACA2sFmjDHl2SE2Nlbdu3fXyy+/LEnKz89XTEyM7r//fk2cOLHI9uPHj9f27du1fPly53OPPPKI1q5dq2+//bZMY2ZlZSksLEzz58/Xb3/7W0nSTz/9pLZt2yo5OVk9e146PJ44cUKhoaHKyspSSEhIeU65Uh05IoWFScZI+/ZJjRtbVgoAAIDHqqxsR7atoJwj0gdhkow0aJ8USLgFAAAoL7fJdhZxh/P/347/KemdJLVu0Fo/jf/JkhoAAABqgvJku3LNqJCbm6uNGzcqISHh1wHsdiUkJCg5ObnYfeLj47Vx40bndLc///yzFi1apBtvvLHMY27cuFHnzp1z2aZNmzZq0qRJicd1V0uXFjQptG9PkwIAAICVyLaVIH2pJCPVbU+TAgAAADxWclpBDo+LibO4EgAAgNqjXIvIHj58WHl5eQoPD3d5Pjw8XD/9VHyn6fDhw3X48GFdc801Msbo/Pnzuu+++5zT45ZlzIyMDPn6+qpu3bpFtsnIyCj2uDk5OcrJyXH+fOLEifKcapVZXLiEb2KitXUAAADUdmTbSpBeGG4jCbcAAADwXMn7ChoV4qPjLa4EAACg9ijXjAqXY8WKFZo+fbpeeeUVbdq0SQsXLtRnn32mZ555pkqPO2PGDIWGhjq/YmJiqvR4ZZGf/2ujwgCW8AUAAPA4ZNsLmPwLGhUItwAAAPBM5/PPa+3+tZKYUQEAAKA6latRoWHDhvLy8lJmZqbL85mZmYqIiCh2nylTpmjEiBG699571b59ew0ePFjTp0/XjBkzlJ+fX6YxIyIilJubq+PHj5f5uJMmTVJWVpbzKy0trTynWiW2bZMyM6XAQOmaa6yuBgAAoHYj21bQ8W3S2UzJK1AKI9wCAADAM32X+Z1OnzutEL8QtQtrZ3U5AAAAtUa5GhV8fX3VtWtXLV++3Plcfn6+li9frri44rtNT58+Lbvd9TBeXl6SJGNMmcbs2rWrfHx8XLZJSUnR3r17Szyun5+fQkJCXL6stmRJwfe+fSU/P2trAQAAqO3IthWUXhhuw/tKXoRbAAAAeCbHsg+xjWNlt1X5BMQAAAAo5F3eHSZMmKA777xT3bp1U48ePTRr1ixlZ2dr1KhRkqSRI0eqcePGmjFjhiQpKSlJM2fOVOfOnRUbG6udO3dqypQpSkpKcv6l7qXGDA0N1T333KMJEyaofv36CgkJ0f3336+4uDj17Nmzsq5FlWPZBwAAAPdCtq2AA4XhNopwCwAAAM/laFSIi2bZBwAAgOpU7kaFYcOG6dChQ3ryySeVkZGhTp06afHixQoPD5ck7d271+VfmU2ePFk2m02TJ0/W/v37FRYWpqSkJP3lL38p85iS9MILL8hut+vWW29VTk6OEhMT9corr1Tk3KvVyZPSt98WPE5MtLYWAAAAFCDbXqZzJ6VDheE2knALAAAAz5WcVtCoEB8Tb3ElAAAAtYvNGGOsLqI6nDhxQqGhocrKyrJkqtyPP5YGDZJatJB27qz2wwMAANQoVmc7q1l+/vs+lr4eJAW3kG4m3AIAAFSE5dnOYlae/8Hsgwp/vqCh+Nhjx1TXv261Hh8AAKCmKU+2Y9GtasKyDwAAAKgxHMs+RBJuAQAA4Lkcsym0C2tHkwIAAEA1o1GhGhhDowIAAABqCGOk9MJwG0W4BQAAgOdK3lfQqBAXHWdxJQAAALUPjQrVIDVV2rNH8vWVrrvO6moAAACACjiZKmXvkey+UqPrrK4GAAAAuGyORoX4mHiLKwEAAKh9aFSoBo7ZFK65RgoOtrYWAAAAoEIcsymEXSP5EG4BAADgmc7lndP6/eslMaMCAACAFWhUqAYs+wAAAIAa40BhuI0k3AIAAMBzbc3cqjPnz6iuf121btja6nIAAABqHRoVqtiZM9KKFQWPaVQAAACARzt/Rjq4ouBxFOEWAAAAnis5rWDZh57RPWW38dfkAAAA1Y0EVsW++aagWSEqSrr6aqurAQAAACrg0DdS3hkpIEoKJdwCAADAcyXvK2hUYNkHAAAAa9CoUMWWLCn4PmCAZLNZWwsAAABQIemF4TaScAsAAADPtjpttSQpPibe4koAAABqJxoVqtjiwiV8WfYBAAAAHi+9MNyy7AMAAECNNXv2bDVr1kz+/v6KjY3VunXrStx24cKF6tatm+rWraugoCB16tRJ//nPf6qx2suTfjJdv2T9Ipts6tG4h9XlAAAA1Eo0KlShvXulH3+U7HYpIcHqagAAAIAKyN4rZf0o2exSBOEWAACgJlqwYIEmTJigqVOnatOmTerYsaMSExN18ODBYrevX7++nnjiCSUnJ2vbtm0aNWqURo0apSWOaWbdlGPZh6sbXa0QvxCLqwEAAKidaFSoQo48Hhsr1atnbS0AAABAhTiWfWgQK/kSbgEAAGqimTNnavTo0Ro1apTatWunOXPmKDAwUG+++Wax21933XUaPHiw2rZtqxYtWujBBx9Uhw4d9O2331Zz5eWTnFbQqBAXHWdxJQAAALUXjQpViGUfAAAAUGM4ln2IJNwCAADURLm5udq4caMSLpga1m63KyEhQcnJyZfc3xij5cuXKyUlRb179y5xu5ycHJ04ccLlq7o5ZlSIj4mv9mMDAACgAI0KVeTcOWnZsoLHNCoAAADAo+WfkzIKwy2NCgAAADXS4cOHlZeXp/DwcJfnw8PDlZGRUeJ+WVlZCg4Olq+vr2666Sa99NJLuuGGG0rcfsaMGQoNDXV+xcTEVNo5lEVuXq42HNggSYqLYUYFAAAAq9CoUEXWrpVOnJAaNJC6drW6GgAAAKACDq+Vzp2Q/BpI9Qm3AAAA+FWdOnW0ZcsWrV+/Xn/5y180YcIErVixosTtJ02apKysLOdXWlpa9RUraXP6ZuXk5ahBQANdWf/Kaj02AAAAfuVtdQE1VadO0ocfSkeOSF5eVlcDAAAAVEC9TtK1H0q5RyQ74RYAAKAmatiwoby8vJSZmenyfGZmpiIiIkrcz263q2XLlpKkTp06afv27ZoxY4auu+66Yrf38/OTn59fpdVdXm0attEHt32gY2eOyWazWVYHAABAbUejQhUJDpYGDbK6CgAAAKAS+ARLMYOsrgIAAABVyNfXV127dtXy5cs1qPAvNvPz87V8+XKNHz++zOPk5+crJyeniqqsuFD/UA1pO8TqMgAAAGo9GhUAAAAAAAAAAJowYYLuvPNOdevWTT169NCsWbOUnZ2tUaNGSZJGjhypxo0ba8aMGZKkGTNmqFu3bmrRooVycnK0aNEi/ec//9E///lPK08DAAAAHoBGBQAAAAAAAACAhg0bpkOHDunJJ59URkaGOnXqpMWLFys8PFyStHfvXtntduf22dnZ+uMf/6h9+/YpICBAbdq00VtvvaVhw4ZZdQoAAADwEDZjjLG6iOpw4sQJhYaGKisrSyEhIVaXAwAAgAqo7dmutp8/AABATVLbs11tP38AAICapDzZzl7qqwAAAAAAAAAAAAAAAJWIRgUAAAAAAAAAAAAAAFBtaFQAAAAAAAAAAAAAAADVhkYFAAAAAAAAAAAAAABQbWhUAAAAAAAAAAAAAAAA1YZGBQAAAAAAAAAAAAAAUG1oVAAAAAAAAAAAAAAAANWGRgUAAAAAAAAAAAAAAFBtaFQAAAAAAAAAAAAAAADVhkYFAAAAAAAAAAAAAABQbWhUAAAAAAAAAAAAAAAA1YZGBQAAAAAAAAAAAAAAUG28rS6guhhjJEknTpywuBIAAABUlCPTOTJebUO2BQAAqDnItmRbAACAmqI82bbWNCqcPHlSkhQTE2NxJQAAAKgsJ0+eVGhoqNVlVDuyLQAAQM1DtiXbAgAA1BRlybY2U0tadfPz83XgwAHVqVNHNputWo554sQJxcTEKC0tTSEhIdVyzOpW087Rk8/HE2p31xrdqS6raqnu41b0eFVdb2WPX5njXc5YlXV8dxqnqq+pO9XoCeNYce8yxujkyZOKioqS3V77VjMj21aNmnaOnnw+nlC7u9boTnWRbatn/+oen2xb+eOQbd1rHLJt9SPbVo2ado6efD6eULu71uhOdZFtq2f/6h6fbFv545Bt3Wscd8+2tWZGBbvdrujoaEuOHRISYvkfolWtpp2jJ5+PJ9TurjW6U11W1VLdx63o8aq63soevzLHu5yxKuv47jROVV9Td6rRE8ap7ntIbfzXZg5k26pV087Rk8/HE2p31xrdqS6ybfXsX93jk20rfxyyrXuNQ7atPmTbqlXTztGTz8cTanfXGt2pLrJt9exf3eOTbSt/HLKte43jrtm29rXoAgAAAAAAAAAAAAAAy9CoAAAAAAAAAAAAAAAAqg2NClXIz89PU6dOlZ+fn9WlVJmado6efD6eULu71uhOdVlVS3Uft6LHq+p6K3v8yhzvcsaqrOO70zhVfU3dqUZPGMed7qOoOrXh91zTztGTz8cTanfXGt2pLrJt9exf3eOTbSt/HLKte43jTvdRVJ3a8HuuaefoyefjCbW7a43uVBfZtnr2r+7xybaVPw7Z1r3Gcaf7aHFsxhhjdREAAAAAAAAAAAAAAKB2YEYFAAAAAAAAAAAAAABQbWhUAAAAAAAAAAAAAAAA1YZGBQAAAAAAAAAAAAAAUG1oVLhM06ZNk81mc/lq06ZNqfu8//77atOmjfz9/dW+fXstWrSomqotm6+//lpJSUmKioqSzWbTRx995Hzt3Llzeuyxx9S+fXsFBQUpKipKI0eO1IEDB0od83KuU2Up7XwkKTMzU3fddZeioqIUGBioAQMGKDU1tdQxFy5cqG7duqlu3boKCgpSp06d9J///KfSa58xY4a6d++uOnXqqFGjRho0aJBSUlJctrnuuuuKXNv77ruvzMe47777ZLPZNGvWrMuq8Z///Kc6dOigkJAQhYSEKC4uTp9//rnz9bNnz2rcuHFq0KCBgoODdeuttyozM7PUMU+dOqXx48crOjpaAQEBateunebMmVOpdV3OdauMuv7617/KZrPpoYcecj53Oddo2rRpatOmjYKCglSvXj0lJCRo7dq15T62gzFGAwcOLPYzcjnHvvhYe/bsKXK9HV/vv/++c9yLX7vyyiudn8+AgAA1adJE9erVK/N1MsboySefVHBwcKn3oLFjx6pFixYKCAhQWFiYbrnlFv3000+ljj1s2LBSxyzPe6y4c7fb7c73WEZGhkaMGKGIiAgFBQWpS5cu+uCDD7R//379/ve/V4MGDRQQEKD27dtrw4YNkgo+A+3bt5efn5/sdrvsdrs6d+5c7P3t4nGioqIUGRkpf39/de/eXSNHjrzkff/iMRo3bqyWLVsW+xks7b5z8Tht2rTRwIEDXc7x/fff180336zQ0FAFBQWpe/fu2rt3b6njhIeHy9vbu9j3oLe3twYMGKDvv/++1M/iwoUL5efnV+wYQUFB8vf3V0xMjK644grn+/WBBx5QVlZWkfNs1qxZseP4+fm5fKZK+2yWNEbz5s2d16Zt27aKj49XUFCQQkJC1Lt3b505c6bM9QQHBysqKkr+/v4KCgpSUFCQ6tSpo9tuu02ZmZnOz1hkZKQCAgKUkJDgfI+Vdh+ePXu2mjVrJn9/f8XGxmrdunVFaoI1yLZkW7It2bY8yLZk25KuKdm2+HHItmRbVC+yLdmWbEu2LQ+yLdm2pGtKti1+HLIt2bYy0ahQAVdddZXS09OdX99++22J265evVq333677rnnHm3evFmDBg3SoEGD9P3331djxaXLzs5Wx44dNXv27CKvnT59Wps2bdKUKVO0adMmLVy4UCkpKbr55psvOW55rlNlKu18jDEaNGiQfv75Z3388cfavHmzmjZtqoSEBGVnZ5c4Zv369fXEE08oOTlZ27Zt06hRozRq1CgtWbKkUmtfuXKlxo0bpzVr1mjp0qU6d+6c+vfvX6S20aNHu1zbZ599tkzjf/jhh1qzZo2ioqIuu8bo6Gj99a9/1caNG7Vhwwb17dtXt9xyi3744QdJ0sMPP6xPP/1U77//vlauXKkDBw5oyJAhpY45YcIELV68WG+99Za2b9+uhx56SOPHj9cnn3xSaXVJ5b9uFa1r/fr1evXVV9WhQweX5y/nGrVq1Uovv/yyvvvuO3377bdq1qyZ+vfvr0OHDpXr2A6zZs2SzWYr03lc6tjFHSsmJsblWqenp+upp55ScHCwBg4c6NzuwvvEgQMHFBoa6vx8Dho0SEePHpWvr68WL15cpuv07LPP6h//+Id+85vfqEWLFurfv79iYmK0e/dul3tQ165dNXfuXG3fvl1LliyRMUb9+/dXXl5eiWPn5uaqUaNGev755yVJS5cuLXJfK8977KqrrtIdd9yhpk2b6oMPPtCGDRuc77GBAwcqJSVFn3zyib777jsNGTJEQ4cOVffu3eXj46PPP/9cP/74o/7+97+rXr16kgo+A926dZOfn59efvll3XPPPdq6dav69u2rs2fPOo977Ngx9erVyznOs88+q0OHDumhhx7Spk2bdNVVV+mdd97RAw88UOJ9/+IxfvzxR40dO1aTJk0q8hl88cUXS7zvXDxOcnKyjh07psDAQOe4jzzyiMaMGaM2bdpoxYoV2rZtm6ZMmSJ/f/8Sxxk5cqTOnz+v559/XmvWrNH06dMlSS1atJAkvfnmm2ratKni4uL0ySeflPhZrF+/vl599VWtXLlSycnJevrpp52vTZo0SW+//bby8vJ0+vRpbdy4UfPmzdPixYt1zz33FDnX9evXO98Xs2fP1t/+9jdJ0pw5c1w+U6V9Ni8cIz09Xf/6178kSbGxsVqxYoXmzZunvXv3qm/fvlq3bp3Wr1+v8ePHy24vGvscYyUlJalVq1b6+9//Lkk6f/68jh8/roYNG+rqq6+WJI0bN065ublKSkrS3/72N/3jH//QnDlztHbtWgUFBSkxMVFnz54t8T78/PPPa8KECZo6dao2bdqkjh07KjExUQcPHiz2PFH9yLZkW7It2bYsyLZkW7It2daBbEu2dWdkW7It2ZZsWxZkW7It2ZZs60C2tSjbGlyWqVOnmo4dO5Z5+9tuu83cdNNNLs/FxsaasWPHVnJllUOS+fDDD0vdZt26dUaS+eWXX0rcprzXqapcfD4pKSlGkvn++++dz+Xl5ZmwsDDz+uuvl2vszp07m8mTJ1dWqcU6ePCgkWRWrlzpfK5Pnz7mwQcfLPdY+/btM40bNzbff/+9adq0qXnhhRcqrc569eqZ//u//zPHjx83Pj4+5v3333e+tn37diPJJCcnl7j/VVddZZ5++mmX57p06WKeeOKJSqnLmMu7bhWp6+TJk+bKK680S5cudTn25V6ji2VlZRlJZtmyZWU+tsPmzZtN48aNTXp6epk+86Ud+1LHulCnTp3M3Xff7fz54vvEhZ9Px3VasGCB8/N5qeuUn59vIiIizHPPPecc+/jx48bPz8+88847pZ7T1q1bjSSzc+fOErdxjLl7924jyWzevNnl9fK8xxxjlfQe8/HxMf/+979dnvf39zctW7YsccwLz9+hbt26xtvb2+X8H3vsMXPNNdc4f+7Ro4cZN26c8+e8vDwTFRVlZsyY4Xzu4vv+xWOUJDQ01NSrV6/E+87F4xQ37rBhw8zvf//7Uo9z8X6RkZHm5Zdfdv7seG81a9bMtGjRwuTn55ujR48aSea+++5zbleW95jNZjMBAQEmPz/fGGOKvMfee+894+vra86dO1dqzQ8++KCzFsdnas6cOeX6bF555ZUmODjYWUtsbGy5/lw6ffq08fLyMv/73//Mgw8+aAIDA82oUaNMy5Ytjc1mM1lZWWbIkCHmjjvuMMePHzeSTP369V3eY5f6jNWrV880b978ku8xWIdsS7Z1INv+imxbFNm2KLJt0bHItmRbsi2sRrYl2zqQbX9Fti2KbFsU2bboWGRbsi3Ztmoxo0IFpKamKioqSldccYXuuOOOItOYXCg5OVkJCQkuzyUmJio5Obmqy6wyWVlZstlsqlu3bqnblec6VZecnBxJcunostvt8vPzK3PnsDFGy5cvV0pKinr37l0ldTo4pqGpX7++y/Nvv/22s2tq0qRJOn36dKnj5Ofna8SIEfrTn/6kq666qtLqy8vL07vvvqvs7GzFxcVp48aNOnfunMt7vk2bNmrSpEmp7/n4+Hh98skn2r9/v4wx+uqrr7Rjxw7179+/UupyKO91q0hd48aN00033VTk83+51+hCubm5eu211xQaGqqOHTuW+dhSQbf98OHDNXv2bEVERJTpeKUdu7RjXWjjxo3asmVLkY7FC+8TDz/8sKSCz6fjOvXv39/5+bzUddq9e7cyMjKctaSmpqpt27ay2WyaNm1aifeg7OxszZ07V82bN1dMTEyp55GamqrY2FhJ0uOPP15kzPK8x1JTU7V79279v//3/zR48GD98ssvzvdYx44dtWDBAh09elT5+fl69913lZOTo2uuuUZDhw5Vo0aN1LlzZ73++uvFnr/jM3D69Gl16tTJ5Zp98skn6tatm3OcdevWKT8/3/m63W5XQkKCyz4X3/cvHuPiWvLy8jR//nydOHFCY8eOLfG+c/E4s2bNkp+fn/PnTp066aOPPlKrVq2UmJioRo0aKTY2tsjUWhePc/DgQZcpqhz3/r179+ruu++WzWbT5s2bnefmUNp7zBijefPmyRijG264wdk9GxoaqtjYWOc+WVlZCgkJkbe3d7HnLBV8jt566y3dfffdOnfunF577TWFhIRo5syZZf5snj171vl+HDBggBo2bKi1a9cqIyND8fHxCg8PV58+fUr9s+38+fPKy8uTl5eX3nrrLfXq1Utffvml8vPzZYxRSkqKvv32Ww0cOFD+/v6y2+06evSoy+f94vN3cLwHT506pb1797rsU9x7DNYi25JtybYFyLYlI9u6ItsWPxbZlmxLtoU7INuSbcm2Bci2JSPbuiLbFj8W2ZZsS7atYlXeClFDLVq0yLz33ntm69atZvHixSYuLs40adLEnDhxotjtfXx8zPz5812emz17tmnUqFF1lFtuukQn0JkzZ0yXLl3M8OHDSx2nvNepqlx8Prm5uaZJkyZm6NCh5ujRoyYnJ8f89a9/NZJM//79Sx3r+PHjJigoyHh7exs/Pz/zxhtvVGnteXl55qabbjK9evVyef7VV181ixcvNtu2bTNvvfWWady4sRk8eHCpY02fPt3ccMMNzu6tinbmbtu2zQQFBRkvLy8TGhpqPvvsM2OMMW+//bbx9fUtsn337t3Nn//85xLHO3v2rBk5cqSRZLy9vY2vr6/517/+VWl1GXN51+1y63rnnXfM1Vdfbc6cOWOMce3YvNxrZIwxn376qQkKCjI2m81ERUWZdevWlevYxhgzZswYc8899zh/vtRnvrRjX+pYF/rDH/5g2rZt6/LcxfeJnj17Gi8vLzNo0CDz2muvGV9f3yKfz9Ku06pVq4wkc+DAAZexr732WtOgQYMi96DZs2eboKAgI8m0bt261K7cC+tdtGiRkWQ6dOjgMmZ53mOOsdavX2/69etnJBlJxsfHx/zrX/8yx44dM/3793e+90JCQoyPj4/x8/MzkyZNMps2bTKvvvqq8ff3N/PmzXM5/4CAAJfPwNChQ81tt93mPLafn59znCVLlhhJxtfX1zmOMcb86U9/Mj169DDGFH/fv3CMC2t55plnnJ9BPz8/07lz51LvOxeP4+3tbSSZm266yWzatMk8++yzzvpmzpxpNm/ebGbMmGFsNptZsWJFieN0797d2Gw289e//tXk5eU5f2eSzA8//GBycnLM7373u2Lv/Re/xy6893t5eRlJZtOmTS77OK7xoUOHTJMmTczjjz9e6ntpwYIFxm63m4CAAOdnavDgweX6bL766qtGkvH39zczZ840//rXv5zn+Nhjj5lNmzaZhx56yPj6+podO3aUOE5cXJxp27at8fLyMnv27DG/+c1vnONIMtOmTTOnTp0y48ePdz534MCBYs/fmKL34X//+99Gklm9erXLPhe+x2Atsi3ZlmxLtr0Usm1RZNvixyLbkm3JtrAa2ZZsS7Yl214K2bYosm3xY5FtybZk26pFo0IlOXbsmAkJCXFOU3SxmhR4c3NzTVJSkuncubPJysoq17iXuk5Vpbjz2bBhg+nYsaORZLy8vExiYqIZOHCgGTBgQKlj5eXlmdTUVLN582bz/PPPm9DQUPPVV19VWe333Xefadq0qUlLSyt1u+XLl5c69dGGDRtMeHi42b9/v/O5igbenJwck5qaajZs2GAmTpxoGjZsaH744YfLDnPPPfecadWqlfnkk0/M1q1bzUsvvWSCg4PN0qVLK6Wu4lzqul1uXXv37jWNGjUyW7dudT5XWYH31KlTJjU11SQnJ5u7777bNGvWzGRmZpb52B9//LFp2bKlOXnypPP1sgbei48dHR1tGjZsWOKxLnT69GkTGhpqnn/++VKPcezYMRMUFGSio6Odf7Be/Pksa+C90NChQ82gQYOK3IOOHz9uduzYYVauXGmSkpJMly5dnOG9NI4pxL7++utS72vleY/Nnz/fBAcHm+HDh5vg4GBzyy23mB49ephly5aZLVu2mGnTphlJRaZmvP/++03Pnj1dzn/VqlUun4HExESXwOvj42Pi4uKMMcbs37/fSDK//e1vneMY82sYKem+f+EYF9YSGxtrUlNTzX/+8x8TFBRk6tWr5/wMFnffuXgcHx8fExER4azFUV+DBg1c9ktKSjK/+93vShzn4MGDpnnz5s77fKtWrUx4eLjzfeXl5WXat29vbDZbkXv/xe+xC+/9MTExRpL573//67LP0KFDzeDBg02PHj3MgAEDTG5urilN//79zcCBA52fqYSEBOPt7W1+/vln5zaX+mz26dPHSDK33367MebX33/Lli1drk379u3NxIkTSxxn586dpl69ekaSsdlsxsfHx/Tq1cuEh4ebsLAw5/O///3vTatWrS4ZeC++DzvG5i9zPQfZtmzItuVHtiXbXoxsS7Yl2xYg25JtUXXItmVDti0/si3Z9mJkW7It2bYA2ZZsW1Y0KlSibt26lfhmiomJKfIBf/LJJ02HDh2qobLyK+kDlpubawYNGmQ6dOhgDh8+fFljl3adqkppN4zjx4+bgwcPGmMK1vr54x//WK6x77nnnkt2816ucePGmejoaJebX0lOnTplJJnFixcX+/oLL7xgbDab8fLycn5JMna73TRt2rRS6u3Xr58ZM2aM8w/4Y8eOubzepEkTM3PmzGL3PX36tPHx8TH/+9//XJ6/5557TGJiYqXUVZxLXbfLrevDDz90/oF64fV2/A6WLVtW7mtUkpYtW5rp06eX+djjx48v8b3Qp0+fch07IiKi1GOdP3/eue2///1v4+Pj4/y8lcZxn/j444+d1+nCz2dp12nXrl1GKroGWe/evc0DDzxQ6j0oJyfHBAYGFvkLiuJcuNZZaWOW9z3mGGvo0KFGcl2T0ZiCtc7atGnj8twrr7xioqKiSjz/fv36mcjISPPAAw84n2vSpImzAzQnJ8d4eXmZsWPHOscxxpiRI0ea3/zmNyXe9y8co7haHPcdx1dJ952Lx2nSpImJj493jpOTk2PsdrupU6eOy7H+/Oc/m/j4+EvWExkZafbt22d2795tbDabiYmJcd77Hferi/cr6T22Z88eY7fbjSSX/zgwxpj4+HgTERFh+vXrd8n/aHKM89FHHzmfe/DBB53XpyyfTccYdrvdPPPMM8YYY37++WdnV/OF1+a2224r9V/TOMZ69913nWvE3XbbbebGG280xhgzceJEc+WVVxpjjGnQoEGpn7HiXH/99cZmsxX5s3jkyJHm5ptvLrEuWItsWzZk27Ij25Jty4Js64psS7a9uB6yLdkWl4dsWzZk27Ij25Jty4Js64psS7a9uB6yLdnWLlSKU6dOadeuXYqMjCz29bi4OC1fvtzluaVLl7qsv+Tuzp07p9tuu02pqalatmyZGjRoUO4xLnWdrBAaGqqwsDClpqZqw4YNuuWWW8q1f35+vnP9nMpijNH48eP14Ycf6ssvv1Tz5s0vuc+WLVskqcRrO2LECG3btk1btmxxfkVFRelPf/qTlixZUil1O65F165d5ePj4/KeT0lJ0d69e0t8z587d07nzp2T3e56W/Ly8nJZf6kidRXnUtftcuvq16+fvvvuO5fr3a1bN91xxx3Ox+W9RmU9v0sd+4knnijyXpCkF154QXPnzi3Xsf39/fWHP/yhxGN5eXk5t33jjTd08803KywsrNQxL7xP9OnTRz4+Pnrrrbecn89LXafmzZsrIiLC5dqeOHFCa9euVefOnUu9B5mCBr5yfaZPnz5d6pjleY9deO7GGEkq8t6rW7eujh075vLcjh071LRpU0nFn39ubq4yMzNdrlmvXr2UkpIiSfL19VXXrl21Zs0a5zj5+flatmyZfv755xLv+xeOUVwtjvtOt27dlJSUVOJ95+JxevXqpT179jjH8fX1VXh4uPz8/Eo8Vmn1NGvWTI0bN9Ybb7whu92u4cOHO+/9jnXbLvz9lPYemzt3rho1aiR/f38dPHjQ+fy+ffuUnJysevXq6ZNPPnFZS7M4jnFuuukm53MTJ05UdHS0xo4dW6bPpmOMHj16OM+7WbNmioqKUmpqqsu1ufhalTTWrbfeqpycHJ09e1ZLlixx/pkYEhIiSfryyy915MgRhYWFFfsZK+3+1aBBA5d98vPztXz5co/KQrUJ2bZsyLZlQ7b9Fdm2/OdHtiXbkm1dtyHbkm1RfmTbsiHblg3Z9ldk2/KfH9mWbEu2dd2GbEu2ZUaFy/TII4+YFStWmN27d5tVq1aZhIQE07BhQ2fH2YgRI1y6tFatWmW8vb3N888/b7Zv326mTp1qfHx8zHfffWfVKRRx8uRJs3nzZrN582YjybmezC+//GJyc3PNzTffbKKjo82WLVtMenq68ysnJ8c5Rt++fc1LL73k/PlS18mq8zHGmPfee8989dVXZteuXeajjz4yTZs2NUOGDHEZ4+Lf4/Tp080XX3xhdu3aZX788Ufz/PPPG29vb/P6669Xau1/+MMfTGhoqFmxYoXLtT59+rQxpmCql6efftps2LDB7N6923z88cfmiiuuML1793YZp3Xr1mbhwoUlHqciU4hNnDjRrFy50uzevdts27bNTJw40dhsNvPFF18YYwqmPmvSpIn58ssvzYYNG0xcXFyRqYYurq9Pnz7mqquuMl999ZX5+eefzdy5c42/v7955ZVXKqWuy71ulVGXY5wLp9Yq7zU6deqUmTRpkklOTjZ79uwxGzZsMKNGjTJ+fn5FujcvdeyLqZju9cs9dnHHSk1NNTabzXz++edFjv3II4+YmJgYM2fOHOd9ok6dOubDDz80u3btMgMGDDBeXl7m2muvLfN76a9//aupW7euGTRokHnzzTfNDTfcYCIjI03fvn2d96Bdu3aZ6dOnmw0bNphffvnFrFq1yiQlJZn69eu7TMl28djjxo0zr7/+unnzzTeNJNO+fXtTt25d891335X7Pea4R8bGxprmzZubrl27mvr165sXX3zR+Pn5mbCwMHPttdeatWvXmp07d5rnn3/e2Qn9l7/8xaSmppp27doZX19f89ZbbxljCj4DY8eONSEhIebFF180d999t5FkIiIiXLpFu3XrZux2u3McxxpWY8aMMT/++KO59957jbe3t4mKiirxvr9u3Tpjs9nMb37zG5Oammrefvtt4+PjYyZPnlzivaG4+87FtTz99NNGkhk6dKhzXF9fX+Pl5WVee+01k5qaal566SXj5eVlvvnmG+c4AwcOdBnnqaeeMn5+fmbmzJlmxYoVxs/PzwQGBppPP/3U5d7fvHlzl89iWFiYady4sXPc6dOnm+joaPPyyy+byMhIc/311xu73W4CAwPNxx9/bFavXm3q1atnfHx8zA8//OByrS7sTnf83vPy8kxMTIzp2bPnJT9TJX02//vf/5omTZqYxx57zCxcuND4+Pg4r82QIUOMJPP000+b1NRUM3nyZOPv7+8yjd2Ff17n5eWZRo0amaFDh5qff/7Z3HDDDcbHx8e0atXKzJgxw8yYMcPUq1fP3HTTTaZ+/fpmwoQJzs/Yxx9/bHr06GHat29vmjdvbs6cOeO8D8fHx5tJkyY53wOPP/648fPzM/PmzTM//vijGTNmjKlbt67JyMgwsB7ZlmxLtiXbkm3JtmRbsi3ZlmxbU5BtybZkW7It2ZZsS7Yl25JtPSPb0qhwmYYNG2YiIyONr6+vady4sRk2bJjLG6lPnz7mzjvvdNnnvffeM61atTK+vr7mqquuMp999lk1V126r776yqhw/ZcLv+68807nVDnFfV24zlfTpk3N1KlTnT9f6jpZdT7GGPPiiy+a6Oho4+PjY5o0aWImT57sEt6NKfp7fOKJJ0zLli2Nv7+/qVevnomLizPvvvtupdde0rWeO3euMaZgLavevXub+vXrGz8/P9OyZUvzpz/9qcjacxfuU5yKBN67777bNG3a1Pj6+pqwsDDTr18/5x9oxhhz5swZ88c//tHUq1fPBAYGmsGDB5v09PRS60tPTzd33XWXiYqKMv7+/qZ169bm73//u8nPz6+Uui73ulVGXcYUDYLlvUZnzpwxgwcPNlFRUcbX19dERkaam2++2axbt67cx75YcX+oXu6xizvWpEmTTExMjMnLyyuy/bBhw4wk4+3t7bxPTJkyxfn5jImJMV27di3Xeyk/P99MmTLF+Pn5Oac0Cw8Pd7kH7d+/3wwcONA0atTI+Pj4mOjoaDN8+HDz008/lTp2jx49iv18Tp06tdzvsQvvkYGBgcbf39/4+vo632MpKSlmyJAhplGjRiYwMNB06NDB/Pvf/zaffvqpufrqq42fn5/x9vY2v/nNb5xj33333aZJkybGbrcbm81m7Ha76dy5s0lJSXGpoWnTpub22293jtOmTRvzu9/9zjRp0sT4+vo614K81H0/LCzMNGrUyDlGr169Sr03FHffKa6W8ePHu/z82muvmTfeeMN5D+7YsaPL9FvGFLz3+vbt69yvSZMmJiIiwvj5+Zk6deoYSeaBBx4ocu/Pyspy+Sw2bNjQZV24J554wjmVlyTTqVMn884775gpU6aY8PBw4+PjU+K12r17d5Hf+5IlS4wkk5CQcMnPVEmfzUceecRIcv5eL742I0aMMNHR0SYwMNDExcW5/IeB45o7/rx21BMdHW18fX1No0aNTIcOHUx0dLTx9vY2Xl5exm63m5YtWzrvfY7PmGPtuObNmztrcdyHJZnAwECX98BLL73kfI/16NHDrFmzxsA9kG3JtmRbsi3ZlmxLtiXbkm3JtjUF2ZZsS7Yl25JtybZkW7It2dYzsq2t8MIBAAAAAAAAAAAAAABUOfulNwEAAAAAAAAAAAAAAKgcNCoAAAAAAAAAAAAAAIBqQ6MCAAAAAAAAAAAAAACoNjQqAAAAAAAAAAAAAACAakOjAgAAAAAAAAAAAAAAqDY0KgAAAAAAAAAAAAAAgGpDowIAAAAAAAAAAAAAAKg2NCoAAAAAAAAAAAAAAIBqQ6MCANRC06ZNU3h4uGw2mz766KMy7bNixQrZbDYdP368SmtzJ82aNdOsWbOsLgMAAAClINuWDdkWAADA/ZFty4ZsC9QMNCoAcAt33XWXbDabbDabfH191bJlSz399NM6f/681aVdUnlCozvYvn27nnrqKb366qtKT0/XwIEDq+xY1113nR566KEqGx8AAMAdkW2rD9kWAACgapFtqw/ZFkBt4211AQDgMGDAAM2dO1c5OTlatGiRxo0bJx8fH02aNKncY+Xl5clms8lupx/rYrt27ZIk3XLLLbLZbBZXAwAAUDORbasH2RYAAKDqkW2rB9kWQG3DnwQA3Iafn58iIiLUtGlT/eEPf1BCQoI++eQTSVJOTo4effRRNW7cWEFBQYqNjdWKFSuc+86bN09169bVJ598onbt2snPz0979+5VTk6OHnvsMcXExMjPz08tW7bUG2+84dzv+++/18CBAxUcHKzw8HCNGDFChw8fdr5+3XXX6YEHHtCf//xn1a9fXxEREZo2bZrz9WbNmkmSBg8eLJvN5vx5165duuWWWxQeHq7g4GB1795dy5Ytcznf9PR03XTTTQoICFDz5s01f/78IlNWHT9+XPfee6/CwsIUEhKivn37auvWraVex++++059+/ZVQECAGjRooDFjxujUqVOSCqYOS0pKkiTZ7fZSA++iRYvUqlUrBQQE6Prrr9eePXtcXj9y5Ihuv/12NW7cWIGBgWrfvr3eeecd5+t33XWXVq5cqRdffNHZdb1nzx7l5eXpnnvuUfPmzRUQEKDWrVvrxRdfLPWcHL/fC3300Ucu9W/dulXXX3+96tSpo5CQEHXt2lUbNmxwvv7tt9/q2muvVUBAgGJiYvTAAw8oOzvb+frBgweVlJTk/H28/fbbpdYEAABQGrIt2bYkZFsAAOBpyLZk25KQbQFUBI0KANxWQECAcnNzJUnjx49XcnKy3n33XW3btk1Dhw7VgAEDlJqa6tz+9OnT+tvf/qb/+7//0w8//KBGjRpp5MiReuedd/SPf/xD27dv16uvvqrg4GBJBWGyb9++6ty5szZs2KDFixcrMzNTt912m0sd//rXvxQUFKS1a9fq2Wef1dNPP62lS5dKktavXy9Jmjt3rtLT050/nzp1SjfeeKOWL1+uzZs3a8CAAUpKStLevXud444cOVIHDhzQihUr9MEHH+i1117TwYMHXY49dOhQHTx4UJ9//rk2btyoLl26qF+/fjp69Gix1yw7O1uJiYmqV6+e1q9fr/fff1/Lli3T+PHjJUmPPvqo5s6dK6kgcKenpxc7TlpamoYMGaKkpCRt2bJF9957ryZOnOiyzdmzZ9W1a1d99tln+v777zVmzBiNGDFC69atkyS9+OKLiouL0+jRo53HiomJUX5+vqKjo/X+++/rxx9/1JNPPqnHH39c7733XrG1lNUdd9yh6OhorV+/Xhs3btTEiRPl4+MjqeA/QAYMGKBbb71V27Zt04IFC/Ttt986r4tUENDT0tL01Vdf6b///a9eeeWVIr8PAACAy0W2JduWB9kWAAC4M7It2bY8yLYASmQAwA3ceeed5pZbbjHGGJOfn2+WLl1q/Pz8zKOPPmp++eUX4+XlZfbv3++yT79+/cykSZOMMcbMnTvXSDJbtmxxvp6SkmIkmaVLlxZ7zGeeecb079/f5bm0tDQjyaSkpBhjjOnTp4+55pprXLbp3r27eeyxx5w/SzIffvjhJc/xqquuMi+99JIxxpjt27cbSWb9+vXO11NTU40k88ILLxhjjPnmm29MSEiIOXv2rMs4LVq0MK+++mqxx3jttddMvXr1zKlTp5zPffbZZ8Zut5uMjAxjjDEffvihudTtf9KkSaZdu3Yuzz322GNGkjl27FiJ+910003mkUcecf7cp08f8+CDD5Z6LGOMGTdunLn11ltLfH3u3LkmNDTU5bmLz6NOnTpm3rx5xe5/zz33mDFjxrg898033xi73W7OnDnjfK+sW7fO+brjd+T4fQAAAJQV2ZZsS7YFAAA1BdmWbEu2BVBVvKu8EwIAyuh///ufgoODde7cOeXn52v48OGaNm2aVqxYoby8PLVq1cpl+5ycHDVo0MD5s6+vrzp06OD8ecuWLfLy8lKfPn2KPd7WrVv11VdfOTt1L7Rr1y7n8S4cU5IiIyMv2bF56tQpTZs2TZ999pnS09N1/vx5nTlzxtmZm5KSIm9vb3Xp0sW5T8uWLVWvXj2X+k6dOuVyjpJ05swZ53plF9u+fbs6duyooKAg53O9evVSfn6+UlJSFB4eXmrdF44TGxvr8lxcXJzLz3l5eZo+fbree+897d+/X7m5ucrJyVFgYOAlx589e7befPNN7d27V2fOnFFubq46depUptpKMmHCBN177736z3/+o4SEBA0dOlQtWrSQVHAtt23b5jItmDFG+fn52r17t3bs2CFvb2917drV+XqbNm2KTFsGAABQVmRbsm1FkG0BAIA7IduSbSuCbAugJDQqAHAb119/vf75z3/K19dXUVFR8vYuuEWdOnVKXl5e2rhxo7y8vFz2uTCsBgQEuKx9FRAQUOrxTp06paSkJP3tb38r8lpkZKTzsWMaKgebzab8/PxSx3700Ue1dOlSPf/882rZsqUCAgL029/+1jklWlmcOnVKkZGRLmu6ObhDEHvuuef04osvatasWWrfvr2CgoL00EMPXfIc3333XT366KP6+9//rri4ONWpU0fPPfec1q5dW+I+drtdxhiX586dO+fy87Rp0zR8+HB99tln+vzzzzV16lS9++67Gjx4sE6dOqWxY8fqgQceKDJ2kyZNtGPHjnKcOQAAwKWRbYvWR7YtQLYFAACehmxbtD6ybQGyLYCKoFEBgNsICgpSy5YtizzfuXNn5eXl6eDBg7r22mvLPF779u2Vn5+vlStXKiEhocjrXbp00QcffKBmzZo5w/Xl8PHxUV5enstzq1at0l133aXBgwdLKgive/bscb7eunVrnT9/Xps3b3Z2g+7cuVPHjh1zqS8jI0Pe3t5q1qxZmWpp27at5s2bp+zsbGd37qpVq2S329W6desyn1Pbtm31ySefuDy3Zs2aIud4yy236Pe//70kKT8/Xzt27FC7du2c2/j6+hZ7beLj4/XHP/7R+VxJncYOYWFhOnnypMt5bdmypch2rVq1UqtWrfTwww/r9ttv19y5czV48GB16dJFP/74Y7HvL6mgC/f8+fPauHGjunfvLqmge/r48eOl1gUAAFASsi3ZtiRkWwAA4GnItmTbkpBtAVSE3eoCAOBSWrVqpTvuuEMjR47UwoULtXv3bq1bt04zZszQZ599VuJ+zZo105133qm7775bH330kXbv3q0VK1bovffekySNGzdOR48e1e23367169dr165dWrJkiUaNGlUkpJWmWbNmWr58uTIyMpyB9corr9TChQu1ZcsWbd26VcOHD3fp5m3Tpo0SEhI0ZswYrVu3Tps3b9aYMWNcuosTEhIUFxenQYMG6YsvvtCePXu0evVqPfHEE9qwYUOxtdxxxx3y9/fXnXfeqe+//15fffWV7r//fo0YMaLM04dJ0n333afU1FT96U9/UkpKiubPn6958+a5bHPllVdq6dKlWr16tbZv366xY8cqMzOzyLVZu3at9uzZo8OHDys/P19XXnmlNmzYoCVLlmjHjh2aMmWK1q9fX2o9sbGxCgwM1OOPP65du3YVqefMmTMaP368VqxYoV9++UWrVq3S+vXr1bZtW0nSY489ptWrV2v8+PHasmWLUlNT9fHHH2v8+PGSCv4DZMCAARo7dqzWrl2rjRs36t57771kdzcAAEB5kW3JtmRbAABQU5BtybZkWwAVQaMCAI8wd+5cjRw5Uo888ohat26tQYMGaf369WrSpEmp+/3zn//Ub3/7W/3xj39UmzZtNHr0aGVnZ0uSoqKitGrVKuXl5al///5q3769HnroIdWtW1d2e9lvj3//+9+1dOlSxcTEqHPnzpKkmTNnql69eoqPj1dSUpISExNd1jWTpH//+98KDw9X7969NXjwYI0ePVp16tSRv7+/pIKpyhYtWqTevXtr1KhRatWqlX73u9/pl19+KTG8BgYGasmSJTp69Ki6d++u3/72t+rXr59efvnlMp+PVDCt1gcffKCPPvpIHTt21Jw5czR9+nSXbSZPnqwuXbooMTFR1113nSIiIjRo0CCXbR599FF5eXmpXbt2CgsL0969ezV27FgNGTJEw4YNU2xsrI4cOeLSpVuc+vXr66233tKiRYvUvn17vfPOO5o2bZrzdS8vLx05ckQjR45Uq1atdNttt2ngwIF66qmnJBWsV7dy5Urt2LFD1157rTp37qwnn3xSUVFRzjHmzp2rqKgo9enTR0OGDNGYMWPUqFGjcl03AACAsiDbkm3JtgAAoKYg25JtybYALpfNXLx4DADAEvv27VNMTIyWLVumfv36WV0OAAAAcNnItgAAAKgpyLYAUDVoVAAAi3z55Zc6deqU2rdvr/T0dP35z3/W/v37tWPHDvn4+FhdHgAAAFBmZFsAAADUFGRbAKge3lYXAAC11blz5/T444/r559/Vp06dRQfH6+3336bsAsAAACPQ7YFAABATUG2BYDqwYwKAAAAAAAAAAAAAACg2titLgAAAAAAAAAAAAAAANQeNCoAAAAAAAAAAAAAAIBqQ6MCAAAAAAAAAAAAAACoNjQqAAAAAAAAAAAAAACAakOjAgAAAAAAAAAAAAAAqDY0KgAAAAAAAAAAAAAAgGpDowIAAAAAAAAAAAAAAKg2NCoAAAAAAAAAAAAAAIBqQ6MCAAAAAAAAAAAAAACoNv8fyjOzEwn4h/IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701f6fc",
   "metadata": {
    "papermill": {
     "duration": 0.253598,
     "end_time": "2025-03-29T05:45:38.654268",
     "exception": false,
     "start_time": "2025-03-29T05:45:38.400670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 60.92530941963196 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 0.0002644062042236328 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5989, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5124, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4913, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4831, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4735, Accuracy: 0.8103, F1 Micro: 0.8925, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3998, Accuracy: 0.8147, F1 Micro: 0.8931, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3741, Accuracy: 0.8311, F1 Micro: 0.9024, F1 Macro: 0.9006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3304, Accuracy: 0.8616, F1 Micro: 0.9181, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2934, Accuracy: 0.872, F1 Micro: 0.9235, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2501, Accuracy: 0.8951, F1 Micro: 0.9363, F1 Macro: 0.9349\n",
      "\n",
      "Aspect detection accuracy: 0.8951, F1 Micro: 0.9363, F1 Macro: 0.9349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.93      0.99      0.96       187\n",
      "     machine       0.89      0.99      0.94       175\n",
      "      others       0.84      0.94      0.89       158\n",
      "        part       0.92      0.93      0.93       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.86      1.00      0.93       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.97      0.93      1061\n",
      "weighted avg       0.90      0.98      0.94      1061\n",
      " samples avg       0.90      0.98      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5527, Accuracy: 0.7151, F1 Micro: 0.7151, F1 Macro: 0.4169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5656, Accuracy: 0.7151, F1 Micro: 0.7151, F1 Macro: 0.4169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5343, Accuracy: 0.7151, F1 Micro: 0.7151, F1 Macro: 0.4169\n",
      "Epoch 4/10, Train Loss: 0.5062, Accuracy: 0.7043, F1 Micro: 0.7043, F1 Macro: 0.4132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.393, Accuracy: 0.7903, F1 Micro: 0.7903, F1 Macro: 0.6866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3096, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1388, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8919\n",
      "Epoch 9/10, Train Loss: 0.1307, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1284, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8956\n",
      "\n",
      "Sentiment analysis accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.85        53\n",
      "    positive       0.95      0.93      0.94       133\n",
      "\n",
      "    accuracy                           0.91       186\n",
      "   macro avg       0.89      0.90      0.90       186\n",
      "weighted avg       0.92      0.91      0.91       186\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8866, F1 Micro: 0.8866, F1 Macro: 0.7057\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.64      0.74        11\n",
      "     neutral       0.94      0.99      0.97       181\n",
      "    positive       0.94      0.62      0.75        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.75      0.82       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.25      0.38        16\n",
      "     neutral       0.88      0.99      0.93       167\n",
      "    positive       0.83      0.61      0.70        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.61      0.67       216\n",
      "weighted avg       0.87      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.58      0.67        12\n",
      "     neutral       0.84      0.93      0.88       152\n",
      "    positive       0.76      0.56      0.64        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.79      0.69      0.73       216\n",
      "weighted avg       0.82      0.82      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78        23\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.77      0.73      0.75        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.73      0.80       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25        14\n",
      "     neutral       0.87      1.00      0.93       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.62      0.38      0.39       216\n",
      "weighted avg       0.81      0.87      0.81       216\n",
      "\n",
      "Total train time: 71.70187878608704 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 0.00010609626770019531 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5822, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4882, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4556, Accuracy: 0.8013, F1 Micro: 0.8878, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4261, Accuracy: 0.8207, F1 Micro: 0.8963, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3644, Accuracy: 0.8571, F1 Micro: 0.9159, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3037, Accuracy: 0.8862, F1 Micro: 0.9313, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2618, Accuracy: 0.9152, F1 Micro: 0.9478, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2149, Accuracy: 0.9271, F1 Micro: 0.955, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1764, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9618\n",
      "\n",
      "Aspect detection accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.92      0.99      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.92      0.99      0.96       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.93      0.99      0.96      1061\n",
      "weighted avg       0.94      0.99      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6025, Accuracy: 0.654, F1 Micro: 0.654, F1 Macro: 0.3954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.516, Accuracy: 0.654, F1 Micro: 0.654, F1 Macro: 0.3954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4773, Accuracy: 0.654, F1 Micro: 0.654, F1 Macro: 0.3954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3734, Accuracy: 0.8626, F1 Micro: 0.8626, F1 Macro: 0.8352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2571, Accuracy: 0.9479, F1 Micro: 0.9479, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1996, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9473\n",
      "Epoch 7/10, Train Loss: 0.1473, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9246\n",
      "Epoch 8/10, Train Loss: 0.1222, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9272\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9008\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9368\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        73\n",
      "    positive       0.96      0.97      0.96       138\n",
      "\n",
      "    accuracy                           0.95       211\n",
      "   macro avg       0.95      0.94      0.95       211\n",
      "weighted avg       0.95      0.95      0.95       211\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8585\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.50      0.64        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.73      0.79       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.78      0.88        23\n",
      "     neutral       0.92      0.99      0.96       152\n",
      "    positive       0.88      0.73      0.80        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.78      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.80      0.86       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 76.66851258277893 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 0.00010919570922851562 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5647, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5026, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4645, Accuracy: 0.7991, F1 Micro: 0.8859, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4095, Accuracy: 0.8199, F1 Micro: 0.8955, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3672, Accuracy: 0.872, F1 Micro: 0.9237, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2948, Accuracy: 0.8996, F1 Micro: 0.9378, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2449, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1847, Accuracy: 0.9427, F1 Micro: 0.9646, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1505, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1228, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9675\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.6639, F1 Micro: 0.6639, F1 Macro: 0.399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5114, Accuracy: 0.7418, F1 Micro: 0.7418, F1 Macro: 0.6327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3177, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2558, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Epoch 5/10, Train Loss: 0.2134, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8764\n",
      "Epoch 6/10, Train Loss: 0.1592, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9265\n",
      "Epoch 7/10, Train Loss: 0.1329, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8413\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9282\n",
      "\n",
      "Sentiment analysis accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        82\n",
      "    positive       0.97      0.94      0.96       162\n",
      "\n",
      "    accuracy                           0.94       244\n",
      "   macro avg       0.93      0.94      0.94       244\n",
      "weighted avg       0.94      0.94      0.94       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8915\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      1.00      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.86       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.73      0.69      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.84      0.80       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.86      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.59      0.74        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.99      0.84      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 80.16400814056396 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 9.799003601074219e-05 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5634, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5061, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4558, Accuracy: 0.8103, F1 Micro: 0.891, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3878, Accuracy: 0.8594, F1 Micro: 0.916, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2991, Accuracy: 0.904, F1 Micro: 0.9404, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2458, Accuracy: 0.9353, F1 Micro: 0.9598, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1912, Accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9644\n",
      "Epoch 8/10, Train Loss: 0.1522, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1179, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1004, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9683\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.92      0.87      0.90       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6044, Accuracy: 0.6759, F1 Micro: 0.6759, F1 Macro: 0.4033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3893, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2213, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9287\n",
      "Epoch 4/10, Train Loss: 0.1707, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9198\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9124\n",
      "Epoch 6/10, Train Loss: 0.0906, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9188\n",
      "Epoch 7/10, Train Loss: 0.0642, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9203\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "Epoch 10/10, Train Loss: 0.0604, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        82\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8992\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      1.00      0.97       167\n",
      "    positive       0.96      0.76      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.68      0.73      0.70        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.81      0.77       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Total train time: 84.03220987319946 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 0.00010061264038085938 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5538, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4795, Accuracy: 0.7939, F1 Micro: 0.8835, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4223, Accuracy: 0.8259, F1 Micro: 0.8989, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3603, Accuracy: 0.8988, F1 Micro: 0.938, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2691, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1974, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1454, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1296, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9688\n",
      "Epoch 9/10, Train Loss: 0.0981, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0845, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.95      0.89      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6275, Accuracy: 0.6756, F1 Micro: 0.6756, F1 Macro: 0.4032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4365, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2491, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Epoch 4/10, Train Loss: 0.2294, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9045\n",
      "Epoch 5/10, Train Loss: 0.1531, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1243, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9258\n",
      "Epoch 8/10, Train Loss: 0.0713, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9238\n",
      "Epoch 9/10, Train Loss: 0.0881, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9211\n",
      "\n",
      "Sentiment analysis accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9092\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.79      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.71      0.79      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.86      0.82       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 92.00027513504028 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.489059448242188e-05 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5431, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4726, Accuracy: 0.7939, F1 Micro: 0.8836, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4208, Accuracy: 0.843, F1 Micro: 0.9086, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3281, Accuracy: 0.91, F1 Micro: 0.9447, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2559, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1948, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1459, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.1144, Accuracy: 0.9479, F1 Micro: 0.9671, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.0978, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0756, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.6846, F1 Micro: 0.6846, F1 Macro: 0.4179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3363, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 3/10, Train Loss: 0.2283, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8893\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9151\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9255\n",
      "Epoch 9/10, Train Loss: 0.096, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9115\n",
      "\n",
      "Sentiment analysis accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9127\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.92      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 92.35704278945923 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.393692016601562e-05 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5481, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.485, Accuracy: 0.8013, F1 Micro: 0.8862, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4233, Accuracy: 0.8609, F1 Micro: 0.9176, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3111, Accuracy: 0.9315, F1 Micro: 0.9581, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2319, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.1839, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1324, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1028, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0949, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0759, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5992, Accuracy: 0.668, F1 Micro: 0.668, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4387, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2021, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9455\n",
      "Epoch 4/10, Train Loss: 0.1912, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9196\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9541\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9452\n",
      "Epoch 9/10, Train Loss: 0.0853, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9452\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9397\n",
      "\n",
      "Sentiment analysis accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        81\n",
      "    positive       0.98      0.96      0.97       163\n",
      "\n",
      "    accuracy                           0.96       244\n",
      "   macro avg       0.95      0.96      0.95       244\n",
      "weighted avg       0.96      0.96      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9188\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.81      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 92.43827199935913 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.821487426757812e-05 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5337, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4742, Accuracy: 0.8065, F1 Micro: 0.8906, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.386, Accuracy: 0.8981, F1 Micro: 0.9386, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2734, Accuracy: 0.9457, F1 Micro: 0.9665, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1948, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9699\n",
      "Epoch 7/10, Train Loss: 0.1146, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.6743, F1 Micro: 0.6743, F1 Macro: 0.4138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3873, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9322\n",
      "Epoch 3/10, Train Loss: 0.206, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9318\n",
      "Epoch 6/10, Train Loss: 0.1145, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9318\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9092\n",
      "Epoch 8/10, Train Loss: 0.0945, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9285\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Epoch 10/10, Train Loss: 0.0782, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9169\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.93      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9227\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.88      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 95.99830365180969 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 0.012705802917480469 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5432, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.481, Accuracy: 0.8028, F1 Micro: 0.8881, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3936, Accuracy: 0.901, F1 Micro: 0.9392, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2743, Accuracy: 0.9353, F1 Micro: 0.9596, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2034, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1487, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0959, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0793, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5708, Accuracy: 0.6962, F1 Micro: 0.6962, F1 Macro: 0.4828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3153, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1877, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1434, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 7/10, Train Loss: 0.138, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9052\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9243\n",
      "Epoch 9/10, Train Loss: 0.0918, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9115\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        86\n",
      "    positive       0.98      0.93      0.95       174\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.95      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9126\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.84      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.82325458526611 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.393692016601562e-05 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4718, Accuracy: 0.8147, F1 Micro: 0.8937, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3702, Accuracy: 0.9226, F1 Micro: 0.9522, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2691, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1867, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.141, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0769, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5563, Accuracy: 0.7692, F1 Micro: 0.7692, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3383, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2179, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9437\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "Epoch 6/10, Train Loss: 0.134, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1291, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.924\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9035\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9163\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.83      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.95      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.17065906524658 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 9.131431579589844e-05 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4671, Accuracy: 0.8229, F1 Micro: 0.8973, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3494, Accuracy: 0.9115, F1 Micro: 0.946, F1 Macro: 0.944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2464, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1848, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1041, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0588, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5295, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2576, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9099\n",
      "Epoch 3/10, Train Loss: 0.1628, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9088\n",
      "Epoch 4/10, Train Loss: 0.1296, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.151, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1372, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 8/10, Train Loss: 0.1099, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9099\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9089\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8989\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.94      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.84      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.58949160575867 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 8.249282836914062e-05 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5354, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4529, Accuracy: 0.8475, F1 Micro: 0.9097, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.337, Accuracy: 0.9308, F1 Micro: 0.9569, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2264, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.95      0.94      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.8821, F1 Micro: 0.8821, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2607, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Epoch 3/10, Train Loss: 0.1915, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9032\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1031, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1304, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "Epoch 10/10, Train Loss: 0.0395, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9141\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.91        87\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.95      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9178\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.89      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.39000797271729 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 0.0061986446380615234 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5321, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4462, Accuracy: 0.8341, F1 Micro: 0.903, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3289, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2209, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1226, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0958, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 8/10, Train Loss: 0.0702, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.505, Accuracy: 0.8538, F1 Micro: 0.8538, F1 Macro: 0.8212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2463, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9203\n",
      "Epoch 4/10, Train Loss: 0.1263, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1502, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0866, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9435\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9303\n",
      "Epoch 9/10, Train Loss: 0.0472, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9299\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9277\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.14129424095154 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.963180541992188e-05 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5305, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4483, Accuracy: 0.8676, F1 Micro: 0.921, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3174, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2168, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1634, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0927, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.96      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3146, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9089\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9168\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9129\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9011\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        86\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.96      0.97       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.98855543136597 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.724761962890625e-05 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5294, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4418, Accuracy: 0.8497, F1 Micro: 0.9124, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3077, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2091, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1157, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "Epoch 7/10, Train Loss: 0.0838, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.98      0.97      0.97       175\n",
      "      others       0.92      0.98      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.8498, F1 Micro: 0.8498, F1 Macro: 0.8156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.264, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9358\n",
      "Epoch 3/10, Train Loss: 0.1958, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9103\n",
      "Epoch 4/10, Train Loss: 0.1301, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9522\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9193\n",
      "Epoch 8/10, Train Loss: 0.087, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9477\n",
      "Epoch 9/10, Train Loss: 0.0798, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.914\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9114\n",
      "\n",
      "Sentiment analysis accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        86\n",
      "    positive       0.98      0.95      0.97       167\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.95      0.96      0.95       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9338\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.98      0.97      0.97       167\n",
      "    positive       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.98      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.79185152053833 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.796287536621094e-05 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.428, Accuracy: 0.8653, F1 Micro: 0.9198, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3008, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2003, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1444, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.072, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.8386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2954, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9224\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9317\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0795, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9206\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9155\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9183\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9185\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.85      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.62891912460327 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.724761962890625e-05 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4484, Accuracy: 0.8438, F1 Micro: 0.9096, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3054, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1918, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0523, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5026, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1767, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Epoch 7/10, Train Loss: 0.0979, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        85\n",
      "    positive       0.99      0.93      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9275\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.09709668159485 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.006938934326171875 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5334, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4235, Accuracy: 0.8891, F1 Micro: 0.9335, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2803, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9683\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9516, F1 Micro: 0.9694, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4922, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2524, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.182, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9138\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Epoch 8/10, Train Loss: 0.054, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9117\n",
      "Epoch 10/10, Train Loss: 0.0365, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9179\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9247\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.65191316604614 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.653236389160156e-05 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5241, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4336, Accuracy: 0.8996, F1 Micro: 0.9389, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.271, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1874, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0794, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4821, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2401, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1665, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9286\n",
      "Epoch 4/10, Train Loss: 0.1048, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9242\n",
      "Epoch 5/10, Train Loss: 0.0943, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9413\n",
      "Epoch 9/10, Train Loss: 0.0713, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0545, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9269\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9284\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.3818027973175 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.034706115722656e-05 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5172, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4213, Accuracy: 0.8966, F1 Micro: 0.9368, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2699, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1745, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0975, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0503, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4789, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8999\n",
      "Epoch 2/10, Train Loss: 0.205, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.139, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9166\n",
      "Epoch 7/10, Train Loss: 0.0701, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.84882020950317 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.748603820800781e-05 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4105, Accuracy: 0.9159, F1 Micro: 0.9485, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2568, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0974, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 7/10, Train Loss: 0.0728, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9787\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4659, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2451, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1403, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9266\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9223\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.915\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.9069\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0764, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9333\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9185\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.915\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        86\n",
      "    positive       0.97      0.94      0.96       187\n",
      "\n",
      "    accuracy                           0.94       273\n",
      "   macro avg       0.93      0.94      0.93       273\n",
      "weighted avg       0.94      0.94      0.94       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9218\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.01128435134888 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.700920104980469e-05 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5182, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4149, Accuracy: 0.9182, F1 Micro: 0.95, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2525, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9785\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4603, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9251\n",
      "Epoch 2/10, Train Loss: 0.2125, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9401\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0895, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9199\n",
      "Epoch 8/10, Train Loss: 0.058, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9275\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.905\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9194\n",
      "\n",
      "Sentiment analysis accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       180\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9216\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.96199798583984 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.007330417633056641 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5059, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4018, Accuracy: 0.9167, F1 Micro: 0.9482, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.247, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1192, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0752, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0626, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4922, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8804\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.198, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1439, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9452\n",
      "Epoch 5/10, Train Loss: 0.1087, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9294\n",
      "Epoch 6/10, Train Loss: 0.1149, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9316\n",
      "Epoch 7/10, Train Loss: 0.0793, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9255\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9203\n",
      "Epoch 9/10, Train Loss: 0.0441, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9059\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       178\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.95       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9324\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.00013995170593 s\n",
      "Total runtime: 2604.1325600147247 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADesklEQVR4nOzdd3iV9f3G8fdJCAkrYY9AIIoKDgRFGYqKiiJYf9W6rQUXrRWsigsUcVYcLcW6a0WtgFq3rVsUFAdaHIgKCMomDIUEApnn/P54QiAQMCEhT0Ler+s6V06esz4PgXo35z7fbyQWi8WQJEmSJEmSJEmSJEmqAnFhDyBJkiRJkiRJkiRJkmoPiwqSJEmSJEmSJEmSJKnKWFSQJEmSJEmSJEmSJElVxqKCJEmSJEmSJEmSJEmqMhYVJEmSJEmSJEmSJElSlbGoIEmSJEmSJEmSJEmSqoxFBUmSJEmSJEmSJEmSVGUsKkiSJEmSJEmSJEmSpCpjUUGSJEmSJEmSJEmSJFUZiwqSJEmSJKnGOe+880hPTw97DEmSJEmStBMsKkhSJXrggQeIRCL07Nkz7FEkSZKkCnn88ceJRCKlXkaMGFF8v7feeosLL7yQAw44gPj4+HKXBzY950UXXVTq7ddff33xfVavXl2RU5IkSVItYp6VpOqtTtgDSNLuZOLEiaSnp/Ppp58yb9489tprr7BHkiRJkirklltuYY899ihx7IADDii+PmnSJJ555hkOPvhgUlNTd+o1kpKSeP7553nggQeoW7duidueeuopkpKSyMnJKXH8kUceIRqN7tTrSZIkqfaornlWkmo7V1SQpEry448/8tFHHzF27FhatGjBxIkTwx6pVNnZ2WGPIEmSpBpkwIABnHvuuSUu3bp1K7799ttvJysriw8//JCuXbvu1GuccMIJZGVl8frrr5c4/tFHH/Hjjz9y4oknbvOYhIQEEhMTd+r1thSNRv2lsSRJ0m6suubZXc3fA0uq7iwqSFIlmThxIk2aNOHEE0/ktNNOK7WosHbtWq644grS09NJTEykXbt2DBo0qMSSXzk5Odx0003ss88+JCUl0aZNG37zm98wf/58AKZMmUIkEmHKlCklnnvBggVEIhEef/zx4mPnnXceDRs2ZP78+QwcOJBGjRrx29/+FoAPPviA008/nfbt25OYmEhaWhpXXHEFGzdu3Gbu2bNnc8YZZ9CiRQvq1atHp06duP766wF47733iEQivPjii9s8btKkSUQiET7++ONy/3lKkiSpZkhNTSUhIaFCz9G2bVuOPPJIJk2aVOL4xIkT6dKlS4lPvG1y3nnnbbMsbzQa5Z577qFLly4kJSXRokULTjjhBP73v/8V3ycSiTBs2DAmTpzI/vvvT2JiIm+88QYAX3zxBQMGDCA5OZmGDRty7LHH8sknn1To3CRJklS9hZVnK+v3swA33XQTkUiEb7/9lnPOOYcmTZrQp08fAAoKCrj11lvp2LEjiYmJpKenc91115Gbm1uhc5akinLrB0mqJBMnTuQ3v/kNdevW5eyzz+bBBx/ks88+49BDDwVg/fr1HHHEEXz33XdccMEFHHzwwaxevZpXXnmFJUuW0Lx5cwoLC/nVr37F5MmTOeuss7jssstYt24db7/9NrNmzaJjx47lnqugoID+/fvTp08f/vKXv1C/fn0Ann32WTZs2MAf//hHmjVrxqeffsq9997LkiVLePbZZ4sfP3PmTI444ggSEhL4/e9/T3p6OvPnz+c///kPf/7zn+nbty9paWlMnDiRU045ZZs/k44dO9K7d+8K/MlKkiQpTJmZmdvspdu8efNKf51zzjmHyy67jPXr19OwYUMKCgp49tlnGT58eJlXPLjwwgt5/PHHGTBgABdddBEFBQV88MEHfPLJJxxyyCHF93v33Xf597//zbBhw2jevDnp6el88803HHHEESQnJ3PNNdeQkJDAww8/TN++fZk6dSo9e/as9HOWJEnSrldd82xl/X52S6effjp77703t99+O7FYDICLLrqIJ554gtNOO40rr7yS6dOnM2bMGL777rtSP3wmSVXFooIkVYIZM2Ywe/Zs7r33XgD69OlDu3btmDhxYnFR4e6772bWrFm88MILJd7QHzVqVHFo/Ne//sXkyZMZO3YsV1xxRfF9RowYUXyf8srNzeX0009nzJgxJY7feeed1KtXr/j73//+9+y1115cd911LFq0iPbt2wNw6aWXEovF+Pzzz4uPAdxxxx1A8Im0c889l7Fjx5KZmUlKSgoAq1at4q233irR7JUkSVLN069fv22O7Ww23ZHTTjuNYcOG8dJLL3Huuefy1ltvsXr1as4++2wee+yxX3z8e++9x+OPP86f/vQn7rnnnuLjV1555Tbzzpkzh6+//pr99tuv+Ngpp5xCfn4+06ZNY8899wRg0KBBdOrUiWuuuYapU6dW0plKkiSpKlXXPFtZv5/dUteuXUus6vDVV1/xxBNPcNFFF/HII48AcMkll9CyZUv+8pe/8N5773H00UdX2p+BJJWHWz9IUiWYOHEirVq1Kg51kUiEM888k6effprCwkIAnn/+ebp27brNqgOb7r/pPs2bN+fSSy/d7n12xh//+Mdtjm0ZgrOzs1m9ejWHHXYYsViML774AgjKBu+//z4XXHBBiRC89TyDBg0iNzeX5557rvjYM888Q0FBAeeee+5Ozy1JkqTw3X///bz99tslLrtCkyZNOOGEE3jqqaeAYBuxww47jA4dOpTp8c8//zyRSIQbb7xxm9u2ztJHHXVUiZJCYWEhb731FieffHJxSQGgTZs2nHPOOUybNo2srKydOS1JkiSFrLrm2cr8/ewmF198cYnvX3vtNQCGDx9e4viVV14JwKuvvlqeU5SkSuWKCpJUQYWFhTz99NMcffTR/Pjjj8XHe/bsyV//+lcmT57M8ccfz/z58zn11FN3+Fzz58+nU6dO1KlTef/zXKdOHdq1a7fN8UWLFjF69GheeeUV1qxZU+K2zMxMAH744QeAUvdQ21Lnzp059NBDmThxIhdeeCEQlDd69erFXnvtVRmnIUmSpJD06NGjxLYJu9I555zD7373OxYtWsRLL73EXXfdVebHzp8/n9TUVJo2bfqL991jjz1KfL9q1So2bNhAp06dtrnvvvvuSzQaZfHixey///5lnkeSJEnVQ3XNs5X5+9lNts65CxcuJC4ubpvf0bZu3ZrGjRuzcOHCMj2vJO0KFhUkqYLeffddli9fztNPP83TTz+9ze0TJ07k+OOPr7TX297KCptWbthaYmIicXFx29z3uOOO4+eff+baa6+lc+fONGjQgKVLl3LeeecRjUbLPdegQYO47LLLWLJkCbm5uXzyySfcd9995X4eSZIk1V7/93//R2JiIoMHDyY3N5czzjhjl7zOlp9ekyRJkipLWfPsrvj9LGw/51ZktV5J2lUsKkhSBU2cOJGWLVty//33b3PbCy+8wIsvvshDDz1Ex44dmTVr1g6fq2PHjkyfPp38/HwSEhJKvU+TJk0AWLt2bYnj5Wm/fv3118ydO5cnnniCQYMGFR/fetmzTcve/tLcAGeddRbDhw/nqaeeYuPGjSQkJHDmmWeWeSZJkiSpXr16nHzyyUyYMIEBAwbQvHnzMj+2Y8eOvPnmm/z8889lWlVhSy1atKB+/frMmTNnm9tmz55NXFwcaWlp5XpOSZIk1T5lzbO74vezpenQoQPRaJTvv/+efffdt/j4ihUrWLt2bZm3WZOkXSHul+8iSdqejRs38sILL/CrX/2K0047bZvLsGHDWLduHa+88gqnnnoqX331FS+++OI2zxOLxQA49dRTWb16dakrEWy6T4cOHYiPj+f9998vcfsDDzxQ5rnj4+NLPOem6/fcc0+J+7Vo0YIjjzyS8ePHs2jRolLn2aR58+YMGDCACRMmMHHiRE444YRy/WJZkiRJArjqqqu48cYbueGGG8r1uFNPPZVYLMbNN9+8zW1bZ9etxcfHc/zxx/Pyyy+zYMGC4uMrVqxg0qRJ9OnTh+Tk5HLNI0mSpNqpLHl2V/x+tjQDBw4EYNy4cSWOjx07FoATTzzxF59DknYVV1SQpAp45ZVXWLduHf/3f/9X6u29evWiRYsWTJw4kUmTJvHcc89x+umnc8EFF9C9e3d+/vlnXnnlFR566CG6du3KoEGD+Ne//sXw4cP59NNPOeKII8jOzuadd97hkksu4de//jUpKSmcfvrp3HvvvUQiETp27Mh///tfVq5cWea5O3fuTMeOHbnqqqtYunQpycnJPP/889vshQbw97//nT59+nDwwQfz+9//nj322IMFCxbw6quv8uWXX5a476BBgzjttNMAuPXWW8v+BylJkqQaa+bMmbzyyisAzJs3j8zMTG677TYAunbtykknnVSu5+vatStdu3Yt9xxHH300v/vd7/j73//O999/zwknnEA0GuWDDz7g6KOPZtiwYTt8/G233cbbb79Nnz59uOSSS6hTpw4PP/wwubm5O9xbWJIkSTVbGHl2V/1+trRZBg8ezD/+8Q/Wrl3LUUcdxaeffsoTTzzBySefzNFHH12uc5OkymRRQZIqYOLEiSQlJXHccceVentcXBwnnngiEydOJDc3lw8++IAbb7yRF198kSeeeIKWLVty7LHH0q5dOyBo0r722mv8+c9/ZtKkSTz//PM0a9aMPn360KVLl+Lnvffee8nPz+ehhx4iMTGRM844g7vvvpsDDjigTHMnJCTwn//8hz/96U+MGTOGpKQkTjnlFIYNG7ZNiO7atSuffPIJN9xwAw8++CA5OTl06NCh1P3VTjrpJJo0aUI0Gt1ueUOSJEm7l88//3ybT4tt+n7w4MHl/sVuRTz22GMceOCBPProo1x99dWkpKRwyCGHcNhhh/3iY/fff38++OADRo4cyZgxY4hGo/Ts2ZMJEybQs2fPKphekiRJYQgjz+6q38+W5p///Cd77rknjz/+OC+++CKtW7dm5MiR3HjjjZV+XpJUHpFYWdaGkSSpDAoKCkhNTeWkk07i0UcfDXscSZIkSZIkSZIkVUNxYQ8gSdp9vPTSS6xatYpBgwaFPYokSZIkSZIkSZKqKVdUkCRV2PTp05k5cya33norzZs35/PPPw97JEmSJEmSJEmSJFVTrqggSaqwBx98kD/+8Y+0bNmSf/3rX2GPI0mSJEmSJEmSpGrMFRUkSZIkSZIkSZIkSVKVcUUFSZIkSZIkSZIkSZJUZSwqSJIkSZIkSZIkSZKkKlMn7AGqSjQaZdmyZTRq1IhIJBL2OJIkSaqAWCzGunXrSE1NJS6u9nVvzbaSJEm7D7Ot2VaSJGl3UZ5sW2uKCsuWLSMtLS3sMSRJklSJFi9eTLt27cIeo8qZbSVJknY/ZltJkiTtLsqSbWtNUaFRo0ZA8IeSnJwc8jSSJEmqiKysLNLS0oozXm1jtpUkSdp9mG3NtpIkSbuL8mTbWlNU2LRsWHJysoFXkiRpN1Fbl4Y120qSJO1+zLZmW0mSpN1FWbJt7dv0TJIkSZIkSZIkSZIkhcaigiRJkiRJkiRJkiRJqjIWFSRJkiRJkiRJkiRJUpWxqCBJkiRJkiRJkiRJkqqMRQVJkiRJkiRJkiRJklRlLCpIkiRJkiRJkiRJkqQqY1FBkiRJkiRJkiRJkiRVGYsKkiRJkiRJkiRJkiSpylhUkCRJkiRJkiRJkiRJVcaigiRJkiRJkiRJkiRJqjIWFSRJkiRJkiRJkiRJUpWxqCBJkiRJkiRJkiRJkqqMRQVJkiRJkiRJkiRJklRlLCpIkiRJkiRJkiRJkqQqY1FBkiRVmcJCeP99WLcu7EkkSZKkCooWwsr3Id9wK0mSpJotvzCfyT9MJjMnM+xRVItYVJAkSVUiNxdOPx2OOgr23hsefTQoLkiSJEk1TmEuTDsd3jkK/rM3zH80KC5IkiRJNcy7P75L14e60u/Jfuxxzx7cMe0OsvOywx5LlWDGshkMfmkwG/I3hD1KqSwqSJKkXW7DBjj5ZHjxxeD7FSvgoovg0EODFRYkSZKkGqNgA7x/MiwpCrc5K2D6RfDmocEKC5IkSVINsDRrKWc9dxbH/utYvlv9HfGReNbkrGHk5JF0/HtH/j797+QW5IY9pnbSsnXL+PXTv+ZfX/2LG969IexxSmVRQZIk7VLr1sHAgfDGG1C/Prz2GowdCykp8MUXwQoLp58OP/4Y9qSqiLlzw55AkiSpCuSvgykDYfkbEF8f+r4GB4+FhBRY80WwwsIHp8N6w22NlmW4lSRJu6+8wjzu/vBuOt3XiWe+eYa4SBzDDh3GiqtW8K+T/8WeTfZkRfYKLnvjMva+d2/++fk/yS/MD3vsSpNfmM/qDavDHmOX2pi/kZOfPpml65ayb/N9GX3U6LBHKlUkFovFwh6iKmRlZZGSkkJmZibJyclhjyNJUq2wZg2ccAJ8+ikkJwclhcMPD25bvRpGj4aHH4ZoFBITYfhwGDkSGjUKd26V3cqVcMUV8PTT8PHH0KNH1bxubc92tf38JUkKRd4aeO8E+OlTSEgOSgotisJtzmr4ejTMexhiUYhLhM7DYf+RkGC4rTFyVsKMK2DR03Dcx9C8asJtbc92tf38JUm1U25BLhO/nsjHiz/mmD2O4ZR9TyGpTtIuf913f3yXYa8N47vV3wHQu11v7h94Pwe1Oaj4PvmF+Yz/Yjy3vn8rS9ctBWCvpntxc9+bOeuAs4iL7NrPwa/ZuIY357/J58s/p3ub7gzYewDJiWXPCAXRAhZnLmbB2gWbL5mbry/JWkI0FqVjk44M2GsAA/YeQN/0vtRPqL8Lz6rqxGIxznnhHJ6e9TRN6zXl04s+pWPTjlX2+uXJdhYVJEnSLrFyJRx/PHz1FTRtCm+9Bd27b3u/WbOCN7rfeSf4vnVruP12GDwY4nbx2k9r1sC8eXDggUFRQmUXjcJjj8HVVwd/jpEI/PWvwc+yKtT2bFfbz1+SpCqXsxLePR7WfgV1m8Ixb0HTUsLt2lnw+RWQURRuk1pD19thz8Gwi3+hS94aWDcPGh8I8YbbcolF4YfH4Iurgz9HInDwX6Fz1YTb2p7tavv5S5Jql583/sxD/3uIez+9l4z1GcXHm9ZryqADB3HRwRexf8v9K/11l2Yt5cq3ruSZb54BoEX9Ftx13F0M6jpou8WDnIIcHvzsQcZMG8OqDasAOKDlAdx69K38utOviUQilTJbLBbju9Xf8d+5/+XV71/lw0UfUhgrLL69bnxdjt3jWE7pfAr/1+n/aFa/GUuylpQsIqwtWUTY8vFlkVQniaM6HMWAvQYwcO+B7N1s70o5tzDcOvVWRk8ZTZ24Orzzu3c4Kv2oKn19iwqlMPBKklR1li6Ffv1g9mxo1SooIRxwwPbvH4vBf/4DV14ZFAcADj4Yxo2DI46ovLkKCmD69KA08dZbwUoP0Sh07hys7HDkkZX3Wruz776DP/wBPvgg+L5bN/jHP+DQQ6tuhtqe7Wr7+UuSVKU2LIV3+0HWbEhqBce8A41/Idwu/Q98fiWsLwq3TQ6G7uOgZSWG22gB/DQdlr8VXH7+NHjDPbkz9HgYWhpuyyTzO/j0D7CqKNw26QY9/gHNqi7c1vZsV9vPX5JUO/y45kf+9snfePSLR9mQvwGAto3a8n+d/o//zP0PS7KWFN+3d7veDDl4CGfsfwYN6jao0OvmFeZxzyf3cPPUm8nOzyYuEsclh1zCLUffQpN6Tcr0HOvz1nPPJ/dw90d3k5mbCcAhqYdw29G3cXzH43eqsJBTkMN7P77Hq9+/yqvfv8qCtQtK3L5fi/3o1bYX0xZPY+5Pm7flihAhLhL3i0WExPhEOjTuQHrjdNJT0oOvW1wa1G3Aez++x2vfv8br815ncdbiEo+vqastPPvNs5zx3BkAPHLSI1x08EVVPoNFhVIYeCVJtU0sBnPnwrvvwqJF8LvfwX777frX/fFHOPbY4GtaGkyeDHuXsYCalwf33gu33AJZWcGxM86AO++E9PSdm+eHHzYXEyZP3vy8m9SrBxs3BtcvvBDuuitYAaKsYjFYvx6WL4eMjJJfs7NhwIBgZYk6dXZu/uogLy8onXz1FXzyCTzyCOTnQ/36wc/qssuq/vxqe7ar7ecvSaqFYjFYNxdWvAvZiyD9XGhc+Z8028b6H2HysZD9I9RPg2MmQ3IZw21hHsy9F2bdAvlFIbT9GdDtTmiYvpPz/LC5mLBi8ubn3SS+HhQWhduOF0K3uyCxnOG2YD1sXA45GcHXjRmQsxwKsqHNAGhzPMTV4HBbmBeUTtZ+Bas/gfmPQDQf4uvDgbdAp8uq/Pxqe7ar7ecvSVUpvzCf1RtWszJ7Jas2rAq+Zq8qvr56w2r2aLwHg7oOomvrrmGPu1v4dOmn/OWjv/D8d88TjUUB6NqqK1cfdjVn7H8GCfEJFEYLeXP+mzzy+SP8Z85/it+Eb1S3Eed0OYchBw+he2opq3n9grJs81Aeazau4S8f/YV7pt9Ddn42AEe0P4I/H/Nnjujwy4XcJVlLeHVuUEyY/OPk4sIGBMWCo/c4ml/t/StO3OdE0hunA8FqC7NXz+bF2S/y4uwX+d+y/wHBKgvFxYNSigitGrYq8xYVsViMb1d9y+vzXuf1ea/zwcIPyI/mF9+eVCeJvul9g+LCXgMqZbWFgmgBa3PWsjZnLZk5mcSIEReJK/WyqZzxS5c5P83h+CePZ2PBRi7veTl/O+FvFZ5zZ1hUKIWBV5JUGyxcGBQTNl2WLdt8W3w8/PGPcNNN0KzZrnn9OXOClRSWLIGOHYNiQIcO5X+elSth9OjgDfFoNNiW4aqrYMQIaNhwx4/NyoL33guKCW++CfPnl7y9aVM47rigPHD88dCgQfC8//hHcHuLFvC3v8GZZ8Lq1aUXELb+umHDtnNsKTU12Mri/PPLXtoIy6pVQSFh02XmTPj226CYsKUTT4T779+5n29lqO3ZrrafvySplsheCBnvBuWEFe/Cxi3CbSQe9roYDrwZEndRuM2aE6yksGEJNOwIx06GBjsRfnJWwszRwRvisSjEJcK+V8F+IyDhF8JtfhaseK+onPAmrN8q3NZtCq2PC8oDbY6HOg3gyxEwryjcJraAg/8GHc6E3NUlCwhbFxE2Fn1f+Avhtl4q7DEY9jy/7KWNsOSsCgoJa4oua2dC1rdBMWFLqSfCoffv3M+3EtT2bFfbz1+SKmJT8aC00sGq7FWs3FDy2NqctWV+7m6tu3Fe1/M4p8s5tGjQYtedxG4oGovy37n/5S8f/YUPFn1QfLx/x/5cddhVHLvHsdtdhSBjfQaPf/k4//z8n8xfszn7HdT6IC46+CLO6XIOjZMa7/D1d2abh/JYmb2SMR+M4cH/PUhuYW7xud12zG0cknpI8f0Ko4VMXzq9uJzw1YqvSjxP20Zt+dU+v+LEvU/kmD2OKdPqESvWr6AwVkjrhq0r5VxKsy53He/++G6ZVlvYr8V+xYWDTZc1G9dsvp6zpuRtRd+vz1u/S2YHGLDXAF45+xXqhFQutqhQCgOvJGl3lJERvCm/qZjwww8lb09MhMMPD76+/npwrEmToKzwxz9CQkLlzTJzZlAAWLkS9t032O4hNbXiz3n55cE5ArRpA2PGBKtDxBXl0MJCmDFjczHh44+DY5vUqQOHHba5mHDwwUFpY2vTpgXbGXz7bfB9JBJ8oKysGjWC1q2DGVu3Di75+fDvf8NPP22+X58+cMEFcPrpv1y62JUKCoJiydalhOXLS79/SgoceCB07Qr9+wdFhUrahm6n1PZsV9vPX5K0m9qYEbwpv6mYsH6rcBuXCC0OD74uLwq3CY2hy02wzyUQV4nhds1MeO+4oGSQvG+w3UP9CobbNTPh88uDcwSo1wa6joE9fgebfskaLYSfZ0BGUTFh9cew5bK2kTrQ4jBoXVRMaHIwxJUSbldOg8/+AJnfbnogUI5wW6cR1GsdzJjUOrjE8mHRvyF3i3Dbog/seQG0P/2XSxe7UrQgKJZsKiWsLSolbNxOuE1IgcYHQpOu0KZ/UFQIMdzW9mxX289fkrYWi8X4aeNPLFy7kEWZi1iStYSV2SuLV0HYsoiwJmdNuZ8/LhJHi/otaNGgBS3qt6Blg5bF3zet15SpC6fyypxXyCvMA6BOXB1+tc+vOK/reQzceyAJ8ZWYuXYzOQU5PPnVk/z1478y56c5ACTEJXBOl3MY3ns4B7Y6sMzPFY1FmbJgCv/8/J88/93zxT+PenXqcfr+pzPk4CEcnnZ4icJDZWzzUB5LspZw69RbGf/leAqiBQCc0vkU/q/T/zH5x8m8/v3r/LRxc3aMEKFXu17F5YQDWx24U9tGVKVfWm2hohrWbUhyYjLxkXiisWiJS4zYNseKb4vFtrkvwFEdjuLls14mJSml0mYsL4sKpTDwSpJ2B2vWwJQpm4sJm95U3yQ+Hnr2hGOOCS69e0NSUnDbe+8Fb/rPnBl837kzjB0bbE1QUZ99Frx5vWYNdOsWlAZaVFLROhaDl1+GK6/cXMQ45JCgrPDhh0Eh4uefSz5mr72CeY4/Hvr2hbL+pz8vD+6+G269FXJzgzJEy5abywdblhC2PtZgO4XfvDz4z39g/Hh4441ghQgI7n/mmcEqC4cfvmt/L7pmDXz5ZclSwrffBue4tUgkWA2ja9eSl/btwy0mbK22Z7vafv6SpN1E3hpYMWVzMSFzq3AbiYdmPaHVMdD6GGjeG+KLwu2K92DG5cGb0QDJneCgsdB2YMXn+ukzeK9/MF+TbnD0W5BUieF2ycvwxZWbixhNDwnKCqs+hIx3IG+rcNtwr+DN9DbHQ6u+kFDG//YX5sF3d8OsWyGaG5QhEltuLh/UaxOUEZJab3usznbCbWEeLP0P/DAelr8RrBABwf3bnxmsstBiF4fbvDWw5svNhYQ1XwV/d6KlhFsiwWoYTbpC467B1yZdoX71Cre1PdvV9vOXVPvkF+azdN3S4iLCwsySXxdlLiqxJP4viYvE0bx+882lgwYtaFm/ZckiwhbXm9Rr8oufRP9pw088PetpHv/q8eKl9iH4ZP5vu/yW87qdt1ttDRGNRdmQv4H1eevJzssOvuZnl7he6m35JY/NXj2b1RtWA5CSmMLFh1zMpT0upW1y2wrN99OGn3hy5pM88vkjfLtqc2bu3LwzFx10EYO6DuLrlV9vs83DAyc+QLfW3Sr02mUx/+f53Dz1ZibMnFD8hvkmjZMa079jf361z684Ya8TaF6/+S6fZ1fatNrC6/Ne5415b5CxPoMm9ZrQOKkxTZKCr1tetj626b6NkxqTkphSacWfWCxWvH1E2CwqlMLAK0mqiTZuDN6Mnzw5eEP+8883v9ENwe/WunULSgnHHht8Wr9Ro+0/X2EhPPoojBoVLPEPQVHhr38NVkHYGR98EHy6ft066NUrWLmhceOde64dyc2Fe+6B224LXmtLycnB+ffvH6zqsOeeFXutdesgOzsoW5S2+sLOWrYM/vWvoLTw/febj++9d7DKwqBBFVuFIhaDpUvhiy9KXhYuLP3+DRtuXiVh0+WAA8Jd6aGsanu2q+3nL0mqoQo2wuoPIWNy8Ib8ms83v9ENQCQoBrQ6BlofG3xaP2EH4TZaCD88Cl+NgtyicNvmBDh4LKTsZLhd+QFMOREK1kGzXnD061C38c49144U5sKce2DWbcFrbSkhGVodW1ROOA4aVjDc5q+DguxgG4jSVl/YWRuWwY//CkoL67YIt432DlZZ2GNQxVahiMVg41L4+QtYs8Ulezvhtk7DzaskbColpBwQ7koPZVTbs11tP39Ju5+s3KxtSghbXl+2bhnREhmodG0atqF9SnvSUtJo1aBVySLCVqsg7Mo3J2etnMUTXz7BkzOfZEX2iuLjlbk1RCwWY23OWjLWZ2x7yd58fWX2SvILg0+zb/mG+JZvdZb3eEG0gI0FGys0/5bap7Tnil5XcOFBF9IocQdZdifEYjE+WfIJj3z+CM9880xxoaVOXJ3iFQ0qe5uH8vh21bfc+v6tzPt5HkenH82v9vkVh6UdFtoWBAqHRYVSGHglqWoUFkJmZnBZu3bz1y2vZ2VB9+5w1lmbl+9XYNM2BpuKCR9+uO2n3jt3Dt6UP+YYOOooaLYTW/JmZgZv+N9zT7A9QXw8DB0KN94ITZuW/Xnefht+/eugUHH00fDKK7v+Te4VK4IVD777Do44Ilg1oUePYIuHmiIWC362jz0GzzwTlCIg+PdwwglBaeGkk6Bu3e0/RzQalB22LiWsXl36/dPTg1LLlqWE9PSa+2+wtme72n7+klRlooWQnxlc8tZu8XUt5GUGX/OzoGl36HDW5uX7Fdi0jcGKomLCqg+3/dR7cufgTfnWx0DLoyBxJ8JtXiZ8c1vwxn80P1iJYe9Lgi0hEssRbpe/De//Ggo3Qquj4chXdv2b3BtXBCseZH0HLY4IVk1o1gNq0i9zY7HgZ/vDY7DomaAUAcG/hzYnBKWFtidB/A7CbSwalB22LiXkbifcNkgPSi1brpLQIL3G/hus7dmutp+/pJolGouSsT5ju6shLFy7kMzczF98nsT4RNqntKdD4w60Ty76mtI+OJbSgXbJ7Uisk1gFZ1R2BdEC3pr/Fo9/+Tgvz3m5xNYQJ+59Iud1C7aGqLvFf/M35m9kRfaKEsWD5euWb1NAyFifUfx8YYoQoUHdBjRIaEDDug23ud6wbkMaJGz/9mb1mnFEhyOq5I35rNwsnvr6KR75/BFmLJ+xy7d5kMrKokIpDLySVDY5OSVLBaUVDXZ0+9afdN+RI46Ahx/e+U/y7w5iMZgzJyglTJ4cbM+QudX/l2nbNigm9OsXlBPaVmylsBK+/x6uuiooGEBQUrj5Zrj44l9+4/+VV+D004OtDQYOhOeeg3r1Km+22mL9enj22WCVhWnTNh9v3hzOPTfYGqJTJ5g1q2QhYebMzQWHLcXHB/+mDjpo86Vbt12zykWYanu2q+3nL0llVpizVcGglKLBjm7f+pPuO9LiCOjx8M5/kn93EItB1pyglLBicrA9Q/5W4bZe22C1hNb9gpUT6ldiuM36Hr64CpYWhdu6TaHLzbD3HyDuF5ZUXfIKTDsdonmQOhD6PAd1DLfllr8eFj0brLKwaotwm9gc0s8NtoZI7gSZs0qWEtbO3Fxw2FIkHpL3hSYHQdODgq9Nuu2aVS5CVNuzXW0/f0nhyCnIITMnk7U5a8nMLfpa2ve5wdc1OWtYtm4ZizMXl2l/+mb1mpVaROiQEnxt2aAlkWq0DVF5/bzx52BriC8f57NlnxUfb16/Ofu12I8V64NyQllKG1tqnNSY1g1bb740aF3i+1YNW5EYv7nAseWfYYTITh2Pi8QVFw3q1alXI38us1fPpn5CfdqntA97FMmiQmkMvJIU2LQ0/DffBHvUb7rMnx+UDUrbs35n1K8fvDGaklLya+PGwRupjz8evMmakAAjRsB110FSUuW8dnW3dGlQSti0asKyZSVvT0kJVifo1y8oKHTqtOu3T33nHbjiiuDNcID99oOxY4OtFErz9NPBm+iFhXDqqTBp0o4//a+ymTs3+LfxxBMl/17Exwd/1lurVy/YumHLUsIBB9SOwkhtz3a1/fwlqdimpeHXfgNZ3wb71Gd+C+vnB4WDUves3wnx9YM3RhNStvraOHgj9cfHgzdZ4xJgvxGw/3UQX0vC7YalwVYOm1ZN2LhVuE1ICVYnaN0vWDkhuQrCbcY7MOOK4M1wCN7oPvhvkLqdcLvgafj4XIgVQtqpcNikHX/6X2WTNRd+eBx+fKLk34tIfPBnvbX4ekVbN2xRSkg5oFYURmp7tqvt5y+p/AqjhazLW7f9csGW32/neEU+vR8fiaddcrvtFhHSUtJoWLf6bz1UWb5Z+Q1PfBVsDZGxPmOb2xPjE2nTqM12ywdblhCS6tSSDC3txiwqlMLAK6m2iUZh0aKSZYRNl19a9SASKb1gsKNjW9+e8AsfWFq4EIYNg//+N/h+773hoYeCFQN2J5uKIf/73+ZiwuzZJe+TmAiHH765mNC9e/DGdFUrKIBHHoEbboCffgqOnXgi/PWvQVlik/Hj4aKLgnM799xg+4KatO1CTVBQAG+9FfxZv/JKsD1H06YlCwkHHQT77BPO35XqoLZnu9p+/pJqoVgUshcFJYQtCwmZ35Zh1YPItgWDTdcTGkPdTV93cPsvfRo/eyF8NgyWFYXbRnvDoQ8F2xnsTjYVQ3763+ZiQtZW4TYuEVocvrmY0LQ7xIUQWKIFMP8RmHkD5BaF29SBcPDYoCyxyfzxMP0iIBZ84r/XYzVr24WaIFoAy98KVllY+kqwPUfdplutknAQNNonnL8r1UBtz3a1/fwlbRaLxVi+fjmzV88uvvy49kfW5qwtLhtk5maSlZtVKa8XIUJKUgopiSk0Tmpc8voWxzZ936ZRGzqkdKBNozZVsrR/TVMQLeDdH9/lpw0/lSgmpCSm1MhVCiTtHIsKpTDwStpdFRbCggXblhG++670ZeEheFN5772DT83vv3/wdZ99oFmzoGjQsGHV7Fsfi8ELL8Cll8Ly5cGxwYPhL38Jlr2vSaLR4Ofw3XclfwalFUMiETjkkM3bORx2WPX6BPzatXDLLXDvvcEb5nXqBKWS0aNhwgT405+C+/3hD/DAA1Xzd6U2W7s22B6ibdtd/+HDmqS2Z7vafv6SdmPRQshesG0hIeu70peFB4jUCYoBKftByv7B10b7QGKzoHBQp2HV7Fsfi8HiF2DGpbCxKNzuMRgO+gsk1bBwG4sW/Ry+2+Jn8d12iiERaHrI5u0cmh9WvT4Bn7cWvr4F5t4LsYLg78s+w6DLaPhxAswoCrd7/QEOfaBq/q7UZnlroWB9sAWI4bZYbc92tf38pdoorzCPeT/PK1FI2HRZl1f2rbfq1alXokiw5fXtlQ22/L5h3YbE+d9+SapUFhVKYeCVVNMVFMAPP2xbSJg9GzZuLP0xCQnBJ+G3LCTstx/stVf1WqY/MzPY+uHBB4Pf7zZrFnyKf9Cg6ve7q/z8YJuMLYsI3323459DfHxQBNm0nUPfvtCkSZWOvVPmzoUrr9y86kVyMmQVFdavuCL4GVW3n49qj9qe7Wr7+UvaDUQLYP0PpRQSZkPhdkJVXAI06lSykJCyHzTcq3ot05+XCV9dB98/CMSCwsRBf4U9qmG4jebDuvkliwhZ3+345xCJD4ogxds59IW6NSDcZs2Fz6/cvOpFQjLkF4XbTlfAwYZbhae6Zbv777+fu+++m4yMDLp27cq9995Ljx49Sr1vfn4+Y8aM4YknnmDp0qV06tSJO++8kxNOOKHMr1fdzl9S5fl548+llhF+WPMDhaVtAwTEReLo2KQjnZt3pnPzzuzVdC+a1WtWatmgbnXKgJIkwKJCqQy8kmqK/HyYN2/bQsKcOZC7nS12ExOhc+dtCwkdO9asJfk/+QR+/3v4+uvg+6OPDraD2Gefqp8lJyd4o37LQsK338L33wc/o9LUrRsUQ/bdd/PPYN99g9UrEhOrdv7K9NZbQTHh22+D72+4AW6+2d/jKly1PdvV9vOXVINE82HdvC2KCJu+zoHodsJtXCIkdy6lkNCxZi3Jv/oT+PT3sLYo3LY6OtgOIjmEcFuYE7xRv6mIsOlnse774GdUmri6wRYJyftu/hkk7xusXhFfg8Pt8rfg8yuCPwOAA26ALoZbhas6ZbtnnnmGQYMG8dBDD9GzZ0/GjRvHs88+y5w5c2jZsuU297/22muZMGECjzzyCJ07d+bNN99k+PDhfPTRRxx00EFles3qdP6Syq8wWsjCzIWlFhJWbVi13cc1qtuouIyw5aVjk44k1qnBWUOSajmLCqUw8EqqrgoK4OOP4dVX4Y034JtvgmOlqVev5Jvgm0oJe+yx++xTn58Pf/sb3HRTsEJBYiJcfz1cc03lv9mfnx9s1/D990E5ZNPl+++D1Sui0dIfV7/+5p/Dlj+PPfaoWcWQ8igogEmTICkJzjgj7Gkks11tP39J1Vi0AFZ/DMtehWVvQOY3wXL7pYmvV/JN8E2lhAZ77D771EfzYfbf4OubghUK4hJh/+thv2sq/83+aD6sXxCUD9bPCwoi6+YF32f/EGznUJr4+pCyLyTvF3xN2S+43nCPmlUMKY9oASyYBPFJ0MFwq/BVp2zXs2dPDj30UO677z4AotEoaWlpXHrppYwYMWKb+6empnL99dczdOjQ4mOnnnoq9erVY8KECWV6zep0/pK2b33eeub+NHebMsLcn+aSW7idAiqQlpxWaiGhTcM2RCwKStJupzzZbjf9f5ySVL2tXg2vvx6UE958M9iDfksNGmx+83vLUkKHDhC3m2+blpAQlBJOPx0uuSQob4weDU89BQ8/DEccUb7ny8uDH38svYywcCEUlr7KHAApKSVXRth0PS1t9/85bK1OnWArDkmSpG3krIblr8PSV2H5m5C/tuTtdRoUvQm+X8lSQoMOsLvvCRyXEJQS2p8On10Cy9+Ar0fDwqegx8PQspzhtjAPsn8MygebigjrN5URFsJ2llAGICGl5MoIm67XT9v9fw5bi6sDexpupa3l5eUxY8YMRo4cWXwsLi6Ofv368fHHH5f6mNzcXJKSkkocq1evHtOmTduls0raNWKxGMvWLStZRvgp+Loka8l2H5cYn8g+zfbZpoywT7N9aFi3YRWegSSpJrGoIElVIBaDL78MigmvvgrTpwfHNmnaFE44AU48EQ4/vHa+Eb61PfaA116DZ56Byy8Ptl848ki46CK4887gz2yTnJztlxEWLdr+yggQrFKx117BZe+9g68dOwbFhNatXQFWkiRpG7EYrPkyWDVh6avw03Rgi3Bbtym0OQHanggtDq+db4RvreEe0Pc1WPgMfH55sP3CO0dCx4ug252QuEW4LcyB9VuUEdZvsTLChkXbXxkBglUqGu0FDfcKtmhotFewZUbKvpBkuJW0Y6tXr6awsJBWrVqVON6qVStmz55d6mP69+/P2LFjOfLII+nYsSOTJ0/mhRdeoHAHnwrIzc0ld4u9LbOysirnBCT9osJoIRnrM1ictZglWUtYkrWExZmLWbJuCT+s+YHZq2ezPm/9dh/fskFLOjfvTKdmnUoUEjqkdCB+d1kRS5JUZSwqSNIusn49vPNOUEx47TVYtqzk7QceGBQTTjwRevXafbZuqEyRCJx1FvTvDyNGwD/+Af/8J7zyCvzf/20uJyxeXLL4sbUGDbYtI2y6pKb6+1pJkqRflL8eMt4p2tLhNdi4VbhtfCCknhiUE5r12n22bqhMkQiknwWp/eHLETDvHzD/n7D0FWj7f5vLCRsWU6L4sbU6DYqKCFuWEYq+r2e4lVS17rnnHoYMGULnzp2JRCJ07NiR888/n/Hjx2/3MWPGjOHmm2+uwiml2qEgWkDG+ozN5YNNRYSiUsLirMUsX7ecwh2twATER+Lp2LRjUEJotrmM0Kl5J5rWa7rDx0qSVB4WFSSpEs2bt3nVhKlTg20HNqlfH/r1C4oJAwdCu3bhzVnTNGkSbPvwu9/BH/4A334bFBa21KhR6UWEvfeGVq38fa0kSVK5rZsXrJiw7FVYORWiW4Tb+PrQul9QTEgdCPUNt2VWt0mw7UP67+CzP0Dmt0FhYUt1GpVeRGi0NyQZbiXtGs2bNyc+Pp4VK1aUOL5ixQpat25d6mNatGjBSy+9RE5ODj/99BOpqamMGDGCPffcc7uvM3LkSIYPH178fVZWFmlpaZVzEtJuqiBawPJ1y0sUD7a+XpYSAgRFhNRGqaSlpNEuuR3tGrUjLSWNDikd6Ny8Mx2bdqRufN0qOCtJUm1nUUGSKiAvDz74YHM5Ye7ckrfvuefmVROOOgq22rZR5dSnD3zxBYwfD0uXliwjtGjh72slSZIqpDAPVn2wuZywbqtw23DPYNWE1BOh1VEQb7itkJZ94IQv4IfxsGFpURGhqIyQaLiVVPXq1q1L9+7dmTx5MieffDIA0WiUyZMnM2zYsB0+NikpibZt25Kfn8/zzz/PGWecsd37JiYmkpiYWJmjSzVaQbSAZeuWldyKIWsJS9Ztvr58/XKiO9r+qUiduDpBCSG5qISQ3K7k9ZQ0WjVo5TYNkqRqwaKCJJVTRkawlcOrr8Lbb8O6dZtvq1MHjjhiczmhUyd/v1jZ6taFiy8OewpJkqTdxMaMYCuHZa/C8rehYItwG6kDLY/YXE5INtxWuvi6sLfhVlL1MXz4cAYPHswhhxxCjx49GDduHNnZ2Zx//vkADBo0iLZt2zJmzBgApk+fztKlS+nWrRtLly7lpptuIhqNcs0114R5GlK1snrDauasnrPd1RAy1meUuYTQtlHb4sLBppUQtiwktGzQ0hKCJKnGsKggSb8gGoX//W/zqgkzZpS8vVUrGDAgKCYcdxykpIQzpyRJkvSLYlH46X9BMWHZq/DzVuE2qRWkDgiKCa2Pg7qGW0mqTc4880xWrVrF6NGjycjIoFu3brzxxhu0atUKgEWLFhEXF1d8/5ycHEaNGsUPP/xAw4YNGThwIE8++SSNGzcO6Qyk6iEWi/H+wve577P7ePG7F39xS4aEuATaJrfddgWELa63atiKuEjcDp9HkqSaJBKLxWLlfdD999/P3XffTUZGBl27duXee++lR48epd43Pz+fMWPG8MQTT7B06VI6derEnXfeyQknnFB8n5tuuombb765xOM6derE7Nmzi7/Pycnhyiuv5OmnnyY3N5f+/fvzwAMPFIfkX5KVlUVKSgqZmZkkJyeX95Ql1TKZmfDWW0Ex4fXXYeXKkrcfeujmVRMOPhji/P8IklSlKjPbmW0l7fbyMiHjrWBLh+WvQ85W4bbpodC2aNWEpgeDvwCXpCpV27NdbT9/7V6y87KZ+PVE7vv0Pr5e+XXx8Q4pHWif0r5E+WDL1RBaNmhpCUGStFsoT7Yr94oKzzzzDMOHD+ehhx6iZ8+ejBs3jv79+zNnzhxatmy5zf1HjRrFhAkTeOSRR+jcuTNvvvkmp5xyCh999BEHHXRQ8f32339/3nnnnc2D1Sk52hVXXMGrr77Ks88+S0pKCsOGDeM3v/kNH374YXlPQZK2EYvBd98FxYTXXoNp06CgYPPtyclw/PFBMWHAgGAVBUlSzWe2lbRbisUg67ugmLDsNVg1DWJbhNuEZGh9fFBOaDMA6hluJUmSKmLez/N44LMHGP/FeDJzMwGon1Cfc7ucy9AeQzmw1YEhTyhJUvVT7hUVevbsyaGHHsp9990HQDQaJS0tjUsvvZQRI0Zsc//U1FSuv/56hg4dWnzs1FNPpV69ekyYMAEIPnX20ksv8eWXX5b6mpmZmbRo0YJJkyZx2mmnATB79mz23XdfPv74Y3r16vWLc9vMlbS1WAy+/BImTYLnn4cffyx5+777wsCBQTmhTx9ISAhlTElSKSor25ltJe02YjFY8yUsnASLnofsrcJt8r6QOjAoJ7ToA3GGW0mqLmp7tqvt56+aKxqL8sa8N7jv0/t4fd7rxcc7NunI0EOHcl6382hSr0mIE0qSVPV22YoKeXl5zJgxg5EjRxYfi4uLo1+/fnz88celPiY3N5ekpKQSx+rVq8e0adNKHPv+++9JTU0lKSmJ3r17M2bMGNq3bw/AjBkzyM/Pp1+/fsX379y5M+3bty/zL3MlaZN58+Cpp4KCwharcJOYCEcfHRQTBg6EPfcMb0ZJ0q5ntpW0W1g3DxY8FRQUsrYIt3GJ0OroYDuHtgOhoeFWkiSpMqzZuIbHv3yc+z+7n/lr5hcfH7j3QIYdOoz+e/V3GwdJksqgXEWF1atXU1hYuM3eua1atSqx5+6W+vfvz9ixYznyyCPp2LEjkydP5oUXXqCwsLD4Pj179uTxxx+nU6dOLF++nJtvvpkjjjiCWbNm0ahRIzIyMqhbty6NGzfe5nUzMjJKfd3c3Fxyc3OLv8/KyirPqUrazSxfDv/+d1BO+PTTzceTkuCkk+Dss4OtHRo0CG9GSVLVMttKqrE2LoeF/w7KCT9tEW7jk6DtSdDhbGhzPNQx3EqSJFWWmStmcv+n9zPh6wlsyN8AQEpiChccdAGXHHoJezXdK+QJJUmqWcpVVNgZ99xzD0OGDKFz585EIhE6duzI+eefz/jx44vvM2DAgOLrBx54ID179qRDhw78+9//5sILL9yp1x0zZgw333xzheeXVHOtXQsvvhiUE959F6LR4Hh8PBx3HJxzDvz61+CqgpKksjLbSgpN3lpY/GJQTljxLsSKwm0kHlofB+nnQLtfQ4LhVpIkqbLkF+bz0uyXuO+z+3h/4fvFx7u07MKwHsP4bZff0qCu5VBJknZGuYoKzZs3Jz4+nhUrVpQ4vmLFClq3bl3qY1q0aMFLL71ETk4OP/30E6mpqYwYMYI9d7CmeuPGjdlnn32YN28eAK1btyYvL4+1a9eW+OTZjl535MiRDB8+vPj7rKws0tLSynqqkmqojRvh1VeDcsKrr0Je3ubbDjssKCecfjq0bBnejJKk6sFsK6naK9gIy16FBZOCr9Etwm3zw4JyQvvTIclwK0mSVJky1mfwyIxHeGjGQyxbtwyA+Eg8v9n3NwzrMYwj2h9BJBIJeUpJkmq2chUV6tatS/fu3Zk8eTInn3wyANFolMmTJzNs2LAdPjYpKYm2bduSn5/P888/zxlnnLHd+65fv5758+fzu9/9DoDu3buTkJDA5MmTOfXUUwGYM2cOixYtonfv3qU+R2JiIomJieU5PUk1VEFBsGLCpEnwwguwbt3m2/bfH377WzjrLNhjj/BmlCRVP2ZbSdVStCBYMWHBJFj8AhRsEW5T9of030KHs6Ch4VaSJKkyxWIxpi+dzn2f3se/v/k3+dF8AFo2aMnvD/49fzjkD7RLbhfylJIk7T7KvfXD8OHDGTx4MIcccgg9evRg3LhxZGdnc/755wMwaNAg2rZty5gxYwCYPn06S5cupVu3bixdupSbbrqJaDTKNddcU/ycV111FSeddBIdOnRg2bJl3HjjjcTHx3P22WcDkJKSwoUXXsjw4cNp2rQpycnJXHrppfTu3ZtevXpVxp+DpBomFoPp04NywjPPwMqVm29r3z5YOeGcc6BLl/BmlCRVf2ZbSdVCLAY/TQ/KCYuegZwtwm399sHKCennQGPDrSRJUmXbmL+RZ755hvs+vY8Zy2cUH+/VrhfDDh3GafudRmIdi+OSJFW2chcVzjzzTFatWsXo0aPJyMigW7duvPHGG7Rq1QqARYsWERcXV3z/nJwcRo0axQ8//EDDhg0ZOHAgTz75ZIllbpcsWcLZZ5/NTz/9RIsWLejTpw+ffPIJLVq0KL7P3/72N+Li4jj11FPJzc2lf//+PPDAAxU4dUk10TffBOWEp56CH3/cfLx5czjjjKCc0Ls3bPE/Q5IkbZfZVlKo1n4DCyfBgqcge4twm9gc2p8RlBOa94aI4VaSJKmyLVy7kAf/9yD//Pyf/LTxJwAS4xM5u8vZDD10KIekHhLyhJIk7d4isVgsFvYQVSErK4uUlBQyMzNJTk4OexxJ5bBwITz9dFBQmDlz8/GGDeGUU+Dss6FfP0hICG9GSVLVqu3Zrrafv1SjZS+EhU8Hqyes3SLc1mkI7U6B9LOhdT+IM9xKUm1R27NdbT9/Va1YLMa7P77LfZ/dxytzXiEaiwLQPqU9lxxyCRcefCHN6zcPeUpJkmqu8mS7cq+oIElVYfVqePbZoJwwbdrm4wkJMHBgsHLCr34F9euHN6MkSZJUJjmrYfGzQTlh1RbhNi4BUgdCh3Og7a+gjuFWkiRpV1iXu45/ffUv7vvsPmavnl18/Ng9juXSHpfyq31+RXxcfIgTSpJU+1hUkFRtrFsHL78cbOvw1ltQUBAcj0Sgb9+gnPCb30DTpqGOKUmSJP2y/HWw5GVY+BQsfwtiReGWCLTqG5QT0n4DiYZbSZKkXWX26tnc/+n9PPHVE6zLWwdAw7oNGdx1MEMPHcq+LfYNeUJJkmoviwqSQpWXB2+8Eayc8MorsHHj5tu6dw/KCWeeCW3bhjejJEmSVCaFebD8jWDlhKWvQOEW4bZp96Cc0OFMqG+4lSRJ2lUKo4W8+v2r3Pfpfbz9w9vFxzs168SwHsMY1HUQyYluMyJJUtgsKkiqctEovP9+UE547jlYs2bzbXvvHZQTzj4bOnUKb0ZJkiSpTGJRWPl+UE5Y/BzkbRFuG+0dlBPSz4Zkw60kSdKu9NOGn3j0i0d54LMHWJi5EIC4SBwn7XMSw3oM49g9jiUSiYQ8pSRJ2sSigqRdbt06WLgwuLz3Hjz9NCxduvn2Nm3grLOCgkL37sFWD5IkSVK1lL8OshcGlxXvwcKnYeMW4bZeG2h/FqSfE6yiYLiVJEnapT5f/jn3fXofT816ipyCHACa1mvKkIOHcPEhF5PeOD3cASVJUqksKkiqkFgMfv55cxFh4UJYsKDk9z//vO3jGjeG004LVk446iiIj6/qySVJkqStxGKQ9/PmIkL2QsheUPL7vFLCbUJjaH8adDgbWh4FcYZbSZKkXSmvMI/nv32e+z67j48Wf1R8/KDWB3Fpj0s564CzqJdQL8QJJUnSL7GoIGmHolFYsWLHRYT163/5eZo0gQ4dYL/94Iwz4IQTIDFxl48vSZIkbRaLQs6KHRcRCsoQbus2gQYdIHk/6HAGtDkB4g23kiRJu9qydct4+H8P8/CMh1mRvQKAhLgETt//dIYdOoxe7Xq5vYMkSTWERQWplisoCLZh2F4JYdEiyM395edp1SooImy6pKeX/D45eVefiSRJkmq9aEGwDcOm0sH6BbBhy1LCIoiWIdwmtQqKCMWX9JLfJxhuJUmSqtKc1XMYPWU0L3z3AgXRAgBSG6VycfeLGdJ9CK0btg55QkmSVF4WFaTdXG5uUDbYXhFhyRIoLNzxc8TFQdu22y8itG8P9VxJTZIkSbtaYW5QNtiwRREhe+Hm7zcsgdgvhNtIHNRru/0iQv32UMdwK0mSVF1syN/AcU8ex+KsxQAc2eFIhh06jJM7n0xCfELI00mSpJ1lUUHaDcRi8OGHMHPmtls0ZGT88uMTEoKywfZWQ2jXLriPJEmStMvFYrDqQ1g7c9stGnLKEG7jEoKywfZWQ6jfLriPJEmSaoS7P7ybxVmL6ZDSgZfPepmurbuGPZIkSaoEFhWkGmzDBpgwAf7+d/jmm+3fr379HW/L0KZNsGqCJEmSFJqCDbBgAsz5O2TuINzG19/xtgz12gSrJkiSJKnGW5K1hDs/vBOAu4+725KCJEm7EYsKUg20aBHcfz888gisWRMca9AAjjkmKCFsXURo3hwikTAnliRJkrYjexHMvR/mPwJ5ReG2TgNodUxRCSG9ZBEh0XArSZJUW4ycPJKNBRvp074Pp+13WtjjSJKkSmRRQaohYjGYNg3uuQdefBGi0eD4HnvApZfC+edD48ahjihJkiSVTSwGq6bBnHtgyYsQKwq3DfaATpfCnudD3cahjihJkqRwTV8ynQkzJxAhwrj+44hYVpUkabdiUUGq5nJy4Omng+0dvvhi8/FjjoHLLoMTT4T4+PDmkyRJksqsMAcWPh1s77Bmi3Db6hjodBmknghxhltJkqTaLhaLcfmblwMwuNtguqd2D3cgSZJU6SwqSNXUsmXw4IPw8MOwalVwLCkJfve7YAWFLl3CnU+SJEkqsw3L4PsHYd7DkFsUbuOTIP13wQoKjQ23kiRJ2uypWU/xyZJPaJDQgD8f8+ewx5EkSbuARQWpmpk+Pdje4dlnoaAgOJaWBkOHwkUXQbNm4c4nSZIkldnq6cH2DouehVhRuK2fBvsMhY4XQaLhVpIkSSVtyN/Ate9cC8B1R1xHaqPUkCeSJEm7gkUFqRrIy4PnngsKCp9+uvl4nz7B9g4nnwx1/NcqSZKkmqAwDxY/FxQUftoi3LboE2zv0O5kiDPcSpIkqXR/+egvLMlaQoeUDlzR64qwx5EkSbuIvx2SQrRyZbC1w4MPwvLlwbG6deHss+FPf4KDDw53PkmSJKnMclbC9w/DvAdhY1G4jasLHc6GTn+CpoZbSZIk7diSrCXc+eGdANx13F3US6gX8kSSJGlXsaggheCLL4LVE556KlhNAaB1a7jkEvjDH6Bly3DnkyRJksrs5y+C1RMWPgXRonCb1Br2vgT2/gMkGW4lSZJUNtdNvo4N+Rs4PO1wTt/v9LDHkSRJu5BFBamKFBTASy8FBYVp0zYf79Ej2N7htNOC1RQkSZKkai9aAEteCgoKq7YIt816BNs7pJ0G8YZbSZIkld30JdN5cuaTAIw7YRyRSCTkiSRJ0q5kUUHaxX7+GR55BO6/HxYvDo7VqQOnnx4UFHr2DHc+SZIkqcxyf4b5j8Dc+2FDUbiN1IH2pwcFheaGW0mSJJVfLBbj8jcvB+C8budxSOoh4Q4kSZJ2OYsK0i4yaxb8/e8wYQJs3Bgca9Ei2Nrhj3+E1NRw55MkSZLKbO0smPN3WDABCovCbWIL2OsPsPcfob7hVpIkSTvv6VlP88mST2iQ0IA/H/PnsMeRJElVwKKCVIkKC+HVV4PtHd59d/Pxbt2C1RPOOguSkkIbT5IkSSq7aCEsezXY3mHFFuG2Sbdg9YQOZ0G84VaSJEkVsyF/A9e+cy0AI/uMJLWRJVhJkmoDiwpSJcjMhPHj4b774IcfgmNxcXDKKUFBoU8fcEs1SZIk1Qh5mfDDeJh7H6wvCreROGh3SlBQaGG4lSRJUuX560d/ZXHWYtqntGd47+FhjyNJkqqIRQWpAubMgXvvhccfh+zs4FiTJjBkCAwdCu3bhzqeJEmSVHZZc2DOvfDj41BQFG7rNoGOQ2CfodDAcCtJkqTKtTRrKXd8eAcAd/W7i3oJ9UKeSJIkVRWLClI5RaPw1lvw97/D669vPr7//vCnP8G550L9+uHNJ0mSJJVZLArL34I5f4flW4TblP2h058g/VyoY7iVJEnSrjFy8kg25G/g8LTDOWP/M8IeR5IkVSGLClIZrV8PTzwRrKAwZ05wLBKBX/0q2N7hmGNcAVeSJEk1RP56+PEJmHtvsJICABFo+6tge4dWhltJkiTtWp8u/ZQnZz4JwLgTxhExf0qSVKtYVJB+wQ8/wP33w6OPQmZmcCw5GS64AIYNg44dw51PkiRJKrP1P8Dc+2H+o5BfFG4TkmHPC2CfYdDIcCtJkqRdLxaLcfkblwMwuOtgDkk9JNyBJElSlbOoIJUiFoP33gu2d3jlleB7gH32gUsvhcGDoVGjcGeUJEmSyiQWgxXvwdy/w5JXgKJw22gf2OdS2HMwJBhuJUmSVHWe+eYZPl7yMfUT6nP7sbeHPY4kSQqBRQVpCzk5MGFCUFD4+uvNx084Af70J+jfH+LiwptPkiRJKrPCHPhxQlBQWLtFuG1zAnT6E7TpDxHDrSRJkqrWhvwNXPP2NQCM7DOS1EapIU8kSZLCYFFBKhKLwcknw5tvBt83aADnnRds79C5c5iTSZIkSeUUi8H7J8PyonBbpwHscV6wvUOK4VaSJEnh+etHf2Vx1mLap7Tnyt5Xhj2OJEkKiUUFqcjbbwclhcREuP12uOACaNw47KkkSZKknZDxdlBSiEuErrdDxwugbuOwp5IkSVIttzRrKXd8eAcAd/W7i3oJ9UKeSJIkhcWigkTwgbNRo4Lrl1wCw4eHO48kSZK002Ix+Koo3O59CexruJUkSVL1cN2717EhfwOHpR3GGfufEfY4kiQpRG5IKgGvvAKffRZs9zBiRNjTSJIkSRWw9BX4+bNgu4f9DbeSJEmqHj5b+hn/+upfAIzrP45IJBLyRJIkKUwWFVTrRaNwww3B9csug5Ytw51HkiRJ2mmxKMwsCredLoMkw60kSZLCF4vFuPzNywEY1HUQh7Y9NNyBJElS6CwqqNZ79ln4+mtISYGrrgp7GkmSJKkCFj0La7+GhBTY13ArSZKk6uGZb57ho8UfUT+hPrcfc3vY40iSpGrAooJqtYICuPHG4PqVV0KTJuHOI0mSJO20aAF8XRRuO18JdQ23kiRJCt/G/I1c8/Y1AIzsM5K2yW1DnkiSJFUHFhVUq02cCHPmQLNmwbYPkiRJUo21YCJkzYHEZtDZcCtJkqTq4a8f/5XFWYtJS07jyt5Xhj2OJEmqJiwqqNbKy4Obbw6uX3stJCeHO48kSZK00wrz4OuicLvvtZBguJUkSVL4lq1bxphpYwC467i7qJdQL+SJJElSdWFRQbXWY4/Bjz9C69YwdGjY00iSJEkV8MNjkP0jJLWGfQy3kiRp591///2kp6eTlJREz549+fTTT3d4/3HjxtGpUyfq1atHWloaV1xxBTk5OVU0raq76yZfx4b8DfRu15sz9z8z7HEkSVI1YlFBtVJODtx6a3D9+uuhfv1w55EkSZJ2WmEOzCoKt/tfD3UMt5Ikaec888wzDB8+nBtvvJHPP/+crl270r9/f1auXFnq/SdNmsSIESO48cYb+e6773j00Ud55plnuO6666p4clVHny39jCe+egKAe064h0gkEvJEkiSpOrGooFrpoYdg6VJIS4MhQ8KeRpIkSaqA7x+CjUuhfhrsZbiVJEk7b+zYsQwZMoTzzz+f/fbbj4ceeoj69eszfvz4Uu//0Ucfcfjhh3POOeeQnp7O8ccfz9lnn/2LqzBo9xeLxbj8zcsBGNR1EIe2PTTcgSRJUrVjUUG1zvr1MCbYFo3RoyExMdx5JEmSpJ2Wvx6+LQq3B4yGeMOtJEnaOXl5ecyYMYN+/foVH4uLi6Nfv358/PHHpT7msMMOY8aMGcXFhB9++IHXXnuNgQMHbvd1cnNzycrKKnHR7uff3/ybjxZ/RP2E+tx+zO1hjyNJkqqhnSoqlGefsvz8fG655RY6duxIUlISXbt25Y033ihxnzFjxnDooYfSqFEjWrZsycknn8ycOXNK3Kdv375EIpESl4svvnhnxlctd999sHIldOwIgweHPY0kSQqb2VY12tz7IGclNOwIexpuJUnSzlu9ejWFhYW0atWqxPFWrVqRkZFR6mPOOeccbrnlFvr06UNCQgIdO3akb9++O9z6YcyYMaSkpBRf0tLSKvU8FL6N+Ru55p1rABhx+AjaJrcNeSJJklQdlbuoUN59ykaNGsXDDz/Mvffey7fffsvFF1/MKaecwhdffFF8n6lTpzJ06FA++eQT3n77bfLz8zn++OPJzs4u8VxDhgxh+fLlxZe77rqrvOOrlsvMhE1/bW66CRISQh1HkiSFzGyrGi0vE74r+nvT5SaIM9xKkqSqNWXKFG6//XYeeOABPv/8c1544QVeffVVbr311u0+ZuTIkWRmZhZfFi9eXIUTqyqM/XgsizIXkZacxpWHXRn2OJIkqZqKxGKxWHke0LNnTw499FDuu+8+AKLRKGlpaVx66aWMGDFim/unpqZy/fXXM3To0OJjp556KvXq1WPChAmlvsaqVato2bIlU6dO5cgjjwSCT51169aNcePGlWfcYllZWaSkpJCZmUlycvJOPYdqvptugptvhn33ha+/hvj4sCeSJEk7o7KyndlWNdrMm2DWzZC8Lwz8GuIMt5Ik1UTVJdvl5eVRv359nnvuOU4++eTi44MHD2bt2rW8/PLL2zzmiCOOoFevXtx9993FxyZMmMDvf/971q9fT1zcL39OrrqcvyrHsnXL2OfefcjOz2bSbyZxdpezwx5JkiRVofJku3KtqLAz+5Tl5uaSlJRU4li9evWYNm3adl8nMzMTgKZNm5Y4PnHiRJo3b84BBxzAyJEj2bBhQ3nGVy33008wdmxw/ZZbLClIklTbmW1Vo+X+BLOLwu2Bt1hSkCRJFVa3bl26d+/O5MmTi49Fo1EmT55M7969S33Mhg0btikjxBf90q2cn4/TbuK6ydeRnZ9N73a9OeuAs8IeR5IkVWN1ynPnHe1TNnv27FIf079/f8aOHcuRRx5Jx44dmTx5Mi+88AKFhYWl3j8ajXL55Zdz+OGHc8ABBxQfP+ecc+jQoQOpqanMnDmTa6+9ljlz5vDCCy+U+jy5ubnk5uYWf5+VlVWeU9Vu6K67YN06OOgg+M1vwp5GkiSFzWyrGu3bu6BgHTQ5CNIMt5IkqXIMHz6cwYMHc8ghh9CjRw/GjRtHdnY2559/PgCDBg2ibdu2jBkzBoCTTjqJsWPHctBBB9GzZ0/mzZvHDTfcwEknnVRcWFDt8b9l/+OJr54AYNwJ44hEIiFPJEmSqrNyFRV2xj333MOQIUPo3LkzkUiEjh07cv755zN+/PhS7z906FBmzZq1zafSfv/73xdf79KlC23atOHYY49l/vz5dOzYcZvnGTNmDDfffHPlnoxqrIwMuPfe4Pqtt0IZVp2TJEnahtlW1cLGDJhbFG4PvBUihltJklQ5zjzzTFatWsXo0aPJyMigW7duvPHGG8Xl3kWLFpVYQWHUqFFEIhFGjRrF0qVLadGiBSeddBJ//vOfwzoFhSQWi3H5G5cD8LsDf0ePtj3CHUiSJFV75fqNVvPmzYmPj2fFihUljq9YsYLWrVuX+pgWLVrw0ksvkZ2dzcKFC5k9ezYNGzZkzz333Oa+w4YN47///S/vvfce7dq12+EsPXv2BGDevHml3j5y5EgyMzOLL4sXLy7LKWo3NWYMbNwIvXrBwIFhTyNJkqoDs61qrG/GQOFGaNYLUg23kiSpcg0bNoyFCxeSm5vL9OnTi7MqwJQpU3j88ceLv69Tpw433ngj8+bNY+PGjSxatIj777+fxo0bV/3gCtWz3z7Lh4s/pH5CfW4/9vawx5EkSTVAuYoKO7NP2SZJSUm0bduWgoICnn/+eX79618X3xaLxRg2bBgvvvgi7777LnvssccvzvLll18C0KZNm1JvT0xMJDk5ucRFtdPixfDQQ8H1224DVxyTJElgtlUNlb0Y5hWF266GW0mSJIVvY/5Grn77agCuPfxa2iXvuKgtSZIEO7H1Q3n3KZs+fTpLly6lW7duLF26lJtuuoloNMo111xT/JxDhw5l0qRJvPzyyzRq1IiMjAwAUlJSqFevHvPnz2fSpEkMHDiQZs2aMXPmTK644gqOPPJIDjzwwMr4c9Bu7LbbIC8P+vaFY44JexpJklSdmG1V43xzG0TzoGVfaGW4lSRJUvjGfjyWRZmLSEtO46rDrgp7HEmSVEOUu6hQ3n3KcnJyGDVqFD/88AMNGzZk4MCBPPnkkyWW/3rwwQcB6Nu3b4nXeuyxxzjvvPOoW7cu77zzTvEvjtPS0jj11FMZNWrUTpyyapP582HTltG33uoHziRJUklmW9Uo6+bD/KJwe6DhVpIkSeFbtm4ZY6YFxe47+91J/YT6IU8kSZJqikgsFouFPURVyMrKIiUlhczMTJfKrUUGDYInn4QTToDXXw97GkmSVFlqe7ar7edfa300CBY8CW1OgKMNt5Ik7S5qe7ar7edf053/8vk8/uXj9GrXi48u+IiIZVpJkmq18mS7uB3eKtVg334LEyYE12+7LdxZJEmSpArJ/BYWFIXbroZbSZIkhW/Gshk8/uXjAIzrP86SgiRJKheLCtpt3XQTxGJwyinQvXvY00iSJEkV8PVNQAzanQJNDbeSJEkKVywW47I3LgPg3APPpWe7niFPJEmSahqLCtotffklPPtssG3vzTeHPY0kSZJUAWu+hEXPAhE40HArSZKk8D377bN8uPhD6ifUZ8yxY8IeR5Ik1UAWFbRbGj06+HrWWdClS7izSJIkSRUysyjcdjgLGhtuJUmSFK6N+Ru55u1rALj28Gtpl9wu5IkkSVJNZFFBu53p0+E//4G4uGD7B0mSJKnGWj0dlv4HInHQ5aawp5EkSZL42yd/Y2HmQtolt+Oqw64KexxJklRDWVTQbueGG4KvgwfDPvuEO4skSZJUITOLwu0egyHZcCtJkqRwLV+3nNs/uB2AO/vdSf2E+iFPJEmSaiqLCtqtTJ0Kb78NCQmbt3+QJEmSaqQVUyHjbYhLgAMMt5IkSQrfde9eR3Z+Nr3a9eLsA84OexxJklSDWVTQbiMWg1GjgutDhkB6eqjjSJIkSTsvFoOZReG24xBomB7qOJIkSdKMZTN4/MvHARjXfxyRSCTcgSRJUo1mUUG7jbfegmnTICkJrr8+7GkkSZKkClj+FqyaBvFJsL/hVpIkSeGKxWJc/ublAJx74Ln0bNcz3IEkSVKNZ1FBu4UtV1O45BJITQ13HkmSJGmnbbmawt6XQH3DrSRJksL13LfPMW3RNOrVqceYY8eEPY4kSdoNWFTQbuGVV+B//4MGDeDaa8OeRpIkSaqApa/Az/+DOg1gP8OtJEmSwpVTkMPVb18NwLWHX0u75HYhTyRJknYHFhVU40WjcMMNwfXLLoOWLcOdR5IkSdppsSjMLAq3nS6DJMOtJEmSwjX247EszFxIu+R2XH341WGPI0mSdhMWFVTjPfssfP01pKTAVVeFPY0kSZJUAYuehbVfQ0IK7Gu4lSRJUriWr1vO7R/cDsAdx95B/YT6IU8kSZJ2FxYVVKMVFMDo0cH1K6+EJk3CnUeSJEnaadECmFkUbjtfCXUNt5IkSQrX9e9eT3Z+Nj3b9uTsLmeHPY4kSdqNWFRQjTZhAsydC82aweWXhz2NJEmSVAELJsC6uZDYDDpfHvY0kiRJquVmLJvB418+DsC4E8YRF/HtBEmSVHlMFqqx8vLg5puD6yNGQKNG4c4jSZIk7bTCPPi6KNzuNwISDLeSJEkKTywW44o3ryBGjN92+S292vUKeyRJkrSbsaigGmv8eFiwAFq3hksuCXsaSZIkqQJ+GA/ZCyCpNextuJUkSVK4nv/ueT5Y9AH16tRjzLFjwh5HkiTthiwqqEbauBFuvTW4fv31UL9+uPNIkiRJO61gI8wqCrf7Xw91DLeSJEkKT05BDle/fTUA1xx+DWkpaSFPJEmSdkcWFVQjPfwwLFsGaWkwZEjY00iSJEkVMO9h2LgM6qfBXoZbSZIkhetvH/+NBWsX0LZRW64+7Oqwx5EkSbspiwqqcdavh9tvD66PHg2JieHOI0mSJO20/PXwTVG4PWA0xBtuJUmSFJ7l65Zz+7Qgn97Z704a1G0Q8kSSJGl3ZVFBNc6998KqVdCxIwweHPY0kiRJUgXMvRdyV0HDjrCn4VaSJEnhGvXuKNbnradn256c3eXssMeRJEm7MYsKqlHWroW77gqu33wzJCSEOo4kSZK08/LWwrdF4bbLzRBnuJUkSVJ4Pl/+OY99+RgA404YR1zEtw8kSdKuY9JQjfK3vwVlhf32g7POCnsaSZIkqQJm/w3y10LKftDBcCtJkqTwxGIxLn/jcmLEOKfLOfRq1yvskSRJ0m7OooJqjNWrg6ICwC23QHx8uPNIkiRJOy1ndVBUAOhyC8QZbiVJkhSe5797ng8WfUC9OvW449g7wh5HkiTVAhYVVGPcfTesWwcHHQSnnBL2NJIkSVIFfHc3FKyDJgdBmuFWkiRJ4ckpyOHqt68G4JrDryEtJS3kiSRJUm1gUUE1QkYG3HtvcP3WWyHOv7mSJEmqqTZmwNyicHvgreDev5IkSQrRuE/GsWDtAto2asvVh10d9jiSJKmW8DdiqhFuvx02boRevWDgwLCnkSRJkirgm9uhcCM06wWphltJkiSFJ2N9Bn/+4M8A3NHvDhrUbRDyRJIkqbawqKBqb9EiePjh4Pptt0EkEu48kiRJ0k7LXgTzisJtV8OtJEmSwnX95OtZn7eeHm17cE6Xc8IeR5Ik1SIWFVTt3XYb5OXB0UfDsceGPY0kSZJUAbNug2getDoaWhtuJUmSFJ7Pl3/OY18+BsC4/uOIc0sySZJUhUweqtbmzYPx44Prt94a7iySJElShaybBz8UhdsDDbeSJEkKTywW44o3ryBGjLMPOJveab3DHkmSJNUyFhVUrd1yCxQWwoABcPjhYU8jSZIkVcDXt0CsENoMgBaGW0mSJIXnhe9e4P2F71OvTj3u7Hdn2ONIkqRayKKCqq1vv4UJE4LrrqYgSZKkGi3zW1hQFG67Gm4lSZIUnpyCHK5++2oArj7satJS0kKeSJIk1UYWFVRt3XQTxGJwyinQvXvY00iSJEkV8PVNQAzanQJNDbeSJEkKz7hPxvHj2h9JbZTKNYdfE/Y4kiSplrKooGrpiy/g2WchEoGbbw57GkmSJKkCfv4CFj0LROBAw60kSZLCk7E+gz9/8GcA7jj2DhrUbRDyRJIkqbayqKBqafTo4OtZZ0GXLuHOIkmSJFXIzKJw2+EsaGy4lSRJUnhGvTuK9Xnr6dG2B7898LdhjyNJkmoxiwqqdj75BP77X4iPD7Z/kCRJkmqs1Z/Asv9CJB663BT2NJIkSarFvlj+BeO/GA/AuP7jiIv49oAkSQqPSUTVzg03BF8HD4Z99gl3FkmSJKlCZhaF2z0GQ7LhVpIkSeGIxWJc8eYVxIhx9gFn0zutd9gjSZKkWs6igqqVKVPgnXcgIWFzYUGSJEmqkVZMgYx3IC4BDjDcSpIkKTwvfPcCUxdOJalOEnf0uyPscSRJkiwqqPqIxTaXE4YMgfT0UMeRJEmSdl4stnk1hY5DoGF6qONIkiSp9sopyOHqt68G4OrDrqZ9SvuQJ5IkSbKooGrkzTdh2jRISoLrrw97GkmSJKkClr8Jq6ZBfBLsb7iVJElSeO755B5+XPsjqY1Suebwa8IeR5IkCbCooGoiFoNRo4Lrl1wCqanhziNJkiTttFgMZhaF270vgfqGW0mSJIUjY30Gf/7gzwDccewdNKzbMOSJJEmSAhYVVC28/DLMmAENGsC114Y9jSRJklQBS16Gn2dAnQawn+FWkiRJ4bnh3RtYl7eOQ1MP5bcH/jbscSRJkopZVFDoolG4oWj73ssug5Ytw51HkiRJ2mmxKMwsCredLoMkw60kSZLC8cXyL3j0i0cBGHfCOOIivh0gSZKqD5OJQvfvf8OsWZCSAlddFfY0kiRJUgUs/DdkzoKEFNjXcCtJkqRwxGIxrnjzCmLEOOuAszgs7bCwR5IkSSphp4oK999/P+np6SQlJdGzZ08+/fTT7d43Pz+fW265hY4dO5KUlETXrl154403yv2cOTk5DB06lGbNmtGwYUNOPfVUVqxYsTPjqxopKIAbbwyuX3UVNGkS7jySJKn2Mduq0kQL4OuicLvvVVDXcCtJkqRwvDj7RaYunEpSnSTuOPaOsMeRJEnaRrmLCs888wzDhw/nxhtv5PPPP6dr167079+flStXlnr/UaNG8fDDD3Pvvffy7bffcvHFF3PKKafwxRdflOs5r7jiCv7zn//w7LPPMnXqVJYtW8ZvfvObnThlVScTJsDcudCsWbDtgyRJUlUy26pSLZgA6+ZCYrNg2wdJkqQaqDxF3r59+xKJRLa5nHjiiVU4sUozZtoYAK7qfRUdGncIeRpJkqRtRWKxWKw8D+jZsyeHHnoo9913HwDRaJS0tDQuvfRSRowYsc39U1NTuf766xk6dGjxsVNPPZV69eoxYcKEMj1nZmYmLVq0YNKkSZx22mkAzJ49m3333ZePP/6YXr16/eLcWVlZpKSkkJmZSXJycnlOWbtIXh506gQLFsDdd7vtgyRJKrvKynZmW1Wawjz4byfIXgAH3e22D5IkqcyqU7Z75plnGDRoEA899BA9e/Zk3LhxPPvss8yZM4eWLVtuc/+ff/6ZvLy84u9/+uknunbtyj//+U/OO++8Mr1mdTr/3cWajWtodlczYsRYNnwZbRq1CXskSZJUS5Qn25VrRYW8vDxmzJhBv379Nj9BXBz9+vXj448/LvUxubm5JCUllThWr149pk2bVubnnDFjBvn5+SXu07lzZ9q3b7/D183KyipxUfXy6KNBSaF1a7jkkrCnkSRJtY3ZVpXqh0eDkkJSa9jbcCtJkmqmsWPHMmTIEM4//3z2228/HnroIerXr8/48eNLvX/Tpk1p3bp18eXtt9+mfv36nH766VU8ubY0bdE0YsTYp9k+lhQkSVK1Va6iwurVqyksLKRVq1Yljrdq1YqMjIxSH9O/f3/Gjh3L999/TzQa5e233+aFF15g+fLlZX7OjIwM6tatS+PGjcv8umPGjCElJaX4kpaWVp5T1S62cSPcdltw/frroX79cOeRJEm1j9lWlaZgI8wqCrf7Xw91DLeSJKnm2Zki79YeffRRzjrrLBo0aLDd+1jC3fWmLJgCwFEdjgp3EEmSpB0oV1FhZ9xzzz3svffedO7cmbp16zJs2DDOP/984uJ27UuPHDmSzMzM4svixYt36eupfB56CJYtg/btYciQsKeRJEkqG7OtSjXvIdi4DOq3h70Mt5IkqWbamSLvlj799FNmzZrFRRddtMP7WcLd9aYunApA3/S+4Q4iSZK0A+X6jWrz5s2Jj49nxYoVJY6vWLGC1q1bl/qYFi1a8NJLL5Gdnc3ChQuZPXs2DRs2ZM899yzzc7Zu3Zq8vDzWrl1b5tdNTEwkOTm5xEXVw/r1MGZMcH30aEhMDHceSZJUO5ltVSny18M3ReG2y2iIN9xKkqTa6dFHH6VLly706NFjh/ezhLtrZeZk8kXGF4ArKkiSpOqtXEWFunXr0r17dyZPnlx8LBqNMnnyZHr37r3DxyYlJdG2bVsKCgp4/vnn+fWvf13m5+zevTsJCQkl7jNnzhwWLVr0i6+r6ufee2HVKthrLxg0KOxpJElSbWW2VaWYey/kroKGe8EehltJklRz7UyRd5Ps7GyefvppLrzwwl98HUu4u9a0RdOIxqJ0bNKRtsltwx5HkiRpu+qU9wHDhw9n8ODBHHLIIfTo0YNx48aRnZ3N+eefD8CgQYNo27YtY4o+Mj99+nSWLl1Kt27dWLp0KTfddBPRaJRrrrmmzM+ZkpLChRdeyPDhw2natCnJyclceuml9O7dm169elXGn4OqyNq1cNddwfWbboKEhDCnkSRJtZ3ZVhWStxa+LQq3XW6COMOtJEmqubYs3Z588snA5tLtsGHDdvjYZ599ltzcXM4999wqmFQ74rYPkiSppih3UeHMM89k1apVjB49moyMDLp168Ybb7xRvHfZokWLSuzRm5OTw6hRo/jhhx9o2LAhAwcO5Mknn6Rx48Zlfk6Av/3tb8TFxXHqqaeSm5tL//79eeCBBypw6grD2LFBWWG//eCss8KeRpIk1XZmW1XI7LGQvxZS9oMOhltJklTzlbfIu8mjjz7KySefTLNmzcIYW1vYVFRw2wdJklTdRWKxWCzsIapCVlYWKSkpZGZmupxYSFavhj32gPXr4bnn4NRTw55IkiTVVLU929X2868WclbDK3tAwXro8xy0N9xKkqSdU92y3X333cfdd99dXLr9+9//Ts+ePQHo27cv6enpPP7448X3nzNnDp07d+att97iuOOOK/frVbfzr8nW5a6jyZ1NKIwVsvDyhbRPaR/2SJIkqZYpT7Yr94oK0s66666gpHDQQXDKKWFPI0mSJFXAd3cFJYUmB0Ga4VaSJO0+hg0btt2tHqZMmbLNsU6dOlFLPgtX7X24+EMKY4Xs0XgPSwqSJKnai/vlu0gVt3w53HdfcP3WWyHOv3mSJEmqqTYuh7lF4fbAWyFiuJUkSVL4pi4o2vYh3W0fJElS9edv1FQlxoyBjRuhd28YODDsaSRJkqQK+GYMFG6E5r0h1XArSZKk6mHKwikA9O3QN9Q5JEmSysKigna5RYvg4YeD67fdBpFIuPNIkiRJOy17EcwrCrcHGm4lSZJUPWTnZfO/Zf8DXFFBkiTVDBYVtMvdeivk5cHRR8Mxx4Q9jSRJklQBs26FaB60OhpaG24lSZJUPXy0+CMKogW0T2lPeuP0sMeRJEn6RRYVtEvNmwePPRZcv/XWcGeRJEmSKmTdPPihKNweaLiVJElS9TFlwRQA+qb3DXUOSZKksrKooF3q5puhsBAGDIDDDw97GkmSJKkCvr4ZYoXQZgC0MNxKkiSp+pi6cCoAR3Vw2wdJklQzWFTQLvPttzBxYnDd1RQkSZJUo2V+CwuKwm1Xw60kSZKqjw35G/h06aeARQVJklRzWFTQLnPjjRCLwSmnQPfuYU8jSZIkVcDMG4EYtDsFmhpuJUmSVH18vPhj8qP5tEtux55N9gx7HEmSpDKxqKBd4osv4LnnIBKBW24JexpJkiSpAn7+AhY/B0TgQMOtJEmSqpctt32IRCIhTyNJklQ2FhW0S4weHXw9+2w44IBwZ5EkSZIqZGZRuO1wNjQ23EqSJKl6mbJgCuC2D5IkqWaxqKBK98kn8N//Qnx8sP2DJEmSVGOt/gSW/Rci8dDFcCtJkqTqZWP+RqYvnQ5A3/S+4Q4jSZJUDhYVVOlGjQq+Dh4M++wT7iySJElShXxVFG73GAzJhltJkiRVL9OXTievMI82DduwV9O9wh5HkiSpzCwqqFK99x5MngwJCXDDDWFPI0mSJFXAivdgxWSIS4ADDLeSJEmqfoq3fUg/ikgkEu4wkiRJ5WBRQZUmFttcThgyBNLTQx1HkiRJ2nmxGMwsCrcdh0DD9FDHkSRJkkozdeFUAPp26BvuIJIkSeVkUUGV5s034cMPISkJrr8+7GkkSZKkClj+Jqz6EOKTYH/DrSRJkqqfnIIcPlnyCRCsqCBJklSTWFRQpYjFYFTR9r1Dh0JqarjzSJIkSTstFoOZReF276FQ33ArSZKk6ufTpZ+SU5BDqwat6NSsU9jjSJIklYtFBVWKl1+GGTOgQQO49tqwp5EkSZIqYMnL8PMMqNMA9jPcSpIkqXqauiDY9uGo9KOIRCIhTyNJklQ+FhVUYYWFcEPR9r2XXw4tWoQ6jiRJkrTzooUwsyjcdrockgy3kiRJqp6mLiwqKnRw2wdJklTzWFRQhf373zBrFqSkwJVXhj2NJEmSVAGL/g2ZsyAhBfY13EqSJKl6yivM46PFHwHQN71vuMNIkiTtBIsKqpCCArjxxuD6VVdBkybhziNJkiTttGgBfF0Ubve9CuoabiVJklQ9fbb0MzYWbKRF/Rbs23zfsMeRJEkqN4sKqpAnn4Tvv4dmzeCyy8KeRpIkSaqAH5+Edd9DYjPoZLiVJElS9bVp24cjOxxJJBIJeRpJkqTys6igCvnb34KvI0ZAo0bhziJJkiRVyJyicLvfCEgw3EqSJKn6mrJgCuC2D5IkqeayqKCdtmgRfP01xMXBBReEPY0kSZJUAdmLYO3XEImDPQ23kiRJqr7yC/P5cPGHABzV4aiQp5EkSdo5FhW0015/Pfjaqxc0bRruLJIkSVKFLCsKt816QaLhVpIkSdXX/5b9jw35G2haryn7t9w/7HEkSZJ2ikUF7bRNRYUBA8KdQ5IkSaqw5UXhNtVwK0mSpOpt6sKpQLCaQlzEX/FLkqSayRSjnZKbC++8E1wfODDcWSRJkqQKKcyFjKJwm2q4lSRJUvW2ZVFBkiSpprKooJ0ybRpkZ0OrVtCtW9jTSJIkSRWwahoUZENSK2jSLexpJEmSpO0qiBYwbdE0AI5Kt6ggSZJqLosK2imvvRZ8HTAA4vxbJEmSpJpsWVG4TR0ALp0rSZKkauzz5Z+zPm89TZKacGCrA8MeR5Ikaaf5WzjtlNeLtvAd4Ba+kiRJqumWFYXbNoZbSZIkVW9TFwTbPhzR4QjiLNlKkqQazCSjcluwAL77DuLj4bjjwp5GkiRJqoD1CyDrO4jEQxvDrSRJkqq3KQunAHBUB7d9kCRJNZtFBZXbptUUeveGJk3CnUWSJEmqkOVF4bZ5b6hruJUkSVL1VRgtZNqiaQD0Te8b7jCSJEkVZFFB5fZa0Ra+AweGO4ckSZJUYUuLwm2q4VaSJEnV25cZX5KVm0VKYgpdW3UNexxJkqQKsaigcsnJgXffDa4PcAtfSZIk1WSFObCiKNymGm4lSZJUvU1ZMAWAPu37EB8XH+4wkiRJFWRRQeXy/vuwYQO0aQNdLe1KkiSpJlv5PhRugHptoLHhVpIkSdXb1IVTAbd9kCRJuweLCiqX14u28B0wACKRcGeRJEmSKmRZUbhtY7iVJElS9VYYLeSDRR8AcFSHo0KeRpIkqeIsKqhcXivawnegW/hKkiSppltWFG5TDbeSJEmq3maumMnanLU0qtuIg9ocFPY4kiRJFWZRQWU2fz7MnQt16kC/fmFPI0mSJFXAuvmwbi5E6kBrw60kSZKqt03bPvRp34c6cXVCnkaSJKniLCqozDZt+3D44ZCSEu4skiRJUoVs2vahxeFQ13ArSZKk6m3KgimA2z5IkqTdh0UFldmmosKAAeHOIUmSJFXY8qJwm2q4lSRJUvUWjUX5YNEHAPRN7xvuMJIkSZXEooLKZONGePfd4PpAt/CVJElSTVawEVYUhdtUw60kSZKqt1krZ/Hzxp9pkNCAg9scHPY4kiRJlcKigspk6lTIyYG2beGAA8KeRpIkSaqAlVOhMAfqtYUUw60kSZKqt03bPhze/nAS4hPCHUaSJKmSWFRQmbz2WvB14ECIRMKdRZIkSaqQZUXhNtVwK0mSpOpv6sKpAPTt0DfcQSRJkirRThUV7r//ftLT00lKSqJnz558+umnO7z/uHHj6NSpE/Xq1SMtLY0rrriCnJyc4tvT09OJRCLbXIYOHVp8n759+25z+8UXX7wz42snvF60he8At/CVJEm7GbNtLbSsKNymGm4lSZJUvUVjUd5f+D4AR6UfFfI0kiRJladOeR/wzDPPMHz4cB566CF69uzJuHHj6N+/P3PmzKFly5bb3H/SpEmMGDGC8ePHc9hhhzF37lzOO+88IpEIY8eOBeCzzz6jsLCw+DGzZs3iuOOO4/TTTy/xXEOGDOGWW24p/r5+/frlHV874fvvYd48SEiAY48NexpJkqTKY7athbK+h/XzIC4BWhtuJUmSVL19u+pbVm9YTb069Tgk9ZCwx5EkSao05S4qjB07liFDhnD++ecD8NBDD/Hqq68yfvx4RowYsc39P/roIw4//HDOOeccIPiE2dlnn8306dOL79OiRYsSj7njjjvo2LEjRx1VsiFav359WrduXd6RVUGbVlPo0weSk8OdRZIkqTKZbWuh5UXhtkUfSDDcSpIkqXqbuiDY9uHw9odTN75uyNNIkiRVnnJt/ZCXl8eMGTPo16/f5ieIi6Nfv358/PHHpT7msMMOY8aMGcVL6P7www+89tprDBw4cLuvMWHCBC644AIiW+0XO3HiRJo3b84BBxzAyJEj2bBhQ3nG1056rWgLX7d9kCRJuxOzbS21rCjctjHcSpIkqfqbujAoKhzVwW0fJEnS7qVcKyqsXr2awsJCWrVqVeJ4q1atmD17dqmPOeecc1i9ejV9+vQhFotRUFDAxRdfzHXXXVfq/V966SXWrl3Leeedt83zdOjQgdTUVGbOnMm1117LnDlzeOGFF0p9ntzcXHJzc4u/z8rKKseZapMNG2DKlOD6dn7/LkmSVCOZbWuhgg2wYkpwPdVwK0mSpOotFotZVJAkSbutcm/9UF5Tpkzh9ttv54EHHqBnz57MmzePyy67jFtvvZUbbrhhm/s/+uijDBgwgNTU1BLHf//73xdf79KlC23atOHYY49l/vz5dOzYcZvnGTNmDDfffHPln1At8957kJsLaWmw335hTyNJkhQus20Nt+I9iOZC/TRIMdxKkiSpepu9ejYrs1eSVCeJHm17hD2OJElSpSrX1g/NmzcnPj6eFStWlDi+YsWK7e6ve8MNN/C73/2Oiy66iC5dunDKKadw++23M2bMGKLRaIn7Lly4kHfeeYeLLrroF2fp2bMnAPPmzSv19pEjR5KZmVl8Wbx4cVlOUVt5vWgL34EDYavViiVJkmo0s20ttKwo3KYabiVJkrbn/vvvJz09naSkJHr27Fm87dn2rF27lqFDh9KmTRsSExPZZ599eG3TXrKqkE2rKfRu15vEOokhTyNJklS5ylVUqFu3Lt27d2fy5MnFx6LRKJMnT6Z3796lPmbDhg3ExZV8mfj4eCBYumpLjz32GC1btuTEE0/8xVm+/PJLANq0aVPq7YmJiSQnJ5e4qHxiMdj0/ykGuIWvJEnazZhta5lYDJYVhdtUw60kSVJpnnnmGYYPH86NN97I559/TteuXenfvz8rV64s9f55eXkcd9xxLFiwgOeee445c+bwyCOP0LZt2yqefPc0ZcEUAPqm9w11DkmSpF2h3Fs/DB8+nMGDB3PIIYfQo0cPxo0bR3Z2Nueffz4AgwYNom3btowZMwaAk046ibFjx3LQQQcVL497ww03cNJJJxX/UheCXwo/9thjDB48mDp1So41f/58Jk2axMCBA2nWrBkzZ87kiiuu4Mgjj+TAAw+syPlrB+bOhR9/hIQEOPbYsKeRJEmqfGbbWmTdXMj+EeISoJXhVpIkqTRjx45lyJAhxXn4oYce4tVXX2X8+PGMGDFim/uPHz+en3/+mY8++oiEhAQA0tPTq3Lk3VYsFiteUeGoDkeFPI0kSVLlK3dR4cwzz2TVqlWMHj2ajIwMunXrxhtvvEGrVq0AWLRoUYlPmY0aNYpIJMKoUaNYunQpLVq04KSTTuLPf/5zied95513WLRoERdccME2r1m3bl3eeeed4l8cp6WlceqppzJq1Kjyjq9y2LSawpFHQsOG4c4iSZK0K5hta5FNqym0OBISDLeSJElby8vLY8aMGYwcObL4WFxcHP369ePjjz8u9TGvvPIKvXv3ZujQobz88su0aNGCc845h2uvvbZEkVfl9/3P35OxPoPE+ER6tusZ9jiSJEmVLhLbeo3a3VRWVhYpKSlkZma6VG4ZHX88vP02/PWvMHx42NNIkiRtVtuzXW0//53y7vGQ8TYc9FfY13ArSZKqj+qS7ZYtW0bbtm356KOPSmyFds011zB16lSmT5++zWM6d+7MggUL+O1vf8sll1zCvHnzuOSSS/jTn/7EjTfeWOrr5ObmkpubW/x9VlYWaWlpoZ9/dfOPGf/gD//9A0d1OIop500JexxJkqQyKU+2jdvhraq1srNharCyGAPcwleSJEk1WUE2rCwKt6mGW0mSpMoSjUZp2bIl//jHP+jevTtnnnkm119/PQ899NB2HzNmzBhSUlKKL2lpaVU4cc3htg+SJGl3Z1FBpXr3XcjLg/R06Nw57GkkSZKkCsh4F6J50CAdkg23kiRJpWnevDnx8fGsWLGixPEVK1bQunXrUh/Tpk0b9tlnnxLbPOy7775kZGSQl5dX6mNGjhxJZmZm8WXx4sWVdxK7iVgsxpQFUwA4Kt2igiRJ2j1ZVFCpXn89+DpgAEQi4c4iSZIkVcjyonCbariVJEnanrp169K9e3cmT55cfCwajTJ58uQSW0Fs6fDDD2fevHlEo9HiY3PnzqVNmzbUrVu31MckJiaSnJxc4qKS5q+Zz7J1y6gbX5de7XqFPY4kSdIuYVFB24jF4LXXgusDB4Y7iyRJklQhsRgsKwq3qYZbSZKkHRk+fDiPPPIITzzxBN999x1//OMfyc7O5vzzzwdg0KBBjBw5svj+f/zjH/n555+57LLLmDt3Lq+++iq33347Q4cODesUdgtTFwTbPvRo24P6CfVDnkaSJGnXqBP2AKp+Zs+GhQuhbl04+uiwp5EkSZIqIGs2ZC+EuLrQynArSZK0I2eeeSarVq1i9OjRZGRk0K1bN9544w1atWoFwKJFi4iL2/zZt7S0NN58802uuOIKDjzwQNq2bctll13GtddeG9Yp7BamLJwCwFEd3PZBkiTtviwqaBubVlPo2xcaNAh1FEmSJKliNq2m0LIv1DHcSpIk/ZJhw4YxbNiwUm+bMmXKNsd69+7NJ598sounqj1isVjxigp90/uGO4wkSdIu5NYP2sbrRVv4DhgQ7hySJElShS0rCrephltJkiRVfwvWLmBx1mLqxNWhd7veYY8jSZK0y1hUUAnr1sH77wfXB7qFryRJkmqy/HWwqijcphpuJUmSVP1NWTAFgENTD6VBXVcEkyRJuy+LCirh3XchPx/23BP23jvsaSRJkqQKWPEuRPOh4Z7QyHArSZKk6m/qQrd9kCRJtYNFBZXwWtEWvgMHQiQS7iySJElShSwrCrephltJkiTVDJuKCkd1OCrkSSRJknYtiwoqFovB60Vb+A5wC19JkiTVZLEYLCsKt20Mt5IkSar+Fq5dyIK1C4iPxHNY2mFhjyNJkrRLWVRQsW++gcWLISkJ+vYNexpJkiSpAjK/gQ2LIT4JWvUNexpJkiTpF21aTeGQ1EP+v707D4+qvN8/fs9kTyBhC1kgJAiyKfsSA0IiRCDYKGiRihXFBW2hLmgrKAjqT2itRaxi1X4V2rqhLS6tAUQ0UTCyLy4IEYEAWQCBsCeQeX5/JBkZskDIcnKS9+u6cmVyZs5zPudk5nCLH55Hjf0aW1wNAABAzaJRAW4lsykkJEiBgZaWAgAAAFRNyWwKLRMkb8ItAAAA6r60nSz7AAAAGg4aFeCWUryE74gR1tYBAAAAVFlWcbiNJNwCAADAHlJ3pUqSEmISLK0DAACgNtCoAEnSkSPSihVFj5NYwhcAAAB2dvqItL843EYSbgEAAFD37TmyRz8e+lFOh1MD2gywuhwAAIAaR6MCJEmffCKdOSNdeqnUvr3V1QAAAABVkPOJZM5IjS+VGhNuAQAAUPeVLPvQK6KXgv2CLa4GAACg5tGoAEnS4uIlfJlNAQAAALaXVRxuIwi3AAAAsIfUnamSpIToBEvrAAAAqC00KkDG/NyoMIIlfAEAAGBnxvzcqBBJuAUAAIA9pO0qmlEhPibe4koAAABqB40K0NdfS3v3SgEBUjw5GAAAAHZ2+Gvp5F7JK0AKI9wCAACg7ss6mqWMgxlyyKEr21xpdTkAAAC1gkYFKCWl6PvgwZK/v7W1AAAAAFWSVRxuwwZLXoRbAAAA1H1pO4tmU+gZ0VNN/JtYWwwAAEAtoVEB7mUfkljCFwAAAHaXXbLsA+EWAAAA9uBe9iGaGcEAAEDDQaNCA3f4sLRyZdFjGhUAAABgawWHpf3F4ZZGBQAAANhE6s5USTQqAACAhoVGhQbuk0+kwkKpY0fpkkusrgYAAACogpxPJFMoBXeUGhFuAQAAUPflHMvR1p+2yiGHBkYPtLocAACAWkOjQgOXUryE74gR1tYBAAAAVFlWcbiNINwCAADAHj7f9bkkqVtYNzULaGZxNQAAALWHRoUGzBhpcfESviz7AAAAAFszRsoqDrcs+wAAAACbYNkHAADQUNGo0IBt3Cjl5EiBgdKgQVZXAwAAAFTBoY3SqRzJK1BqSbgFAACAPaTtSpMkJcQkWFsIAABALaNRoQErmU1hyBDJz8/aWgAAAIAqyS4Ot+FDJC/CLQAAAOq+fcf36bv930mSBkYPtLgaAACA2kWjQgOWUryE7wiW8AUAAIDdZRWH20jCLQAAAOzh812fS5Iub3m5WgS2sLgaAACA2kWjQgN16JCUnl70OIklfAEAAGBnBYekA8XhNpJwCwAAAHtI21m87EN0grWFAAAAWIBGhQbq448ll0vq0kWKjra6GgAAAKAKsj+WjEsK6SIFEW4BAABgD2m7ihoV4mPiLa4EAACg9tGo0EAtLl7Cl9kUAAAAYHtZxeE2gnALAAAAezhw4oC+3ve1JGlQ9CCLqwEAAKh9NCo0QC7Xz40KI1jCFwAAAHZmXFJ2cbiNJNwCAADAHr7Y9YUkqUtoF7UMamlxNQAAALWPRoUGaMMGad8+qVEj6corra4GAAAAqIJDG6RT+yTvRlIo4RYAAAD2kLozVZIUH82yDwAAoGGiUaEBSkkp+j5kiOTra20tAAAAQJXsLQ634UMkL8ItAAAA7CFtV5okKSEmwdpCAAAALEKjQgPEsg8AAACoN1j2AQAAADZz8ORBbc7dLEkaFD3I4moAAACsQaNCA/PTT9KqVUWPk5KsrQUAAACokvyfpJ+Kw20E4RYAAAD28MWuL2Rk1LF5R4U3Cre6HAAAAEvQqNDAfPyx5HJJl18uRUVZXQ0AAABQBdkfS8YlhVwuBRFuAQAAYA8s+wAAAECjQoNTsuwDsykAAADA9rJKln0g3AIAAMA+ShoV4qPjLa4EAADAOjQqNCAul7RkSdHjESzhCwAAADszLim7ONxGEm4BAABgD4dPHdaG7A2SpPgYGhUAAEDDRaNCA7JunbR/v9S4sTRggNXVAAAAAFVwcJ2Uv1/ybiyFEm4BAABgDysyV8jI6NJmlyqycaTV5QAAAFiGRoUGJCWl6PvVV0s+PtbWAgAAAFRJVnG4jbhachJuAQAAYA9pO1n2AQAAQKJRoUFZXLyEbxJL+AIAAMDusorDbQThFgAAAPaRuitVEss+AAAA0KjQQOzfL61eXfSYRgUAAADY2qn90k/F4TaScAsAAAB7OJJ/ROuz10tiRgUAAAAaFRqIjz+WjJG6dZNatbK6GgAAAKAKsj+WZKQm3aRAwi0AAADsYWXmSrmMS5c0vURRIVFWlwMAAGCpi2pUmDdvnmJiYuTv76/Y2FitLvmn+uWYO3euOnbsqICAAEVFRemBBx7QqVOn3M/PnDlTDofD46tTp04eY5w6dUoTJ05U8+bN1ahRI91www3Kzc29mPIbpJTiJXxHjLC2DgAAgLqGbGtDWcXhNpJwCwAAAPtI3ZkqidkUAAAApItoVFi4cKEmT56sGTNmaP369erevbuGDRumffv2lfn6N998U1OmTNGMGTO0ZcsWvfrqq1q4cKEeeeQRj9dddtllys7Odn+tWLHC4/kHHnhA//3vf/Xuu+8qLS1NWVlZuv766ytbfoNUWCgtXVr0mGUfAAAAfka2tSFXoZRTHG5Z9gEAAAA2krYrTZKUEJNgbSEAAAB1gHdld5gzZ47uuusujR8/XpL00ksv6aOPPtJrr72mKVOmlHr9l19+qQEDBmjs2LGSpJiYGN10001atWqVZyHe3goPDy/zmHl5eXr11Vf15ptvavDgwZKk+fPnq3Pnzvrqq690xRVXVPY0GpQ1a6SffpJCQqS4OKurAQAAqDvItjZ0cI2U/5PkEyK1INwCAADAHo4VHNParLWSmFEBAABAquSMCgUFBVq3bp0SExN/HsDpVGJiotLT08vcp3///lq3bp17Ct0ff/xRKSkpGnHOGgQZGRmKjIzUJZdcoptvvlmZmZnu59atW6fTp097HLdTp05q06ZNucfNz8/XkSNHPL4aqsWLi75ffbXk42NtLQAAAHUF2damsorDbfjVkpNwCwAAAHtYmblShaZQMU1iFN0k2upyAAAALFepGRUOHDigwsJChYWFeWwPCwvT999/X+Y+Y8eO1YEDB3TllVfKGKMzZ87onnvu8ZgeNzY2VgsWLFDHjh2VnZ2txx9/XAMHDtQ333yjxo0bKycnR76+vmrSpEmp4+bk5JR53NmzZ+vxxx+vzOnVWynFS/iOYAlfAAAAN7KtTWUVh9tIwi0AAADso2TZB2ZTAAAAKFKpGRUuRmpqqmbNmqUXX3xR69ev16JFi/TRRx/pySefdL8mKSlJo0ePVrdu3TRs2DClpKTo8OHDeueddy76uFOnTlVeXp77a/fu3dVxOraTmyutLZpRTMOHW1sLAACA3ZFtLXYyVzpYHG4jCbcAAACwj9SdqZJoVAAAAChRqRkVWrRoIS8vL+Xm5npsz83NLXcN3unTp+uWW27RnXfeKUnq2rWrjh8/rgkTJujRRx+V01m6V6JJkybq0KGDfvjhB0lSeHi4CgoKdPjwYY9/eVbRcf38/OTn51eZ06uXli4t+t6zpxQRYW0tAAAAdQnZ1oayi8Nt055SAOEWAAAA9nC84LjWZK2RJCXEJFhbDAAAQB1RqRkVfH191bt3by1fvty9zeVyafny5YqLiytznxMnTpT6C1svLy9JkjGmzH2OHTum7du3K6L4/6z37t1bPj4+HsfdunWrMjMzyz0uiiwuXsI3KcnaOgAAAOoasq0NZReH20jCLQAAAOwjfU+6zrjOKCo4SjFNYqwuBwAAoE6o1IwKkjR58mTdeuut6tOnj/r166e5c+fq+PHjGj9+vCRp3LhxatWqlWbPni1JSk5O1pw5c9SzZ0/Fxsbqhx9+0PTp05WcnOz+S92HHnpIycnJio6OVlZWlmbMmCEvLy/ddNNNkqSQkBDdcccdmjx5spo1a6bg4GD97ne/U1xcnK644orquhb1zpkzP8+oMIIlfAEAAEoh29qI68zPMypEEm4BAABgH+5lH2Li5XA4rC0GAACgjqh0o8KYMWO0f/9+PfbYY8rJyVGPHj20ZMkShYWFSZIyMzM9/pXZtGnT5HA4NG3aNO3du1ehoaFKTk7WU0895X7Nnj17dNNNN+mnn35SaGiorrzySn311VcKDQ11v+bZZ5+V0+nUDTfcoPz8fA0bNkwvvvhiVc693lu9Wjp0SGrSRIqNtboaAACAuodsayM/rZYKDkk+TaTmhFsAAADYR9quNElSQnSCtYUAAADUIQ5T3hy19cyRI0cUEhKivLw8BQcHW11OrZg2TXrqKWnMGOntt62uBgAAoPo0xGx3tgZ5/pumSd8+JbUZI11JuAUAAPVHg8x2Z6nv53/i9Ak1/VNTFRQWKON3GWrfrL3VJQEAANSYymQ7Z4XPwtYWFy/hm8QSvgAAALC7rOJwG0m4BQAAqEnz5s1TTEyM/P39FRsbq9WrV5f72gULFsjhcHh8+fv712K1dd9Xe75SQWGBIhtHql3TdlaXAwAAUGfQqFBP5eRI69cXPR4+3NpaAAAAgCo5mSMdKg63EYRbAACAmrJw4UJNnjxZM2bM0Pr169W9e3cNGzZM+/btK3ef4OBgZWdnu7927dpVixXXfWk7i5d9iEmQw+GwuBoAAIC6g0aFemrJkqLvvXtLxUssAwAAAPaUXRxum/WWAgi3AAAANWXOnDm66667NH78eHXp0kUvvfSSAgMD9dprr5W7j8PhUHh4uPsrjL+M9JC2q6hRIT463uJKAAAA6hYaFeqplJSi7yNGWFsHAAAAUGVZxeE2knALAABQUwoKCrRu3TolJia6tzmdTiUmJio9Pb3c/Y4dO6bo6GhFRUXpuuuu07ffflvhcfLz83XkyBGPr/rq1JlT+mrPV5JoVAAAADgXjQr10Jkz0scfFz1OYglfAAAA2JnrjJRdHG4jCLcAAAA15cCBAyosLCw1I0JYWJhycnLK3Kdjx4567bXX9MEHH+j111+Xy+VS//79tWfPnnKPM3v2bIWEhLi/oqKiqvU86pJVe1YpvzBf4Y3C1aF5B6vLAQAAqFNoVKiH0tOlvDypWTOpXz+rqwEAAACq4EC6dDpP8m0mNSfcAgAA1CVxcXEaN26cevToofj4eC1atEihoaF6+eWXy91n6tSpysvLc3/t3r27FiuuXWcv++BwOCyuBgAAoG7xtroAVL/Fi4u+DxsmeXlZWwsAAABQJVnF4TZimOQk3AIAANSUFi1ayMvLS7m5uR7bc3NzFR4efkFj+Pj4qGfPnvrhhx/KfY2fn5/8/PyqVKtdpO5MlSQlxCRYWgcAAEBdxIwK9VBK8RK+I1jCFwAAAHaXVRxuIwm3AAAANcnX11e9e/fW8uXL3dtcLpeWL1+uuLi4CxqjsLBQX3/9tSIiImqqTNvIP5Ov9D3pkopmVAAAAIAnZlSoZ/bulTZtkhyOohkVAAAAANs6sVc6vEmSo2hGBQAAANSoyZMn69Zbb1WfPn3Ur18/zZ07V8ePH9f48eMlSePGjVOrVq00e/ZsSdITTzyhK664Qu3bt9fhw4f15z//Wbt27dKdd95p5WnUCav3rtapM6fUMqilOrXoZHU5AAAAdQ6NCvXMkiVF3/v2lUJDra0FAAAAqJLs4nDbvK/kT7gFAACoaWPGjNH+/fv12GOPKScnRz169NCSJUsUFhYmScrMzJTT+fMkvYcOHdJdd92lnJwcNW3aVL1799aXX36pLl26WHUKdUbarjRJRbMpOBwOi6sBAACoe2hUqGcWFy/hm5RkbR0AAABAlWUVh9sIwi0AAEBtmTRpkiZNmlTmc6mpqR4/P/vss3r22WdroSr7ObtRAQAAAKU5z/8S2MXp09KyZUWPR7CELwAAAOzMdVrKKQ63kYRbAAAA2EdBYYFWZq6UJMXH0KgAAABQFhoV6pEvv5SOHJFatJD69LG6GgAAAKAK9n8pnT4i+bWQmhNuAQAAYB9rs9bq5JmTahHYQl1CWQYDAACgLDQq1CMlyz4MHy45+c0CAADAzrJLln0YLjkItwAAALCPtJ1Fyz4Mih4kJ1kWAACgTKSkeiQlpeh7Ekv4AgAAwO6yisNtJOEWAAAA9pK6K1WSFB/Nsg8AAADloVGhntizR/r6a8nhkIYNs7oaAAAAoApO7JEOfy3JIUUQbgEAAGAfpwtPa2XmSklSQkyCtcUAAADUYTQq1BMlyz7ExkrNm1tbCwAAAFAlWcXhtnms5Ee4BQAAgH2sz16v46ePq1lAM13e8nKrywEAAKizaFSoJ0oaFVj2AQAAALZX0qjAsg8AAACwmdSdqZKkgW0Gyungr98BAADKQ1KqBwoKpGXLih6PGGFtLQAAAECVFBZIOcXhNpJwCwAAAHtJ25UmiWUfAAAAzodGhXpg5Urp2DGpZUupVy+rqwEAAACq4MBK6cwxyb+l1IxwCwAAAPs44zqjFZkrJEnx0fEWVwMAAFC30ahQD6SkFH0fPlxy8hsFAACAnWUVh9uI4RJT5QIAAMBGNmRv0NGCowrxC1G3sG5WlwMAAFCn8Td/9cDi4iV8k1jCFwAAAHaXVRxuIwi3AAAAsJeSZR8GRQ+Sl9PL4moAAADqNhoVbC4zU/r226KZFIYOtboaAAAAoAqOZ0p53xbNpBBBuAUAAIC9lDQqsOwDAADA+dGoYHMlsylccYXUrJm1tQAAAABVUjKbQvMrJD/CLQAAAOyj0FWoz3d9LklKiEmwthgAAAAboFHB5lKKl/AdMcLaOgAAAIAqyyoOt5GEWwAAANjLptxNOpJ/RMF+weoR3sPqcgAAAOo8GhVsLD9fWr686HESS/gCAADAzgrzpdzicBtJuAUAAIC9pO5MlSRd2eZKeTm9rC0GAADABmhUsLEvvpCOH5fCw6UePayuBgAAAKiC/V9IZ45L/uFS0x5WVwMAAABUStquNElSQnSCtYUAAADYBI0KNra4eAnf4cMlJ79JAAAA2FlWcbiNHC45CLcAAACwD5dx6YtdX0iS4mPiLa4GAADAHvgbQBtLKV7CdwRL+AIAAMDusorDbSThFgAAAPayOXezDp06pEa+jdQropfV5QAAANgCjQo2tWOH9P33kpeXdPXVVlcDAAAAVMGxHdKR7yWHlxROuAUAAIC9pO0sWvbhyjZXytvpbXE1AAAA9kCjgk2VLPvQv7/UpImlpQAAAABVU7LsQ4v+km8TS0sBAAAAKittV1GjQnw0yz4AAABcKBoVbKqkUSEpydo6AAAAgCoraVSIJNwCAADAXlzGRaMCAADARaBRwYZOnZKWLy96PIIlfAEAAGBnhaek3OJwG0m4BQAAgL18u+9bHTx5UIE+geoT2cfqcgAAAGyDRgUb+vxz6eRJKTJS6tbN6moAAACAKtj3uVR4UgqIlJoQbgEAAGAvJbMpDIgaIB8vH4urAQAAsA8aFWwoJaXoe1KS5HBYWwsAAABQJVnF4TaScAsAAAD7Sd2ZKollHwAAACqLRgUbWly8hG8SS/gCAADA7rKKw20E4RYAAAD2YozR57s+lyQlxCRYWwwAAIDN0KhgM9u3S9u2Sd7eUmKi1dUAAAAAVXB0u3R0m+TwlsIJtwAAALCXLQe2aP+J/QrwDlDfVn2tLgcAAMBWaFSwmZLZFAYMkEJCrK0FAAAAqJKS2RRCB0i+hFsAAADYS8myD3FRcfL18rW2GAAAAJuhUcFmUoqX8B0xwto6AAAAgCrLKg63kYRbAAAA2E/arjRJUkJ0grWFAAAA2BCNCjZy8qT02WdFj5NYwhcAAAB2duaktK843EYSbgEAAGAvxhil7SxqVIiPibe4GgAAAPuhUcFGUlOlU6ek1q2lyy+3uhoAAACgCvalSoWnpMDWUgjhFgAAAPay9aetyj2eK39vf/Vr1c/qcgAAAGyHRgUbWVy8hG9SkuRwWFsLAAAAUCVZxeE2gnALAAAA+ymZTeGK1lfI39vf4moAAADsh0YFG0kpXsJ3BEv4AgAAwO6yisNtJOEWAAAA9pO6K1WSFB/Nsg8AAAAX46IaFebNm6eYmBj5+/srNjZWq1evrvD1c+fOVceOHRUQEKCoqCg98MADOnXqlPv52bNnq2/fvmrcuLFatmypkSNHauvWrR5jJCQkyOFweHzdc889F1O+LWVkSNu3Sz4+0pAhVlcDAABQf5BtLXAkQzq2XXL6SOGEWwAAANiLMcY9o0JCTIK1xQAAANhUpRsVFi5cqMmTJ2vGjBlav369unfvrmHDhmnfvn1lvv7NN9/UlClTNGPGDG3ZskWvvvqqFi5cqEceecT9mrS0NE2cOFFfffWVli1bptOnT2vo0KE6fvy4x1h33XWXsrOz3V9PP/10Zcu3rZLZFAYOlBo3trYWAACA+oJsa5GS2RRCB0o+hFsAAADYyw8Hf1D2sWz5evkqtlWs1eUAAADYkndld5gzZ47uuusujR8/XpL00ksv6aOPPtJrr72mKVOmlHr9l19+qQEDBmjs2LGSpJiYGN10001atWqV+zVLlizx2GfBggVq2bKl1q1bp0GDBrm3BwYGKjw8vLIl1wuLi5fwTUqytg4AAID6hGxrkezicBtJuAUAAID9pO5MlSTFtopVgE+AtcUAAADYVKVmVCgoKNC6deuUmJj48wBOpxITE5Wenl7mPv3799e6devcU+j++OOPSklJ0YgR5a9Fm5eXJ0lq1qyZx/Y33nhDLVq00OWXX66pU6fqxIkTlSnftk6ckFJTix5XcNkAAABQCWRbi5w5IeWmFj2OJNwCAADAftJ2sewDAABAVVVqRoUDBw6osLBQYWFhHtvDwsL0/fffl7nP2LFjdeDAAV155ZUyxujMmTO65557PKbHPZvL5dL999+vAQMG6PLLL/cYJzo6WpGRkdq8ebMefvhhbd26VYsWLSpznPz8fOXn57t/PnLkSGVOtU757DMpP19q00bq3NnqagAAAOoHsq1Fcj+TXPlSYBspmHALAAAAezHGuBsV4qPjLa4GAADAviq99ENlpaamatasWXrxxRcVGxurH374Qffdd5+efPJJTZ8+vdTrJ06cqG+++UYrVqzw2D5hwgT3465duyoiIkJDhgzR9u3b1a5du1LjzJ49W48//nj1n5AFSpZ9GDFCcjisrQUAAKAhI9tWg6ySZR8ItwAAALCfHw/9qD1H9sjH6aO4qDirywEAALCtSi390KJFC3l5eSk3N9dje25ubrnr606fPl233HKL7rzzTnXt2lWjRo3SrFmzNHv2bLlcLo/XTpo0Sf/73//02WefqXXr1hXWEhsbK0n64Ycfynx+6tSpysvLc3/t3r37Qk+zTjFGSkkpepzEEr4AAADVhmxrAWOkrOJwG0m4BQAAgP2UzKbQr1U/BfoEWlwNAACAfVWqUcHX11e9e/fW8uXL3dtcLpeWL1+uuLiyu0dPnDghp9PzMF5eXpKKpskq+T5p0iS99957+vTTT9W2bdvz1rJx40ZJUkRERJnP+/n5KTg42OPLjrZtk3bskHx9pcGDra4GAACg/iDbWuDoNun4DsnpK4URbgEAAGA/LPsAAABQPSq99MPkyZN16623qk+fPurXr5/mzp2r48ePa/z48ZKkcePGqVWrVpo9e7YkKTk5WXPmzFHPnj3d0+NOnz5dycnJ7r/UnThxot5880198MEHaty4sXJyciRJISEhCggI0Pbt2/Xmm29qxIgRat68uTZv3qwHHnhAgwYNUrdu3arrWtRJJbMpDBokNWpkbS0AAAD1Ddm2lpXMptBykORDuAUAAID9pO5MlSTFx9CoAAAAUBWVblQYM2aM9u/fr8cee0w5OTnq0aOHlixZorCwMElSZmamx78ymzZtmhwOh6ZNm6a9e/cqNDRUycnJeuqpp9yv+dvf/iZJSkhI8DjW/Pnzddttt8nX11effPKJ+y+Oo6KidMMNN2jatGkXc862srh4Cd8RI6ytAwAAoD4i29ayrOJwG0m4BQAAgP3sPLxTmXmZ8nZ6q39Uf6vLAQAAsDWHKZmjtp47cuSIQkJClJeXZ5upco8dk5o3lwoKpC1bpE6drK4IAACgbrBjtqtOtjz/08ek/zSXXAXSNVukEMItAACAZNNsV43sdP7/2PgP3fbBbbqi9RVKvyPd6nIAAADqnMpkO2eFz8JSn31W1KTQtq3UsaPV1QAAAABVkPtZUZNCUFspmHALAAAA+0ndlSpJSohOsLQOAACA+oBGhTospXgJ36QkyeGwthYAAACgSrKKw20k4RYAAAD2lLYzTZIUHxNvcSUAAAD2R6NCHWWMtLh4Cd+kJGtrAQAAAKrEGCm7ONxGEm4BAABgP5l5mdpxeIe8HF4aEDXA6nIAAABsj0aFOmrLFmnXLsnPT7rqKqurAQAAAKrgyBbp+C7J6SeFEW4BAABgPyWzKfSO7K3Gfo0trgYAAMD+aFSoo0pmU4iPl4KCrK0FAAAAqJKs4nDbMl7yJtwCAADAftJ2FS/7EM2yDwAAANWBRoU6KqV4Cd8RI6ytAwAAAKiyrOJwG0m4BQAAqOvmzZunmJgY+fv7KzY2VqtXr76g/d5++205HA6NHDmyZgu0SOrOVEk0KgAAAFQXGhXqoKNHpS++KHqcxBK+AAAAsLPTR6X9xeE2knALAABQly1cuFCTJ0/WjBkztH79enXv3l3Dhg3Tvn37Ktxv586deuihhzRw4MBaqrR27T2yV9sPbZfT4dSVba60uhwAAIB6gUaFOmj5cun0aaldO+nSS62uBgAAAKiCnOWS67TUqJ3UmHALAABQl82ZM0d33XWXxo8fry5duuill15SYGCgXnvttXL3KSws1M0336zHH39cl1xySS1WW3tKln3oGd5TIf4hFlcDAABQP9CoUActLl7CNylJcjisrQUAAACokuzicBtJuAUAAKjLCgoKtG7dOiUmJrq3OZ1OJSYmKj09vdz9nnjiCbVs2VJ33HFHbZRpCZZ9AAAAqH7eVhcAT8ZIKcVL+I5gCV8AAADYmTFSVnG4jSTcAgAA1GUHDhxQYWGhwsLCPLaHhYXp+++/L3OfFStW6NVXX9XGjRsv+Dj5+fnKz893/3zkyJGLqrc2lcyokBCTYG0hAAAA9QgzKtQx334r7dkj+ftLCQlWVwMAAABUQd630ok9kpe/1DLB6moAAABQjY4ePapbbrlFf//739WiRYsL3m/27NkKCQlxf0VFRdVglVWXfTRb237aJoccGhg90OpyAAAA6g1mVKhjSmZTuOoqKSDA2loAAACAKimZTaHlVZI34RYAAKAua9Gihby8vJSbm+uxPTc3V+Hh4aVev337du3cuVPJycnubS6XS5Lk7e2trVu3ql27dqX2mzp1qiZPnuz++ciRI3W6WaFkNoXu4d3VxL+JtcUAAADUIzQq1DGLi5fwTUqytg4AAACgyrKKw20k4RYAAKCu8/X1Ve/evbV8+XKNHDlSUlHjwfLlyzVp0qRSr+/UqZO+/vprj23Tpk3T0aNH9dxzz5XbfODn5yc/P79qr7+mpO0sXvYhOsHaQgAAAOoZGhXqkCNHpBUrih7TqAAAAABbO31E2l8cbmlUAAAAsIXJkyfr1ltvVZ8+fdSvXz/NnTtXx48f1/jx4yVJ48aNU6tWrTR79mz5+/vr8ssv99i/SZMmklRqu52VzKgQHxNvcSUAAAD1C40Kdcgnn0hnzkiXXiq1b291NQAAAEAV5HwimTNS40ulxoRbAAAAOxgzZoz279+vxx57TDk5OerRo4eWLFmisLAwSVJmZqacTqfFVdae3GO52nJgiyRpYJuBFlcDAABQv9CoUIekFC/hO2KEtXUAAAAAVZZVHG4jCbcAAAB2MmnSpDKXepCk1NTUCvddsGBB9Rdkoc93fS5J6hbWTc0Dm1tcDQAAQP3ScNpf6zhjpMXFS/iy7AMAAABszRgpqzjcRhBuAQAAYE/uZR+iWfYBAACgutGoUEds3ixlZUkBAVI8uRcAAAB2dnizdDJL8gqQwgi3AAAAsKfUnamSpISYBEvrAAAAqI9oVKgjSmZTGDxY8ve3thYAAACgSkpmUwgbLHkRbgEAAGA/+4/v17f7v5UkDYoeZHE1AAAA9Q+NCnVESvESviNYwhcAAAB2l1UcbiMJtwAAALCnz3d9Lkm6LPQytQhsYXE1AAAA9Q+NCnXA4cPSl18WPU5iCV8AAADYWcFh6UBxuI0k3AIAAMCe0nalSWLZBwAAgJpCo0IdsGyZVFgodeoktW1rdTUAAABAFeQsk0yhFNxJakS4BQAAgD2VNCrER8dbXAkAAED9RKNCHbC4eAlfZlMAAACA7WUVh9sIwi0AAADs6acTP2lz7mZJ0qDoQRZXAwAAUD/RqGAxl+vnRoURLOELAAAAOzOunxsVWhFuAQAAYE9fZH4hSercorPCGoVZXA0AAED9RKOCxTZtknJypKAgaeBAq6sBAAAAquDQJulUjuQdJIUSbgEAAGBPaTtZ9gEAAKCm0ahgsZSUou9Dhkh+ftbWAgAAAFRJVnG4DRsieRFuAQAAYE+pu1IlSfExNCoAAADUFBoVLFay7EMSS/gCAADA7rKLw20k4RYAAAD2dOjkIW3K2SSJGRUAAABqEo0KFjp0SEpPL3pMowIAAABsreCQdKA43NKoAAAAAJtakblCRkYdmndQROMIq8sBAACot2hUsNDHH0sul9SlixQdbXU1AAAAQBVkfywZlxTSRQoi3AIAAMCeUnemSmI2BQAAgJpGo4KFSpZ9GDHC2joAAACAKssqWfaBcAsAAAD7StuVJklKiEmwthAAAIB6jkYFi7hcPzcqsOwDAAAAbM24pOzicBtBuAUAAIA95Z3K04acDZKYUQEAAKCm0ahgkQ0bpH37pEaNpCuvtLoaAAAAoAoObZBO7ZO8G0mhhFsAAADY04rMFXIZl9o1badWwa2sLgcAAKBeo1HBIikpRd8TEyVfX2trAQAAAKpkb3G4DU+UvAi3AAAAsCeWfQAAAKg9NCpYpGTZhxEs4QsAAAC7K1n2IZJwCwAAAPsqaVRg2QcAAICaR6OCBX76Sfrqq6LHSSzhCwAAADvL/0k6UBxuIwm3AAAAsKej+Ue1LmudJCk+hkYFAACAmkajggU+/lgyRuraVWrd2upqAAAAgCrI/liSkZp0lQIJtwAAALCnlbtXqtAUqm2TtmoT0sbqcgAAAOo9GhUskFK8hC+zKQAAAMD2sorDbQThFgAAAPaVujNVErMpAAAA1BYaFWqZyyUtWVL0eARL+AIAAMDOjEvKLg63kYRbAAAA2FfarjRJUkJ0grWFAAAANBA0KtSytWulAwek4GCpf3+rqwEAAACq4Ke1Uv4BySdYCiXcAgAAwJ6OFRzT2qy1kphRAQAAoLbQqFDLFi8u+n711ZKPj7W1AAAAAFWSXRxuw6+WnIRbAAAA2NOXu7/UGdcZtQlpo5gmMVaXAwAA0CDQqFDLUoqX8E1iCV8AAADYXVZxuI0k3AIAAMC+0nYWL/sQk2BtIQAAAA0IjQq1aP9+ac2aosc0KgAAAMDWTu2XfioOtxGEWwAAANhX2q6iRoX4aJZ9AAAAqC00KtSipUslY6Tu3aXISKurAQAAAKoge6kkIzXpLgUSbgEAAGBPJ06f0Oq9qyXRqAAAAFCbLqpRYd68eYqJiZG/v79iY2O1evXqCl8/d+5cdezYUQEBAYqKitIDDzygU6dOVWrMU6dOaeLEiWrevLkaNWqkG264Qbm5uRdTvmUWFy/hy2wKAAAAdQfZ9iJlFYdbln0AAACAjaXvTtdp12m1Dm6tS5peYnU5AAAADUalGxUWLlyoyZMna8aMGVq/fr26d++uYcOGad++fWW+/s0339SUKVM0Y8YMbdmyRa+++qoWLlyoRx55pFJjPvDAA/rvf/+rd999V2lpacrKytL1119/EadsjcJCacmSoscjRlhbCwAAAIqQbS+Sq1DKLg63kYRbAAAA2NfZyz44HA6LqwEAAGg4HMYYU5kdYmNj1bdvX73wwguSJJfLpaioKP3ud7/TlClTSr1+0qRJ2rJli5YvX+7e9uCDD2rVqlVasWLFBY2Zl5en0NBQvfnmm/rlL38pSfr+++/VuXNnpaen64orrjhv3UeOHFFISIjy8vIUHBxcmVOuFl99JcXFSSEh0oEDkrd3rZcAAABQb1RXtiPbXqQDX0kfx0k+IdINByQn4RYAAOBiWZ7tLGb1+Q+aP0hfZH6hV37xiu7qfVetHx8AAKA+qUy2q9SMCgUFBVq3bp0SExN/HsDpVGJiotLT08vcp3///lq3bp17utsff/xRKSkpGlE8rcCFjLlu3TqdPn3a4zWdOnVSmzZtyj1uXZOSUvR96FCaFAAAAOoCsm0VZBWH24ihNCkAAADAtk6ePqlVe1dJkhJiEqwtBgAAoIGp1N8qHjhwQIWFhQoLC/PYHhYWpu+//77MfcaOHasDBw7oyiuvlDFGZ86c0T333OOeHvdCxszJyZGvr6+aNGlS6jU5OTllHjc/P1/5+fnun48cOVKZU612i4uX8E1iCV8AAIA6gWxbBVnF4TaCcAsAAAD7WrV3lQoKCxTRKELtm7W3uhwAAIAGpVIzKlyM1NRUzZo1Sy+++KLWr1+vRYsW6aOPPtKTTz5Zo8edPXu2QkJC3F9RUVE1eryK5OZKa9cWPR4+3LIyAAAAUEVkW0knc6WDxeE2knALAAAA+0rdmSpJio+Jl8PhsLYYAACABqZSjQotWrSQl5eXcnNzPbbn5uYqPDy8zH2mT5+uW265RXfeeae6du2qUaNGadasWZo9e7ZcLtcFjRkeHq6CggIdPnz4go87depU5eXlub92795dmVOtVkuXFn3v2VOKiLCsDAAAAJyFbHuRsovDbdOeUgDhFgAAAPaVtitNkpQQnWBtIQAAAA1QpRoVfH191bt3by1fvty9zeVyafny5YqLiytznxMnTsjp9DyMl5eXJMkYc0Fj9u7dWz4+Ph6v2bp1qzIzM8s9rp+fn4KDgz2+rJJSvIRv8dLFAAAAqAPIthcpqzjcRhJuAQAAYF+nzpxS+u50SUUzKgAAAKB2eVd2h8mTJ+vWW29Vnz591K9fP82dO1fHjx/X+PHjJUnjxo1Tq1atNHv2bElScnKy5syZo549eyo2NlY//PCDpk+fruTkZPdf6p5vzJCQEN1xxx2aPHmymjVrpuDgYP3ud79TXFycrrjiiuq6FjXizBnp44+LHiexhC8AAECdQratJNcZKac43EYSbgEAAGBfq/euVn5hvsKCwtSxeUerywEAAGhwKt2oMGbMGO3fv1+PPfaYcnJy1KNHDy1ZskRhYWGSpMzMTI9/ZTZt2jQ5HA5NmzZNe/fuVWhoqJKTk/XUU09d8JiS9Oyzz8rpdOqGG25Qfn6+hg0bphdffLEq514rVq2SDh2SmjaVYmOtrgYAAABnI9tW0k+rpIJDkm9TqTnhFgAAAPaVtrNo2Yf4mHg5HA6LqwEAAGh4HMYYY3URteHIkSMKCQlRXl5erU6VO22a9NRT0pgx0ttv19phAQAA6jWrsl1dYdn5b5omffuU1GaMdCXhFgAAoDqQba05/yH/HKJPd3yqeSPm6bd9f1trxwUAAKjPKpPtnBU+iypLKV7CdwRL+AIAAMDusorDbSThFgAAAPZVUFig9N3pkqSEmARriwEAAGigaFSoQdnZ0oYNRY+HDbO2FgAAAKBKTmZLh4rDbQThFgAAAPa1Zu8anTxzUqGBoercorPV5QAAADRINCrUoCVLir736SOdtSQxAAAAYD9ZxeG2WR8pgHALAAAA+0rdmSpJGhQ9SA6Hw9piAAAAGigaFWrQ4sVF35OSrK0DAAAAqLLs4nAbSbgFAACAvaXtSpPEsg8AAABWolGhhpw5I338cdHjESzhCwAAADtznZGyi8NtJOEWAAAA9nW68LRW7l4pSYqPjre4GgAAgIaLRoUakp4u5eVJzZtLfftaXQ0AAABQBQfSpdN5kl9zqRnhFgAAAPa1NmutTpw+oWYBzXRZy8usLgcAAKDB8ra6gPqqVy/p/felAwckLy+rqwEAAACqoFkvadD7Uv4ByUm4BQAAgH1d1vIyLbpxkQ6ePCing3/HBwAAYBUaFWpIUJB03XVWVwEAAABUA+8gqTXhFgAAAPYX7BesUZ1HWV0GAABAg0fLKAAAAAAAAAAAAAAAqDU0KgAAAAAAAAAAAAAAgFpDowIAAAAAAAAAAAAAAKg1NCoAAAAAAAAAACRJ8+bNU0xMjPz9/RUbG6vVq1eX+9pFixapT58+atKkiYKCgtSjRw/961//qsVqAQAAYFc0KgAAAAAAAAAAtHDhQk2ePFkzZszQ+vXr1b17dw0bNkz79u0r8/XNmjXTo48+qvT0dG3evFnjx4/X+PHjtXTp0lquHAAAAHZDowIAAAAAAAAAQHPmzNFdd92l8ePHq0uXLnrppZcUGBio1157rczXJyQkaNSoUercubPatWun++67T926ddOKFStquXIAAADYDY0KAAAAAAAAANDAFRQUaN26dUpMTHRvczqdSkxMVHp6+nn3N8Zo+fLl2rp1qwYNGlTu6/Lz83XkyBGPLwAAADQ8NCoAAAAAAAAAQAN34MABFRYWKiwszGN7WFiYcnJyyt0vLy9PjRo1kq+vr6655ho9//zzuvrqq8t9/ezZsxUSEuL+ioqKqrZzAAAAgH3QqAAAAAAAAAAAuCiNGzfWxo0btWbNGj311FOaPHmyUlNTy3391KlTlZeX5/7avXt37RULAACAOsPb6gIAAAAAAAAAANZq0aKFvLy8lJub67E9NzdX4eHh5e7ndDrVvn17SVKPHj20ZcsWzZ49WwkJCWW+3s/PT35+ftVWNwAAAOyJGRUAAAAAAAAAoIHz9fVV7969tXz5cvc2l8ul5cuXKy4u7oLHcblcys/Pr4kSAQAAUI8wowIAAAAAAAAAQJMnT9att96qPn36qF+/fpo7d66OHz+u8ePHS5LGjRunVq1aafbs2ZKk2bNnq0+fPmrXrp3y8/OVkpKif/3rX/rb3/5m5WkAAADABmhUAAAAAAAAAABozJgx2r9/vx577DHl5OSoR48eWrJkicLCwiRJmZmZcjp/nqT3+PHj+u1vf6s9e/YoICBAnTp10uuvv64xY8ZYdQoAAACwCYcxxlhdRG04cuSIQkJClJeXp+DgYKvLAQAAQBU09GzX0M8fAACgPmno2a6hnz8AAEB9Upls56zwWQAAAAAAAAAAAAAAgGrUYJZ+KJk44siRIxZXAgAAgKoqyXQNZHKwUsi2AAAA9QfZlmwLAABQX1Qm2zaYRoWjR49KkqKioiyuBAAAANXl6NGjCgkJsbqMWke2BQAAqH/ItmRbAACA+uJCsq3DNJBWXZfLpaysLDVu3FgOh6NWjnnkyBFFRUVp9+7d9XZ9tfp2jnY+HzvUXldrrEt1WVVLbR+3qser6Xqre/zqHO9ixqqu49elcWr6mtalGu0wjhX3LmOMjh49qsjISDmdDW81M7Jtzahv52jn87FD7XW1xrpUF9m2dvav7fHJttU/Dtm2bo1Dtq19ZNuaUd/O0c7nY4fa62qNdakusm3t7F/b45Ntq38csm3dGqeuZ9sGM6OC0+lU69atLTl2cHCw5X+I1rT6do52Ph871F5Xa6xLdVlVS20ft6rHq+l6q3v86hzvYsaqruPXpXFq+prWpRrtME5t30Ma4r82K0G2rVn17RztfD52qL2u1liX6iLb1s7+tT0+2bb6xyHb1q1xyLa1h2xbs+rbOdr5fOxQe12tsS7VRbatnf1re3yybfWPQ7atW+PU1Wzb8Fp0AQAAAAAAAAAAAACAZWhUAAAAAAAAAAAAAAAAtYZGhRrk5+enGTNmyM/Pz+pSakx9O0c7n48daq+rNdaluqyqpbaPW9Xj1XS91T1+dY53MWNV1/Hr0jg1fU3rUo12GKcu3UdRcxrC77m+naOdz8cOtdfVGutSXWTb2tm/tscn21b/OGTbujVOXbqPouY0hN9zfTtHO5+PHWqvqzXWpbrItrWzf22PT7at/nHItnVrnLp0Hy2LwxhjrC4CAAAAAAAAAAAAAAA0DMyoAAAAAAAAAAAAAAAAag2NCgAAAAAAAAAAAAAAoNbQqAAAAAAAAAAAAAAAAGoNjQoXaebMmXI4HB5fnTp1qnCfd999V506dZK/v7+6du2qlJSUWqr2wnz++edKTk5WZGSkHA6H3n//ffdzp0+f1sMPP6yuXbsqKChIkZGRGjdunLKysioc82KuU3Wp6HwkKTc3V7fddpsiIyMVGBio4cOHKyMjo8IxFy1apD59+qhJkyYKCgpSjx499K9//avaa589e7b69u2rxo0bq2XLlho5cqS2bt3q8ZqEhIRS1/aee+654GPcc889cjgcmjt37kXV+Le//U3dunVTcHCwgoODFRcXp8WLF7ufP3XqlCZOnKjmzZurUaNGuuGGG5Sbm1vhmMeOHdOkSZPUunVrBQQEqEuXLnrppZeqta6LuW7VUdcf//hHORwO3X///e5tF3ONZs6cqU6dOikoKEhNmzZVYmKiVq1aVeljlzDGKCkpqczPyMUc+9xj7dy5s9T1Lvl699133eOe+9yll17q/nwGBASoTZs2atq06QVfJ2OMHnvsMTVq1KjCe9Ddd9+tdu3aKSAgQKGhobruuuv0/fffVzj2mDFjKhyzMu+xss7d6XS632M5OTm65ZZbFB4erqCgIPXq1Uv/+c9/tHfvXv36179W8+bNFRAQoK5du2rt2rWSij4DXbt2lZ+fn5xOp5xOp3r27Fnm/e3ccSIjIxURESF/f3/17dtX48aNO+99/9wxWrVqpfbt25f5GazovnPuOJ06dVJSUpLHOb777ru69tprFRISoqCgIPXt21eZmZkVjhMWFiZvb+8y34Pe3t4aPny4vvnmmwo/i4sWLZKfn1+ZYwQFBcnf319RUVG65JJL3O/Xe++9V3l5eaXOMyYmpsxx/Pz8PD5TFX02yxujbdu27mvTuXNn9e/fX0FBQQoODtagQYN08uTJC66nUaNGioyMlL+/v4KCghQUFKTGjRvrxhtvVG5urvszFhERoYCAACUmJrrfYxXdh+fNm6eYmBj5+/srNjZWq1evLlUTrEG2JduSbcm2lUG2JduWd03JtmWPQ7Yl26J2kW3JtmRbsm1lkG3JtuVdU7Jt2eOQbcm21YlGhSq47LLLlJ2d7f5asWJFua/98ssvddNNN+mOO+7Qhg0bNHLkSI0cOVLffPNNLVZcsePHj6t79+6aN29eqedOnDih9evXa/r06Vq/fr0WLVqkrVu36tprrz3vuJW5TtWpovMxxmjkyJH68ccf9cEHH2jDhg2Kjo5WYmKijh8/Xu6YzZo106OPPqr09HRt3rxZ48eP1/jx47V06dJqrT0tLU0TJ07UV199pWXLlun06dMaOnRoqdruuusuj2v79NNPX9D47733nr766itFRkZedI2tW7fWH//4R61bt05r167V4MGDdd111+nbb7+VJD3wwAP673//q3fffVdpaWnKysrS9ddfX+GYkydP1pIlS/T6669ry5Ytuv/++zVp0iR9+OGH1VaXVPnrVtW61qxZo5dfflndunXz2H4x16hDhw564YUX9PXXX2vFihWKiYnR0KFDtX///kodu8TcuXPlcDgu6DzOd+yyjhUVFeVxrbOzs/X444+rUaNGSkpKcr/u7PtEVlaWQkJC3J/PkSNH6uDBg/L19dWSJUsu6Do9/fTT+utf/6pf/OIXateunYYOHaqoqCjt2LHD4x7Uu3dvzZ8/X1u2bNHSpUtljNHQoUNVWFhY7tgFBQVq2bKlnnnmGUnSsmXLSt3XKvMeu+yyy3TzzTcrOjpa//nPf7R27Vr3eywpKUlbt27Vhx9+qK+//lrXX3+9Ro8erb59+8rHx0eLFy/Wd999p7/85S9q2rSppKLPQJ8+feTn56cXXnhBd9xxhzZt2qTBgwfr1KlT7uMeOnRIAwYMcI/z9NNPa//+/br//vu1fv16XXbZZXrrrbd07733lnvfP3eM7777TnfffbemTp1a6jP43HPPlXvfOXec9PR0HTp0SIGBge5xH3zwQU2YMEGdOnVSamqqNm/erOnTp8vf37/cccaNG6czZ87omWee0VdffaVZs2ZJktq1aydJeu211xQdHa24uDh9+OGH5X4WmzVrppdffllpaWlKT0/XE0884X5u6tSpeuONN1RYWKgTJ05o3bp1WrBggZYsWaI77rij1LmuWbPG/b6YN2+e/vSnP0mSXnrpJY/PVEWfzbPHyM7O1j/+8Q9JUmxsrFJTU7VgwQJlZmZq8ODBWr16tdasWaNJkybJ6Swd+0rGSk5OVocOHfSXv/xFknTmzBkdPnxYLVq00OWXXy5JmjhxogoKCpScnKw//elP+utf/6qXXnpJq1atUlBQkIYNG6ZTp06Vex9+5plnNHnyZM2YMUPr169X9+7dNWzYMO3bt6/M80TtI9uSbcm2ZNsLQbYl25JtybYlyLZk27qMbEu2JduSbS8E2ZZsS7Yl25Yg21qUbQ0uyowZM0z37t0v+PU33nijueaaazy2xcbGmrvvvruaK6seksx7771X4WtWr15tJJldu3aV+5rKXqeacu75bN261Ugy33zzjXtbYWGhCQ0NNX//+98rNXbPnj3NtGnTqqvUMu3bt89IMmlpae5t8fHx5r777qv0WHv27DGtWrUy33zzjYmOjjbPPvtstdXZtGlT83//93/m8OHDxsfHx7z77rvu57Zs2WIkmfT09HL3v+yyy8wTTzzhsa1Xr17m0UcfrZa6jLm461aVuo4ePWouvfRSs2zZMo9jX+w1OldeXp6RZD755JMLPnaJDRs2mFatWpns7OwL+sxXdOzzHetsPXr0MLfffrv753PvE2d/Pkuu08KFC92fz/NdJ5fLZcLDw82f//xn99iHDx82fn5+5q233qrwnDZt2mQkmR9++KHc15SMuWPHDiPJbNiwweP5yrzHSsYq7z3m4+Nj/vnPf3ps9/f3N+3bty93zLPPv0STJk2Mt7e3x/k//PDD5sorr3T/3K9fPzNx4kT3z4WFhSYyMtLMnj3bve3c+/65Y5QnJCTENG3atNz7zrnjlDXumDFjzK9//esKj3PufhEREeaFF15w/1zy3oqJiTHt2rUzLpfLHDx40Egy99xzj/t1F/IeczgcJiAgwLhcLmOMKfUee+edd4yvr685ffp0hTXfd9997lpKPlMvvfRSpT6bl156qWnUqJG7ltjY2Er9uXTixAnj5eVl/ve//5n77rvPBAYGmvHjx5v27dsbh8Nh8vLyzPXXX29uvvlmc/jwYSPJNGvWzOM9dr7PWNOmTU3btm3P+x6Ddci2ZNsSZNufkW1LI9uWRrYtPRbZlmxLtoXVyLZk2xJk25+RbUsj25ZGti09FtmWbEu2rVnMqFAFGRkZioyM1CWXXKKbb7651DQmZ0tPT1diYqLHtmHDhik9Pb2my6wxeXl5cjgcatKkSYWvq8x1qi35+fmS5NHR5XQ65efnd8Gdw8YYLV++XFu3btWgQYNqpM4SJdPQNGvWzGP7G2+84e6amjp1qk6cOFHhOC6XS7fccot+//vf67LLLqu2+goLC/X222/r+PHjiouL07p163T69GmP93ynTp3Upk2bCt/z/fv314cffqi9e/fKGKPPPvtM27Zt09ChQ6ulrhKVvW5VqWvixIm65pprSn3+L/Yana2goECvvPKKQkJC1L179ws+tlTUbT927FjNmzdP4eHhF3S8io5d0bHOtm7dOm3cuLFUx+LZ94kHHnhAUtHns+Q6DR061P35PN912rFjh3Jycty1ZGRkqHPnznI4HJo5c2a596Djx49r/vz5atu2raKioio8j4yMDMXGxkqSHnnkkVJjVuY9lpGRoR07duj//b//p1GjRmnXrl3u91j37t21cOFCHTx4UC6XS2+//bby8/N15ZVXavTo0WrZsqV69uypv//972Wef8ln4MSJE+rRo4fHNfvwww/Vp08f9zirV6+Wy+VyP+90OpWYmOixz7n3/XPHOLeWwsJCvfnmmzpy5Ijuvvvucu87544zd+5c+fn5uX/u0aOH3n//fXXo0EHDhg1Ty5YtFRsbW2pqrXPH2bdvn8cUVSX3/szMTN1+++1yOBzasGGD+9xKVPQeM8ZowYIFMsbo6quvdnfPhoSEKDY21r1PXl6egoOD5e3tXeY5S0Wfo9dff1233367Tp8+rVdeeUXBwcGaM2fOBX82T5065X4/Dh8+XC1atNCqVauUk5Oj/v37KywsTPHx8RX+2XbmzBkVFhbKy8tLr7/+ugYMGKBPP/1ULpdLxhht3bpVK1asUFJSkvz9/eV0OnXw4EGPz/u551+i5D147NgxZWZmeuxT1nsM1iLbkm3JtkXItuUj23oi25Y9FtmWbEu2RV1AtiXbkm2LkG3LR7b1RLYteyyyLdmWbFvDarwVop5KSUkx77zzjtm0aZNZsmSJiYuLM23atDFHjhwp8/U+Pj7mzTff9Ng2b94807Jly9oot9J0nk6gkydPml69epmxY8dWOE5lr1NNOfd8CgoKTJs2bczo0aPNwYMHTX5+vvnjH/9oJJmhQ4dWONbhw4dNUFCQ8fb2Nn5+fubVV1+t0doLCwvNNddcYwYMGOCx/eWXXzZLliwxmzdvNq+//rpp1aqVGTVqVIVjzZo1y1x99dXu7q2qduZu3rzZBAUFGS8vLxMSEmI++ugjY4wxb7zxhvH19S31+r59+5o//OEP5Y536tQpM27cOCPJeHt7G19fX/OPf/yj2uoy5uKu28XW9dZbb5nLL7/cnDx50hjj2bF5sdfIGGP++9//mqCgIONwOExkZKRZvXp1pY5tjDETJkwwd9xxh/vn833mKzr2+Y51tt/85jemc+fOHtvOvU9cccUVxsvLy4wcOdK88sorxtfXt9Tns6LrtHLlSiPJZGVleYw9cOBA07x581L3oHnz5pmgoCAjyXTs2LHCrtyz601JSTGSTLdu3TzGrMx7rGSsNWvWmCFDhhhJRpLx8fEx//jHP8yhQ4fM0KFD3e+94OBg4+PjY/z8/MzUqVPN+vXrzcsvv2z8/f3NggULPM4/ICDA4zMwevRoc+ONN7qP7efn5x5n6dKlRpLx9fV1j2OMMb///e9Nv379jDFl3/fPHuPsWp588kn3Z9DPz8/07NmzwvvOueN4e3sbSeaaa64x69evN08//bS7vjlz5pgNGzaY2bNnG4fDYVJTU8sdp2/fvsbhcJg//vGPprCw0P07k2S+/fZbk5+fb371q1+Vee8/9z129r3fy8vLSDLr16/32KfkGu/fv9+0adPGPPLIIxW+lxYuXGicTqcJCAhwf6ZGjRpVqc/myy+/bCQZf39/M2fOHPOPf/zDfY4PP/ywWb9+vbn//vuNr6+v2bZtW7njxMXFmc6dOxsvLy+zc+dO84tf/MI9jiQzc+ZMc+zYMTNp0iT3tqysrDLP35jS9+F//vOfRpL58ssvPfY5+z0Ga5FtybZkW7Lt+ZBtSyPblj0W2ZZsS7aF1ci2ZFuyLdn2fMi2pZFtyx6LbEu2JdvWLBoVqsmhQ4dMcHCwe5qic9WnwFtQUGCSk5NNz549TV5eXqXGPd91qillnc/atWtN9+7djSTj5eVlhg0bZpKSkszw4cMrHKuwsNBkZGSYDRs2mGeeecaEhISYzz77rMZqv+eee0x0dLTZvXt3ha9bvnx5hVMfrV271oSFhZm9e/e6t1U18Obn55uMjAyzdu1aM2XKFNOiRQvz7bffXnSY+/Of/2w6dOhgPvzwQ7Np0ybz/PPPm0aNGplly5ZVS11lOd91u9i6MjMzTcuWLc2mTZvc26or8B47dsxkZGSY9PR0c/vtt5uYmBiTm5t7wcf+4IMPTPv27c3Ro0fdz19o4D332K1btzYtWrQo91hnO3HihAkJCTHPPPNMhcc4dOiQCQoKMq1bt3b/wXru5/NCA+/ZRo8ebUaOHFnqHnT48GGzbds2k5aWZpKTk02vXr3c4b0iJVOIff755xXe1yrzHnvzzTdNo0aNzNixY02jRo3MddddZ/r162c++eQTs3HjRjNz5kwjqdTUjL/73e/MFVdc4XH+K1eu9PgMDBs2zCPw+vj4mLi4OGOMMXv37jWSzC9/+Uv3OMb8HEbKu++fPcbZtcTGxpqMjAzzr3/9ywQFBZmmTZu6P4Nl3XfOHcfHx8eEh4e7aympr3nz5h77JScnm1/96lfljrNv3z7Ttm1b932+Q4cOJiwszP2+8vLyMl27djUOh6PUvf/c99jZ9/6oqCgjyfz73//22Gf06NFm1KhRpl+/fmb48OGmoKDAVGTo0KEmKSnJ/ZlKTEw03t7e5scff3S/5nyfzfj4eCPJ3HTTTcaYn3//7du397g2Xbt2NVOmTCl3nB9++ME0bdrUSDIOh8P4+PiYAQMGmLCwMBMaGure/utf/9p06NDhvIH33Ptwydj8Za59kG0vDNm28si2ZNtzkW3JtmTbImRbsi1qDtn2wpBtK49sS7Y9F9mWbEu2LUK2JdteKBoVqlGfPn3KfTNFRUWV+oA/9thjplu3brVQWeWV9wErKCgwI0eONN26dTMHDhy4qLEruk41paIbxuHDh82+ffuMMUVr/fz2t7+t1Nh33HHHebt5L9bEiRNN69atPW5+5Tl27JiRZJYsWVLm888++6xxOBzGy8vL/SXJOJ1OEx0dXS31DhkyxEyYMMH9B/yhQ4c8nm/Tpo2ZM2dOmfueOHHC+Pj4mP/9738e2++44w4zbNiwaqmrLOe7bhdb13vvvef+A/Xs613yO/jkk08qfY3K0759ezNr1qwLPvakSZPKfS/Ex8dX6tjh4eEVHuvMmTPu1/7zn/80Pj4+7s9bRUruEx988IH7Op39+azoOm3fvt1IpdcgGzRokLn33nsrvAfl5+ebwMDAUn9BUZaz1zqraMzKvsdKxho9erSRPNdkNKZorbNOnTp5bHvxxRdNZGRkuec/ZMgQExERYe699173tjZt2rg7QPPz842Xl5e5++673eMYY8y4cePML37xi3Lv+2ePUVYtJfedkq/y7jvnjtOmTRvTv39/9zj5+fnG6XSaxo0bexzrD3/4g+nfv/9564mIiDB79uwxO3bsMA6Hw0RFRbnv/SX3q3P3K+89tnPnTuN0Oo0kj/84MMaY/v37m/DwcDNkyJDz/kdTyTjvv/++e9t9993nvj4X8tksGcPpdJonn3zSGGPMjz/+6O5qPvva3HjjjRX+a5qSsd5++233GnE33nijGTFihDHGmClTpphLL73UGGNM8+bNK/yMleWqq64yDoej1J/F48aNM9dee225dcFaZNsLQ7a9cGRbsu2FINt6ItuSbc+th2xLtsXFIdteGLLthSPbkm0vBNnWE9mWbHtuPWRbsq1TqBbHjh3T9u3bFRERUebzcXFxWr58uce2ZcuWeay/VNedPn1aN954ozIyMvTJJ5+oefPmlR7jfNfJCiEhIQoNDVVGRobWrl2r6667rlL7u1wu9/o51cUYo0mTJum9997Tp59+qrZt2553n40bN0pSudf2lltu0ebNm7Vx40b3V2RkpH7/+99r6dKl1VJ3ybXo3bu3fHx8PN7zW7duVWZmZrnv+dOnT+v06dNyOj1vS15eXh7rL1WlrrKc77pdbF1DhgzR119/7XG9+/Tpo5tvvtn9uLLX6ELP73zHfvTRR0u9FyTp2Wef1fz58yt1bH9/f/3mN78p91heXl7u17766qu69tprFRoaWuGYZ98n4uPj5ePjo9dff939+TzfdWrbtq3Cw8M9ru2RI0e0atUq9ezZs8J7kClq4KvUZ/rEiRMVjlmZ99jZ526MkaRS770mTZro0KFDHtu2bdum6OhoSWWff0FBgXJzcz2u2YABA7R161ZJkq+vr3r37q2vvvrKPY7L5dInn3yiH3/8sdz7/tljlFVLyX2nT58+Sk5OLve+c+44AwYM0M6dO93j+Pr6KiwsTH5+fuUeq6J6YmJi1KpVK7366qtyOp0aO3as+95fsm7b2b+fit5j8+fPV8uWLeXv7699+/a5t+/Zs0fp6elq2rSpPvzwQ4+1NMtSMs4111zj3jZlyhS1bt1ad9999wV9NkvG6Nevn/u8Y2JiFBkZqYyMDI9rc+61Km+sG264Qfn5+Tp16pSWLl3q/jMxODhYkvTpp5/qp59+UmhoaJmfsYruX82bN/fYx+Vyafny5bbKQg0J2fbCkG0vDNn2Z2Tbyp8f2ZZsS7b1fA3ZlmyLyiPbXhiy7YUh2/6MbFv58yPbkm3Jtp6vIduSbZlR4SI9+OCDJjU11ezYscOsXLnSJCYmmhYtWrg7zm655RaPLq2VK1cab29v88wzz5gtW7aYGTNmGB8fH/P1119bdQqlHD161GzYsMFs2LDBSHKvJ7Nr1y5TUFBgrr32WtO6dWuzceNGk52d7f7Kz893jzF48GDz/PPPu38+33Wy6nyMMeadd94xn332mdm+fbt5//33TXR0tLn++us9xjj39zhr1izz8ccfm+3bt5vvvvvOPPPMM8bb29v8/e9/r9baf/Ob35iQkBCTmprqca1PnDhhjCma6uWJJ54wa9euNTt27DAffPCBueSSS8ygQYM8xunYsaNZtGhRucepyhRiU6ZMMWlpaWbHjh1m8+bNZsqUKcbhcJiPP/7YGFM09VmbNm3Mp59+atauXWvi4uJKTTV0bn3x8fHmsssuM5999pn58ccfzfz5842/v7958cUXq6Wui71u1VFXyThnT61V2Wt07NgxM3XqVJOenm527txp1q5da8aPH2/8/PxKdW+e79jnUhnd6xd77LKOlZGRYRwOh1m8eHGpYz/44IMmKirKvPTSS+77ROPGjc17771ntm/fboYPH268vLzMwIEDL/i99Mc//tE0adLEjBw50rz22mvm6quvNhEREWbw4MHue9D27dvNrFmzzNq1a82uXbvMypUrTXJysmnWrJnHlGznjj1x4kTz97//3bz22mtGkunatatp0qSJ+frrryv9Hiu5R8bGxpq2bdua3r17m2bNmpnnnnvO+Pn5mdDQUDNw4ECzatUq88MPP5hnnnnG3Qn91FNPmYyMDNOlSxfj6+trXn/9dWNM0Wfg7rvvNsHBwea5554zt99+u5FkwsPDPbpF+/TpY5xOp3uckjWsJkyYYL777jtz5513Gm9vbxMZGVnufX/16tXG4XCYX/ziFyYjI8O88cYbxsfHx0ybNq3ce0NZ951za3niiSeMJDN69Gj3uL6+vsbLy8u88sorJiMjwzz//PPGy8vLfPHFF+5xkpKSPMZ5/PHHjZ+fn5kzZ45JTU01fn5+JjAw0Pz3v//1uPe3bdvW47MYGhpqWrVq5R531qxZpnXr1uaFF14wERER5qqrrjJOp9MEBgaaDz74wHz55ZemadOmxsfHx3z77bce1+rs7vSS33thYaGJiooyV1xxxXk/U+V9Nv/973+bNm3amIcfftgsWrTI+Pj4uK/N9ddfbySZJ554wmRkZJhp06YZf39/j2nszv7zurCw0LRs2dKMHj3a/Pjjj+bqq682Pj4+pkOHDmb27Nlm9uzZpmnTpuaaa64xzZo1M5MnT3Z/xj744APTr18/07VrV9O2bVtz8uRJ9324f//+ZurUqe73wCOPPGL8/PzMggULzHfffWcmTJhgmjRpYnJycgysR7Yl25JtybZkW7It2ZZsS7Yl29YXZFuyLdmWbEu2JduSbcm2ZFt7ZFsaFS7SmDFjTEREhPH19TWtWrUyY8aM8XgjxcfHm1tvvdVjn3feecd06NDB+Pr6mssuu8x89NFHtVx1xT777DOj4vVfzv669dZb3VPllPV19jpf0dHRZsaMGe6fz3edrDofY4x57rnnTOvWrY2Pj49p06aNmTZtmkd4N6b07/HRRx817du3N/7+/qZp06YmLi7OvP3229Vee3nXev78+caYorWsBg0aZJo1a2b8/PxM+/btze9///tSa8+dvU9ZqhJ4b7/9dhMdHW18fX1NaGioGTJkiPsPNGOMOXnypPntb39rmjZtagIDA82oUaNMdnZ2hfVlZ2eb2267zURGRhp/f3/TsWNH85e//MW4XK5qqetir1t11GVM6SBY2Wt08uRJM2rUKBMZGWl8fX1NRESEufbaa83q1asrfexzlfWH6sUeu6xjTZ061URFRZnCwsJSrx8zZoyRZLy9vd33ienTp7s/n1FRUaZ3796Vei+5XC4zffp04+fn557SLCwszOMetHfvXpOUlGRatmxpfHx8TOvWrc3YsWPN999/X+HY/fr1K/PzOWPGjEq/x86+RwYGBhp/f3/j6+vrfo9t3brVXH/99aZly5YmMDDQdOvWzfzzn/80//3vf83ll19u/Pz8jLe3t/nFL37hHvv22283bdq0MU6n0zgcDuN0Ok3Pnj3N1q1bPWqIjo42N910k3ucTp06mV/96lemTZs2xtfX170W5Pnu+6GhoaZly5buMQYMGFDhvaGs+05ZtUyaNMnj51deecW8+uqr7ntw9+7dPabfMqbovTd48GD3fm3atDHh4eHGz8/PNG7c2Egy9957b6l7f15ensdnsUWLFh7rwj366KPuqbwkmR49epi33nrLTJ8+3YSFhRkfH59yr9WOHTtK/d6XLl1qJJnExMTzfqbK+2w++OCDRpL793rutbnllltM69atTWBgoImLi/P4D4OSa17y53VJPa1btza+vr6mZcuWplu3bqZ169bG29vbeHl5GafTadq3b+++95V8xkrWjmvbtq27lpL7sCQTGBjo8R54/vnn3e+xfv36ma+++sqgbiDbkm3JtmRbsi3ZlmxLtiXbkm3rC7It2ZZsS7Yl25JtybZkW7KtPbKto/jCAQAAAAAAAAAAAAAA1Djn+V8CAAAAAAAAAAAAAABQPWhUAAAAAAAAAAAAAAAAtYZGBQAAAAAAAAAAAAAAUGtoVAAAAAAAAAAAAAAAALWGRgUAAAAAAAAAAAAAAFBraFQAAAAAAAAAAAAAAAC1hkYFAAAAAAAAAAAAAABQa2hUAAAAAAAAAAAAAAAAtYZGBQBogGbOnKmwsDA5HA69//77F7RPamqqHA6HDh8+XKO11SUxMTGaO3eu1WUAAACgAmTbC0O2BQAAqPvItheGbAvUDzQqAKgTbrvtNjkcDjkcDvn6+qp9+/Z64okndObMGatLO6/KhMa6YMuWLXr88cf18ssvKzs7W0lJSTV2rISEBN1///01Nj4AAEBdRLatPWRbAACAmkW2rT1kWwANjbfVBQBAieHDh2v+/PnKz89XSkqKJk6cKB8fH02dOrXSYxUWFsrhcMjppB/rXNu3b5ckXXfddXI4HBZXAwAAUD+RbWsH2RYAAKDmkW1rB9kWQEPDnwQA6gw/Pz+Fh4crOjpav/nNb5SYmKgPP/xQkpSfn6+HHnpIrVq1UlBQkGJjY5Wamured8GCBWrSpIk+/PBDdenSRX5+fsrMzFR+fr4efvhhRUVFyc/PT+3bt9err77q3u+bb75RUlKSGjVqpLCwMN1yyy06cOCA+/mEhATde++9+sMf/qBmzZopPDxcM2fOdD8fExMjSRo1apQcDof75+3bt+u6665TWFiYGjVqpL59++qTTz7xON/s7Gxdc801CggIUNu2bfXmm2+WmrLq8OHDuvPOOxUaGqrg4GANHjxYmzZtqvA6fv311xo8eLACAgLUvHlzTZgwQceOHZNUNHVYcnKyJMnpdFYYeFNSUtShQwcFBAToqquu0s6dOz2e/+mnn3TTTTepVatWCgwMVNeuXfXWW2+5n7/tttuUlpam5557zt11vXPnThUWFuqOO+5Q27ZtFRAQoI4dO+q5556r8JxKfr9ne//99z3q37Rpk6666io1btxYwcHB6t27t9auXet+fsWKFRo4cKACAgIUFRWle++9V8ePH3c/v2/fPiUnJ7t/H2+88UaFNQEAAFSEbEu2LQ/ZFgAA2A3ZlmxbHrItgKqgUQFAnRUQEKCCggJJ0qRJk5Senq63335bmzdv1ujRozV8+HBlZGS4X3/ixAn96U9/0v/93//p22+/VcuWLTVu3Di99dZb+utf/6otW7bo5ZdfVqNGjSQVhcnBgwerZ8+eWrt2rZYsWaLc3FzdeOONHnX84x//UFBQkFatWqWnn35aTzzxhJYtWyZJWrNmjSRp/vz5ys7Odv987NgxjRgxQsuXL9eGDRs0fPhwJScnKzMz0z3uuHHjlJWVpdTUVP3nP//RK6+8on379nkce/To0dq3b58WL16sdevWqVevXhoyZIgOHjxY5jU7fvy4hg0bpqZNm2rNmjV699139cknn2jSpEmSpIceekjz58+XVBS4s7Ozyxxn9+7duv7665WcnKyNGzfqzjvv1JQpUzxec+rUKfXu3VsfffSRvvnmG02YMEG33HKLVq9eLUl67rnnFBcXp7vuust9rKioKLlcLrVu3VrvvvuuvvvuOz322GN65JFH9M4775RZy4W6+eab1bp1a61Zs0br1q3TlClT5OPjI6noP0CGDx+uG264QZs3b9bChQu1YsUK93WRigL67t279dlnn+nf//63XnzxxVK/DwAAgItFtiXbVgbZFgAA1GVkW7JtZZBtAZTLAEAdcOutt5rrrrvOGGOMy+Uyy5YtM35+fuahhx4yu3btMl5eXmbv3r0e+wwZMsRMnTrVGGPM/PnzjSSzceNG9/Nbt241ksyyZcvKPOaTTz5phg4d6rFt9+7dRpLZunWrMcaY+Ph4c+WVV3q8pm/fvubhhx92/yzJvPfee+c9x8suu8w8//zzxhhjtmzZYiSZNWvWuJ/PyMgwksyzzz5rjDHmiy++MMHBwebUqVMe47Rr1868/PLLZR7jlVdeMU2bNjXHjh1zb/voo4+M0+k0OTk5xhhj3nvvPXO+2//UqVNNly5dPLY9/PDDRpI5dOhQuftdc8015sEHH3T/HB8fb+67774Kj2WMMRMnTjQ33HBDuc/Pnz/fhISEeGw79zwaN25sFixYUOb+d9xxh5kwYYLHti+++MI4nU5z8uRJ93tl9erV7udLfkclvw8AAIALRbYl25JtAQBAfUG2JduSbQHUFO8a74QAgAv0v//9T40aNdLp06flcrk0duxYzZw5U6mpqSosLFSHDh08Xp+fn6/mzZu7f/b19VW3bt3cP2/cuFFeXl6Kj48v83ibNm3SZ5995u7UPdv27dvdxzt7TEmKiIg4b8fmsWPHNHPmTH300UfKzs7WmTNndPLkSXdn7tatW+Xt7a1evXq592nfvr2aNm3qUd+xY8c8zlGSTp486V6v7FxbtmxR9+7dFRQU5N42YMAAuVwubd26VWFhYRXWffY4sbGxHtvi4uI8fi4sLNSsWbP0zjvvaO/evSooKFB+fr4CAwPPO/68efP02muvKTMzUydPnlRBQYF69OhxQbWVZ/Lkybrzzjv1r3/9S4mJiRo9erTatWsnqehabt682WNaMGOMXC6XduzYoW3btsnb21u9e/d2P9+pU6dS05YBAABcKLIt2bYqyLYAAKAuIduSbauCbAugPDQqAKgzrrrqKv3tb3+Tr6+vIiMj5e1ddIs6duyYvLy8tG7dOnl5eXnsc3ZYDQgI8Fj7KiAgoMLjHTt2TMnJyfrTn/5U6rmIiAj345JpqEo4HA65XK4Kx37ooYe0bNkyPfPMM2rfvr0CAgL0y1/+0j0l2oU4duyYIiIiPNZ0K1EXgtif//xnPffcc5o7d666du2qoKAg3X///ec9x7ffflsPPfSQ/vKXvyguLk6NGzfWn//8Z61atarcfZxOp4wxHttOnz7t8fPMmTM1duxYffTRR1q8eLFmzJiht99+W6NGjdKxY8d0991369577y01dps2bbRt27ZKnDkAAMD5kW1L10e2LUK2BQAAdkO2LV0f2bYI2RZAVdCoAKDOCAoKUvv27Utt79mzpwoLC7Vv3z4NHDjwgsfr2rWrXC6X0tLSlJiYWOr5Xr166T//+Y9iYmLc4fpi+Pj4qLCw0GPbypUrddttt2nUqFGSisLrzp073c937NhRZ86c0YYNG9zdoD/88IMOHTrkUV9OTo68vb0VExNzQbV07txZCxYs0PHjx93duStXrpTT6VTHjh0v+Jw6d+6sDz/80GPbV199Veocr7vuOv3617+WJLlcLm3btk1dunRxv8bX17fMa9O/f3/99re/dW8rr9O4RGhoqI4ePepxXhs3biz1ug4dOqhDhw564IEHdNNNN2n+/PkaNWqUevXqpe+++67M95dU1IV75swZrVu3Tn379pVU1D19+PDhCusCAAAoD9mWbFsesi0AALAbsi3ZtjxkWwBV4bS6AAA4nw4dOujmm2/WuHHjtGjRIu3YsUOrV6/W7Nmz9dFHH5W7X0xMjG699Vbdfvvtev/997Vjxw6lpqbqnXfekSRNnDhRBw8e1E033aQ1a9Zo+/btWrp0qcaPH18qpFUkJiZGy5cvV05OjjuwXnrppVq0aJE2btyoTZs2aezYsR7dvJ06dVJiYqImTJig1atXa8OGDZowYYJHd3FiYqLi4uI0cuRIffzxx9q5c6e+/PJLPfroo1q7dm2Ztdx8883y9/fXrbfeqm+++UafffaZfve73+mWW2654OnDJOmee+5RRkaGfv/732vr1q168803tWDBAo/XXHrppVq2bJm+/PJLbdmyRXfffbdyc3NLXZtVq1Zp586dOnDggFwuly699FKtXbtWS5cu1bZt2zR9+nStWbOmwnpiY2MVGBioRx55RNu3by9Vz8mTJzVp0iSlpqZq165dWrlypdasWaPOnTtLkh5++GF9+eWXmjRpkjZu3KiMjAx98MEHmjRpkqSi/wAZPny47r77bq1atUrr1q3TnXfeed7ubgAAgMoi25JtybYAAKC+INuSbcm2AKqCRgUAtjB//nyNGzdODz74oDp27KiRI0dqzZo1atOmTYX7/e1vf9Mvf/lL/fa3v1WnTp1011136fjx45KkyMhIrVy5UoWFhRo6dKi6du2q+++/X02aNJHTeeG3x7/85S9atmyZoqKi1LNnT0nSnDlz1LRpU/Xv31/JyckaNmyYx7pmkvTPf/5TYWFhGjRokEaNGqW77rpLjRs3lr+/v6SiqcpSUlI0aNAgjR8/Xh06dNCvfvUr7dq1q9zwGhgYqKVLl+rgwYPq27evfvnLX2rIkCF64YUXLvh8pKJptf7zn//o/fffV/fu3fXSSy9p1qxZHq+ZNm2aevXqpWHDhikhIUHh4eEaOXKkx2seeugheXl5qUuXLgoNDVVmZqbuvvtuXX/99RozZoxiY2P1008/eXTplqVZs2Z6/fXXlZKSoq5du+qtt97SzJkz3c97eXnpp59+0rhx49ShQwfdeOONSkpK0uOPPy6paL26tLQ0bdu2TQMHDlTPnj312GOPKTIy0j3G/PnzFRkZqfj4eF1//fWaMGGCWrZsWanrBgAAcCHItmRbsi0AAKgvyLZkW7ItgIvlMOcuHgMAsMSePXsUFRWlTz75REOGDLG6HAAAAOCikW0BAABQX5BtAaBm0KgAABb59NNPdezYMXXt2lXZ2dn6wx/+oL1792rbtm3y8fGxujwAAADggpFtAQAAUF+QbQGgdnhbXQAANFSnT5/WI488oh9//FGNGzdW//799cYbbxB2AQAAYDtkWwAAANQXZFsAqB3MqAAAAAAAAAAAAAAAAGqN0+oCAAAAAAAAAAAAAABAw0GjAgAAAAAAAAAAAAAAqDU0KgAAAAAAAAAAAAAAgFpDowIAAAAAAAAAAAAAAKg1NCoAAAAAAAAAAAAAAIBaQ6MCAAAAAAAAAAAAAACoNTQqAAAAAAAAAAAAAACAWkOjAgAAAAAAAAAAAAAAqDU0KgAAAAAAAAAAAAAAgFrz/wH8iQbHdJY/zgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110c834",
   "metadata": {
    "papermill": {
     "duration": 0.3481,
     "end_time": "2025-03-29T05:45:39.814745",
     "exception": false,
     "start_time": "2025-03-29T05:45:39.466645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fbfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2aba8f8bd62458a9b0e40e2f5a9bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 68.68153238296509 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 0.00019598007202148438 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6049, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5195, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4816, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4492, Accuracy: 0.7991, F1 Micro: 0.8866, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4084, Accuracy: 0.8125, F1 Micro: 0.8931, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4057, Accuracy: 0.8147, F1 Micro: 0.8934, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.367, Accuracy: 0.8259, F1 Micro: 0.8984, F1 Macro: 0.8966\n",
      "Epoch 8/10, Train Loss: 0.3229, Accuracy: 0.8237, F1 Micro: 0.8963, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2746, Accuracy: 0.8356, F1 Micro: 0.9028, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2443, Accuracy: 0.846, F1 Micro: 0.9082, F1 Macro: 0.905\n",
      "\n",
      "Aspect detection accuracy: 0.846, F1 Micro: 0.9082, F1 Macro: 0.905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.84      1.00      0.91       187\n",
      "     machine       0.81      1.00      0.90       175\n",
      "      others       0.87      0.82      0.84       158\n",
      "        part       0.84      0.95      0.89       158\n",
      "       price       0.87      1.00      0.93       192\n",
      "     service       0.93      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      1061\n",
      "   macro avg       0.86      0.96      0.90      1061\n",
      "weighted avg       0.86      0.97      0.91      1061\n",
      " samples avg       0.86      0.97      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6562, Accuracy: 0.7708, F1 Micro: 0.7708, F1 Macro: 0.4353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.549, Accuracy: 0.7708, F1 Micro: 0.7708, F1 Macro: 0.4353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.553, Accuracy: 0.7778, F1 Micro: 0.7778, F1 Macro: 0.4664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4387, Accuracy: 0.7986, F1 Micro: 0.7986, F1 Macro: 0.7236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3944, Accuracy: 0.8542, F1 Micro: 0.8542, F1 Macro: 0.8168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.198, Accuracy: 0.8542, F1 Micro: 0.8542, F1 Macro: 0.8223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.8542, F1 Micro: 0.8542, F1 Macro: 0.8196\n",
      "Epoch 8/10, Train Loss: 0.1403, Accuracy: 0.8472, F1 Micro: 0.8472, F1 Macro: 0.8034\n",
      "Epoch 9/10, Train Loss: 0.1183, Accuracy: 0.8472, F1 Micro: 0.8472, F1 Macro: 0.8034\n",
      "Epoch 10/10, Train Loss: 0.0696, Accuracy: 0.8264, F1 Micro: 0.8264, F1 Macro: 0.7914\n",
      "\n",
      "Sentiment analysis accuracy: 0.8542, F1 Micro: 0.8542, F1 Macro: 0.8196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.91      0.74        33\n",
      "    positive       0.97      0.84      0.90       111\n",
      "\n",
      "    accuracy                           0.85       144\n",
      "   macro avg       0.80      0.87      0.82       144\n",
      "weighted avg       0.89      0.85      0.86       144\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8372, F1 Micro: 0.8372, F1 Macro: 0.5515\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       1.00      0.04      0.08        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.61      0.35      0.33       216\n",
      "weighted avg       0.82      0.84      0.77       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.12      0.22        16\n",
      "     neutral       0.80      1.00      0.89       167\n",
      "    positive       1.00      0.18      0.31        33\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.93      0.44      0.47       216\n",
      "weighted avg       0.85      0.81      0.75       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.86      0.81      0.83       152\n",
      "    positive       0.62      0.60      0.61        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.64      0.75      0.67       216\n",
      "weighted avg       0.78      0.76      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.52      0.60        23\n",
      "     neutral       0.83      0.95      0.89       152\n",
      "    positive       0.77      0.49      0.60        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.77      0.65      0.69       216\n",
      "weighted avg       0.81      0.81      0.80       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.08      0.14        13\n",
      "     neutral       0.87      1.00      0.93       186\n",
      "    positive       1.00      0.12      0.21        17\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.96      0.40      0.43       216\n",
      "weighted avg       0.89      0.88      0.83       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        14\n",
      "     neutral       0.93      1.00      0.96       185\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.63      0.71       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Total train time: 72.76596736907959 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 0.00012731552124023438 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5814, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5218, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4933, Accuracy: 0.8013, F1 Micro: 0.887, F1 Macro: 0.8849\n",
      "Epoch 4/10, Train Loss: 0.4744, Accuracy: 0.8028, F1 Micro: 0.8862, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.42, Accuracy: 0.8207, F1 Micro: 0.8963, F1 Macro: 0.8945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3953, Accuracy: 0.8281, F1 Micro: 0.8987, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.341, Accuracy: 0.8542, F1 Micro: 0.9132, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2843, Accuracy: 0.8884, F1 Micro: 0.9321, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2146, Accuracy: 0.8921, F1 Micro: 0.9335, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.176, Accuracy: 0.9129, F1 Micro: 0.946, F1 Macro: 0.9424\n",
      "\n",
      "Aspect detection accuracy: 0.9129, F1 Micro: 0.946, F1 Macro: 0.9424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.95      1.00      0.97       187\n",
      "     machine       0.86      0.99      0.92       175\n",
      "      others       0.91      0.81      0.86       158\n",
      "        part       0.91      0.97      0.94       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.97      0.95      1061\n",
      "   macro avg       0.93      0.96      0.94      1061\n",
      "weighted avg       0.93      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6317, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4932, Accuracy: 0.7662, F1 Micro: 0.7662, F1 Macro: 0.6274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3626, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2313, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1749, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8901\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8727\n",
      "Epoch 8/10, Train Loss: 0.1196, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8975\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.889\n",
      "\n",
      "Sentiment analysis accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.97      0.86        62\n",
      "    positive       0.99      0.89      0.94       169\n",
      "\n",
      "    accuracy                           0.91       231\n",
      "   macro avg       0.88      0.93      0.90       231\n",
      "weighted avg       0.93      0.91      0.92       231\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.7976\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.55      0.71        11\n",
      "     neutral       0.96      1.00      0.98       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.99      0.81      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.25      0.38        16\n",
      "     neutral       0.86      0.99      0.92       167\n",
      "    positive       0.94      0.48      0.64        33\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.87      0.58      0.65       216\n",
      "weighted avg       0.86      0.86      0.84       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.91      0.80      0.85       152\n",
      "    positive       0.62      0.77      0.69        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.70      0.80      0.74       216\n",
      "weighted avg       0.82      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.83      0.76        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.96      0.61      0.75        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.80      0.82       216\n",
      "weighted avg       0.90      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.75      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Total train time: 81.22237420082092 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 0.00011873245239257812 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5723, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.495, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4681, Accuracy: 0.8088, F1 Micro: 0.8913, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.432, Accuracy: 0.8237, F1 Micro: 0.8976, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3701, Accuracy: 0.8497, F1 Micro: 0.9108, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.304, Accuracy: 0.8973, F1 Micro: 0.9369, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2373, Accuracy: 0.933, F1 Micro: 0.9588, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1998, Accuracy: 0.942, F1 Micro: 0.9638, F1 Macro: 0.9615\n",
      "Epoch 9/10, Train Loss: 0.1454, Accuracy: 0.9382, F1 Micro: 0.9614, F1 Macro: 0.9583\n",
      "Epoch 10/10, Train Loss: 0.1293, Accuracy: 0.9368, F1 Micro: 0.9602, F1 Macro: 0.9564\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9638, F1 Macro: 0.9615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      1.00      0.96       175\n",
      "      others       0.92      0.90      0.91       158\n",
      "        part       0.93      0.96      0.94       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6, Accuracy: 0.6955, F1 Micro: 0.6955, F1 Macro: 0.4102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4496, Accuracy: 0.8395, F1 Micro: 0.8395, F1 Macro: 0.8068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2814, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1856, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8832\n",
      "Epoch 6/10, Train Loss: 0.0874, Accuracy: 0.8724, F1 Micro: 0.8724, F1 Macro: 0.8451\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.8313, F1 Micro: 0.8313, F1 Macro: 0.8218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1171, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.879\n",
      "Epoch 9/10, Train Loss: 0.1014, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.886\n",
      "\n",
      "Sentiment analysis accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        74\n",
      "    positive       0.98      0.87      0.92       169\n",
      "\n",
      "    accuracy                           0.90       243\n",
      "   macro avg       0.87      0.91      0.89       243\n",
      "weighted avg       0.91      0.90      0.90       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.929, F1 Micro: 0.929, F1 Macro: 0.8522\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.92      1.00      0.96       167\n",
      "    positive       1.00      0.64      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.95      0.80      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.92      0.89      0.91       152\n",
      "    positive       0.76      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.79      0.75       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.87      0.77        23\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.97      0.68      0.80        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 82.29853177070618 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 0.00010967254638671875 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.4882, Accuracy: 0.7872, F1 Micro: 0.8775, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4576, Accuracy: 0.8222, F1 Micro: 0.8985, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3933, Accuracy: 0.8616, F1 Micro: 0.9183, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3275, Accuracy: 0.9189, F1 Micro: 0.9504, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2427, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1856, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9687\n",
      "Epoch 8/10, Train Loss: 0.1487, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.1172, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.967\n",
      "Epoch 10/10, Train Loss: 0.1005, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9678\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      1.00      0.96       175\n",
      "      others       0.88      0.97      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6685, Accuracy: 0.6696, F1 Micro: 0.6696, F1 Macro: 0.401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4002, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2589, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1004, Accuracy: 0.9391, F1 Micro: 0.9391, F1 Macro: 0.9329\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9233\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9233\n",
      "Epoch 8/10, Train Loss: 0.1347, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8804\n",
      "Epoch 9/10, Train Loss: 0.0823, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8466\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9201\n",
      "\n",
      "Sentiment analysis accuracy: 0.9391, F1 Micro: 0.9391, F1 Macro: 0.9329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        76\n",
      "    positive       0.98      0.93      0.95       154\n",
      "\n",
      "    accuracy                           0.94       230\n",
      "   macro avg       0.92      0.94      0.93       230\n",
      "weighted avg       0.94      0.94      0.94       230\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8865\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.92      1.00      0.96       167\n",
      "    positive       1.00      0.61      0.75        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.95      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.88      0.97      0.92       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.76      0.79       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 79.5239679813385 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 0.00010514259338378906 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4799, Accuracy: 0.8028, F1 Micro: 0.8889, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4436, Accuracy: 0.8393, F1 Micro: 0.9071, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3456, Accuracy: 0.8988, F1 Micro: 0.9391, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2594, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1983, Accuracy: 0.9427, F1 Micro: 0.9643, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.149, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9682\n",
      "Epoch 8/10, Train Loss: 0.111, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9648\n",
      "Epoch 9/10, Train Loss: 0.0946, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9681\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.92      0.89      0.91       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6038, Accuracy: 0.6962, F1 Micro: 0.6962, F1 Macro: 0.4104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4196, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8883\n",
      "Epoch 3/10, Train Loss: 0.2266, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1799, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1582, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.906\n",
      "Epoch 6/10, Train Loss: 0.1553, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8744\n",
      "Epoch 7/10, Train Loss: 0.1197, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8935\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8972\n",
      "\n",
      "Sentiment analysis accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.97      0.90        79\n",
      "    positive       0.99      0.91      0.95       181\n",
      "\n",
      "    accuracy                           0.93       260\n",
      "   macro avg       0.91      0.94      0.92       260\n",
      "weighted avg       0.94      0.93      0.93       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8904\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      1.00      0.97       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.82      0.78       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 88.20084047317505 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.512901306152344e-05 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4713, Accuracy: 0.8155, F1 Micro: 0.895, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4248, Accuracy: 0.8512, F1 Micro: 0.9134, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.322, Accuracy: 0.9338, F1 Micro: 0.9594, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2266, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1789, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1428, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1114, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0894, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Epoch 10/10, Train Loss: 0.0804, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5726, Accuracy: 0.6865, F1 Micro: 0.6865, F1 Macro: 0.4957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3606, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2028, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9301\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9108\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9164\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8882\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0769, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0416, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        80\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.93      0.94      0.93       252\n",
      "weighted avg       0.94      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8968\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.71      0.82        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 91.81110405921936 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.822845458984375e-05 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4748, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4073, Accuracy: 0.8676, F1 Micro: 0.9221, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3182, Accuracy: 0.936, F1 Micro: 0.9605, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.226, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.163, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1223, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0978, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.971\n",
      "Epoch 10/10, Train Loss: 0.0752, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.573, Accuracy: 0.8016, F1 Micro: 0.8016, F1 Macro: 0.7413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.341, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2225, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9339\n",
      "Epoch 5/10, Train Loss: 0.1794, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1743, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9335\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9214\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9259\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9241\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9293\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        82\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.94      0.93       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9079\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      1.00      0.97       167\n",
      "    positive       1.00      0.73      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.96      0.85      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 95.66078543663025 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.34600830078125e-05 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5257, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4548, Accuracy: 0.817, F1 Micro: 0.8961, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3705, Accuracy: 0.8988, F1 Micro: 0.9391, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2666, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9688\n",
      "Epoch 5/10, Train Loss: 0.1892, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1369, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5558, Accuracy: 0.7619, F1 Micro: 0.7619, F1 Macro: 0.6465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3164, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2057, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.932\n",
      "Epoch 5/10, Train Loss: 0.1535, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1571, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9347\n",
      "Epoch 7/10, Train Loss: 0.1329, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0864, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9073\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.81      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.93908929824829 s\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 0.015788555145263672 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4706, Accuracy: 0.7991, F1 Micro: 0.8854, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4119, Accuracy: 0.878, F1 Micro: 0.9274, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2815, Accuracy: 0.9315, F1 Micro: 0.9574, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2122, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1516, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1191, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.0959, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0785, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5741, Accuracy: 0.8333, F1 Micro: 0.8333, F1 Macro: 0.7883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3345, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9238\n",
      "Epoch 3/10, Train Loss: 0.2119, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.919\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1674, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9238\n",
      "Epoch 6/10, Train Loss: 0.1212, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9147\n",
      "Epoch 7/10, Train Loss: 0.1334, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9224\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9092\n",
      "Epoch 9/10, Train Loss: 0.0832, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9147\n",
      "Epoch 10/10, Train Loss: 0.073, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90        82\n",
      "    positive       0.95      0.95      0.95       176\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.93      0.92      0.92       258\n",
      "weighted avg       0.93      0.93      0.93       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8952\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.77      0.70      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.77      0.81       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.86      0.88      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 100.88276362419128 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.34600830078125e-05 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4636, Accuracy: 0.8199, F1 Micro: 0.897, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3689, Accuracy: 0.9204, F1 Micro: 0.9517, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2482, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1829, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1433, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.108, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9703\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5689, Accuracy: 0.8167, F1 Micro: 0.8167, F1 Macro: 0.7588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2942, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9175\n",
      "Epoch 3/10, Train Loss: 0.2119, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Epoch 6/10, Train Loss: 0.1364, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9134\n",
      "Epoch 7/10, Train Loss: 0.1244, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.922\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9224\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9101\n",
      "Epoch 10/10, Train Loss: 0.1042, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9142\n",
      "\n",
      "Sentiment analysis accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        83\n",
      "    positive       0.98      0.93      0.95       168\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.95      0.93       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9053\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.369961977005 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 9.179115295410156e-05 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5352, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4587, Accuracy: 0.8341, F1 Micro: 0.9047, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3418, Accuracy: 0.942, F1 Micro: 0.9643, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2306, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1231, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0837, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5153, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2796, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 3/10, Train Loss: 0.206, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9181\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9375\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.934\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9063\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9386\n",
      "\n",
      "Sentiment analysis accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.95       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.84      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 97.95717763900757 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 8.58306884765625e-05 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4615, Accuracy: 0.8304, F1 Micro: 0.9026, F1 Macro: 0.9017\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3574, Accuracy: 0.9338, F1 Micro: 0.9595, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1665, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1198, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.0548, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5665, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.299, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1557, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9472\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9422\n",
      "Epoch 5/10, Train Loss: 0.1109, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9338\n",
      "Epoch 6/10, Train Loss: 0.1087, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.952\n",
      "\n",
      "Sentiment analysis accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.95      0.97       173\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.94      0.96      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9179\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.96      0.67      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.72770953178406 s\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 0.006855487823486328 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4555, Accuracy: 0.8594, F1 Micro: 0.9176, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3165, Accuracy: 0.9427, F1 Micro: 0.9645, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2009, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2723, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2097, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9438\n",
      "Epoch 6/10, Train Loss: 0.1486, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9351\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.929\n",
      "\n",
      "Sentiment analysis accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.93      0.96      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9154\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 113.99359226226807 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.392333984375e-05 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4533, Accuracy: 0.8661, F1 Micro: 0.9214, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3174, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2043, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6006, Accuracy: 0.668, F1 Micro: 0.668, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3139, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "Epoch 3/10, Train Loss: 0.2075, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1756, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 5/10, Train Loss: 0.1497, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9269\n",
      "Epoch 6/10, Train Loss: 0.1313, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1137, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 8/10, Train Loss: 0.098, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9161\n",
      "Epoch 9/10, Train Loss: 0.0971, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9109\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        84\n",
      "    positive       0.96      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.93      0.93       253\n",
      "weighted avg       0.94      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9033\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.02185845375061 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.20159912109375e-05 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.525, Accuracy: 0.8006, F1 Micro: 0.8878, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4439, Accuracy: 0.8683, F1 Micro: 0.9227, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3135, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2138, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1464, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5605, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2633, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1842, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9186\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.9078\n",
      "Epoch 6/10, Train Loss: 0.1423, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9094\n",
      "Epoch 7/10, Train Loss: 0.1047, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9176\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9189\n",
      "Epoch 9/10, Train Loss: 0.085, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.9417\n",
      "\n",
      "Sentiment analysis accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.9417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       186\n",
      "\n",
      "    accuracy                           0.95       273\n",
      "   macro avg       0.94      0.95      0.94       273\n",
      "weighted avg       0.95      0.95      0.95       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9197\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.88      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.95      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.20889115333557 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.678436279296875e-05 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4384, Accuracy: 0.8661, F1 Micro: 0.9208, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3048, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1991, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1421, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1088, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5067, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2559, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1885, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9516\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9519\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9186\n",
      "Epoch 8/10, Train Loss: 0.0799, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9254\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.96      0.94       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.59416556358337 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.059906005859375e-05 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5281, Accuracy: 0.8043, F1 Micro: 0.8897, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4286, Accuracy: 0.881, F1 Micro: 0.9291, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2834, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1888, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0759, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9731\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5193, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2633, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1565, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9292\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1049, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1069, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9451\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.93        84\n",
      "    positive       0.95      0.98      0.96       162\n",
      "\n",
      "    accuracy                           0.95       246\n",
      "   macro avg       0.95      0.94      0.95       246\n",
      "weighted avg       0.95      0.95      0.95       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9141\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 117.41645097732544 s\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.0066070556640625 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5281, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.433, Accuracy: 0.8817, F1 Micro: 0.9299, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2936, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1892, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0859, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.293, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9423\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9466\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        83\n",
      "    positive       0.97      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.95      0.95      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.44646382331848 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.250640869140625e-05 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5288, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4198, Accuracy: 0.9048, F1 Micro: 0.9422, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.267, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1223, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5064, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2127, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9251\n",
      "Epoch 3/10, Train Loss: 0.1973, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9189\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "Epoch 7/10, Train Loss: 0.0851, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9289\n",
      "Epoch 8/10, Train Loss: 0.0917, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9189\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9153\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9003\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        84\n",
      "    positive       0.96      0.96      0.96       170\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.94      0.94      0.94       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9162\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.89593291282654 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.630752563476562e-05 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4146, Accuracy: 0.9055, F1 Micro: 0.9433, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2602, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1725, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "Epoch 6/10, Train Loss: 0.09, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5035, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.247, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2036, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1536, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 5/10, Train Loss: 0.1237, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 6/10, Train Loss: 0.0809, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1068, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9141\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        84\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9184\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.15848112106323 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.153915405273438e-05 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5269, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4051, Accuracy: 0.9144, F1 Micro: 0.9479, F1 Macro: 0.9468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2541, Accuracy: 0.9546, F1 Micro: 0.972, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0936, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0712, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0535, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5033, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2417, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9409\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9099\n",
      "Epoch 4/10, Train Loss: 0.1388, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9317\n",
      "Epoch 5/10, Train Loss: 0.1035, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "Epoch 6/10, Train Loss: 0.089, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9263\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9052\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9328\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.925\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      1.00      0.89        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.91      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.8398814201355 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 8.296966552734375e-05 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5218, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4099, Accuracy: 0.907, F1 Micro: 0.9438, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2525, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0924, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0724, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0615, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4463, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2063, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1477, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1361, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1095, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9446\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9443\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0377, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9473\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "    positive       0.96      0.97      0.97       171\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.95      0.94      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9204\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.6626696586609 s\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.012090206146240234 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5143, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3927, Accuracy: 0.9219, F1 Micro: 0.9525, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2392, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1664, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9772\n",
      "Epoch 7/10, Train Loss: 0.0739, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.99      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4967, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2308, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9303\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.102, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9228\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9269\n",
      "Epoch 10/10, Train Loss: 0.1153, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9195\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       0.95      0.77      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.14914751052856 s\n",
      "Total runtime: 2628.093569755554 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6159439,
     "sourceId": 10801903,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5235.934097,
   "end_time": "2025-03-29T05:45:43.453697",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-29T04:18:27.519600",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b76c78c43834b38bf593fc82cf9e8e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4989dd61672f4fe89162d187f8fc0fef",
       "placeholder": "",
       "style": "IPY_MODEL_8559d5645bb14100b16b0ebd3658c6e2",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "0f4c5a163dd649f2ad0ac7dfce438124": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "11497f8c6584470d90dd6379978e5a57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8a2b9d5e2bc945a7baa60d53879b1c34",
       "placeholder": "",
       "style": "IPY_MODEL_cf942841f4164059a71f3568cb5d4293",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,151kB/s]"
      }
     },
     "11854aa6c48a428da6dc4dac5098f4fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ce6b782ec8c24085939db02214a31d66",
       "max": 497787752,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_42522c29655841d8a4c8c1caa55f8985",
       "tabbable": null,
       "tooltip": null,
       "value": 497787752
      }
     },
     "14ae1f2e32684a0184eec21645d23c81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bef107311b9b4ec2a03327199c33874f",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ce8b349953dc46738195b4abb7362979",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "15af0e6914444fc084db6d96c7ed8336": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a794b6c7c6f4863b27c9b226b79855a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1e8b056e181b4838b596ff2784aefbde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3028a9c7128c4b058e7444d874e588e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a1369937653474aae1188147efb4465",
       "placeholder": "",
       "style": "IPY_MODEL_84ebab9500d64c7cb43bd0d597771571",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,162B/s]"
      }
     },
     "36853977434a4d94b8b9b17b9083bc1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3bd89fa61b324133a2886db8c3c8bbb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c0c6f0ae60cb4d969088ca2e0a892021",
        "IPY_MODEL_4d265914614a492d812f47bdbde9e7fa",
        "IPY_MODEL_895239de01d94a5b8f3916c0aadd8d6c"
       ],
       "layout": "IPY_MODEL_dacfc00053234b87a4276877d32d048a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3c27cfee495b44c098ebc273a45294f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "416f72167e2a4696a16749dba904fa10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42522c29655841d8a4c8c1caa55f8985": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "425275665dde42f2b9284a4907bf6052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0b76c78c43834b38bf593fc82cf9e8e7",
        "IPY_MODEL_11854aa6c48a428da6dc4dac5098f4fb",
        "IPY_MODEL_6c05ba04ec4f4b5e83fdd956fb576b2a"
       ],
       "layout": "IPY_MODEL_eb2013680dd343e7b53749e61271c6b4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "46afa6099eb24f308e052b63e55663d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "495a481ec28541acaa2f0ad2caf712c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4985601007d64ca4b0099df773b3dcf9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4989dd61672f4fe89162d187f8fc0fef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d265914614a492d812f47bdbde9e7fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_702f4b63e34047fcb838240f5814ccc0",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0f4c5a163dd649f2ad0ac7dfce438124",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "5a1369937653474aae1188147efb4465": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5eb81634cbb74602a8e73cbab8019998": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6926cdcf3ed5484cb57c930bc8bd98a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6c05ba04ec4f4b5e83fdd956fb576b2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_416f72167e2a4696a16749dba904fa10",
       "placeholder": "",
       "style": "IPY_MODEL_6f5e937bda35416aafe5045c3db107f8",
       "tabbable": null,
       "tooltip": null,
       "value": "498M/498M[00:02&lt;00:00,197MB/s]"
      }
     },
     "6f097eda218b4cffbe6f1f32738b7845": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7506d980de8f4b6f9e1f79b122e2f556",
        "IPY_MODEL_a50bb9b3707e416ba309da84fc6ccbf6",
        "IPY_MODEL_11497f8c6584470d90dd6379978e5a57"
       ],
       "layout": "IPY_MODEL_1e8b056e181b4838b596ff2784aefbde",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6f5e937bda35416aafe5045c3db107f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "702f4b63e34047fcb838240f5814ccc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "708100fc2b9d46979a67279479cab897": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7506d980de8f4b6f9e1f79b122e2f556": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c1eb86f7f374f9a990bb50171397d10",
       "placeholder": "",
       "style": "IPY_MODEL_b49eada6611d46198aad9d5420d779f5",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "84ebab9500d64c7cb43bd0d597771571": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8559d5645bb14100b16b0ebd3658c6e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "85bfa56a38904f398a086a1891088942": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d414b93ddfa942328bdff2a4e8fd5036",
       "placeholder": "",
       "style": "IPY_MODEL_495a481ec28541acaa2f0ad2caf712c0",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,12.3kB/s]"
      }
     },
     "895239de01d94a5b8f3916c0aadd8d6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15af0e6914444fc084db6d96c7ed8336",
       "placeholder": "",
       "style": "IPY_MODEL_ac3d63ce39e640ce8016a2e60b60f639",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,7.81MB/s]"
      }
     },
     "8a2b9d5e2bc945a7baa60d53879b1c34": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c1eb86f7f374f9a990bb50171397d10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9528ced462aa4a7688efababa83ce30b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5eb81634cbb74602a8e73cbab8019998",
       "placeholder": "",
       "style": "IPY_MODEL_b32ba3dd45414985ac8ab081ba4422ee",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "994d5145a7ab4c52b0002ddcba445ad0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b42cf57cbf8743dfa99d6244a76bbcb4",
        "IPY_MODEL_14ae1f2e32684a0184eec21645d23c81",
        "IPY_MODEL_85bfa56a38904f398a086a1891088942"
       ],
       "layout": "IPY_MODEL_ca7257b4f0234ea1af67a0bc381767e9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a50bb9b3707e416ba309da84fc6ccbf6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e27a5100aa7143849f590a3d778a21c7",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_36853977434a4d94b8b9b17b9083bc1e",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "ac3d63ce39e640ce8016a2e60b60f639": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b32ba3dd45414985ac8ab081ba4422ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b42cf57cbf8743dfa99d6244a76bbcb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_708100fc2b9d46979a67279479cab897",
       "placeholder": "",
       "style": "IPY_MODEL_46afa6099eb24f308e052b63e55663d6",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "b49eada6611d46198aad9d5420d779f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bef107311b9b4ec2a03327199c33874f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0c6f0ae60cb4d969088ca2e0a892021": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d32849a6df074e57948b6fc9a7596edb",
       "placeholder": "",
       "style": "IPY_MODEL_1a794b6c7c6f4863b27c9b226b79855a",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "ca7257b4f0234ea1af67a0bc381767e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce6b782ec8c24085939db02214a31d66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce8b349953dc46738195b4abb7362979": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cf942841f4164059a71f3568cb5d4293": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d32849a6df074e57948b6fc9a7596edb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d414b93ddfa942328bdff2a4e8fd5036": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d434ae89a0bd491d80aee9e9f15c9ec6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3c27cfee495b44c098ebc273a45294f9",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6926cdcf3ed5484cb57c930bc8bd98a2",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "dacfc00053234b87a4276877d32d048a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e27a5100aa7143849f590a3d778a21c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb2013680dd343e7b53749e61271c6b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ecb90d3ae0294bb6b5549b4b7e6de5ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9528ced462aa4a7688efababa83ce30b",
        "IPY_MODEL_d434ae89a0bd491d80aee9e9f15c9ec6",
        "IPY_MODEL_3028a9c7128c4b058e7444d874e588e4"
       ],
       "layout": "IPY_MODEL_4985601007d64ca4b0099df773b3dcf9",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
