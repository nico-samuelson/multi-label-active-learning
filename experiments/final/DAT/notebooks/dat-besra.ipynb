{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ddd2418",
   "metadata": {
    "papermill": {
     "duration": 0.007231,
     "end_time": "2025-01-28T09:09:32.189616",
     "exception": false,
     "start_time": "2025-01-28T09:09:32.182385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e677e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:09:32.201556Z",
     "iopub.status.busy": "2025-01-28T09:09:32.201236Z",
     "iopub.status.idle": "2025-01-28T09:10:06.867880Z",
     "shell.execute_reply": "2025-01-28T09:10:06.867198Z"
    },
    "papermill": {
     "duration": 34.67405,
     "end_time": "2025-01-28T09:10:06.869385",
     "exception": false,
     "start_time": "2025-01-28T09:09:32.195335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b3fb",
   "metadata": {
    "papermill": {
     "duration": 0.005279,
     "end_time": "2025-01-28T09:10:06.880751",
     "exception": false,
     "start_time": "2025-01-28T09:10:06.875472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98705e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:06.892448Z",
     "iopub.status.busy": "2025-01-28T09:10:06.892005Z",
     "iopub.status.idle": "2025-01-28T09:10:06.895165Z",
     "shell.execute_reply": "2025-01-28T09:10:06.894569Z"
    },
    "papermill": {
     "duration": 0.010275,
     "end_time": "2025-01-28T09:10:06.896448",
     "exception": false,
     "start_time": "2025-01-28T09:10:06.886173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0be9060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:06.908272Z",
     "iopub.status.busy": "2025-01-28T09:10:06.908060Z",
     "iopub.status.idle": "2025-01-28T09:10:06.911531Z",
     "shell.execute_reply": "2025-01-28T09:10:06.910947Z"
    },
    "papermill": {
     "duration": 0.010871,
     "end_time": "2025-01-28T09:10:06.912741",
     "exception": false,
     "start_time": "2025-01-28T09:10:06.901870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dadeb2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:06.924177Z",
     "iopub.status.busy": "2025-01-28T09:10:06.923938Z",
     "iopub.status.idle": "2025-01-28T09:10:06.936998Z",
     "shell.execute_reply": "2025-01-28T09:10:06.936149Z"
    },
    "papermill": {
     "duration": 0.019961,
     "end_time": "2025-01-28T09:10:06.938310",
     "exception": false,
     "start_time": "2025-01-28T09:10:06.918349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a87e91",
   "metadata": {
    "papermill": {
     "duration": 0.005267,
     "end_time": "2025-01-28T09:10:06.948864",
     "exception": false,
     "start_time": "2025-01-28T09:10:06.943597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27538b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:06.960111Z",
     "iopub.status.busy": "2025-01-28T09:10:06.959877Z",
     "iopub.status.idle": "2025-01-28T09:10:07.019073Z",
     "shell.execute_reply": "2025-01-28T09:10:07.017625Z"
    },
    "papermill": {
     "duration": 0.066659,
     "end_time": "2025-01-28T09:10:07.020772",
     "exception": false,
     "start_time": "2025-01-28T09:10:06.954113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-besra'\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "sequence_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c78efe",
   "metadata": {
    "papermill": {
     "duration": 0.005145,
     "end_time": "2025-01-28T09:10:07.031370",
     "exception": false,
     "start_time": "2025-01-28T09:10:07.026225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a72092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:07.043050Z",
     "iopub.status.busy": "2025-01-28T09:10:07.042747Z",
     "iopub.status.idle": "2025-01-28T09:10:07.193599Z",
     "shell.execute_reply": "2025-01-28T09:10:07.192767Z"
    },
    "papermill": {
     "duration": 0.158393,
     "end_time": "2025-01-28T09:10:07.194947",
     "exception": false,
     "start_time": "2025-01-28T09:10:07.036554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctor-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec693c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:07.207463Z",
     "iopub.status.busy": "2025-01-28T09:10:07.207204Z",
     "iopub.status.idle": "2025-01-28T09:10:07.228675Z",
     "shell.execute_reply": "2025-01-28T09:10:07.228068Z"
    },
    "papermill": {
     "duration": 0.029029,
     "end_time": "2025-01-28T09:10:07.229960",
     "exception": false,
     "start_time": "2025-01-28T09:10:07.200931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01235316",
   "metadata": {
    "papermill": {
     "duration": 0.005727,
     "end_time": "2025-01-28T09:10:07.241214",
     "exception": false,
     "start_time": "2025-01-28T09:10:07.235487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71668bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:07.253077Z",
     "iopub.status.busy": "2025-01-28T09:10:07.252839Z",
     "iopub.status.idle": "2025-01-28T09:10:08.502618Z",
     "shell.execute_reply": "2025-01-28T09:10:08.502007Z"
    },
    "papermill": {
     "duration": 1.257251,
     "end_time": "2025-01-28T09:10:08.504028",
     "exception": false,
     "start_time": "2025-01-28T09:10:07.246777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185957f902b44cc98499c9916f4bce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ea5b5ed6be4d94b3d800e53d28f82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d831c11c554c07bc87fc14f892c09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883813edbbaf4c26add3473d5e87c618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678ab729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.517563Z",
     "iopub.status.busy": "2025-01-28T09:10:08.517304Z",
     "iopub.status.idle": "2025-01-28T09:10:08.521423Z",
     "shell.execute_reply": "2025-01-28T09:10:08.520799Z"
    },
    "papermill": {
     "duration": 0.011885,
     "end_time": "2025-01-28T09:10:08.522607",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.510722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53966da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.535331Z",
     "iopub.status.busy": "2025-01-28T09:10:08.535132Z",
     "iopub.status.idle": "2025-01-28T09:10:08.540915Z",
     "shell.execute_reply": "2025-01-28T09:10:08.540167Z"
    },
    "papermill": {
     "duration": 0.013364,
     "end_time": "2025-01-28T09:10:08.542132",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.528768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7a02220a7070>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7a02220a4820>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataloaders(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36a859",
   "metadata": {
    "papermill": {
     "duration": 0.005664,
     "end_time": "2025-01-28T09:10:08.553966",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.548302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36978996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.566964Z",
     "iopub.status.busy": "2025-01-28T09:10:08.566737Z",
     "iopub.status.idle": "2025-01-28T09:10:08.570511Z",
     "shell.execute_reply": "2025-01-28T09:10:08.569740Z"
    },
    "papermill": {
     "duration": 0.011558,
     "end_time": "2025-01-28T09:10:08.571746",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.560188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89b3a6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.584619Z",
     "iopub.status.busy": "2025-01-28T09:10:08.584424Z",
     "iopub.status.idle": "2025-01-28T09:10:08.588803Z",
     "shell.execute_reply": "2025-01-28T09:10:08.588243Z"
    },
    "papermill": {
     "duration": 0.012117,
     "end_time": "2025-01-28T09:10:08.589961",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.577844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c204ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.602816Z",
     "iopub.status.busy": "2025-01-28T09:10:08.602618Z",
     "iopub.status.idle": "2025-01-28T09:10:08.614591Z",
     "shell.execute_reply": "2025-01-28T09:10:08.614017Z"
    },
    "papermill": {
     "duration": 0.019851,
     "end_time": "2025-01-28T09:10:08.615734",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.595883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde1fb2",
   "metadata": {
    "papermill": {
     "duration": 0.006142,
     "end_time": "2025-01-28T09:10:08.628094",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.621952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5397aefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.640826Z",
     "iopub.status.busy": "2025-01-28T09:10:08.640625Z",
     "iopub.status.idle": "2025-01-28T09:10:08.645705Z",
     "shell.execute_reply": "2025-01-28T09:10:08.645112Z"
    },
    "papermill": {
     "duration": 0.013018,
     "end_time": "2025-01-28T09:10:08.646965",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.633947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee56df",
   "metadata": {
    "papermill": {
     "duration": 0.005823,
     "end_time": "2025-01-28T09:10:08.658709",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.652886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6cd5438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.671539Z",
     "iopub.status.busy": "2025-01-28T09:10:08.671342Z",
     "iopub.status.idle": "2025-01-28T09:10:08.690104Z",
     "shell.execute_reply": "2025-01-28T09:10:08.689297Z"
    },
    "papermill": {
     "duration": 0.026689,
     "end_time": "2025-01-28T09:10:08.691330",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.664641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_score(p, y, alpha=0.1, beta=3):\n",
    "    \"\"\"Calculates Beta score for a given probability p and label y.\"\"\"\n",
    "    \n",
    "    if y == 1:\n",
    "        return -betaln(alpha, beta + 1) + betaln(alpha + p, beta + 1 - p)\n",
    "    elif y == 0:\n",
    "        return -betaln(alpha + 1, beta) + betaln(alpha + 1 - p, beta + p)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: y must be 0 or 1.\")\n",
    "\n",
    "def bayesian_update(prior, likelihood, evidence, alpha=0.1, beta_param=3):\n",
    "    \"\"\" \n",
    "    Bayes' Theorem: P(y'|x') = P(x'|y') * P(y') / P(x')\n",
    "    P(y'|x') or likelihood = model probs\n",
    "    p(y') or prior = class probabilities\n",
    "    p(x') or evidence = 1 / number of data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Beta score to simulate the posterior\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    \n",
    "    # We calculate the posterior using the Beta distribution\n",
    "    return posterior\n",
    "\n",
    "def compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx):\n",
    "    scores_before = []\n",
    "    scores_after = []\n",
    "\n",
    "    # Before data addition: calculate Beta score for predicted prob\n",
    "    scores_before.append(beta_score(predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    scores_before.append(beta_score(1-predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    \n",
    "    # After data addition: use Bayesian update (posterior probability)\n",
    "    # class_probs = labeled_dataset.get_per_class_probs() \n",
    "    # label_probs = labeled_dataset.get_global_probs() \n",
    "    \n",
    "    for k in range(2):\n",
    "        prior = predicted_prob\n",
    "        likelihood = class_probs[class_idx][k]  # Likelihood is the true label (0 or 1)\n",
    "        posterior = bayesian_update(prior, likelihood, 1)\n",
    "        scores_after.append(beta_score(posterior, int(1 if posterior >= 0.5 else 0)))\n",
    "\n",
    "    score_diff_0 = scores_after[0] - scores_before[0]\n",
    "    score_diff_1 = scores_after[1] - scores_before[1]\n",
    "    return label_probs['0'] * score_diff_0 + label_probs['1'] * score_diff_1\n",
    "\n",
    "# Function to compute Expected Score Change (âˆ†Q)\n",
    "def besra_sampling(models, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    \n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    labeled_dataset = DoctorAnswerDataset(current_X_train, current_y_train, tokenizer, max_length=sequence_length)\n",
    "    label_probs = labeled_dataset.get_global_probs()\n",
    "    class_probs = labeled_dataset.get_per_class_probs()\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    start_time = time.time()\n",
    "    score_changes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        # all_probs = []\n",
    "        model_probs = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.sigmoid(logits)  # Multi-label classification uses sigmoid\n",
    "                model_probs.append(probs.unsqueeze(0))  # Add batch dimension for averaging\n",
    "        \n",
    "        # Stack all model predictions and compute the mean across models\n",
    "        model_probs = torch.cat(model_probs, dim=0)  # Concatenate predictions across models\n",
    "        probs = model_probs.mean(dim=0)  # Take the mean along the model axis\n",
    "\n",
    "        # Calculate Beta scores before and after data addition\n",
    "        for i in range(len(probs)):\n",
    "            score_diff = []\n",
    "            for class_idx in range(probs.shape[1]):\n",
    "                predicted_prob = probs[i, class_idx].item()\n",
    "                score_diff.append(compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx))\n",
    "            \n",
    "            score_changes.append(np.mean(score_diff))\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    \n",
    "    accelerator.wait_for_everyone()\n",
    "    \n",
    "    if accelerator.is_local_main_process:\n",
    "        num_of_candidates = len(score_changes[:math.ceil(0.1 * len(score_changes))])\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "\n",
    "        # Determine number of clusters\n",
    "        if num_of_candidates <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            n_clusters = n_clusters\n",
    "        elif num_of_candidates > n_clusters and num_of_candidates < nearest_cp - current_train_size:\n",
    "            n_clusters = num_of_candidates\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            n_clusters = nearest_cp - current_train_size\n",
    "\n",
    "        score_changes = np.array(score_changes)\n",
    "        score_changes = score_changes.reshape(-1, 1)\n",
    "            \n",
    "        kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "        kmeans.fit(score_changes)\n",
    "\n",
    "        if current_train_size > checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Samples above threshold:\", num_of_candidates)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]  # Indices of samples in the current cluster\n",
    "                \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances to the cluster center\n",
    "                cluster_distances = np.linalg.norm(score_changes[cluster_indices] - cluster_center, axis=1)\n",
    "                closest_sample_index = cluster_indices[np.argmin(cluster_distances)]  # Closest sample index\n",
    "                collected_indices.add(closest_sample_index)\n",
    "\n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "            \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    '1-FR': [y_train[i][0] for i in temp],\n",
    "                    '2-GI': [y_train[i][1] for i in temp],\n",
    "                    '3-PI': [y_train[i][2] for i in temp],\n",
    "                    '4-DM': [y_train[i][3] for i in temp],\n",
    "                    '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                    '6-RE': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Samples above threshold:\", num_of_candidates)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594429fc",
   "metadata": {
    "papermill": {
     "duration": 0.005968,
     "end_time": "2025-01-28T09:10:08.703328",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.697360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a10decb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.716239Z",
     "iopub.status.busy": "2025-01-28T09:10:08.716007Z",
     "iopub.status.idle": "2025-01-28T09:10:08.725717Z",
     "shell.execute_reply": "2025-01-28T09:10:08.725172Z"
    },
    "papermill": {
     "duration": 0.017534,
     "end_time": "2025-01-28T09:10:08.727000",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.709466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "\n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}')\n",
    "            models.append(model)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (models, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5a78beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.739765Z",
     "iopub.status.busy": "2025-01-28T09:10:08.739544Z",
     "iopub.status.idle": "2025-01-28T09:10:08.742769Z",
     "shell.execute_reply": "2025-01-28T09:10:08.742036Z"
    },
    "papermill": {
     "duration": 0.011077,
     "end_time": "2025-01-28T09:10:08.744157",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.733080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [[50, 67, 42], [81, 90, 11], [14, 7, 33], [3, 44, 85], [94, 21, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bb1b3",
   "metadata": {
    "papermill": {
     "duration": 0.00575,
     "end_time": "2025-01-28T09:10:08.756127",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.750377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e5af6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T09:10:08.768809Z",
     "iopub.status.busy": "2025-01-28T09:10:08.768614Z",
     "iopub.status.idle": "2025-01-28T10:31:18.915689Z",
     "shell.execute_reply": "2025-01-28T10:31:18.914496Z"
    },
    "papermill": {
     "duration": 4870.155491,
     "end_time": "2025-01-28T10:31:18.917556",
     "exception": false,
     "start_time": "2025-01-28T09:10:08.762065",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6831, Accuracy: 0.9048, F1 Micro: 0.9315, F1 Macro: 0.6789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5382, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4056, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3446, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2908, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2621, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2184, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2003, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1778, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1998, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 38.42217469215393 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7322, Accuracy: 0.7842, F1 Micro: 0.8247, F1 Macro: 0.5223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5256, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4072, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3384, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3043, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2231, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2092, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1837, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2024, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 36.44893455505371 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6606, Accuracy: 0.9613, F1 Micro: 0.9707, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4941, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3791, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2728, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2492, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2031, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1903, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1682, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1943, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 37.217400312423706 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 19.285139083862305 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5893, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3719, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2665, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2403, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1758, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1773, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1748, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1631, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1734, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1582, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 41.40238070487976 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6374, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3776, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2848, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2484, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1845, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1804, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.168, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 41.517603635787964 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5696, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3464, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2516, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2281, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1754, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1776, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1624, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1794, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1662, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 40.409364461898804 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 20.197197437286377 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5114, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2694, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2148, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1908, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2063, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1795, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1503, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1378, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 10/10, Train Loss: 0.1173, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Model 1 - Iteration 97: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 45.32075619697571 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5412, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.286, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2227, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1977, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.191, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2149, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1844, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1559, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1488, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1285, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6559\n",
      "Model 2 - Iteration 97: Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 46.490057706832886 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4847, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2517, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.212, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1903, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1845, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.214, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1831, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1509, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 9/10, Train Loss: 0.14, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Epoch 10/10, Train Loss: 0.1149, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Model 3 - Iteration 97: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 42.71427059173584 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9668, F1 Micro: 0.9748, F1 Macro: 0.6544\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 18.215090036392212 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5086, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2741, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2349, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.229, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1752, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1581, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1526, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1326, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1251, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Model 1 - Iteration 128: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 48.35270833969116 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5178, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2892, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2421, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2331, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1733, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1822, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1604, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1428, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 10/10, Train Loss: 0.139, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6531\n",
      "Model 2 - Iteration 128: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.60728859901428 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4756, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2638, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2328, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2303, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1679, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1787, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1657, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 8/10, Train Loss: 0.1539, Accuracy: 0.9613, F1 Micro: 0.9704, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1312, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 10/10, Train Loss: 0.1272, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Model 3 - Iteration 128: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.433600425720215 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6547\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 16.69890022277832 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4705, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2402, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2036, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1664, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1847, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1608, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1898, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1179, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 9/10, Train Loss: 0.1377, Accuracy: 0.9554, F1 Micro: 0.9655, F1 Macro: 0.6468\n",
      "Epoch 10/10, Train Loss: 0.1238, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Model 1 - Iteration 156: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 47.7212119102478 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.488, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.247, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2087, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1894, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2017, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1314, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 9/10, Train Loss: 0.1519, Accuracy: 0.9554, F1 Micro: 0.9653, F1 Macro: 0.6462\n",
      "Epoch 10/10, Train Loss: 0.1327, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Model 2 - Iteration 156: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 49.37628889083862 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4404, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2288, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2032, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1877, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1653, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Epoch 7/10, Train Loss: 0.193, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.12, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.1411, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.9494, F1 Micro: 0.9606, F1 Macro: 0.6424\n",
      "Model 3 - Iteration 156: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 46.61101150512695 s\n",
      "Averaged - Iteration 156: Accuracy: 0.968, F1 Micro: 0.9757, F1 Macro: 0.655\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 14.723693132400513 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4324, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2257, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1869, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1888, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1496, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 7/10, Train Loss: 0.1211, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Epoch 8/10, Train Loss: 0.1168, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 9/10, Train Loss: 0.0984, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0876, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Model 1 - Iteration 181: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.74      0.77       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 51.95392036437988 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4551, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2403, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1923, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1983, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1595, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1353, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 8/10, Train Loss: 0.1301, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Epoch 9/10, Train Loss: 0.1045, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6523\n",
      "Model 2 - Iteration 181: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 51.91119074821472 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4098, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2234, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1886, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1951, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1581, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 7/10, Train Loss: 0.127, Accuracy: 0.9568, F1 Micro: 0.9667, F1 Macro: 0.6478\n",
      "Epoch 8/10, Train Loss: 0.1195, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.6476\n",
      "Epoch 9/10, Train Loss: 0.098, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6508\n",
      "Epoch 10/10, Train Loss: 0.0875, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7193\n",
      "Model 3 - Iteration 181: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 49.76226472854614 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9682, F1 Micro: 0.9758, F1 Macro: 0.6612\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 13.543659448623657 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4047, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1688, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1567, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1563, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1215, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 10/10, Train Loss: 0.0988, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Model 1 - Iteration 203: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 56.713865518569946 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4273, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2182, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1786, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1811, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1712, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.1722, Accuracy: 0.9613, F1 Micro: 0.9701, F1 Macro: 0.6503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1403, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Epoch 10/10, Train Loss: 0.1074, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Model 2 - Iteration 203: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.97      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.97      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 55.03547430038452 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2069, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1737, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1684, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1597, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.1535, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1159, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0887, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7514\n",
      "Model 3 - Iteration 203: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.75      0.75       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 56.721349477767944 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9685, F1 Micro: 0.9761, F1 Macro: 0.665\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 12.329276323318481 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3723, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2157, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1963, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1485, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1496, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.13, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1219, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0821, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7469\n",
      "Model 1 - Iteration 223: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.99638628959656 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4163, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2261, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1971, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2019, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1689, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1591, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1712, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 8/10, Train Loss: 0.1462, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.1323, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0892, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7794\n",
      "Model 2 - Iteration 223: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 56.61354327201843 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3636, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2018, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1622, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.152, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 7/10, Train Loss: 0.1571, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.1318, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1181, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7514\n",
      "Model 3 - Iteration 223: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.75      0.75       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 57.12543606758118 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9689, F1 Micro: 0.9763, F1 Macro: 0.6776\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 10.729298830032349 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3889, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2026, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1815, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1755, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.131, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.746\n",
      "Epoch 10/10, Train Loss: 0.0797, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.7504\n",
      "Model 1 - Iteration 241: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.71052265167236 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4042, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2106, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1619, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1401, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7963\n",
      "Epoch 9/10, Train Loss: 0.0941, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7654\n",
      "Model 2 - Iteration 241: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.74      0.77       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 57.966028451919556 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3709, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2019, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1956, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1848, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1757, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 6/10, Train Loss: 0.1557, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1251, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0781, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "Model 3 - Iteration 241: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.474653005599976 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9694, F1 Micro: 0.9767, F1 Macro: 0.6888\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 9.672141313552856 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3892, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2124, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2082, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2011, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1579, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1552, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Epoch 8/10, Train Loss: 0.1178, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7663\n",
      "Epoch 9/10, Train Loss: 0.1002, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7532\n",
      "Epoch 10/10, Train Loss: 0.0796, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7801\n",
      "Model 1 - Iteration 250: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.73504996299744 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4133, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2197, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2096, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2057, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1686, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1676, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Epoch 8/10, Train Loss: 0.1282, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Epoch 9/10, Train Loss: 0.1044, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.7939\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "Model 2 - Iteration 250: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.42239475250244 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3745, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2113, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2065, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2035, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1707, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1568, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1488, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.757\n",
      "Epoch 8/10, Train Loss: 0.1155, Accuracy: 0.9598, F1 Micro: 0.9689, F1 Macro: 0.7585\n",
      "Epoch 9/10, Train Loss: 0.0913, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7933\n",
      "Epoch 10/10, Train Loss: 0.0749, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7953\n",
      "Model 3 - Iteration 250: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.73      0.79      0.76       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.288235902786255 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9697, F1 Micro: 0.977, F1 Macro: 0.6963\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 9.05510950088501 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2073, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1751, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1987, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1359, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1251, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.1116, Accuracy: 0.9613, F1 Micro: 0.9706, F1 Macro: 0.7302\n",
      "Epoch 9/10, Train Loss: 0.0949, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7393\n",
      "Epoch 10/10, Train Loss: 0.0704, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7661\n",
      "Model 1 - Iteration 265: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 60.15022921562195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3945, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2101, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1773, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1852, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1432, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1284, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.1101, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7577\n",
      "Epoch 9/10, Train Loss: 0.0948, Accuracy: 0.9762, F1 Micro: 0.9818, F1 Macro: 0.7995\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7987\n",
      "Model 2 - Iteration 265: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.18524479866028 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3644, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.209, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1749, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2028, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1846, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.139, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1243, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1087, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0913, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Model 3 - Iteration 265: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.67910814285278 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7056\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 8.335171937942505 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3693, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2145, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1965, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1865, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 6/10, Train Loss: 0.1661, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.1339, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "Epoch 9/10, Train Loss: 0.0923, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7773\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "Model 1 - Iteration 279: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.69797682762146 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3856, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1966, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2006, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1958, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1733, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1426, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1087, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0936, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7977\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7796\n",
      "Model 2 - Iteration 279: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.93      0.94      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.98      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 65.73229646682739 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3478, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2145, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1959, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1966, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1905, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.169, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1313, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0844, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7631\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7664\n",
      "Model 3 - Iteration 279: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.25027894973755 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7129\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.864465713500977 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3639, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2054, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2041, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1664, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1239, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.756\n",
      "Epoch 10/10, Train Loss: 0.0774, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7586\n",
      "Model 1 - Iteration 292: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.64790368080139 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.377, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2096, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2064, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1902, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1792, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1711, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0951, Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "Epoch 9/10, Train Loss: 0.0864, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7881\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Model 2 - Iteration 292: Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.89665865898132 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3488, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2052, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1803, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1729, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1178, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7932\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7772\n",
      "Model 3 - Iteration 292: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.63241481781006 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9709, F1 Micro: 0.9779, F1 Macro: 0.7187\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.930008888244629 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3661, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2182, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1795, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1582, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 6/10, Train Loss: 0.1577, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1278, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1083, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7521\n",
      "Epoch 10/10, Train Loss: 0.0711, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.767\n",
      "Model 1 - Iteration 300: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 63.583580493927 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1844, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1605, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1589, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1306, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.1102, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7595\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7491\n",
      "Model 2 - Iteration 300: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.32646179199219 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3505, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2155, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1811, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1629, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1647, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1326, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.1093, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7227\n",
      "Epoch 9/10, Train Loss: 0.0844, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Model 3 - Iteration 300: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.82927632331848 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7245\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.465321063995361 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3377, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2043, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1848, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1437, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1518, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7664\n",
      "Epoch 7/10, Train Loss: 0.1199, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.7454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7652\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7512\n",
      "Model 1 - Iteration 310: Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.68971037864685 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3517, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2095, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1504, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1575, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.1259, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.761\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Model 2 - Iteration 310: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.6561050415039 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.323, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2041, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1878, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Epoch 7/10, Train Loss: 0.1171, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.7633\n",
      "Epoch 8/10, Train Loss: 0.0839, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7952\n",
      "Model 3 - Iteration 310: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.8862452507019 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9715, F1 Micro: 0.9784, F1 Macro: 0.7293\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.373427629470825 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3455, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1831, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1985, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 6/10, Train Loss: 0.144, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1266, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Epoch 8/10, Train Loss: 0.1014, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0834, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7987\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.8033\n",
      "Model 1 - Iteration 320: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.96      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 65.23468136787415 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2077, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1885, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2024, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1621, Accuracy: 0.9658, F1 Micro: 0.9736, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1464, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1109, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0827, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "Model 2 - Iteration 320: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.28851008415222 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.333, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.206, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1996, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1812, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 6/10, Train Loss: 0.1473, Accuracy: 0.9539, F1 Micro: 0.9641, F1 Macro: 0.7108\n",
      "Epoch 7/10, Train Loss: 0.1267, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7688\n",
      "Model 3 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.73      0.83      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.0503888130188 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.733\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.263678789138794 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3496, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2126, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1804, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1688, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1593, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1347, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7356\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7402\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7521\n",
      "Model 1 - Iteration 330: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.98658204078674 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3669, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2153, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1705, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1621, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Epoch 7/10, Train Loss: 0.1395, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.7617\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7846\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 2 - Iteration 330: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.37453269958496 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3393, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2119, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.166, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1638, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1402, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.731\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 330: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.80876684188843 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9718, F1 Micro: 0.9786, F1 Macro: 0.7357\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.947092533111572 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3296, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2039, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.147, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.1526, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.7329\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7402\n",
      "Epoch 8/10, Train Loss: 0.0878, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0635, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7818\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7595\n",
      "Model 1 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.04250478744507 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3494, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1934, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1616, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7569\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7528\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7346\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7346\n",
      "Model 2 - Iteration 340: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 66.88294720649719 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3193, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2046, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1888, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.6495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1461, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.756\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7652\n",
      "Model 3 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.89896583557129 s\n",
      "Averaged - Iteration 340: Accuracy: 0.972, F1 Micro: 0.9787, F1 Macro: 0.7389\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.150299787521362 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3324, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1914, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.8023\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7567\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7585\n",
      "Model 1 - Iteration 350: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.98611283302307 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3484, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1311, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.11, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.779\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7751\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7409\n",
      "Model 2 - Iteration 350: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.9151656627655 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3198, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1882, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1745, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1355, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1117, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.7585\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.747\n",
      "Model 3 - Iteration 350: Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.72      0.79      0.75       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.84081983566284 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9721, F1 Micro: 0.9788, F1 Macro: 0.7406\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.540713310241699 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3308, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1903, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1734, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 5/10, Train Loss: 0.1637, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1361, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7534\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7809\n",
      "Model 1 - Iteration 360: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 71.44397711753845 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3454, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1926, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1745, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1695, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 2 - Iteration 360: Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.99052500724792 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3176, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1906, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7577\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7466\n",
      "Model 3 - Iteration 360: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.71132135391235 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9723, F1 Micro: 0.9789, F1 Macro: 0.7432\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.1366982460021973 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3265, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1647, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1634, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.138, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7218\n",
      "Epoch 7/10, Train Loss: 0.0957, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9643, F1 Micro: 0.9731, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7439\n",
      "Model 1 - Iteration 370: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.89297366142273 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3378, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1611, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.1469, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7687\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7328\n",
      "Model 2 - Iteration 370: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.88826084136963 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3075, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1631, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1557, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.1399, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.081, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7317\n",
      "Epoch 9/10, Train Loss: 0.0515, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0512, Accuracy: 0.9777, F1 Micro: 0.9831, F1 Macro: 0.8236\n",
      "Model 3 - Iteration 370: Accuracy: 0.9777, F1 Micro: 0.9831, F1 Macro: 0.8236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.83      0.82       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 74.56272530555725 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9725, F1 Micro: 0.9791, F1 Macro: 0.7463\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4522948265075684 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3105, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1735, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1793, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1538, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.126, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0634, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7595\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7393\n",
      "Model 1 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.10860562324524 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3234, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1761, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1583, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1301, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.0664, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7679\n",
      "Model 2 - Iteration 380: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.21842241287231 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.296, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1711, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1804, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1523, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1176, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7486\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7643\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.71      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.92768597602844 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9725, F1 Micro: 0.9791, F1 Macro: 0.7471\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.962644338607788 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3172, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1758, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1491, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1329, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7944\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.8033\n",
      "Model 1 - Iteration 390: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.46027088165283 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3263, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1783, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1304, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0942, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7885\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9628, F1 Micro: 0.9713, F1 Macro: 0.7912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7353\n",
      "Model 2 - Iteration 390: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 75.99233078956604 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2965, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1656, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1487, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1192, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7402\n",
      "Epoch 7/10, Train Loss: 0.0837, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7577\n",
      "Model 3 - Iteration 390: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.73      0.79      0.76       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 77.88717126846313 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9726, F1 Micro: 0.9792, F1 Macro: 0.7487\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.475881576538086 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3068, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1736, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1574, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.0987, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7227\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7384\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7449\n",
      "Model 1 - Iteration 400: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.70      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 71.83664536476135 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3272, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1761, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1675, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1452, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.1022, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7679\n",
      "Epoch 9/10, Train Loss: 0.0487, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7752\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7441\n",
      "Model 2 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 72.40436053276062 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2969, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1733, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1563, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7532\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7625\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7439\n",
      "Model 3 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 72.82945346832275 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9727, F1 Micro: 0.9792, F1 Macro: 0.7498\n",
      "Total sampling time: 207.35 seconds\n",
      "Total runtime: 4869.004877567291 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c4d32",
   "metadata": {
    "papermill": {
     "duration": 0.17521,
     "end_time": "2025-01-28T10:31:19.322680",
     "exception": false,
     "start_time": "2025-01-28T10:31:19.147470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6e467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 2\n",
      "Random seed: [81, 90, 11]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.729, Accuracy: 0.8631, F1 Micro: 0.9017, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5287, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3941, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3215, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2834, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2603, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2039, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1971, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1658, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1961, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 37.0333776473999 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6703, Accuracy: 0.9524, F1 Micro: 0.9636, F1 Macro: 0.6474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3514, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2824, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2493, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2304, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1774, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1638, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.187, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.99708127975464 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6306, Accuracy: 0.881, F1 Micro: 0.9154, F1 Macro: 0.6678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.489, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.367, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3145, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2751, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2459, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.202, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1973, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1738, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1977, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 36.58040642738342 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 16.986857652664185 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.623, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2698, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.202, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1855, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1911, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1482, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1487, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1374, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1361, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.34528636932373 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5645, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3288, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2383, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1752, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.178, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1412, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1439, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1341, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1308, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.561328649520874 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5494, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3421, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2605, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2024, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1868, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1889, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1494, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1502, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1361, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1387, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 41.302767753601074 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 16.543762683868408 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5156, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2455, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.121, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1517, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1281, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1335, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 10/10, Train Loss: 0.1215, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6537\n",
      "Model 1 - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 42.306899070739746 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4701, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2169, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1144, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1244, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1268, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 10/10, Train Loss: 0.114, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 2 - Iteration 97: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 42.54634475708008 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4545, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1508, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1222, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1452, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.13, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1359, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1199, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Model 3 - Iteration 97: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 43.703248023986816 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9669, F1 Micro: 0.9749, F1 Macro: 0.6545\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 14.902961254119873 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4883, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.239, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1472, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1436, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1262, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1254, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1243, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Model 1 - Iteration 128: Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.98      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 46.2161865234375 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4499, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2192, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.162, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1438, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1349, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1225, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1177, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.117, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Model 2 - Iteration 128: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 45.784119844436646 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4395, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2359, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1749, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1459, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1424, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1297, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1262, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1266, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Model 3 - Iteration 128: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 46.63508725166321 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9676, F1 Micro: 0.9754, F1 Macro: 0.6549\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 13.755214929580688 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4516, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2413, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2033, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1684, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1262, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1233, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 10/10, Train Loss: 0.1037, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 1 - Iteration 156: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 47.38105845451355 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4204, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2292, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1786, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1375, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.161, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 8/10, Train Loss: 0.1183, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1189, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0992, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Model 2 - Iteration 156: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 47.856303215026855 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4192, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2414, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.205, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1342, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1722, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1349, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1294, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1219, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Model 3 - Iteration 156: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 49.55726718902588 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9683, F1 Micro: 0.9759, F1 Macro: 0.6552\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.13783884048462 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4242, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2207, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1924, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.195, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1725, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1348, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.1139, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6515\n",
      "Epoch 9/10, Train Loss: 0.0847, Accuracy: 0.9524, F1 Micro: 0.963, F1 Macro: 0.6446\n",
      "Epoch 10/10, Train Loss: 0.0842, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.7286\n",
      "Model 1 - Iteration 181: Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.98      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 48.63688325881958 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3912, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2125, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.187, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1953, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1658, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1284, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1241, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 8/10, Train Loss: 0.11, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6559\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 10/10, Train Loss: 0.0792, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.654\n",
      "Model 2 - Iteration 181: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 48.78320050239563 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3883, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2249, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1911, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1722, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1399, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1396, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1282, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 9/10, Train Loss: 0.0995, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.0917, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Model 3 - Iteration 181: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 51.15170240402222 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9686, F1 Micro: 0.9761, F1 Macro: 0.6553\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.878174543380737 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4043, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2152, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1858, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2032, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1616, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1629, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.1056, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.0982, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0731, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7513\n",
      "Model 1 - Iteration 203: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.76      0.75      0.75       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 50.92510747909546 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3687, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2075, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2003, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1575, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.164, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1109, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1046, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 10/10, Train Loss: 0.0827, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.656\n",
      "Model 2 - Iteration 203: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 51.18635892868042 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2148, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1997, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.165, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1374, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.1119, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.108, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.077, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7191\n",
      "Model 3 - Iteration 203: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 49.32942175865173 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9689, F1 Micro: 0.9763, F1 Macro: 0.66\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 10.050333023071289 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4032, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1971, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1627, Accuracy: 0.9598, F1 Micro: 0.9689, F1 Macro: 0.6493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1464, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 8/10, Train Loss: 0.1141, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0831, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7506\n",
      "Model 1 - Iteration 223: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.75      0.75       439\n",
      "weighted avg       0.96      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 50.56891131401062 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3638, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.19, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1822, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1682, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.155, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 7/10, Train Loss: 0.1434, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.1063, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6515\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7116\n",
      "Model 2 - Iteration 223: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.73      0.70      0.71       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 49.45758128166199 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3652, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1959, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1842, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1739, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.168, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1474, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1204, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.097, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6552\n",
      "Epoch 10/10, Train Loss: 0.0815, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7293\n",
      "Model 3 - Iteration 223: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 52.342759132385254 s\n",
      "Averaged - Iteration 223: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.6657\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 9.137323379516602 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3819, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2093, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1866, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1797, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1297, Accuracy: 0.9568, F1 Micro: 0.9665, F1 Macro: 0.6472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1127, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7469\n",
      "Epoch 8/10, Train Loss: 0.092, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7637\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7669\n",
      "Model 1 - Iteration 241: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.96      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.75      0.78      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 54.07024550437927 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3454, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1832, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1712, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 6/10, Train Loss: 0.1234, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7116\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.7146\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7217\n",
      "Model 2 - Iteration 241: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 51.15584969520569 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.35, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2099, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1334, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7293\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7099\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7069\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7534\n",
      "Model 3 - Iteration 241: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.71      0.75      0.73       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 52.825390577316284 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9692, F1 Micro: 0.9766, F1 Macro: 0.6715\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.169477462768555 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3829, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1883, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2035, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.176, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 6/10, Train Loss: 0.1728, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 7/10, Train Loss: 0.1324, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6515\n",
      "Epoch 8/10, Train Loss: 0.1128, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0752, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Model 1 - Iteration 250: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.77568244934082 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3518, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1819, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2021, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1729, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 6/10, Train Loss: 0.1642, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 7/10, Train Loss: 0.1312, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0948, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7384\n",
      "Model 2 - Iteration 250: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.73      0.75      0.74       439\n",
      "weighted avg       0.96      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 53.410632848739624 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3539, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1877, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1817, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1762, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Epoch 8/10, Train Loss: 0.1351, Accuracy: 0.9628, F1 Micro: 0.9712, F1 Macro: 0.6511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0997, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0816, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7505\n",
      "Model 3 - Iteration 250: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.76      0.75      0.75       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 56.26869225502014 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9694, F1 Micro: 0.9767, F1 Macro: 0.6806\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.714063882827759 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3572, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1773, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1802, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1643, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1313, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1145, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7987\n",
      "Model 1 - Iteration 265: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.334219217300415 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3299, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2017, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1733, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.176, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7124\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7117\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "Model 2 - Iteration 265: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.74      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 55.943857192993164 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3368, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2082, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1407, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1258, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7812\n",
      "Epoch 8/10, Train Loss: 0.0951, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7972\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7963\n",
      "Model 3 - Iteration 265: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 56.110252380371094 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9698, F1 Micro: 0.977, F1 Macro: 0.6899\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.398010969161987 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.368, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1853, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1834, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.1316, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.108, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7652\n",
      "Model 1 - Iteration 279: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.7389030456543 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3446, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1811, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1362, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7217\n",
      "Epoch 8/10, Train Loss: 0.0952, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "Model 2 - Iteration 279: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.58731007575989 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3464, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1873, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1596, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1409, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1149, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7569\n",
      "Model 3 - Iteration 279: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.73      0.79      0.76       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.9155490398407 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9701, F1 Micro: 0.9772, F1 Macro: 0.6969\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.500850439071655 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3459, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1904, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1867, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1654, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1721, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1403, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7217\n",
      "Epoch 7/10, Train Loss: 0.0894, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0743, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7679\n",
      "Model 1 - Iteration 292: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.42100214958191 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3183, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1865, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 5/10, Train Loss: 0.1704, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1457, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7402\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.7835\n",
      "Model 2 - Iteration 292: Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.7835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.99      0.96        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.223358154296875 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3222, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1898, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1868, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1774, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1526, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7469\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Model 3 - Iteration 292: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.559388637542725 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9705, F1 Micro: 0.9776, F1 Macro: 0.7039\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.846402883529663 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3485, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1966, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1661, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1254, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7983\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Model 1 - Iteration 300: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.010793685913086 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3179, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1913, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1637, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1623, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1511, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.141, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.1261, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "Epoch 10/10, Train Loss: 0.0662, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "Model 2 - Iteration 300: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 60.251652002334595 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3246, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.195, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1526, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1341, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 9/10, Train Loss: 0.0907, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Model 3 - Iteration 300: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.86746597290039 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9708, F1 Micro: 0.9778, F1 Macro: 0.71\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.80726170539856 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3462, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1875, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1849, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1825, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1381, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.1022, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7789\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7548\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7665\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9688, F1 Micro: 0.9759, F1 Macro: 0.7949\n",
      "Model 1 - Iteration 310: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.272594928741455 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3232, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1827, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1812, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1785, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1352, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.741\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "Model 2 - Iteration 310: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.73      0.75      0.74       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.14107823371887 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3218, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1826, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1633, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1418, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1144, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Epoch 8/10, Train Loss: 0.1002, Accuracy: 0.9628, F1 Micro: 0.9713, F1 Macro: 0.7605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 3 - Iteration 310: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.30626368522644 s\n",
      "Averaged - Iteration 310: Accuracy: 0.971, F1 Micro: 0.978, F1 Macro: 0.7146\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.0883629322052 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3527, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2127, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1884, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1594, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1126, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7519\n",
      "Model 1 - Iteration 320: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.6776487827301 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3266, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2073, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1765, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1892, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9628, F1 Micro: 0.9712, F1 Macro: 0.6511\n",
      "Epoch 7/10, Train Loss: 0.1146, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7243\n",
      "Epoch 9/10, Train Loss: 0.0878, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.741\n",
      "Epoch 10/10, Train Loss: 0.0548, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 320: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.71      0.72       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.625203132629395 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3316, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2115, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1783, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1911, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1633, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1327, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1008, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7673\n",
      "Epoch 9/10, Train Loss: 0.0922, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7634\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7384\n",
      "Model 3 - Iteration 320: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.85027194023132 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7177\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.593877553939819 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3304, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1962, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1826, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1364, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7661\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7401\n",
      "Model 1 - Iteration 330: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.31269955635071 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3074, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1927, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1387, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7175\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7669\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.756\n",
      "Model 2 - Iteration 330: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.314900636672974 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3081, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1962, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1479, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1447, Accuracy: 0.9628, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1181, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0766, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7248\n",
      "Model 3 - Iteration 330: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.69924545288086 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9713, F1 Micro: 0.9782, F1 Macro: 0.7212\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.2505202293396 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.33, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1735, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7762\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7466\n",
      "Model 1 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.42582201957703 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3091, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2027, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1712, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1504, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1411, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0801, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7401\n",
      "Model 2 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.4445812702179 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3064, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2075, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1542, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7394\n",
      "Model 3 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.22350525856018 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9715, F1 Micro: 0.9784, F1 Macro: 0.725\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.030166149139404 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3457, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1823, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1694, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1648, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7892\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 1 - Iteration 350: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.648661851882935 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3214, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1801, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1613, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 6/10, Train Loss: 0.1234, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Epoch 7/10, Train Loss: 0.1, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7679\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7901\n",
      "Model 2 - Iteration 350: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.16757273674011 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3261, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1813, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1796, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.17, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1297, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1112, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7633\n",
      "Model 3 - Iteration 350: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.76944541931152 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7284\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.216259717941284 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3266, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8004\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.805\n",
      "Model 1 - Iteration 360: Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.56965684890747 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3032, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1866, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1741, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7652\n",
      "Epoch 9/10, Train Loss: 0.0439, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "Model 2 - Iteration 360: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.23218560218811 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3051, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1917, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1309, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7963\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.9628, F1 Micro: 0.9713, F1 Macro: 0.7912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.045, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.799\n",
      "Model 3 - Iteration 360: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.63710045814514 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9719, F1 Micro: 0.9786, F1 Macro: 0.7318\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.1922879219055176 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.317, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1982, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1076, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8041\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7625\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0466, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.805\n",
      "Model 1 - Iteration 370: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.78      0.83      0.81       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.48559236526489 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2922, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1943, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7679\n",
      "Epoch 7/10, Train Loss: 0.0747, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7513\n",
      "Epoch 10/10, Train Loss: 0.0371, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 370: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.10550713539124 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2987, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.196, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1603, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1588, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1557, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9613, F1 Micro: 0.9702, F1 Macro: 0.7162\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9658, F1 Micro: 0.9736, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.7432\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7652\n",
      "Model 3 - Iteration 370: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 67.25635170936584 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9721, F1 Micro: 0.9788, F1 Macro: 0.7351\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2641561031341553 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3085, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.149, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7569\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.7623\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Model 1 - Iteration 380: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 70.4209668636322 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.286, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1812, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 6/10, Train Loss: 0.1222, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7753\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.791\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7401\n",
      "Model 2 - Iteration 380: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.65631031990051 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2899, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1827, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1676, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1553, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Model 3 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.2848699092865 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9722, F1 Micro: 0.9788, F1 Macro: 0.7376\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8763539791107178 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3008, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1678, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1472, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1375, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0469, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7932\n",
      "Model 1 - Iteration 390: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.57134866714478 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2782, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1635, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1459, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9628, F1 Micro: 0.9718, F1 Macro: 0.7107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6577\n",
      "Epoch 8/10, Train Loss: 0.0669, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7587\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7373\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.752\n",
      "Model 2 - Iteration 390: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 68.55449151992798 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2858, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1469, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1242, Accuracy: 0.9613, F1 Micro: 0.9706, F1 Macro: 0.7097\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Model 3 - Iteration 390: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.88853788375854 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9722, F1 Micro: 0.9789, F1 Macro: 0.7382\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4199886322021484 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3075, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.186, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1341, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.122, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Model 1 - Iteration 400: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.76906418800354 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2843, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1818, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1496, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1293, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6577\n",
      "Epoch 7/10, Train Loss: 0.1012, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "Model 2 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.17638635635376 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2867, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1837, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1494, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "Model 3 - Iteration 400: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.7627968788147 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9724, F1 Micro: 0.979, F1 Macro: 0.7404\n",
      "Total sampling time: 176.76 seconds\n",
      "Total runtime: 4618.34815621376 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33d617",
   "metadata": {
    "papermill": {
     "duration": 0.180233,
     "end_time": "2025-01-28T10:31:20.036789",
     "exception": false,
     "start_time": "2025-01-28T10:31:19.856556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 3\n",
      "Random seed: [14, 7, 33]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6307, Accuracy: 0.9613, F1 Micro: 0.9706, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4665, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3623, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3058, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2507, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.236, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1862, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1493, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1666, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1322, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.52430009841919 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.745, Accuracy: 0.8318, F1 Micro: 0.8546, F1 Macro: 0.497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.52, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3954, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3352, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2775, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2458, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1904, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1544, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1725, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1346, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.495742082595825 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6258, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4344, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3563, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.293, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.245, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2233, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1817, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1451, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1698, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1324, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.472771406173706 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 18.89532971382141 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3329, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2355, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2134, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2001, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1591, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1527, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1367, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1429, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1462, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.76745557785034 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6424, Accuracy: 0.9226, F1 Micro: 0.9378, F1 Macro: 0.6195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3664, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.261, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2245, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2091, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1646, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1531, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1394, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1462, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1515, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.609875202178955 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5428, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3195, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2329, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2007, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1577, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1552, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1398, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1457, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1507, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 40.28517556190491 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 16.862927198410034 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2526, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1417, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1498, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1649, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1318, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 9/10, Train Loss: 0.1477, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "Epoch 10/10, Train Loss: 0.0999, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 97: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.39639902114868 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2722, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.193, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1469, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.153, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1738, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1411, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1634, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1111, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Model 2 - Iteration 97: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 46.60721230506897 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4545, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2426, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.184, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1759, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1441, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1653, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1124, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Model 3 - Iteration 97: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 47.37489604949951 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6542\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 14.96950364112854 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4474, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2596, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1899, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2041, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1997, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1774, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1513, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1439, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1539, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 10/10, Train Loss: 0.1326, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 128: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 45.91772127151489 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2721, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2084, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2033, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1765, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1524, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1494, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1643, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1433, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Model 2 - Iteration 128: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 48.25507950782776 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4351, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2569, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1911, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2081, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2036, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1839, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1534, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1492, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1707, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1599, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 128: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 47.661044120788574 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9666, F1 Micro: 0.9747, F1 Macro: 0.6544\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 13.34987998008728 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4085, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.237, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2178, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2011, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1769, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1661, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1592, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1283, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1307, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1287, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Model 1 - Iteration 156: Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.97      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 49.544220209121704 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4583, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2456, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2191, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2007, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1765, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1621, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1376, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.14, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1318, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 2 - Iteration 156: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 51.91378426551819 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3979, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2343, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2196, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2018, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1779, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1704, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1688, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1472, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1517, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1528, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Model 3 - Iteration 156: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 51.39199209213257 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9669, F1 Micro: 0.9749, F1 Macro: 0.6545\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.37257719039917 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2089, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1562, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1599, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1546, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1446, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1091, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 10/10, Train Loss: 0.0935, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Model 1 - Iteration 181: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 52.856828689575195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4432, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2147, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1834, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1555, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1427, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1132, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0869, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7229\n",
      "Model 2 - Iteration 181: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.71      0.72       439\n",
      "weighted avg       0.97      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.139976263046265 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3849, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2071, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1842, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1635, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1627, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 8/10, Train Loss: 0.1574, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6515\n",
      "Epoch 9/10, Train Loss: 0.1318, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6526\n",
      "Epoch 10/10, Train Loss: 0.1118, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6527\n",
      "Model 3 - Iteration 181: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 49.14746141433716 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6583\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 11.111387729644775 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3833, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2035, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2062, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1698, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1641, Accuracy: 0.9613, F1 Micro: 0.9706, F1 Macro: 0.6514\n",
      "Epoch 7/10, Train Loss: 0.1365, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1198, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 10/10, Train Loss: 0.0936, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "Model 1 - Iteration 203: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 49.45640730857849 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4275, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2103, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2076, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1686, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1702, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1439, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1274, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0944, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7681\n",
      "Epoch 10/10, Train Loss: 0.0919, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.767\n",
      "Model 2 - Iteration 203: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.645416259765625 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3726, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2023, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1721, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1727, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1514, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 8/10, Train Loss: 0.1401, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1155, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.1077, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Model 3 - Iteration 203: Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.97      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 53.28205394744873 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9677, F1 Micro: 0.9755, F1 Macro: 0.6632\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.920040607452393 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3709, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2163, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1982, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1815, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1942, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1832, Accuracy: 0.9628, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Epoch 7/10, Train Loss: 0.1476, Accuracy: 0.9494, F1 Micro: 0.9606, F1 Macro: 0.6426\n",
      "Epoch 8/10, Train Loss: 0.1318, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.6536\n",
      "Epoch 9/10, Train Loss: 0.1248, Accuracy: 0.9524, F1 Micro: 0.963, F1 Macro: 0.6446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0733, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Model 1 - Iteration 223: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 50.81152558326721 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.414, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2201, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1783, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1977, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1824, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.143, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1306, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Model 2 - Iteration 223: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 55.932661056518555 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.36, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2131, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2058, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.189, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1587, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1473, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1476, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0906, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Model 3 - Iteration 223: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 55.46466135978699 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.6681\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.919959306716919 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3457, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2243, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1745, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1786, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.138, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1115, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Model 1 - Iteration 241: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.71      0.72       439\n",
      "weighted avg       0.97      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 59.65775942802429 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3836, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2277, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1862, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1741, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1277, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Epoch 8/10, Train Loss: 0.1038, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7586\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7554\n",
      "Model 2 - Iteration 241: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 56.22822403907776 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3322, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2201, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1851, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1784, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1934, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1512, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1358, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1053, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7665\n",
      "Model 3 - Iteration 241: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 57.93148112297058 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9686, F1 Micro: 0.9761, F1 Macro: 0.6776\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.258118867874146 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3509, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1927, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1755, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1631, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.1209, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 9/10, Train Loss: 0.0975, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7375\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9554, F1 Micro: 0.9654, F1 Macro: 0.7558\n",
      "Model 1 - Iteration 250: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 56.32528114318848 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3869, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1955, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1727, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1499, Accuracy: 0.9658, F1 Micro: 0.9743, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1113, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.1086, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0885, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7818\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7559\n",
      "Model 2 - Iteration 250: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 57.966835260391235 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3455, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1956, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1813, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1708, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1353, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.1367, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.7152\n",
      "Epoch 9/10, Train Loss: 0.1116, Accuracy: 0.9524, F1 Micro: 0.963, F1 Macro: 0.7842\n",
      "Epoch 10/10, Train Loss: 0.0852, Accuracy: 0.9613, F1 Micro: 0.9704, F1 Macro: 0.7421\n",
      "Model 3 - Iteration 250: Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.95      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.97      0.97       439\n",
      " samples avg       0.98      0.97      0.97       439\n",
      "\n",
      "Training completed in 56.5552191734314 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6795\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.687280654907227 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3546, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2117, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1917, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1844, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 7/10, Train Loss: 0.1404, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7012\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7098\n",
      "Model 1 - Iteration 265: Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.73      0.70      0.71       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 59.602490186691284 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3856, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2136, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.194, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1859, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.9702, F1 Micro: 0.9776, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1365, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.096, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7933\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "Model 2 - Iteration 265: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.01167035102844 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.336, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2105, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1925, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1773, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1564, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1104, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7658\n",
      "Epoch 9/10, Train Loss: 0.0899, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7933\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7324\n",
      "Model 3 - Iteration 265: Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.96      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 59.36856126785278 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9689, F1 Micro: 0.9764, F1 Macro: 0.6867\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.016962051391602 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3494, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2056, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1738, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1728, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1573, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1208, Accuracy: 0.9598, F1 Micro: 0.9696, F1 Macro: 0.6847\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.9598, F1 Micro: 0.9689, F1 Macro: 0.6493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7211\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7645\n",
      "Model 1 - Iteration 279: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.98      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.81      0.70      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 60.58752226829529 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3781, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2059, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1895, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1341, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7976\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.7696\n",
      "Epoch 8/10, Train Loss: 0.0947, Accuracy: 0.9613, F1 Micro: 0.9708, F1 Macro: 0.7376\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Model 2 - Iteration 279: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.914063692092896 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3398, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.203, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1969, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1795, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1734, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 7/10, Train Loss: 0.1266, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.745\n",
      "Epoch 8/10, Train Loss: 0.1111, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7924\n",
      "Epoch 9/10, Train Loss: 0.0794, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7924\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7952\n",
      "Model 3 - Iteration 279: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 58.969552516937256 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9691, F1 Micro: 0.9765, F1 Macro: 0.6899\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.662156343460083 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3374, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1867, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.187, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1727, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1501, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 7/10, Train Loss: 0.1155, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7027\n",
      "Epoch 8/10, Train Loss: 0.1058, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7805\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.7606\n",
      "Model 1 - Iteration 292: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.9754056930542 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3677, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1879, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1434, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7499\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9658, F1 Micro: 0.9736, F1 Macro: 0.793\n",
      "Epoch 8/10, Train Loss: 0.105, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7521\n",
      "Model 2 - Iteration 292: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.705825090408325 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3279, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1867, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1892, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1772, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1626, Accuracy: 0.9628, F1 Micro: 0.9717, F1 Macro: 0.6521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1334, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1218, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0918, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.7597\n",
      "Model 3 - Iteration 292: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.71842575073242 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9694, F1 Micro: 0.9768, F1 Macro: 0.6978\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.945096969604492 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3351, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2024, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1915, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1737, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1527, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1283, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6568\n",
      "Epoch 8/10, Train Loss: 0.1013, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6515\n",
      "Epoch 9/10, Train Loss: 0.0793, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7793\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7965\n",
      "Model 1 - Iteration 300: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.954402446746826 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3661, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2027, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1919, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1732, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7998\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Epoch 9/10, Train Loss: 0.074, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7894\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7502\n",
      "Model 2 - Iteration 300: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.23625564575195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3248, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2035, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1935, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1562, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1823, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1439, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6577\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.9554, F1 Micro: 0.9654, F1 Macro: 0.7555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0894, Accuracy: 0.9762, F1 Micro: 0.9818, F1 Macro: 0.7996\n",
      "Epoch 10/10, Train Loss: 0.073, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 300: Accuracy: 0.9762, F1 Micro: 0.9818, F1 Macro: 0.7996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 60.94557809829712 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9698, F1 Micro: 0.9771, F1 Macro: 0.7017\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.842302083969116 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3239, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1858, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1798, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6554\n",
      "Epoch 7/10, Train Loss: 0.1253, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0855, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.7565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "Model 1 - Iteration 310: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.05557155609131 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3571, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1808, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1853, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1666, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7651\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7551\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9777, F1 Micro: 0.9831, F1 Macro: 0.8006\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9628, F1 Micro: 0.972, F1 Macro: 0.7344\n",
      "Model 2 - Iteration 310: Accuracy: 0.9777, F1 Micro: 0.9831, F1 Macro: 0.8006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.351114988327026 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3168, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1796, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1818, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1814, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1403, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0713, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Model 3 - Iteration 310: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.95      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.76818060874939 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9701, F1 Micro: 0.9773, F1 Macro: 0.7078\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.103864908218384 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3235, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2045, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1796, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1527, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9524, F1 Micro: 0.963, F1 Macro: 0.7101\n",
      "Epoch 8/10, Train Loss: 0.0926, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.7724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0798, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Model 1 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.337127923965454 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3525, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2036, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1564, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1373, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7998\n",
      "Epoch 7/10, Train Loss: 0.0957, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0821, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7876\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "Model 2 - Iteration 320: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.12369465827942 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3167, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2055, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1802, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1595, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1788, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1743, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1147, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0952, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Model 3 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 66.09763813018799 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9704, F1 Micro: 0.9775, F1 Macro: 0.7134\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.998850345611572 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3219, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1998, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1232, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0925, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7812\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.7716\n",
      "Model 1 - Iteration 330: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.61045265197754 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3478, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1976, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1738, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1554, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1044, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7998\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7885\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9688, F1 Micro: 0.9759, F1 Macro: 0.7949\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.768\n",
      "Model 2 - Iteration 330: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.34995770454407 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3132, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1993, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1666, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1398, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1327, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "Epoch 8/10, Train Loss: 0.1026, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Epoch 9/10, Train Loss: 0.077, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7935\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.756\n",
      "Model 3 - Iteration 330: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 64.30231738090515 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7181\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.299192190170288 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3172, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1858, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1668, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.174, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 6/10, Train Loss: 0.1354, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6558\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7469\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9688, F1 Micro: 0.9759, F1 Macro: 0.7949\n",
      "Epoch 9/10, Train Loss: 0.0627, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7449\n",
      "Model 1 - Iteration 340: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.523597717285156 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3435, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1866, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1663, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7902\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 340: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.3984489440918 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3112, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1876, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1696, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1759, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1531, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.129, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.7141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7743\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.9643, F1 Micro: 0.9731, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7449\n",
      "Model 3 - Iteration 340: Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.93      0.92        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.75      0.82      0.77       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 64.50915050506592 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7193\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.702081918716431 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3243, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1871, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1374, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1163, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0836, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.8227\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Model 1 - Iteration 350: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.83      0.82       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 66.39452338218689 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3502, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1861, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.7448\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9628, F1 Micro: 0.9718, F1 Macro: 0.7383\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9628, F1 Micro: 0.9719, F1 Macro: 0.7384\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Model 2 - Iteration 350: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.68987679481506 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3153, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1877, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1449, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1273, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0781, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7602\n",
      "Model 3 - Iteration 350: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.44      1.00      0.62         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.72      0.83      0.76       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.04238152503967 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9708, F1 Micro: 0.9778, F1 Macro: 0.7233\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.513253927230835 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3014, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1736, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.182, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1615, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Epoch 6/10, Train Loss: 0.1467, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.6925\n",
      "Epoch 7/10, Train Loss: 0.1105, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Model 1 - Iteration 360: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.87523436546326 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3267, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1735, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9673, F1 Micro: 0.9754, F1 Macro: 0.7514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1341, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Epoch 7/10, Train Loss: 0.0997, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.8226\n",
      "Epoch 9/10, Train Loss: 0.066, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7602\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.767\n",
      "Model 2 - Iteration 360: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.8226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.83      0.82       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.42051768302917 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2932, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1741, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1717, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7651\n",
      "Epoch 7/10, Train Loss: 0.1234, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9554, F1 Micro: 0.9653, F1 Macro: 0.786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0751, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Model 3 - Iteration 360: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.77248787879944 s\n",
      "Averaged - Iteration 360: Accuracy: 0.971, F1 Micro: 0.9779, F1 Macro: 0.7269\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.757744073867798 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2961, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1826, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 6/10, Train Loss: 0.115, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0912, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7669\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7781\n",
      "Model 1 - Iteration 370: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.74      0.83      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.19263219833374 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.32, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1725, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7772\n",
      "Epoch 6/10, Train Loss: 0.0982, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7438\n",
      "Epoch 7/10, Train Loss: 0.0804, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 10/10, Train Loss: 0.0386, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7317\n",
      "Model 2 - Iteration 370: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.89826583862305 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.292, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1848, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1338, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0927, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9598, F1 Micro: 0.9695, F1 Macro: 0.7364\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7355\n",
      "Model 3 - Iteration 370: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 70.17027688026428 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9711, F1 Micro: 0.9781, F1 Macro: 0.73\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4186270236968994 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2939, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1839, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1645, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1623, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1594, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7227\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.7623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7645\n",
      "Model 1 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.67860770225525 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3165, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1842, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1076, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.778\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7402\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.75\n",
      "Model 2 - Iteration 380: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.07526540756226 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2828, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1822, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1662, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.9628, F1 Micro: 0.9713, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.7805\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7558\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9628, F1 Micro: 0.9717, F1 Macro: 0.7483\n",
      "Model 3 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.81132340431213 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9713, F1 Micro: 0.9781, F1 Macro: 0.7322\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8714549541473389 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2909, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1499, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0924, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7679\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9613, F1 Micro: 0.97, F1 Macro: 0.7901\n",
      "Model 1 - Iteration 390: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 73.74350261688232 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3127, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1509, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1537, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1237, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9583, F1 Micro: 0.9689, F1 Macro: 0.7256\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.9598, F1 Micro: 0.9696, F1 Macro: 0.7366\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7512\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7401\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7401\n",
      "Model 2 - Iteration 390: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.71621894836426 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2822, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1845, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1194, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 3 - Iteration 390: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 73.9428641796112 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9714, F1 Micro: 0.9783, F1 Macro: 0.7349\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3756449222564697 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2855, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1279, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7657\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7894\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7664\n",
      "Model 1 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.85325765609741 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3101, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.18, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1511, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9598, F1 Micro: 0.97, F1 Macro: 0.7331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.768\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0524, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.752\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.768\n",
      "Model 2 - Iteration 400: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.3396053314209 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2751, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.18, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1533, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1404, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.6567\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9613, F1 Micro: 0.9702, F1 Macro: 0.7603\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Model 3 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.03438758850098 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9716, F1 Micro: 0.9784, F1 Macro: 0.7371\n",
      "Total sampling time: 178.85 seconds\n",
      "Total runtime: 4719.362025499344 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d715a6",
   "metadata": {
    "papermill": {
     "duration": 0.186114,
     "end_time": "2025-01-28T10:31:20.791509",
     "exception": false,
     "start_time": "2025-01-28T10:31:20.605395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 4\n",
      "Random seed: [3, 44, 85]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6126, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4357, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3375, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2836, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2449, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2302, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1839, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1819, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1606, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1907, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.78120303153992 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6621, Accuracy: 0.8661, F1 Micro: 0.9026, F1 Macro: 0.6463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4867, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3687, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2982, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2528, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2381, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1912, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1809, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1601, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.187, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 36.32634234428406 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5926, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4277, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3326, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.271, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2403, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2317, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1791, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.178, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1561, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1803, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.76842427253723 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 16.651413917541504 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5248, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3041, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2293, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1899, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.172, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1736, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1589, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.153, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1482, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1581, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.20077633857727 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5788, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3303, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1941, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1734, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1708, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1598, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1518, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1486, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1553, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 38.97668814659119 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5151, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2943, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1683, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1587, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1541, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1449, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1554, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 40.987462520599365 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 16.246240854263306 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4327, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2088, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1522, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1615, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1426, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1627, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1282, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.007277727127075 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4764, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2057, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1781, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1593, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1336, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1587, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1176, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Model 2 - Iteration 97: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 43.98249626159668 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4205, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2028, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2071, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1746, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1556, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1387, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1431, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1107, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.45980668067932 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6541\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 15.75223970413208 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4246, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2437, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.206, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1621, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1764, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1545, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1871, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1352, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 10/10, Train Loss: 0.1305, Accuracy: 0.9554, F1 Micro: 0.9658, F1 Macro: 0.6476\n",
      "Model 1 - Iteration 128: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.4255633354187 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4636, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2473, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.209, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1815, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1793, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1506, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1756, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1251, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 10/10, Train Loss: 0.116, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 2 - Iteration 128: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 45.52046465873718 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4237, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2346, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.206, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1774, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1715, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1481, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 8/10, Train Loss: 0.1641, Accuracy: 0.9628, F1 Micro: 0.9717, F1 Macro: 0.6521\n",
      "Epoch 9/10, Train Loss: 0.1132, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.6511\n",
      "Epoch 10/10, Train Loss: 0.1043, Accuracy: 0.9554, F1 Micro: 0.9656, F1 Macro: 0.647\n",
      "Model 3 - Iteration 128: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 41.020159006118774 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6542\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 13.715013980865479 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3835, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2249, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2066, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1546, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1595, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1443, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1081, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.6491\n",
      "Epoch 10/10, Train Loss: 0.1217, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.6487\n",
      "Model 1 - Iteration 156: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 46.78840112686157 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2289, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2076, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1658, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1535, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1539, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1353, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.095, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6526\n",
      "Epoch 10/10, Train Loss: 0.1046, Accuracy: 0.9554, F1 Micro: 0.9655, F1 Macro: 0.6468\n",
      "Model 2 - Iteration 156: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 46.39920997619629 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3791, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2233, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2049, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.166, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1485, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1356, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Epoch 10/10, Train Loss: 0.102, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.6497\n",
      "Model 3 - Iteration 156: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 46.46043586730957 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9662, F1 Micro: 0.9744, F1 Macro: 0.6542\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.551710367202759 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3707, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2396, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1984, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1866, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1616, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.149, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1374, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1315, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6537\n",
      "Epoch 10/10, Train Loss: 0.1034, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Model 1 - Iteration 181: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 50.769519329071045 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3963, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2382, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1572, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1412, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1294, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.1098, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0884, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Model 2 - Iteration 181: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 52.56332445144653 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3683, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2391, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.203, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1859, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.166, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1425, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1263, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 9/10, Train Loss: 0.1109, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.6497\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Model 3 - Iteration 181: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 49.17656683921814 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9666, F1 Micro: 0.9747, F1 Macro: 0.6544\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 11.15018606185913 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3577, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1603, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.164, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1614, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.137, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 9/10, Train Loss: 0.1182, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.6518\n",
      "Epoch 10/10, Train Loss: 0.1016, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.6486\n",
      "Model 1 - Iteration 203: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 51.58844828605652 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3832, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1903, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1498, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1556, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1489, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.1264, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.0994, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Epoch 10/10, Train Loss: 0.0871, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6531\n",
      "Model 2 - Iteration 203: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 49.48532581329346 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3503, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1613, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1497, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.1397, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 8/10, Train Loss: 0.119, Accuracy: 0.9524, F1 Micro: 0.963, F1 Macro: 0.6446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 10/10, Train Loss: 0.088, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6531\n",
      "Model 3 - Iteration 203: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 48.181596517562866 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9671, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 10.203853130340576 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3595, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2053, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1911, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1753, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1428, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1397, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1216, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.6518\n",
      "Epoch 10/10, Train Loss: 0.0966, Accuracy: 0.9568, F1 Micro: 0.9668, F1 Macro: 0.6487\n",
      "Model 1 - Iteration 223: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 53.52865767478943 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1857, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1818, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1822, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1774, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1313, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.1293, Accuracy: 0.9598, F1 Micro: 0.9689, F1 Macro: 0.6493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1182, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0872, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Model 2 - Iteration 223: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 54.29932904243469 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3606, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.207, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.174, Accuracy: 0.9554, F1 Micro: 0.9658, F1 Macro: 0.6474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1743, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 7/10, Train Loss: 0.1285, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6508\n",
      "Epoch 8/10, Train Loss: 0.1258, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.6486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1146, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0918, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Model 3 - Iteration 223: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.71      0.72       439\n",
      "weighted avg       0.97      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 51.90944218635559 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9674, F1 Micro: 0.9753, F1 Macro: 0.6575\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 9.462226867675781 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3297, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1896, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1729, Accuracy: 0.9598, F1 Micro: 0.9694, F1 Macro: 0.6505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1468, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1245, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 9/10, Train Loss: 0.1192, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0768, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7211\n",
      "Model 1 - Iteration 241: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.98      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.81      0.70      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 56.48762559890747 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3506, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1965, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1881, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1762, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1694, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1361, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6979\n",
      "Epoch 9/10, Train Loss: 0.1017, Accuracy: 0.9628, F1 Micro: 0.9718, F1 Macro: 0.6915\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.7264\n",
      "Model 2 - Iteration 241: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 54.5774085521698 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3258, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1969, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.151, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1559, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1128, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 8/10, Train Loss: 0.0963, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7031\n",
      "Epoch 9/10, Train Loss: 0.0894, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Model 3 - Iteration 241: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.87510061264038 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9678, F1 Micro: 0.9756, F1 Macro: 0.665\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.27743935585022 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3393, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2116, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1548, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1347, Accuracy: 0.9613, F1 Micro: 0.9704, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.697\n",
      "Epoch 9/10, Train Loss: 0.0863, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0812, Accuracy: 0.9568, F1 Micro: 0.9667, F1 Macro: 0.7032\n",
      "Model 1 - Iteration 250: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.25      0.25      0.25         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.69      0.71      0.70       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 55.14173746109009 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3588, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.216, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2045, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1635, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0756, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7116\n",
      "Model 2 - Iteration 250: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.73      0.70      0.71       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 55.176644802093506 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.331, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2146, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1613, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1573, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 7/10, Train Loss: 0.1263, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7666\n",
      "Epoch 9/10, Train Loss: 0.0785, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0729, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Model 3 - Iteration 250: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 55.16752076148987 s\n",
      "Averaged - Iteration 250: Accuracy: 0.968, F1 Micro: 0.9757, F1 Macro: 0.6711\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 9.056970596313477 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3168, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1747, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1568, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1469, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1112, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7118\n",
      "Epoch 9/10, Train Loss: 0.0944, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Model 1 - Iteration 265: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 58.0306601524353 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3371, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1968, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1818, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.152, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1448, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 8/10, Train Loss: 0.1075, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7283\n",
      "Epoch 9/10, Train Loss: 0.09, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.7494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7233\n",
      "Model 2 - Iteration 265: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.93      0.96      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.70      0.72       439\n",
      "weighted avg       0.98      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 56.622056007385254 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3079, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1963, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1615, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1477, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1301, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0945, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7661\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 265: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 59.89294981956482 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9685, F1 Micro: 0.9761, F1 Macro: 0.6794\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.223835706710815 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3212, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1752, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.131, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1177, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.721\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7626\n",
      "Model 1 - Iteration 279: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.13728737831116 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3418, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1897, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1835, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1514, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1212, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0772, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7108\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7106\n",
      "Model 2 - Iteration 279: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.73      0.70      0.71       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 59.24282956123352 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3177, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1659, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1387, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1086, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.0962, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "Model 3 - Iteration 279: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.78      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.589815616607666 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6825\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.583129644393921 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.316, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1794, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1666, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1619, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1429, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 8/10, Train Loss: 0.1176, Accuracy: 0.9628, F1 Micro: 0.9721, F1 Macro: 0.7346\n",
      "Epoch 9/10, Train Loss: 0.1114, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.7329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7402\n",
      "Model 1 - Iteration 292: Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       439\n",
      "   macro avg       0.71      0.79      0.74       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.054805755615234 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3346, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1811, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1566, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1227, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7664\n",
      "Epoch 9/10, Train Loss: 0.0912, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7477\n",
      "Model 2 - Iteration 292: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.72      0.79      0.75       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.05728530883789 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.314, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1786, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1592, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1399, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7295\n",
      "Epoch 8/10, Train Loss: 0.0925, Accuracy: 0.9613, F1 Micro: 0.971, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "Model 3 - Iteration 292: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.860013246536255 s\n",
      "Averaged - Iteration 292: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.6882\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.8823254108428955 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.32, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2015, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1751, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1757, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1629, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1481, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 7/10, Train Loss: 0.1354, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7665\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9628, F1 Micro: 0.972, F1 Macro: 0.7386\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7442\n",
      "Model 1 - Iteration 300: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.91668701171875 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.338, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2028, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1591, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1386, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 7/10, Train Loss: 0.1231, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0898, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7217\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7219\n",
      "Model 2 - Iteration 300: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.81      0.70      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.45529556274414 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3155, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2004, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1257, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1133, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.8043\n",
      "Model 3 - Iteration 300: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.8043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.78      0.83      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.90320634841919 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9692, F1 Micro: 0.9766, F1 Macro: 0.6936\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.586451530456543 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.304, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1697, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1649, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1288, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7868\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7569\n",
      "Epoch 9/10, Train Loss: 0.055, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.8023\n",
      "Model 1 - Iteration 310: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.8023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.95      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.78      0.82      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 64.28121066093445 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3223, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1729, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1635, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.145, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7987\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9702, F1 Micro: 0.9771, F1 Macro: 0.7958\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Model 2 - Iteration 310: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.96      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 64.44969367980957 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2994, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1719, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1749, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1836, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1543, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Epoch 7/10, Train Loss: 0.1145, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7727\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7982\n",
      "Model 3 - Iteration 310: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.36224246025085 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9695, F1 Micro: 0.9768, F1 Macro: 0.7007\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.164455890655518 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3171, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2082, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.193, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1389, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1257, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7982\n",
      "Epoch 8/10, Train Loss: 0.1011, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0808, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.8034\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.82\n",
      "Model 1 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.8034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.78      0.83      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.77592325210571 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3341, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1716, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1396, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.721\n",
      "Epoch 7/10, Train Loss: 0.1236, Accuracy: 0.9613, F1 Micro: 0.97, F1 Macro: 0.7158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0886, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7511\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7677\n",
      "Model 2 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.06104373931885 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3149, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2091, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1918, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1668, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1255, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Epoch 7/10, Train Loss: 0.1192, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7513\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7663\n",
      "Model 3 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.9857702255249 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9697, F1 Micro: 0.977, F1 Macro: 0.7066\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.727051258087158 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3069, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1871, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1654, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7982\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9613, F1 Micro: 0.971, F1 Macro: 0.7339\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9613, F1 Micro: 0.9704, F1 Macro: 0.7828\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9628, F1 Micro: 0.9719, F1 Macro: 0.7431\n",
      "Model 1 - Iteration 330: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.48029899597168 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3274, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1903, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1833, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1615, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1424, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7656\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0752, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7807\n",
      "Model 2 - Iteration 330: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.93      0.95      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.78      0.78      0.78       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 67.70708966255188 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3054, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1898, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1805, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1562, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7226\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7555\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7384\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9598, F1 Micro: 0.9696, F1 Macro: 0.7422\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7448\n",
      "Model 3 - Iteration 330: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.70      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.346646308898926 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7101\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.25272274017334 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2961, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2016, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1758, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.156, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.121, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0974, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8218\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.7706\n",
      "Model 1 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.83      0.82       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.073322057724 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3097, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2029, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1762, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1574, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.128, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7894\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9658, F1 Micro: 0.9735, F1 Macro: 0.7928\n",
      "Model 2 - Iteration 340: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 66.072270154953 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2916, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2038, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1475, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 7/10, Train Loss: 0.1054, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7543\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7793\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7762\n",
      "Model 3 - Iteration 340: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.98901104927063 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7155\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.623793840408325 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3035, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1877, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1525, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1625, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.153, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7793\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.7547\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9554, F1 Micro: 0.9664, F1 Macro: 0.7431\n",
      "Model 1 - Iteration 350: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 65.99057340621948 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3215, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1912, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1529, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1621, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.1557, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.122, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.0926, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.7735\n",
      "Model 2 - Iteration 350: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.92287993431091 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2999, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1881, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1403, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1123, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Model 3 - Iteration 350: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 66.11032319068909 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9704, F1 Micro: 0.9775, F1 Macro: 0.7199\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.3424246311187744 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2887, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1859, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Epoch 7/10, Train Loss: 0.1191, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.7274\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9494, F1 Micro: 0.9606, F1 Macro: 0.7522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Model 1 - Iteration 360: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.62849998474121 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3074, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1733, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1619, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1472, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9613, F1 Micro: 0.97, F1 Macro: 0.7599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7963\n",
      "Model 2 - Iteration 360: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.60726547241211 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2824, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1882, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1538, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1261, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7764\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.9613, F1 Micro: 0.9701, F1 Macro: 0.7732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "Model 3 - Iteration 360: Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.94      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 70.70384430885315 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7228\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.8106260299682617 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2899, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1678, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.137, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0997, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7876\n",
      "Epoch 8/10, Train Loss: 0.07, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7942\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9613, F1 Micro: 0.9704, F1 Macro: 0.7821\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7847\n",
      "Model 1 - Iteration 370: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 67.8903455734253 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3042, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1683, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1668, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.062, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.7961\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.9598, F1 Micro: 0.9696, F1 Macro: 0.729\n",
      "Epoch 10/10, Train Loss: 0.0426, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7438\n",
      "Model 2 - Iteration 370: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.07807755470276 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2832, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1611, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "Epoch 7/10, Train Loss: 0.0819, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7793\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0384, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Model 3 - Iteration 370: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.23069834709167 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9707, F1 Micro: 0.9777, F1 Macro: 0.7257\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7584118843078613 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.188, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1845, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1719, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7449\n",
      "Model 1 - Iteration 380: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.75192761421204 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2894, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1904, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1825, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1468, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1296, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9613, F1 Micro: 0.97, F1 Macro: 0.7158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7875\n",
      "Model 2 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.77      0.79      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.38728928565979 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2675, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1809, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7755\n",
      "Epoch 8/10, Train Loss: 0.0713, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7521\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.8209\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7559\n",
      "Model 3 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.00982022285461 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9708, F1 Micro: 0.9778, F1 Macro: 0.7283\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.816786289215088 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2731, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1531, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1518, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1396, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7894\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7449\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7679\n",
      "Model 1 - Iteration 390: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.58978819847107 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2876, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1559, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1493, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1221, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.73\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.7424\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7534\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 390: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.31918692588806 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2649, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1549, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1562, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1276, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9702, F1 Micro: 0.9776, F1 Macro: 0.7767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8218\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7935\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7459\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7559\n",
      "Model 3 - Iteration 390: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.83      0.82       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.90536832809448 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9709, F1 Micro: 0.9779, F1 Macro: 0.7311\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5524916648864746 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.272, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1703, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1473, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1509, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1271, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7606\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7942\n",
      "Epoch 9/10, Train Loss: 0.0445, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7626\n",
      "Epoch 10/10, Train Loss: 0.0365, Accuracy: 0.9613, F1 Micro: 0.9708, F1 Macro: 0.7424\n",
      "Model 1 - Iteration 400: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 69.1945960521698 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2857, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1482, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1457, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1197, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7228\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9628, F1 Micro: 0.9712, F1 Macro: 0.791\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Model 2 - Iteration 400: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 70.78635740280151 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2676, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1475, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1413, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.7565\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7762\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "Model 3 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.76      0.83      0.79       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.96842622756958 s\n",
      "Averaged - Iteration 400: Accuracy: 0.971, F1 Micro: 0.9779, F1 Macro: 0.7318\n",
      "Total sampling time: 178.39 seconds\n",
      "Total runtime: 4646.875190496445 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9dbe9",
   "metadata": {
    "papermill": {
     "duration": 0.173705,
     "end_time": "2025-01-28T10:31:21.525114",
     "exception": false,
     "start_time": "2025-01-28T10:31:21.351409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 5\n",
      "Random seed: [94, 21, 5]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6719, Accuracy: 0.9613, F1 Micro: 0.9708, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.463, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3423, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2807, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2271, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2166, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1838, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1666, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1537, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1572, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.696197271347046 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6567, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3456, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2812, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2195, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1801, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1679, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.156, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1547, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 35.42227077484131 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6631, Accuracy: 0.9628, F1 Micro: 0.9719, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4692, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3641, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2945, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2409, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2408, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2023, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1813, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1708, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1651, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 36.01416373252869 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 19.612046718597412 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5774, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3087, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.229, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1765, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1578, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1467, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1625, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1575, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1133, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 42.88917088508606 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.555, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3091, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2194, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1686, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1526, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1629, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1505, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1117, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.29992961883545 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5717, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3169, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2491, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1772, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.187, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1689, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1551, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1685, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1602, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.118, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 39.93359613418579 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 17.040085792541504 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4671, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2486, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.191, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1488, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1453, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1387, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1404, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 1 - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 44.50895810127258 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4609, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2434, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1503, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1437, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.15, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 8/10, Train Loss: 0.1436, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6531\n",
      "Epoch 9/10, Train Loss: 0.1303, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.137, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 2 - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 43.09995794296265 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4788, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2685, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1684, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1489, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1537, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1549, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1406, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1414, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Model 3 - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 45.29814672470093 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 15.275693655014038 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4536, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2243, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1854, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1634, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1406, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 8/10, Train Loss: 0.1394, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Epoch 9/10, Train Loss: 0.1336, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "Epoch 10/10, Train Loss: 0.1144, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.6536\n",
      "Model 1 - Iteration 128: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 43.299092531204224 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4489, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2203, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.185, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1637, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1432, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6531\n",
      "Epoch 8/10, Train Loss: 0.1418, Accuracy: 0.9628, F1 Micro: 0.9718, F1 Macro: 0.6522\n",
      "Epoch 9/10, Train Loss: 0.1335, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 10/10, Train Loss: 0.1076, Accuracy: 0.9554, F1 Micro: 0.9656, F1 Macro: 0.647\n",
      "Model 2 - Iteration 128: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 40.68514323234558 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4544, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2364, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1923, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1951, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1482, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1488, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1463, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 10/10, Train Loss: 0.12, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Model 3 - Iteration 128: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 46.832483768463135 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6541\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 14.24722671508789 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4083, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2238, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1767, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1399, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1429, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1334, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1223, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "Epoch 10/10, Train Loss: 0.0932, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Model 1 - Iteration 156: Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      0.99      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 45.85940480232239 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4045, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.224, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1359, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1411, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1457, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6496\n",
      "Epoch 8/10, Train Loss: 0.1349, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.6512\n",
      "Epoch 9/10, Train Loss: 0.1165, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 10/10, Train Loss: 0.0936, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6508\n",
      "Model 2 - Iteration 156: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 43.87781476974487 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4136, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2372, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.141, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1447, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1545, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1421, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1294, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 10/10, Train Loss: 0.1042, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Model 3 - Iteration 156: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 49.281593322753906 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9664, F1 Micro: 0.9745, F1 Macro: 0.6542\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.602153778076172 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3705, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2045, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1406, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1499, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1231, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.1177, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 10/10, Train Loss: 0.0954, Accuracy: 0.9628, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Model 1 - Iteration 181: Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.65       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.97       439\n",
      "\n",
      "Training completed in 52.09384536743164 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3666, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2022, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1696, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1545, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1461, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1511, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 8/10, Train Loss: 0.12, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.6476\n",
      "Epoch 9/10, Train Loss: 0.1101, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.6498\n",
      "Epoch 10/10, Train Loss: 0.0868, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6545\n",
      "Model 2 - Iteration 181: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 51.62329840660095 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2146, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1606, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1271, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.1233, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1022, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Model 3 - Iteration 181: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 54.29999828338623 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9667, F1 Micro: 0.9747, F1 Macro: 0.6544\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 12.042125463485718 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3784, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2018, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1773, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1616, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1573, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 8/10, Train Loss: 0.1295, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Epoch 9/10, Train Loss: 0.1184, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.1031, Accuracy: 0.9613, F1 Micro: 0.9702, F1 Macro: 0.6505\n",
      "Model 1 - Iteration 203: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 53.127055406570435 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3713, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2014, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1761, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1604, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6531\n",
      "Epoch 7/10, Train Loss: 0.1569, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.6512\n",
      "Epoch 8/10, Train Loss: 0.1256, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.111, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Epoch 10/10, Train Loss: 0.0939, Accuracy: 0.9509, F1 Micro: 0.9618, F1 Macro: 0.6436\n",
      "Model 2 - Iteration 203: Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 50.462470293045044 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3877, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2115, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1787, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1827, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1667, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1561, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 8/10, Train Loss: 0.1291, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.1149, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0994, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.6495\n",
      "Model 3 - Iteration 203: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 51.70942568778992 s\n",
      "Averaged - Iteration 203: Accuracy: 0.967, F1 Micro: 0.975, F1 Macro: 0.6546\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 10.425134181976318 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.351, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2026, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1286, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.1334, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.1115, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 10/10, Train Loss: 0.0864, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Model 1 - Iteration 223: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 53.6327121257782 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3472, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1969, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1649, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1746, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.165, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1234, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 8/10, Train Loss: 0.1244, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1093, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 10/10, Train Loss: 0.0843, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 2 - Iteration 223: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.68937063217163 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2113, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1754, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1782, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1697, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1283, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.1341, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1167, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.657\n",
      "Model 3 - Iteration 223: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 57.015493869781494 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.6548\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 9.392027616500854 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3364, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1722, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1489, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.0891, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Model 1 - Iteration 241: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 54.815420389175415 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3316, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1569, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1497, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1446, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6527\n",
      "Epoch 8/10, Train Loss: 0.0968, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6527\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.7191\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Model 2 - Iteration 241: Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.87      1.00      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       439\n",
      "   macro avg       0.64      0.67      0.65       439\n",
      "weighted avg       0.95      0.98      0.97       439\n",
      " samples avg       0.96      0.99      0.97       439\n",
      "\n",
      "Training completed in 56.06400489807129 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3464, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2016, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.163, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1769, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1565, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1517, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.9673, F1 Micro: 0.975, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.0938, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6922\n",
      "Epoch 10/10, Train Loss: 0.0819, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Model 3 - Iteration 241: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 56.310675382614136 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9676, F1 Micro: 0.9754, F1 Macro: 0.6549\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.648976564407349 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3357, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1679, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1624, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.15, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1366, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1261, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.0716, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6552\n",
      "Model 1 - Iteration 250: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 59.669395446777344 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.336, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1692, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1596, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1421, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 7/10, Train Loss: 0.1311, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1184, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.6544\n",
      "Model 2 - Iteration 250: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 57.448100090026855 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3458, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1771, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1648, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1507, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1408, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1194, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0719, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6931\n",
      "Model 3 - Iteration 250: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 56.616721630096436 s\n",
      "Averaged - Iteration 250: Accuracy: 0.968, F1 Micro: 0.9757, F1 Macro: 0.655\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 8.0319983959198 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3256, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2134, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1693, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.171, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.147, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1364, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.0972, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.0849, Accuracy: 0.9613, F1 Micro: 0.9709, F1 Macro: 0.7066\n",
      "Epoch 10/10, Train Loss: 0.0698, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Model 1 - Iteration 265: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.902095794677734 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3192, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2163, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1686, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1692, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1509, Accuracy: 0.9643, F1 Micro: 0.9728, F1 Macro: 0.6528\n",
      "Epoch 7/10, Train Loss: 0.1387, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Epoch 8/10, Train Loss: 0.1004, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0878, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7031\n",
      "Epoch 10/10, Train Loss: 0.0686, Accuracy: 0.9613, F1 Micro: 0.9703, F1 Macro: 0.6508\n",
      "Model 2 - Iteration 265: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       439\n",
      "   macro avg       0.70      0.71      0.70       439\n",
      "weighted avg       0.96      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.97       439\n",
      "\n",
      "Training completed in 57.10538387298584 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3388, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2215, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1754, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1713, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1512, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1402, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.0984, Accuracy: 0.9613, F1 Micro: 0.9706, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.0867, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.6552\n",
      "Epoch 10/10, Train Loss: 0.0697, Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.6534\n",
      "Model 3 - Iteration 265: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 58.9007773399353 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9681, F1 Micro: 0.9758, F1 Macro: 0.6566\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.700828552246094 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3492, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1548, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1428, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1224, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 9/10, Train Loss: 0.0908, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0808, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 1 - Iteration 279: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.98      0.98       439\n",
      "\n",
      "Training completed in 59.50752258300781 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3466, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1704, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1701, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1562, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1426, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1215, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1129, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7301\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0698, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Model 2 - Iteration 279: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.71      0.72       439\n",
      "weighted avg       0.97      0.99      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.67536950111389 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3518, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1963, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.176, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 7/10, Train Loss: 0.1201, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Epoch 8/10, Train Loss: 0.1188, Accuracy: 0.9613, F1 Micro: 0.9707, F1 Macro: 0.6838\n",
      "Epoch 9/10, Train Loss: 0.0941, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Epoch 10/10, Train Loss: 0.0818, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7037\n",
      "Model 3 - Iteration 279: Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 58.26143980026245 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9684, F1 Micro: 0.976, F1 Macro: 0.6585\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.965753078460693 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3282, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1855, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1825, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1576, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1492, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1243, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.1155, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7294\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6552\n",
      "Model 1 - Iteration 292: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.501909494400024 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3278, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1849, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1835, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1562, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 7/10, Train Loss: 0.1277, Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1189, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 9/10, Train Loss: 0.0887, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7054\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6532\n",
      "Model 2 - Iteration 292: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.52044177055359 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3401, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1886, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1866, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1612, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1316, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.1216, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.6894\n",
      "Epoch 10/10, Train Loss: 0.0662, Accuracy: 0.9702, F1 Micro: 0.9771, F1 Macro: 0.6557\n",
      "Model 3 - Iteration 292: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.18838357925415 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9687, F1 Micro: 0.9762, F1 Macro: 0.6584\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.117645740509033 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.322, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1744, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1839, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1417, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.1079, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7046\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9598, F1 Micro: 0.9694, F1 Macro: 0.7129\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9628, F1 Micro: 0.9719, F1 Macro: 0.6887\n",
      "Model 1 - Iteration 300: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 60.32296848297119 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3145, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1732, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1844, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1755, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1646, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 6/10, Train Loss: 0.1497, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1407, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.1045, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0752, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7781\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.719\n",
      "Model 2 - Iteration 300: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.74      0.83      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 62.1648371219635 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3264, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.178, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1877, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1705, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1565, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1504, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.1171, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0905, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7234\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7116\n",
      "Model 3 - Iteration 300: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.70      0.72       439\n",
      "weighted avg       0.97      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 62.333027601242065 s\n",
      "Averaged - Iteration 300: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.6627\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.707890272140503 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3217, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2023, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1623, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1751, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1324, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Epoch 7/10, Train Loss: 0.121, Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.0916, Accuracy: 0.9628, F1 Micro: 0.972, F1 Macro: 0.7434\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.9628, F1 Micro: 0.9717, F1 Macro: 0.7434\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9658, F1 Micro: 0.9742, F1 Macro: 0.7387\n",
      "Model 1 - Iteration 310: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.97      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.97      0.97       439\n",
      " samples avg       0.98      0.98      0.97       439\n",
      "\n",
      "Training completed in 61.87197971343994 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3184, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2041, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1806, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1369, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Epoch 7/10, Train Loss: 0.1248, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0726, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.7932\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7793\n",
      "Model 2 - Iteration 310: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.74      0.83      0.78       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 63.262824296951294 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3299, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2096, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.184, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1034, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7469\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0598, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7345\n",
      "Model 3 - Iteration 310: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.33      0.75      0.46         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.71      0.79      0.73       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.27565383911133 s\n",
      "Averaged - Iteration 310: Accuracy: 0.969, F1 Micro: 0.9765, F1 Macro: 0.6667\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.2803449630737305 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3213, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1686, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1739, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1697, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1359, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 320: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.20583891868591 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3233, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1931, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1819, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1767, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1404, Accuracy: 0.9598, F1 Micro: 0.9689, F1 Macro: 0.6493\n",
      "Epoch 8/10, Train Loss: 0.101, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7587\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9539, F1 Micro: 0.9642, F1 Macro: 0.7547\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7654\n",
      "Model 2 - Iteration 320: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 61.71709895133972 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3361, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1984, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1709, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1792, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 6/10, Train Loss: 0.1689, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1394, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6576\n",
      "Epoch 8/10, Train Loss: 0.1044, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7678\n",
      "Model 3 - Iteration 320: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 64.96793413162231 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9693, F1 Micro: 0.9767, F1 Macro: 0.6713\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.79789400100708 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3109, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1948, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1391, Accuracy: 0.9539, F1 Micro: 0.964, F1 Macro: 0.645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1215, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.744\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9688, F1 Micro: 0.976, F1 Macro: 0.795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Model 1 - Iteration 330: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 66.91570496559143 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3117, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1957, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1413, Accuracy: 0.933, F1 Micro: 0.947, F1 Macro: 0.6299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7236\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.7975\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9598, F1 Micro: 0.9691, F1 Macro: 0.7595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Model 2 - Iteration 330: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 66.11950516700745 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3208, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.198, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1563, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1396, Accuracy: 0.9658, F1 Micro: 0.9736, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7781\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 330: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.74      0.83      0.78       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 64.79128646850586 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9695, F1 Micro: 0.9769, F1 Macro: 0.6784\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.317572116851807 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3011, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1773, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1538, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1633, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0642, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9628, F1 Micro: 0.972, F1 Macro: 0.7434\n",
      "Model 1 - Iteration 340: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.68069362640381 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2991, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1771, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1555, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1615, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.6547\n",
      "Epoch 6/10, Train Loss: 0.1409, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.6525\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9568, F1 Micro: 0.9666, F1 Macro: 0.7133\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.7914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9598, F1 Micro: 0.9695, F1 Macro: 0.7412\n",
      "Model 2 - Iteration 340: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.99      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 65.34128499031067 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3091, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1725, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1662, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1534, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Epoch 7/10, Train Loss: 0.1172, Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6531\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6576\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7537\n",
      "Model 3 - Iteration 340: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.65      0.66      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 65.2892074584961 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9698, F1 Micro: 0.977, F1 Macro: 0.6825\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.854186773300171 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3037, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1694, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1513, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7394\n",
      "Epoch 9/10, Train Loss: 0.0655, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7962\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7579\n",
      "Model 1 - Iteration 350: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.89      1.00      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       439\n",
      "   macro avg       0.65      0.67      0.66       439\n",
      "weighted avg       0.96      0.98      0.97       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.18658781051636 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3048, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1683, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1613, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1591, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1341, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0999, Accuracy: 0.9747, F1 Micro: 0.9809, F1 Macro: 0.7903\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0598, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 2 - Iteration 350: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.72546172142029 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3143, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1745, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1624, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.162, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.1001, Accuracy: 0.9673, F1 Micro: 0.9753, F1 Macro: 0.7339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7346\n",
      "Model 3 - Iteration 350: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 68.86014747619629 s\n",
      "Averaged - Iteration 350: Accuracy: 0.97, F1 Micro: 0.9772, F1 Macro: 0.6856\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.590625047683716 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2955, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1609, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1241, Accuracy: 0.9643, F1 Micro: 0.9724, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9643, F1 Micro: 0.9732, F1 Macro: 0.7442\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 360: Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.7979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.96      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.78      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 67.82994365692139 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2966, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1635, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1311, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.6495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1147, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.78\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7772\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9643, F1 Micro: 0.9724, F1 Macro: 0.792\n",
      "Model 2 - Iteration 360: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 67.0966203212738 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3046, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1673, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.6555\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9643, F1 Micro: 0.9725, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1194, Accuracy: 0.9702, F1 Micro: 0.9772, F1 Macro: 0.6559\n",
      "Epoch 8/10, Train Loss: 0.0799, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9702, F1 Micro: 0.9775, F1 Macro: 0.7478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "Model 3 - Iteration 360: Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.95284652709961 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6902\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.8839187622070312 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2879, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1866, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1663, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1501, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.0839, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.7645\n",
      "Model 1 - Iteration 370: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.08422565460205 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2836, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1861, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1662, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1124, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0958, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7664\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0409, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8218\n",
      "Model 2 - Iteration 370: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.8218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.83      0.82       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.57900738716125 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2981, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1905, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1458, Accuracy: 0.9628, F1 Micro: 0.9714, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7045\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0448, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "Model 3 - Iteration 370: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.75      0.79      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.84214878082275 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9704, F1 Micro: 0.9775, F1 Macro: 0.6953\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.392133951187134 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.279, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1872, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 6/10, Train Loss: 0.1257, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7585\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9688, F1 Micro: 0.9762, F1 Macro: 0.7784\n",
      "Model 1 - Iteration 380: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.98      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 71.29813694953918 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2789, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1879, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.7286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.72\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.7617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0435, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Model 2 - Iteration 380: Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 74.69127917289734 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2913, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1642, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1468, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.9732, F1 Micro: 0.9795, F1 Macro: 0.6576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0407, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 3 - Iteration 380: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 73.90556287765503 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9706, F1 Micro: 0.9777, F1 Macro: 0.7\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8773062229156494 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2763, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1468, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.1203, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.655\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7974\n",
      "Epoch 9/10, Train Loss: 0.0447, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7521\n",
      "Epoch 10/10, Train Loss: 0.0361, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7554\n",
      "Model 1 - Iteration 390: Accuracy: 0.9717, F1 Micro: 0.9786, F1 Macro: 0.7974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.88      0.99      0.93        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.79      0.80       439\n",
      "weighted avg       0.96      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 70.56628108024597 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2799, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1305, Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.7587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.6577\n",
      "Epoch 9/10, Train Loss: 0.0531, Accuracy: 0.9643, F1 Micro: 0.9726, F1 Macro: 0.7755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "Model 2 - Iteration 390: Accuracy: 0.9777, F1 Micro: 0.983, F1 Macro: 0.8005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.57508277893066 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.289, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1951, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1579, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.6569\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1144, Accuracy: 0.9673, F1 Micro: 0.9748, F1 Macro: 0.6539\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9673, F1 Micro: 0.9749, F1 Macro: 0.7199\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "Model 3 - Iteration 390: Accuracy: 0.9762, F1 Micro: 0.9819, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.98      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 69.96044254302979 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9708, F1 Micro: 0.9778, F1 Macro: 0.7043\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6111228466033936 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2909, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.176, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9688, F1 Micro: 0.9764, F1 Macro: 0.7303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7681\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9732, F1 Micro: 0.9796, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9643, F1 Micro: 0.973, F1 Macro: 0.744\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9643, F1 Micro: 0.9729, F1 Macro: 0.7559\n",
      "Model 1 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9808, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.90      1.00      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       439\n",
      "   macro avg       0.81      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.97      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.07213234901428 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2882, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1778, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1248, Accuracy: 0.9732, F1 Micro: 0.9797, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9598, F1 Micro: 0.969, F1 Macro: 0.7895\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7567\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9717, F1 Micro: 0.9784, F1 Macro: 0.78\n",
      "Model 2 - Iteration 400: Accuracy: 0.9747, F1 Micro: 0.9807, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.91      0.99      0.95        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       439\n",
      "   macro avg       0.82      0.75      0.77       439\n",
      "weighted avg       0.97      0.99      0.98       439\n",
      " samples avg       0.98      0.99      0.98       439\n",
      "\n",
      "Training completed in 72.22501492500305 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.299, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.181, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1721, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9658, F1 Micro: 0.9741, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.1203, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.7208\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.9628, F1 Micro: 0.9716, F1 Macro: 0.7482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.9717, F1 Micro: 0.9783, F1 Macro: 0.7797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9762, F1 Micro: 0.9818, F1 Macro: 0.7996\n",
      "Model 3 - Iteration 400: Accuracy: 0.9762, F1 Micro: 0.9818, F1 Macro: 0.7996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       112\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       112\n",
      "        4-DM       0.92      0.97      0.94        97\n",
      "     5-EDTRB       0.99      1.00      1.00       111\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       439\n",
      "   macro avg       0.82      0.79      0.80       439\n",
      "weighted avg       0.97      0.98      0.98       439\n",
      " samples avg       0.98      0.98      0.98       439\n",
      "\n",
      "Training completed in 73.79087090492249 s\n",
      "Averaged - Iteration 400: Accuracy: 0.971, F1 Micro: 0.9779, F1 Macro: 0.7074\n",
      "Total sampling time: 184.41 seconds\n",
      "Total runtime: 4729.580111980438 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXhU9dn/8c9k30gCJCQEAoGwL4KioBQFFVlFwQ21yqZYUWorrT6iiFZrqVX5YSmKpQiouJalWCkKQRQUQUFEtrAnLElIgCQkIevM74+TGYgEyDIzZ2Z4v65rrnNy5pzvuYc+19PTySf3bbHZbDYBAAAAAAAAAAAAAAC4gZ/ZBQAAAAAAAAAAAAAAgEsHQQUAAAAAAAAAAAAAAOA2BBUAAAAAAAAAAAAAAIDbEFQAAAAAAAAAAAAAAABuQ1ABAAAAAAAAAAAAAAC4DUEFAAAAAAAAAAAAAADgNgQVAAAAAAAAAAAAAACA2xBUAAAAAAAAAAAAAAAAbkNQAQAAAAAAAAAAAAAAuA1BBQAAAAAA4HXGjBmjpKQks8sAAAAAAAB1QFABAJzojTfekMViUa9evcwuBQAAAKiX+fPny2KxVPt66qmnHOd98cUXeuCBB9SlSxf5+/vXOjxgX/PBBx+s9v1nnnnGcU5OTk59PhIAAAAuITzPAoBnCzC7AADwJQsXLlRSUpI2btyovXv3qk2bNmaXBAAAANTLCy+8oFatWlU51qVLF8f++++/r48++khXXHGFEhIS6nSPkJAQLVq0SG+88YaCgoKqvPfBBx8oJCRExcXFVY7PmTNHVqu1TvcDAADApcNTn2cB4FJHRwUAcJIDBw7o22+/1fTp0xUbG6uFCxeaXVK1CgsLzS4BAAAAXmTw4MG67777qry6d+/ueP8vf/mL8vPz9c0336hbt251usegQYOUn5+v//3vf1WOf/vttzpw4ICGDh16zjWBgYEKDg6u0/3OZrVa+dIYAADAh3nq86yr8T0wAE9HUAEAnGThwoVq2LChhg4dqjvuuKPaoEJubq4ef/xxJSUlKTg4WM2bN9eoUaOqtPwqLi7W888/r3bt2ikkJERNmzbVbbfdpn379kmS1qxZI4vFojVr1lRZ++DBg7JYLJo/f77j2JgxYxQREaF9+/ZpyJAhatCggX79619LktauXas777xTLVq0UHBwsBITE/X444/r9OnT59S9a9cu3XXXXYqNjVVoaKjat2+vZ555RpL05ZdfymKxaMmSJedc9/7778tisWj9+vW1/vcEAACAd0hISFBgYGC91mjWrJmuu+46vf/++1WOL1y4UF27dq3yF292Y8aMOactr9Vq1euvv66uXbsqJCREsbGxGjRokH744QfHORaLRRMnTtTChQvVuXNnBQcHa8WKFZKkH3/8UYMHD1ZkZKQiIiJ044036rvvvqvXZwMAAIBnM+t51lnfz0rS888/L4vFoh07dujee+9Vw4YN1adPH0lSeXm5XnzxRSUnJys4OFhJSUl6+umnVVJSUq/PDAD1xegHAHCShQsX6rbbblNQUJDuuecevfnmm/r+++911VVXSZIKCgp07bXXaufOnRo3bpyuuOIK5eTkaNmyZTp8+LBiYmJUUVGhm2++WSkpKbr77rv1u9/9TqdOndLKlSu1bds2JScn17qu8vJyDRw4UH369NGrr76qsLAwSdInn3yioqIiTZgwQY0bN9bGjRs1c+ZMHT58WJ988onj+q1bt+raa69VYGCgHnroISUlJWnfvn369NNP9dJLL6lfv35KTEzUwoULNWLEiHP+TZKTk3XNNdfU418WAAAAZsrLyztnlm5MTIzT73Pvvffqd7/7nQoKChQREaHy8nJ98sknmjRpUo07HjzwwAOaP3++Bg8erAcffFDl5eVau3atvvvuO1155ZWO81avXq2PP/5YEydOVExMjJKSkrR9+3Zde+21ioyM1JNPPqnAwEC99dZb6tevn7766iv16tXL6Z8ZAAAAruepz7PO+n72bHfeeafatm2rv/zlL7LZbJKkBx98UAsWLNAdd9yhP/zhD9qwYYOmTZumnTt3VvvHZwDgLgQVAMAJNm3apF27dmnmzJmSpD59+qh58+ZauHChI6jwyiuvaNu2bVq8eHGVX+hPmTLF8dD4zjvvKCUlRdOnT9fjjz/uOOepp55ynFNbJSUluvPOOzVt2rQqx19++WWFhoY6fn7ooYfUpk0bPf3000pPT1eLFi0kSb/97W9ls9m0efNmxzFJ+utf/yrJ+Iu0++67T9OnT1deXp6ioqIkSdnZ2friiy+qJHsBAADgffr373/Osbo+m17IHXfcoYkTJ2rp0qW677779MUXXygnJ0f33HOP5s2bd9Hrv/zyS82fP1+PPfaYXn/9dcfxP/zhD+fUm5qaqp9//lmdOnVyHBsxYoTKysq0bt06tW7dWpI0atQotW/fXk8++aS++uorJ31SAAAAuJOnPs866/vZs3Xr1q1KV4effvpJCxYs0IMPPqg5c+ZIkh555BE1adJEr776qr788ktdf/31Tvs3AIDaYPQDADjBwoULFRcX53ios1gsGjlypD788ENVVFRIkhYtWqRu3bqd03XAfr79nJiYGP32t7897zl1MWHChHOOnf0QXFhYqJycHPXu3Vs2m00//vijJCNs8PXXX2vcuHFVHoJ/Wc+oUaNUUlKif//7345jH330kcrLy3XffffVuW4AAACYb9asWVq5cmWVlys0bNhQgwYN0gcffCDJGCPWu3dvtWzZskbXL1q0SBaLRc8999w57/3yWbpv375VQgoVFRX64osvNHz4cEdIQZKaNm2qe++9V+vWrVN+fn5dPhYAAABM5qnPs878ftbu4YcfrvLz8uXLJUmTJk2qcvwPf/iDJOmzzz6rzUcEAKeiowIA1FNFRYU+/PBDXX/99Tpw4IDjeK9evfTaa68pJSVFAwYM0L59+3T77bdfcK19+/apffv2Cghw3v97DggIUPPmzc85np6erqlTp2rZsmU6efJklffy8vIkSfv375ekameona1Dhw666qqrtHDhQj3wwAOSjPDG1VdfrTZt2jjjYwAAAMAkPXv2rDI2wZXuvfde3X///UpPT9fSpUv1t7/9rcbX7tu3TwkJCWrUqNFFz23VqlWVn7Ozs1VUVKT27dufc27Hjh1ltVp16NAhde7cucb1AAAAwDN46vOsM7+ftfvlc25aWpr8/PzO+Y42Pj5e0dHRSktLq9G6AOAKBBUAoJ5Wr16tjIwMffjhh/rwww/PeX/hwoUaMGCA0+53vs4K9s4NvxQcHCw/P79zzr3pppt04sQJ/d///Z86dOig8PBwHTlyRGPGjJHVaq11XaNGjdLvfvc7HT58WCUlJfruu+/0j3/8o9brAAAA4NJ1yy23KDg4WKNHj1ZJSYnuuusul9zn7L9eAwAAAJylps+zrvh+Vjr/c259uvUCgKsQVACAelq4cKGaNGmiWbNmnfPe4sWLtWTJEs2ePVvJycnatm3bBddKTk7Whg0bVFZWpsDAwGrPadiwoSQpNze3yvHapF9//vln7d69WwsWLNCoUaMcx3/Z9sze9vZidUvS3XffrUmTJumDDz7Q6dOnFRgYqJEjR9a4JgAAACA0NFTDhw/Xe++9p8GDBysmJqbG1yYnJ+vzzz/XiRMnatRV4WyxsbEKCwtTamrqOe/t2rVLfn5+SkxMrNWaAAAAuPTU9HnWFd/PVqdly5ayWq3as2ePOnbs6DielZWl3NzcGo9ZAwBX8Lv4KQCA8zl9+rQWL16sm2++WXfcccc5r4kTJ+rUqVNatmyZbr/9dv30009asmTJOevYbDZJ0u23366cnJxqOxHYz2nZsqX8/f319ddfV3n/jTfeqHHd/v7+Vda077/++utVzouNjdV1112nt99+W+np6dXWYxcTE6PBgwfrvffe08KFCzVo0KBafbEMAAAASNIf//hHPffcc3r22Wdrdd3tt98um82mP/3pT+e898tn11/y9/fXgAED9J///EcHDx50HM/KytL777+vPn36KDIyslb1AAAA4NJUk+dZV3w/W50hQ4ZIkmbMmFHl+PTp0yVJQ4cOvegaAOAqdFQAgHpYtmyZTp06pVtuuaXa96+++mrFxsZq4cKFev/99/Xvf/9bd955p8aNG6cePXroxIkTWrZsmWbPnq1u3bpp1KhReueddzRp0iRt3LhR1157rQoLC7Vq1So98sgjuvXWWxUVFaU777xTM2fOlMViUXJysv773//q2LFjNa67Q4cOSk5O1h//+EcdOXJEkZGRWrRo0Tmz0CTp73//u/r06aMrrrhCDz30kFq1aqWDBw/qs88+05YtW6qcO2rUKN1xxx2SpBdffLHm/5AAAADwWlu3btWyZcskSXv37lVeXp7+/Oc/S5K6deumYcOG1Wq9bt26qVu3brWu4/rrr9f999+vv//979qzZ48GDRokq9WqtWvX6vrrr9fEiRMveP2f//xnrVy5Un369NEjjzyigIAAvfXWWyopKbngbGEAAAB4NzOeZ131/Wx1tYwePVr//Oc/lZubq759+2rjxo1asGCBhg8fruuvv75Wnw0AnImgAgDUw8KFCxUSEqKbbrqp2vf9/Pw0dOhQLVy4UCUlJVq7dq2ee+45LVmyRAsWLFCTJk104403qnnz5pKMJO3y5cv10ksv6f3339eiRYvUuHFj9enTR127dnWsO3PmTJWVlWn27NkKDg7WXXfdpVdeeUVdunSpUd2BgYH69NNP9dhjj2natGkKCQnRiBEjNHHixHMeort166bvvvtOzz77rN58800VFxerZcuW1c5XGzZsmBo2bCir1Xre8AYAAAB8y+bNm8/5azH7z6NHj671F7v1MW/ePF122WWaO3eunnjiCUVFRenKK69U7969L3pt586dtXbtWk2ePFnTpk2T1WpVr1699N5776lXr15uqB4AAABmMON51lXfz1bnX//6l1q3bq358+dryZIlio+P1+TJk/Xcc885/XMBQG1YbDXpDQMAQA2Ul5crISFBw4YN09y5c80uBwAAAAAAAAAAAB7Iz+wCAAC+Y+nSpcrOztaoUaPMLgUAAAAAAAAAAAAeio4KAIB627Bhg7Zu3aoXX3xRMTEx2rx5s9klAQAAAAAAAAAAwEPRUQEAUG9vvvmmJkyYoCZNmuidd94xuxwAAAAAAAAAAAB4MDoqAAAAAAAAAAAAAAAAt6GjAgAAAAAAAAAAAAAAcBuCCgAAAAAAAAAAAAAAwG0CzC7AXaxWq44ePaoGDRrIYrGYXQ4AAADqwWaz6dSpU0pISJCf36WXveXZFgAAwHfwbMuzLQAAgK+ozbPtJRNUOHr0qBITE80uAwAAAE506NAhNW/e3Owy3I5nWwAAAN/Dsy0AAAB8RU2ebS+ZoEKDBg0kGf8okZGRJlcDAACA+sjPz1diYqLjGe9Sw7MtAACA7+DZlmdbAAAAX1GbZ9tLJqhgbxsWGRnJAy8AAICPuFRbw/JsCwAA4Ht4tuXZFgAAwFfU5Nn20ht6BgAAAAAAAAAAAAAATENQAQAAAAAAAAAAAAAAuA1BBQAAAAAAAAAAAAAA4DYEFQAAAAAAAAAAAAAAgNsQVAAAAAAAAAAAAAAAAG5DUAEAAAAAAAAAAAAAALgNQQUAAAAAAAAAAAAAAOA2BBUAAAAAAAAAAAAAAIDbEFQAAAAAAAAAAAAAAABuQ1ABAAAAAAAAAC4Rs2bNUlJSkkJCQtSrVy9t3LjxgufPmDFD7du3V2hoqBITE/X444+ruLi4XmsCAAAABBUAAAAAAAAA4BLw0UcfadKkSXruuee0efNmdevWTQMHDtSxY8eqPf/999/XU089peeee047d+7U3Llz9dFHH+npp5+u85oAAACARFABAAAAAAAAAC4J06dP1/jx4zV27Fh16tRJs2fPVlhYmN5+++1qz//222/1q1/9Svfee6+SkpI0YMAA3XPPPVU6JtR2TQAAAEAiqAAAAAAAAAAAPq+0tFSbNm1S//79Hcf8/PzUv39/rV+/vtprevfurU2bNjmCCfv379fy5cs1ZMiQOq8JAAAASFKA2QUAAAAAAAAAAFwrJydHFRUViouLq3I8Li5Ou3btqvaae++9Vzk5OerTp49sNpvKy8v18MMPO0Y/1GXNkpISlZSUOH7Oz8+vz8cCAACAlyKoAAAA4CFKS6WNG6VrrpH8/d1774wM6Ztv6rdGjx5Sq1bOqQcAAAA+oKJY8g9x/31P7ZNO7ZZCm0lhzaSgRpLF4v46fMCaNWv0l7/8RW+88YZ69eqlvXv36ne/+51efPFFPfvss3Vac9q0afrTn/7k5EoBAAC8X1lFmfJK8pRfku945RXnqU2jNuoY29Hs8pyOoAIAAICH+Otfpeeek379a+ndd933XerOnVKvXtKpU/VbZ+5cggoAAACotH++tOEB6Yr/J7V/zH33PbVP+t/lUvlZD7f+IZWhheZntmFn/9xMComX/Hz7q9KYmBj5+/srKyuryvGsrCzFx8dXe82zzz6r+++/Xw8++KAkqWvXriosLNRDDz2kZ555pk5rTp48WZMmTXL8nJ+fr8TExPp8NAAAAI91JP+I/pP6Hx3JP2KED0qN8EGVMEJlOKG4vLjaNcICw3TgdwfUJLyJm6t3Ld9++gYAAPAiS5ca24ULpZ49pcfc8H1ufr40YoQRUkhKkurz/eAvur0CAADgUnbgHclmlTb/QWrcU4q52vX3rCiVvrnbCCkExxjHSnKMzg4F+4zX+Vj8jLCCPbzQ5jdSwkDX1+xGQUFB6tGjh1JSUjR8+HBJktVqVUpKiiZOnFjtNUVFRfLz86tyzL+y/ZvNZqvTmsHBwQoODnbOhwIAAPBAx4uO6987/q0Ptn2gr9O+lk22Wl0fFhimqOAoRQZHKqMgQ/kl+frfnv9pdPfRLqrYHAQVAAAAPMDx49KWLWd+/sMfpO7dpeuuc909rVZp9GgpNVVq3lzasEFq4luhXAAAAJiholjK/tbYt5VL39wjDf5RCop27X23TpFO/CAFNZQGbZLCWxi1nD4qFR2Rig5Lpyu3RUfO7J/OMOo8fdR4SVLzW11bq0kmTZqk0aNH68orr1TPnj01Y8YMFRYWauzYsZKkUaNGqVmzZpo2bZokadiwYZo+fbouv/xyx+iHZ599VsOGDXMEFi62JgAAwKXgVMkpLd21VB9s+0Ar969UubXc8d6vEn+lK5peocjgSEcAITI4UlEhZ/bt7zUIbqCAszp9TVk9RS+tfUnL9y4nqAAAAADn+/JLyWaTOnUyAgrvvy/ddZe0aZPUrJlr7vnyy0YXh6AgadEiQgoAAABwkpz1krVECmkiBURIBfulDeOlPh+7br7Z0c+lna8Y+73mGiEFyRj7ENHaeJ2PtUIqOVY1vBDT2zV1mmzkyJHKzs7W1KlTlZmZqe7du2vFihWKq2yPlp6eXqWDwpQpU2SxWDRlyhQdOXJEsbGxGjZsmF566aUarwkAAOCrTped1vI9y/XBtg/02Z7PqoxuuDz+ct3T5R7d1fkutYxuWed7DG07VC+tfUmf7/1cZRVlCvQPdEbpHsFis9lq12vCS+Xn5ysqKkp5eXmKjIw0uxwAAIAqHn5YeustY9zDX/4i9e4tbd0qXX21tGaN5OzOqJ9/Lg0ebIQj5syRKkfOeg1nPtvNmjVLr7zyijIzM9WtWzfNnDlTPXv2rPbcsrIyTZs2TQsWLNCRI0fUvn17vfzyyxo0aJDjnIqKCj3//PN67733lJmZqYSEBI0ZM8bxJa8kLV68WLNnz9amTZt04sQJ/fjjj+revbspnx8AAMDptk6Vtr0otbxH6vC49EVvo2PBVbOltr9x/v1OZ0n/u0wqPia1nSBd9Ybz7+FCl/qz3aX++QEAgHcpqyhTyoEUfbDtAy3ZuUSnSk853mvXuJ3u6XKP7u5ytzrEdHDK/SqsFYp/LV45RTlaM3qN+ib1dcq6rlKbZzu/C74LAAAAt0hJMbb9+0vh4dLixVJ0tPTdd9Lvf+/cex04IN1zjxFSGD/e+0IKzvTRRx9p0qRJeu6557R582Z169ZNAwcO1LFjx6o9f8qUKXrrrbc0c+ZM7dixQw8//LBGjBihH3/80XHOyy+/rDfffFP/+Mc/tHPnTr388sv629/+ppkzZzrOKSwsVJ8+ffTyyy+7/DMCAAC4XdaXxjbuBqnxVVL3vxo/b/69lPuzc+9ls0rrRxkhhagu0uWvOXd9AAAAQNK69HWa8N8JSpieoMELB+udn97RqdJTSoxM1BO9n9CmhzZp16O79Hy/550WUpAkfz9/DWpj/JHUZ3s+c9q6noCOCgAAACZLS5OSkiR/f+nECcn+qPK//0lDhxqBgrlzpXHj6n+voiLpV7+StmyRevaUvv7a+d0a3MFZz3a9evXSVVddpX/84x+SJKvVqsTERP32t7/VU089dc75CQkJeuaZZ/Too486jt1+++0KDQ3Ve++9J0m6+eabFRcXp7lz5573HLuDBw+qVatWdFQAAAC+o7xQ+ndDyVomDdsrNUg2wgRfDZOOLpciO0iDfpACwp1zvx2vSFuelPxDpYHfS9GdnbOuG13qz3aX+ucHAACeb86mOXrovw85fo4Ni9Wdne7UPV3vUe/E3vKzuLY3wIfbPtQ9i+5Rp9hO2v7Idpfeq77oqAAAAOBF7N0UevY8E1KQjNEMf/qTsf/II9IPP9TvPjabMWJiyxYpNlZatMg7QwrOUlpaqk2bNql///6OY35+furfv7/Wr19f7TUlJSUKCQmpciw0NFTr1q1z/Ny7d2+lpKRo9+7dkqSffvpJ69at0+DBg13wKQAAADxM9jdGSCEsUYpobRyz+ElXz5dCE6T8XdIPjznnXse/l3562tjvMcMrQwoAAADwfLO+nyVJuqX9LVrx6xU6+oejmjV0lvq06OPykIIkDUweKD+Ln3Zk79DB3IMuv5+7EFQAAAAw2apVxvbGG89975lnpFtukUpKpNtuk7Kz636ff/xDevddo3PDxx9LzZvXfS1fkJOTo4qKCsXFxVU5HhcXp8zMzGqvGThwoKZPn649e/bIarVq5cqVWrx4sTIyMhznPPXUU7r77rvVoUMHBQYG6vLLL9fvf/97/frXv65zrSUlJcrPz6/yAgAA8EiOsQ/XSxbLmeMhsVLvhZIs0v63pYPv1+8+ZfnSN3dLtnIp8Q4peXz91gMAAACqse/EPv2U9ZP8Lf56+5a3NbDNQAX4Bbi1hoahDdU7sbckafme5W69tysRVAAAADCRzSatXm3sn/WH/Q5+ftI770ht20qHDkl33y2Vl9f+PmvXSpMmGfuvvCL161fnki9pr7/+utq2basOHTooKChIEydO1NixY+Xnd+ax+uOPP9bChQv1/vvva/PmzVqwYIFeffVVLViwoM73nTZtmqKiohyvxMREZ3wcAAAA53MEFW449724flKXZ439jb+RTu2t2z1sNmnjBKlgvxTWQur1z6qhCAAAAMBJFu9cLEnql9RPjcMam1bH0LZDJUmf7fnMtBqcjaACAACAibZvl7KypNBQ6eqrqz8nKkpaskQKDzdCDU8/Xbt7HD0q3XmnEXC4+27p97+vd9k+ISYmRv7+/srKyqpyPCsrS/Hx8dVeExsbq6VLl6qwsFBpaWnatWuXIiIi1Lp1a8c5TzzxhKOrQteuXXX//ffr8ccf17Rp0+pc6+TJk5WXl+d4HTp0qM5rAQAAuExZvnSicl5Z3PXVn9PlWanJdVJ5gbRupFRRUvv7HHhHSntfsvhLv/pACmpY95oBAACAC1i8ywgq3N7xdlPrsAcVVh9YraKyIlNrcRaCCgAAACayj3249lopOPj853XuLM2bZ+y/8or0ySc1W7+0VLrjDiMM0bWr9K9/8cdmdkFBQerRo4dSUlIcx6xWq1JSUnTNNddc8NqQkBA1a9ZM5eXlWrRokW699VbHe0VFRVU6LEiSv7+/rFZrnWsNDg5WZGRklRcAAIDHObZWslVIEa2l8BbVn+MXYIyACG4sndwsbfm/2t0jf7f0w6PGftc/SbG961czAAAAcB5H8o/ou8PfySKLhncYbmotXZp0UWJkoorLi/XlgS9NrcVZCCoAAACYyP478urGPvzSnXdKTz5p7I8dK23bdvFrfv97af16KTr6TFcGnDFp0iTNmTNHCxYs0M6dOzVhwgQVFhZq7NixkqRRo0Zp8uTJjvM3bNigxYsXa//+/Vq7dq0GDRokq9WqJ+3/wUgaNmyYXnrpJX322Wc6ePCglixZounTp2vEiBGOc06cOKEtW7Zox44dkqTU1FRt2bJFmZmZbvrkAAAALnChsQ9nC2suXT3f2E99XTq8rGbrV5RI39wtlRdKTfpJnZ6qa6UAAADARS3dtVSSdE3iNWraoKmptVgsFp8b/0BQAQAAwCRlZdKaNcb+jTfW7JqXXjLOLSyUbrtNys09/7nz5klvvml0UFi4UEpOrm/FvmfkyJF69dVXNXXqVHXv3l1btmzRihUrFBcXJ0lKT09XRkaG4/zi4mJNmTJFnTp10ogRI9SsWTOtW7dO0dHRjnNmzpypO+64Q4888og6duyoP/7xj/rNb36jF1980XHOsmXLdPnll2voUON/XNx99926/PLLNXv2bPd8cAAAAFfIWm1szzf24WzNbpbaP27sfzdWKqzBaKstT0knfzS6MfR+T/Lzr3utAAAAwEXYxz7c1uE2kysxDG13Jqhgs9lMrqb+LDZf+BQ1kJ+fr6ioKOXl5dEqFwAAeIRvv5V+9SupUSMpO1vyq2GENDtbuvJKKT1dGjZMWrr03Gs3bTLWLimR/vQnaepUp5dvqkv92e5S//wAAMADlZyQFsVIskkjjkqhNfiLs4oSaeWvpBObpNhrpRtXG6MhqnPkM+mrm439vp8aQQcfcak/213qnx8AAHimnKIcxb8arwpbhfY9tk+tG7Y2uyQVlRWp0cuNVFJRom0Ttqlzk85ml3SO2jzb0VEBAADAJPaxDzfcUPOQgiTFxkqLF0vBwdKnn0p//nPV97OzjW4LJSVGkGHKFOfVDAAAAFTr2NeSbFJkh5qFFCTJP1j61YdSQAMpe6207YXqzys6Kn03xthv95hPhRQAAADgmZalLlOFrULd47t7REhBksICw3R9K6N7mS+MfyCoAAAAYJJVq4xt//61v7ZHD8k+JeD556XPKp9Ly8ule+4xui20bSu9+27tQhAAAABAnWR9aWxrMvbhbA3aSD3fMva3/fnMOnbWCmn9/VJJjtSwu3T53+pdKgAAAHAxi3caYx9u73i7yZVUNbTtmfEP3o6vrQEAAExQWCitX2/s33hj3dYYM0aaMEGy2aT77pP27pWeecbo1BAebnRdiIpyWskAAADA+WWtNra1DSpIUtI9UvIDkmzSt7+Wio+deW/n34y1/cOM7gv+wU4pFwAAADif/JJ8rdy/UpJ0W8fbTK6mKntQ4Zv0b3Ty9EmTq6kfggoAAAAmWLtWKiuTWrSQkpPrvs6MGdLVV0u5uVK/ftLfKv/A7O23pS5dnFAoAAAAcDHF2VLeNmO/Sb+6rdHj71JkR+l0hrR+tGSzSjnfSVufNd6/8h9SZHunlAsAAIC6q7BW6FDeIbPLcKnle5artKJU7Ru3V8eYjmaXU0Wrhq3UMaajKmwV+mLfF2aXUy8EFQAAAEyQkmJs+/eXLJa6rxMUJC1aJMXFSUeOGMf++EfprrvqXyMAAABQI8fWGNvorlJIbN3WCAiT+nws+YdIGSukrc9J39wj2SqklvdIrcc4q1oAAADUw6TPJ6nFjBb68sCXFz/ZS9nHPtzW8TZZ6vPlrYv4yvgHggoAAAAmWLXK2NZ17MPZEhKkf/9batRIuvVWadq0+q8JAAAA1Fhm5diHJnUY+3C26C5Sj9eN/e1/lgoPSuGtpJ6z65fuBQAAgNOsP2zMs/067WuTK3GN02WntXzPckmeN/bBbmg7I6jwv73/U4W1wuRq6o6gAgAAgJvl5Ehbthj7zggqSFKfPlJGhrR0qRQQ4Jw1AQAAgBo5VvnXdHH1DCpIUvJ4qcWdxr4lQPrVh1JgZP3XBQAAgFOk56VLknaf2G1yJa7xxb4vVFhWqBZRLdSjaQ+zy6nWrxJ/pcjgSOUU5eiHoz+YXU6dEVQAAABwsy8rv8ft0sUY2eAsQUHOWwsAAACokaKjUn6qJIsU17f+61ksUs85UvKD0jXvSDE9678mAAAAnKK4vFhZhVmSpNScVJOrcY3FuyrHPnTwzLEPkhToH6gByQMkeff4B4IKAAAAbmYf+9C/v7l1AAAAAPWWVZnCbXi5FNTQOWsGRUm95khJ9zhnPQAAADjFobxDjv3dx3fLZrOZWI3zlVWUaVnqMkmeO/bBbmhbY/wDQQUAAADUWEqKsXXW2AcAAADANM4c+wAAAACPlpaX5tg/VXpKmQWZJlbjfGsOrlFuca6ahDdR78TeZpdzQYPbDJYkbc7YrIxTGSZXUzcEFQAAANzo4EFp3z7J31+67jqzqwEAAADqyd5RIe4Gc+sAAACAy6XnpVf5effx3SZV4hqLdxpjH4a3Hy5/P3+Tq7mwuIg4XZVwlSRp+Z7lJldTNwQVAAAA3MjeTaFXLyky0txaAAAAgHopTJMK9ksWf6nJtWZXAwAAABdLy02r8nPq8VSTKnG+CmuFluxaIkm6vdPtJldTM94+/oGgAgAAgButWmVsGfsAAAAAr2fvptDoSimwgbm1AAAAwOXsox/8LUa3AV/qqLD+8HplFWYpOiRa/ZL6mV1OjQxtZwQVVu5fqdKKUpOrqT2CCgAAAG5is0mrVxv7/fubWwsAAABQb4x9AAAAuKTYRz9c3fxqSb7VUcE+9mFYu2EK8g8yuZqauaLpFYoLj1NBaYHWpq01u5xaI6gAAADgJtu2SceOSWFh0tVXm10NAAAAUA8221lBhevNrQUAAABuYe+ocFPrmyRJqTm+EVSw2WyOoMJtHW8zuZqa87P4aXDbwZK8c/wDQQUAAAA3sY99uO46Kcg7QrkAAABA9Qr2SUWHJL9AKfZXZlcDAAAAF7ParDqUd0iSdFOyEVTYf3K/yirKzCzLKX7M/FFpeWkKCwzTgOQBZpdTK0PbGuMfCCoAAADgvFJSjO2NN5pbBwAAAFBv9m4Kja+WAsLMrQUAAAAul1mQqTJrmfwt/roq4SqFBYapwlah/Sf3m11avdm7KQxpO0Rhgd71bHtT65sU4Beg3cd3a++JvWaXUysEFQAAANygrEz66itjn6ACAAAAvB5jHwAAAC4p6XnpkqRmkc0U6B+odo3bSZJ2H99tZllOsWjnIknSbR28Z+yDXVRIlK5tca0k6bPd3tVVgaACAACAG2zcKBUUSI0bS926mV0NAAAAUA82m5S12tgnqAAAAHBJSMtNkyS1iGohSWrfuL0kKfV4qmk1OcPO7J3albNLQf5BGtpuqNnl1Il9/MPyvctNrqR2CCoAAAC4gX3sww03SH48gQEAAMCb5e+SirMk/xAp5mqzqwEAAIAb2DsqtIxqKUk+01HBPvahf+v+igyONLmauhnSdogkac3BNSooLTC5mprja3IAAAA3WLXK2Pbvb24dAAAAQL3Zxz7E9DbCCgAAAPB5aXm+2VFh8S4jqOCNYx/sOsR0UKvoViqtKFXK/hSzy6kxggoAAAAuVlAgffedsX/jjebWAgAAANQbYx8AAAAuOb7YUeFg7kFtztgsP4ufbml/i9nl1JnFYnGMf/hsz2cmV1NzBBUAAABcbO1aqaxMSkqSWrc2uxoAAACgHmxW6dgaY5+gAgAAwCXjnI4KMUZHhcyCTOWX5JtWV33Yxz70bdlXseGxJldTP0PbGUGF5XuWy2azmVxNzRBUAAAAcLGUym5bN94oWSzm1gIAAADUS+42qeS4FBAuNbrK7GoAAADgJo6OCtFGR4XI4EjFR8RL8t6uCvagwm0dvXfsg12/pH4KCwzTkVNH9FPWT2aXUyMEFQAAAFxs1Spjy9gHAAAAeL2sL41tbB/JP8jcWgAAAOAW+SX5yi3OlXSmo4J0ZvxDak6qGWXVS8apDH176FtJ0vAOw80txglCAkJ0YyvjC+jle5abXE3NEFQAAABwoexs6afKAOsNN5hbCwAAAFBvWauNLWMfAAAALhn2bgqNQhspIijCcbx9Y2P8Q+px7wsq/Cf1P7LJpl7Neql5ZHOzy3GKIW2HSJI+2/OZyZXUDEEFAAAAF/qy8g/OunaV4uLMrQUAAACoF2uFdOwrYz+OFC4AAMClIi03TVLVbgrSmY4K3jj6wZfGPtjZgwrfHf5Ox4uOm1zNxRFUAAAAcCH72If+/c2tAwAAAKi33C1SWZ4UGCk1vNzsagAAAOAm9o4KLaNaVjnurR0VTpw+oS8PGn9h5ktBhRZRLdS1SVdZbVat2LvC7HIuqk5BhVmzZikpKUkhISHq1auXNm7ceN5zy8rK9MILLyg5OVkhISHq1q2bVqyo+g+TlJQki8VyzuvRRx89Zz2bzabBgwfLYrFo6dKldSkfAADAbVJSjO2NN5pbBwAAAFBvmZVjH2Kvk/wCzK0FAAAAbpOWd/GOCjabze111dWnqZ+q3Fquy+IuU5tGbcwux6mGth0qyTvGP9Q6qPDRRx9p0qRJeu6557R582Z169ZNAwcO1LFjx6o9f8qUKXrrrbc0c+ZM7dixQw8//LBGjBihH3/80XHO999/r4yMDMdr5cqVkqQ777zznPVmzJghi8VS27IBAADc7sABaf9+KSBAuu46s6sBAAAA6imrcq5ZPGMfAAAALiXn66jQumFr+Vv8VVRWpCOnjphRWp0s3lU59qGD73RTsBvazggqrNi7QuXWcpOrubBaBxWmT5+u8ePHa+zYserUqZNmz56tsLAwvf3229We/+677+rpp5/WkCFD1Lp1a02YMEFDhgzRa6+95jgnNjZW8fHxjtd///tfJScnq2/fvlXW2rJli1577bXz3gsAAMCT2Lsp9OolNWhgbi0AAABAvVjLpOy1xn7c9ebWgnqpTbfcfv36VdsJd+jQoY5zCgoKNHHiRDVv3lyhoaGO74wBAIDvOF9HhUD/QLVu2FqS0VXBGxSUFujzvZ9L8q2xD3ZXN79aDUMa6mTxSW04vMHsci6oVkGF0tJSbdq0Sf3PGrLs5+en/v37a/369dVeU1JSopCQkCrHQkNDtW7duvPe47333tO4ceOqdE4oKirSvffeq1mzZik+Pv6itZaUlCg/P7/KCwAAwJ0Y+wAAAACfcfwHqbxACmokRV9mdjWoo9p2y128eHGVTrjbtm2Tv79/lU64kyZN0ooVK/Tee+9p586d+v3vf6+JEydq2bJl7vpYAADAxRwdFaJbnvNe+5j2kqTUnFS31lRX/9vzP5VUlKhNozbq0qSL2eU4XYBfgAa1GSTJ88c/1CqokJOTo4qKCsXFxVU5HhcXp8zMzGqvGThwoKZPn649e/bIarVq5cqVjgfc6ixdulS5ubkaM2ZMleOPP/64evfurVtvvbVGtU6bNk1RUVGOV2JiYo2uAwAAcAar9UxQ4ayMJwAAAOCdjlWOfYjrJ1lq3aQVHqK23XIbNWpUpRPuypUrFRYWViWo8O2332r06NHq16+fkpKS9NBDD6lbt24X7NQAAAC8R1lFmY6eOirp3I4KktS+sRFU8JaOCvaxD7d3vL3KH837kiFth0jysaBCXbz++utq27atOnTooKCgIE2cOFFjx46Vn1/1t547d64GDx6shIQEx7Fly5Zp9erVmjFjRo3vO3nyZOXl5Tlehw4dqu9HAQAAqLFt26TsbCkszBj9AAAAAHi1rMqgQhPGPnirunTL/aW5c+fq7rvvVnh4uONY7969tWzZMh05ckQ2m01ffvmldu/erQEDBlS7Bp1wAQDwLkdOHZHVZlWwf7CahDc55/12jdtJklKPe35HheLyYv13938l+ebYB7tBbQbJIou2Zm3VoTzP/R15rYIKMTEx8vf3V1ZWVpXjWVlZ5x3HEBsbq6VLl6qwsFBpaWnatWuXIiIi1Lp163POTUtL06pVq/Tggw9WOb569Wrt27dP0dHRCggIUEBAgCTp9ttvV79+/aq9b3BwsCIjI6u8AAAA3GXVKmPbt68UFGRuLQAAAEC9VJRI2ZVjXOMIKnirunTLPdvGjRu1bdu2c767nTlzpjp16qTmzZsrKChIgwYN0qxZs3TddddVuw6dcAEA8C5puWmSpMSoRPlV01nL3lHBG4IKq/avUkFpgZpHNteVCVeaXY7LxITF6OrmV0uSlu9ZbnI151eroEJQUJB69OihFHsfY0lWq1UpKSm65pprLnhtSEiImjVrpvLyci1atKjaEQ7z5s1TkyZNNHTo0CrHn3rqKW3dulVbtmxxvCTp//2//6d58+bV5iMAAAC4hf1x6cYbza0DAAAAqLfjG6SKYimkiRTVyexqYJK5c+eqa9eu6tmzZ5XjM2fO1Hfffadly5Zp06ZNeu211/Too49qlT29/Qt0wgUAwLuk56VLklpGtaz2fXtHhYO5B1VSXuK2uupi8U5j7MOIDiOqDV34kqFtjd+3e/L4h4DaXjBp0iSNHj1aV155pXr27KkZM2aosLBQY8eOlSSNGjVKzZo107Rp0yRJGzZs0JEjR9S9e3cdOXJEzz//vKxWq5588skq61qtVs2bN0+jR492dEyws89A+6UWLVqoVatWtf0IAAAALlVaKn31lbF/VldVAAAAwDudPfbBR+f4Xgrq0i3XrrCwUB9++KFeeOGFKsdPnz6tp59+WkuWLHH88dlll12mLVu26NVXX60yZsIuODhYwcHB9fw0AADAXdLyjI4KLaJaVPt+fES8GgQ10KnSU9p3cp86xXpmsLXcWq7/pP5Hkm+PfbAb2m6opnw5RSkHUlRcXqyQgBCzSzpHraMiI0eO1KuvvqqpU6eqe/fu2rJli1asWOFoGZaenq6MjAzH+cXFxZoyZYo6deqkESNGqFmzZlq3bp2io6OrrLtq1Sqlp6dr3Lhx9ftEAAAAJtu4USoslGJipK5dza4GAAAAqCd7UIGxD16tPt1yP/nkE5WUlOi+++6rcrysrExlZWXy86v6NbO/v7+sVqvzigcAAKa5WEcFi8Xi6Kqw+/hut9VVW1+nfa0Tp08oJixGfVr0Mbscl+sW100JDRJUVFakrw5+ZXY51ap1RwVJmjhxoiZOnFjte2vWrKnyc9++fbVjx46LrjlgwADZbLYa11CbcwEAANzJ/r3fDTdIfr7dQQwAAAC+rvy0lLPe2Ceo4PVq2y3Xbu7cuRo+fLgaN25c5XhkZKT69u2rJ554QqGhoWrZsqW++uorvfPOO5o+fbrbPhcAAHCdi3VUkKT2Me21KWOTUnNS3VVWrdnHPgxvP1wBfnX6FblXsVgsGtJmiOZtmaddObs0sM1As0s6h+//pwAAAOBm9lGsjH0AAACA18v5VrKWSqHNpAZtza4G9TRy5EhlZ2dr6tSpyszMVPfu3c/plvvL7gipqalat26dvvjii2rX/PDDDzV58mT9+te/1okTJ9SyZUu99NJLevjhh13+eQAAgOs5OipEV99RQZLaNfL8jgqf7/tckjS8w3BzC3Gj5/s9r1cGvKLokGizS6kWQQUAAAAnKiiQvvvO2L/xRnNrAQAAAOrt7LEPFou5tcApatMtV5Lat29/we628fHxmjdvnrPKAwAAHsRmsyktt2YdFSQp9bhndlQoKivSvhP7JEk9m/U0uRr3aRbZzOwSLohmxAAAAE709ddSebnUqpXUurXZ1aAmZs2apaSkJIWEhKhXr17auHHjec8tKyvTCy+8oOTkZIWEhKhbt25asWJFlXMqKir07LPPqlWrVgoNDVVycrJefPHFKl/u2mw2TZ06VU2bNlVoaKj69++vPXv2uOwzAgAA1FnWamPL2AcAAIBLzvHTx3W6/LQkKTEy8bzntW9sBBU8taNCak6qbLIpJixGseGxZpeDSnRUAAAAHqmoSPr2W+OX/t7k3XeNLd0UvMNHH32kSZMmafbs2erVq5dmzJihgQMHKjU1VU2aNDnn/ClTpui9997TnDlz1KFDB33++ecaMWKEvv32W11++eWSpJdffllvvvmmFixYoM6dO+uHH37Q2LFjFRUVpccee0yS9Le//U1///vftWDBArVq1UrPPvusBg4cqB07digkJMSt/wYAAADnVVYgHf/e2I+7wdxaAAAA4Hb2bgrxEfEKDgg+73ltGxsjwrKLsnXy9Ek1DG3olvpqanv2dklS59jOJleCsxFUAAAAHunBB6UPPjC7irrr39/sClAT06dP1/jx4zV27FhJ0uzZs/XZZ5/p7bff1lNPPXXO+e+++66eeeYZDRkyRJI0YcIErVq1Sq+99pree+89SdK3336rW2+9VUOHDpUkJSUl6YMPPnB0arDZbJoxY4amTJmiW2+9VZL0zjvvKC4uTkuXLtXdd9/t8s8NAADc7Mh/pV0zpPBEKbKj8YrqKIW3kvz8nXuvkuNS3k4pf1flK1WSTQpNMF5hCVJoszM/h8RKlvM0Xc1eJ9nKpfAkKSLJuXUCAADA46XnpUuSWka1vOB5EUERatagmY6cOqLU46m6uvnV7iivxnZk75AkdYrtZHIlOBtBBQAA4HEyM6VPPjH2u3f3vlG4SUnSsGFmV4GLKS0t1aZNmzR58mTHMT8/P/Xv31/r16+v9pqSkpJzOh6EhoZq3bp1jp979+6tf/7zn9q9e7fatWunn376SevWrdP06dMlSQcOHFBmZqb6n5VmiYqKUq9evbR+/fpqgwolJSUqKSlx/Jyfn1+3Dw0AANzPZpM2/U4q2H/ue37BUmQ7KbJD1QBDg3ZSQOj517RWSEXpvwgkVO6X5NSuPkuAFBp/JrgQmiCFVQYZMj43zmHsAwAAwCUpLc/oqNAiqsVFz23XuJ2OnDqi3cd3e1xQgY4KnomgAgAA8Djz5xsjH66+WjrP74uBesvJyVFFRYXi4uKqHI+Li9OuXbuqvWbgwIGaPn26rrvuOiUnJyslJUWLFy9WRUWF45ynnnpK+fn56tChg/z9/VVRUaGXXnpJv/71ryVJmZmZjvv88r72935p2rRp+tOf/lTnzwoAAEyUvc4IKQQ0kDr+0QgU5O2UTqVKFcVS7s/GqwqLFNHqTHAhoo10OuNMIOHUbuPa8wlrYVwX2cF4WQKk00eNV9GRM/vFWUbHhKLDxut8GPsAAABwSappRwVJat+4vb48+KVSc1JdXVat0VHBMxFUAAAAHsVqlebMMfYfesjcWoBfev311zV+/Hh16NBBFotFycnJGjt2rN5++23HOR9//LEWLlyo999/X507d9aWLVv0+9//XgkJCRo9enSd7jt58mRNmjTJ8XN+fr4SExPr/XkAAIAb7J9nbFuOlLpOPXPcWiEVpUl59m4IlQGG/J1S6Ukj3FCwXzr6WfXr+gUZnRciO5wVSuhodGgICK9ZbdZyI6xQXYjB/gpqJDW/pX7/BgAAAPBKte2oIEm7T+x2aU21dbrstPad2CdJ6tyEjgqehKACAADwKF9+Ke3fL0VGSnfdZXY18GUxMTHy9/dXVlZWleNZWVmKj4+v9prY2FgtXbpUxcXFOn78uBISEvTUU0+pdevWjnOeeOIJPfXUU44RDl27dlVaWpqmTZum0aNHO9bOyspS06ZNq9y3e/fu1d43ODhYwcHB9fm4AADADGUFUvrHxn7rMVXf8/OXIlobr2ZDzhy32aTiY1XDCwX7pJD4qqGE8FbGGvXhF2CMeQhrVr91AAAA4JMcHRWia9BRIaa9JHlcR4XU46myyabGoY0VGxZrdjk4C0EFAADgUezdFO69Vwqv4R+CAXURFBSkHj16KCUlRcOHD5ckWa1WpaSkaOLEiRe8NiQkRM2aNVNZWZkWLVqku85K1RQVFcnPz6/K+f7+/rJarZKkVq1aKT4+XikpKY5gQn5+vjZs2KAJEyY47wMCAADzHVoslRcaoxtietfsGotFCo0zXnH9XFoeAAAAcCFpubXvqLDnxB5ZbVb5WfwucoV7bD+2XZLRTcFisZhcDc5GUAEAAHiMnBxpyRJjf/x4c2vBpWHSpEkaPXq0rrzySvXs2VMzZsxQYWGhxo4dK0kaNWqUmjVrpmnTpkmSNmzYoCNHjqh79+46cuSInn/+eVmtVj355JOONYcNG6aXXnpJLVq0UOfOnfXjjz9q+vTpGjdunCTJYrHo97//vf785z+rbdu2atWqlZ599lklJCQ4AhMAAMBHHJhvbFuPMQIIAAAAgJc4XXZa2UXZkqSWURfvqJAUnaRAv0AVlxfrUN6hGnVhcIcd2TskSZ1iOplcCX6JoAIAAPAY77wjlZZKV1xhvABXGzlypLKzszV16lRlZmaqe/fuWrFiheLi4iRJ6enpVbojFBcXa8qUKdq/f78iIiI0ZMgQvfvuu4qOjnacM3PmTD377LN65JFHdOzYMSUkJOg3v/mNpk49M5P6ySefVGFhoR566CHl5uaqT58+WrFihUJCQtz22QEAgIsVHJSyvpRkkVrdb3Y1AAAAQK3Yxz5EBEUoOiT6oucH+AWoTaM22pmzU7uP7/aYoML2bKOjQqdYggqehqACAADwCDbbmbEPdFOAO02cOPG8ox7WrFlT5ee+fftqx44dF1yvQYMGmjFjhmbMmHHecywWi1544QW98MILtS0XAAB4iwPvGNv4G6Xwi7fKBQAAADyJPajQMqpljUcmtGvcTjtzdir1eKpuSr7JleXVmL2jQucmnU2uBL/kGcNBAADAJe+bb6Rdu6SwMOnee82uBgAAAKgHm1XaP9/YbzXGzEoAAACAOknLS5MktYiqeei2feP2kqTdx3e7pKbaKi4v1r6T+yTRUcETEVQAAAAewd5N4e67pchIc2sBAAAA6iV7nVR4QApoICWOMLsaAAAAoNbO7qhQU+0at5MkpR5PdUlNtZWakyqrzapGoY0UFx5ndjn4BYIKAADAdCdPSh9/bOwz9gEAAABez95NoeVIKSDM1FIAAACAuqhTR4UYo6NCao5nBBW2Z2+XZHRTqOn4CrgPQQUAAGC6hQul4mKpSxepVy+zqwEAAADqoaxASq9M4bYeY2opAAAAQF05OipE176jQnpeuk6XnXZJXbWxI3uHJKlzbGeTK0F1CCoAAABT2Wxnxj6MHy8RbAUAAIBXO7RYKi+UItpIMb3NrgYAAACok7Tc2ndUiA2LVXRItGyyae+Jva4qrcbO7qgAz0NQAQAAmOr776WtW6XgYOm++8yuBgAAAKinA/ONbesxpHABAADglSqsFTqcf1iS1DKq5h0VLBaLo6vC7uO7XVJbbdBRwbMRVAAAAKayd1O44w6pUSNzawEAAADqpeCglPWlJIvU6n6zqwEAAADqJLMgU2XWMvlb/NW0QdNaXdu+cXtJUurxVFeUVmPF5cWOrg50VPBMBBUAAIBpTp2SPvjA2B8/3txaAAAAgHo78I6xjb9RCq95i1wAAADAk6TnpUuSmkc2V4BfQK2utQcVzO6osPv4blltVjUMaaj4iHhTa0H1CCoAAADTfPihVFgotWsnXXed2dUAAAAA9WCzSvvnG/utxphZCQAAAFAvaXlpkqQWUbUP39pHP5jdUWH7se2SjG4KFkayeSSCCgAAwDT2sQ/jxzO+FwAAAF4ue51UeEAKaCAljjC7GgAAAKDO7B0VWka3rPW17WM8o6PCjuwdkqTOsZ1NrQPnR1ABAACY4qefpO+/lwIDpdGjza4GAAAAqCd7N4WWI6WAMFNLAQAAAOojLbeyo0Jk7TsqtGnURpJ04vQJ5RTlOLWu2tiefaajAjwTQQUAAGAKezeF4cOl2FhTSwEAAADqp6xASv/Y2G89xtRSAAAAgPpKz697R4WwwDDHyIjUHPPGPzg6KjSho4KnIqgAAADcrqhIeu89Y3/8eHNrAQAAAOrt0GKpvFCKaCPF9Da7GgAAAKBeHB0VomrfUUGS2jVuJ8m88Q8l5SXae2KvJDoqeDKCCgAAwO0++UTKy5NatZJuvNHsagAAAIB6OjDf2LYeI1ksZlYCAAAA1Ft6XmVHhajad1SQpPaN20uSUo+b01Eh9XiqKmwVig6JVtOIpqbUgIsjqAAAANzOPvbhgQckP55GAAAA4M0KDkpZX0qySK3uN7saAAAAoF7yivOUV5Inqe4dFexBBbM6KtjHPnSK7SQLQWKPxa8GAACAW+3YIX3zjeTvL40da3Y1AAAAQD0deMfYxt8ohdfti1wAAADAU6TlGWMfGoc2VnhQeJ3WsI9+MKujwvZj2yVJnWM7m3J/1AxBBQAA4Fb/+pexvflmKSHB3FoAAACAerFZpf3zjf1WY8ysBAAAAHAK+9iHunZTkKT2MUZHhb0n9qrCWuGUumpjR86ZjgrwXAQVAACA25SUSO9U/sHZ+PHm1gIAAADUW/Y6qfCAFNBAShxhdjUAAABAvaXlGh0VWka3rPMaiZGJCvYPVmlFqaNDgzvRUcE7EFQAAABus2SJdPy41Ly5NGiQ2dUAAAAA9bR/nrFtOVIKCDO3FgAAAMAJHB0VIuveUcHfz19tG7eVJO0+vtspddVUSXmJ9p7YK4mOCp6OoAIAAHCbOXOM7bhxkr+/ubUAAAAA9VJWIKV/Yuy3HmNqKQAAAICz2Dsg1KejgiS1a9xOkpSak1rvmmpj9/HdqrBVKCo4SgkNmD3syQgqAAAAt9i7V1q9WrJYjKACAAAA4NUOLZLKC6WINlJMb7OrAQAAAJzC0VEhqu4dFSSpfeP2kqTU4+4NKuzI3iHJ6KZgsVjcem/UDkEFAADgFv/6l7EdOFBqWb8wLgAAAGC+/fONbesxRhoXAAAA8AGOjgpRzumo4O7RD9uzt0uSOsd2dut9UXsEFQAAgMuVlUnz5xv748ebWgoAAABQfwUHpGNrJFmkVvebXQ0AAADgFKUVpco4lSHJNzoqwLMRVAAAAC736adSVpYUFycNG2Z2NQAAAEA9HXjH2MbfKIXX7wtcAAAAwFMczj8sm2wK9g9Wk/Am9VqrfUx7x5qFpYXOKK9GHB0VmtBRwdMRVAAAAC43Z46xHTtWCgw0txYAAACgXmxWaf8CY7/VGFNLAQAAAJwpPS9dktFNwVLP8WaNQhupcWhjSdKeE3vqXVtNlFaUas9x4150VPB8BBUAAIBLpaVJn39u7D/4oLm1AAAAAPV2bK1UeEAKaCAljjC7GgAAAMBp0nLTJEkto1s6ZT17V4Xdx3c7Zb2L2X18typsFYoMjlSzBs3cck/UHUEFAADgUm+/Ldls0g03SMnJZlcDAAAA1NOB+ca25UgpIMzUUgAAAABncnRUiHTOeLN2jdtJklJzUp2y3sXsyN4hyeimUN+OEHA9ggoAAMBlKiqMoIIkjR9vbi0AAABAvZUVSOmfGPutx5haCgAAAOBsaXlO7qjQuLKjwgn3dFTYfmy7JKlzbGe33A/1Q1ABAAC4zIoV0uHDUuPG0gi64gIAAMDbHVoklRdKEW2kmN5mVwPUyaxZs5SUlKSQkBD16tVLGzduPO+5/fr1k8ViOec1dOjQKuft3LlTt9xyi6KiohQeHq6rrrpK6enprv4oAADAyRwdFaK8tKNCzpmOCvB8BBUAAPBxGRnSn/8sZWe7/95z5hjbUaOk4GD33x8AAABwqv3zjW3rMRKtZOGFPvroI02aNEnPPfecNm/erG7dumngwIE6duxYtecvXrxYGRkZjte2bdvk7++vO++803HOvn371KdPH3Xo0EFr1qzR1q1b9eyzzyokJMRdHwsAADiJo6NClJM7KhzfLZvN5pQ1L4SOCt4lwOwCAACA61it0h13SN9+KxUXG4EFdykrkz77zNh/4AH33RcAAABwiYID0rE1kixSq/vNrgaok+nTp2v8+PEaO3asJGn27Nn67LPP9Pbbb+upp5465/xGjRpV+fnDDz9UWFhYlaDCM888oyFDhuhvf/ub41hycrKLPgEAAHAVm83m9I4KyY2SZZFFeSV5OlZ4THERcU5ZtzqlFaXac2KPJDoqeAs6KgAA4MP++U8jpCBJqe7pruVw6JBUXi6FhEideC4EAACAtzvwjrGNv1EKd84Xt4A7lZaWatOmTerfv7/jmJ+fn/r376/169fXaI25c+fq7rvvVnh4uCTJarXqs88+U7t27TRw4EA1adJEvXr10tKlS13xEQAAgAtlF2WruLxYFlnUPLK5U9YMCQhRUnSSJCn1uGu/oN5zfI/KreVqENTAafXDtQgqAADgo44elf7v/878vH+/e+9vv1+rVnTFBQAAgJOkL5KWtpQyV7v/3vagQqsx7r834AQ5OTmqqKhQXFzVv2SMi4tTZmbmRa/fuHGjtm3bpgcffNBx7NixYyooKNBf//pXDRo0SF988YVGjBih2267TV999VW165SUlCg/P7/KCwAAmM/eTSE+Il7BAc6b49s+5sz4B1fakb1DktFNwcIX0l6BoAIAAD7qscek/HypeWV41KygQuvW7r0vAAAAfFRxtrRxvFSULqV/4t57l56UCiofcJvf4t57Ax5i7ty56tq1q3r27Ok4ZrVaJUm33nqrHn/8cXXv3l1PPfWUbr75Zs2ePbvadaZNm6aoqCjHKzEx0S31AwCAC0vLTZMktYxu6dR12zVqJ0lKzXFtR4Xt2dslMfbBmxBUAADABy1bJi1aJPn7S59UfoebmyudPOm+Gg4cMLYEFQAAAOAUW/7PCAxIZ0ID7lJQ+XAbEicFNnDvvQEniYmJkb+/v7Kysqocz8rKUnx8/AWvLSws1IcffqgHHnjgnDUDAgLU6Rfz/jp27Kj09PRq15o8ebLy8vIcr0OHDtXh0wAAAGezd1RoEeXcMWeOjgon3NNRoXNsZ5feB85DUAEAAB9z6pT06KPG/h//KF19tWTv7GkPD7jD2aMfAAAAgHo5tk7aP+/Mz4VufLCVzgQjwnm4hfcKCgpSjx49lJKS4jhmtVqVkpKia6655oLXfvLJJyopKdF99913zppXXXWVUlOr/oXk7t271bJl9X+NGRwcrMjIyCovAABgvrS8yo4KUU7uqNCYjgqoXoDZBQAAAOeaMkU6fNjoZDB1qnGsdWspK8sID1xxhXvqYPQDAAAAnMJaJn0/wdhvOljK+J9UeFCyVkh+/u6pwd5RIYKHW3i3SZMmafTo0bryyivVs2dPzZgxQ4WFhRo7dqwkadSoUWrWrJmmTZtW5bq5c+dq+PDhaty48TlrPvHEExo5cqSuu+46XX/99VqxYoU+/fRTrVmzxh0fCQAAOInLOio0Njoq7Du5T+XWcgX4Of/X02UVZdp93OjY0LkJHRW8BUEFAAB8yMaN0syZxv7s2VJYmLHfurW0fv2Z8IA7EFQAAACAU+yaIeVtk4JjpGsWSEubGeGF00ekcOd+iXpe9o4KBBXg5UaOHKns7GxNnTpVmZmZ6t69u1asWKG4yjZ86enp8vOr2oQ3NTVV69at0xdffFHtmiNGjNDs2bM1bdo0PfbYY2rfvr0WLVqkPn36uPzzAAAA53FVR4Vmkc0UGhCq0+WndeDkAbVt3Nap60vSnhN7VG4tV0RQhBIjE52+PlyDoAIAAD6irEwaP16y2aT775duuunMe/awgLtGP+TlSSdOGPuMfgAAAECdFR6Sfn7e2L/8FSkkVgpPkk7tMcIDbg8q8HAL7zdx4kRNnDix2veq64LQvn172Wy2C645btw4jRs3zhnlAQAAk7iqo4KfxU/tGrfTT1k/affx3S4JKuzI3iHJGPtgsVicvj5cw+/ipwAAAG/w//6ftHWr1Lix9NprVd+zhwXc1VHBHoiIjZUiItxzTwAAAPigTb+TKoqk2D5Sq1HGsfDKh9sCN6VwJamQ0Q8AAADwXYWlhcopypEktYx2bkcFSWrXuJ0kKfV4qtPXlqTtx7ZLMoIK8B4EFQAA8AH79knPP2/sv/aaERA4m72jgruCCox9AAAAQL0d+Uw6vESyBEhXvSlZKr/GsocFCtz0cGutkAoPVr03AAAA4EMO5R+SJDUIaqCo4Cinr9++cXtJUmqOa4IKO3KMjgqdYzu7ZH24BkEFAAC8nM0mTZggnT4t3XCDNGrUuefYAwNpaVJFhetrsndUIKgAbzBr1iwlJSUpJCREvXr10saNG897bllZmV544QUlJycrJCRE3bp104oVK6qck5SUJIvFcs7r0UcfdZyzb98+jRgxQrGxsYqMjNRdd92lrKwsl31GAAC8TnmR9ENla/oOj0vRXc685+6gwukjkrVM8guUQpu5554AAACAG6Xlpkkyuim4YnRC+xgjqLD7xG6nry3RUcFbEVQAAMDLLVworVwphYRIb70lVfccmZAgBQZKZWXSkSOur8neUaEVI3zh4T766CNNmjRJzz33nDZv3qxu3bpp4MCBOnbsWLXnT5kyRW+99ZZmzpypHTt26OGHH9aIESP0448/Os75/vvvlZGR4XitXLlSknTnnXdKkgoLCzVgwABZLBatXr1a33zzjUpLSzVs2DBZrVbXf2gAALzB9r8YXQzCEqUuU6u+5+6ggv0+YS0lP3/33BMAAABwo/S8dElSi6gWLlnfMfrBBR0VyirKtPu4EYCgo4J3IagAAIAXy8mRHn/c2J86VWrTpvrz/P2lpCRj3x3jHxj9AG8xffp0jR8/XmPHjlWnTp00e/ZshYWF6e233672/HfffVdPP/20hgwZotatW2vChAkaMmSIXnvtNcc5sbGxio+Pd7z++9//Kjk5WX379pUkffPNNzp48KDmz5+vrl27qmvXrlqwYIF++OEHrV692i2fGwAAj5a3S9r5N2O/x+tSYETV9yMq07CFB9xTT0HlfRj7AAAAAB+VllfZUSGqpUvWtwcVMgoydKrklFPX3ntir8qsZQoPDFdiVKJT14ZrEVQAAMCLPfGEEVbo0kX64x8vfK49NEBQATCUlpZq06ZN6t+/v+OYn5+f+vfvr/Xr11d7TUlJiUJCQqocCw0N1bp16857j/fee0/jxo1ztM0rKSmRxWJRcHCw47yQkBD5+fmdd52SkhLl5+dXeQEA4JNsNumHR4xRCwlDpebDzz3HHhgozpLKC11fk72jAkEFAAAA+ChXd1SIDolWk/AmkuTofuAsO7J3SDLGPvhZ+NW3N+E/LQAAvNTq1dL8+caohzlzjNEOF2IPDRxw8R+eWa3SwYPGPqMf4MlycnJUUVGhuLi4Ksfj4uKUmZlZ7TUDBw7U9OnTtWfPHlmtVq1cuVKLFy9WRkZGtecvXbpUubm5GjNmjOPY1VdfrfDwcP3f//2fioqKVFhYqD/+8Y+qqKg47zrTpk1TVFSU45WYSDocAOCjDr4vZX0p+YdIV86sfq5ZULQU1NDYL3BDVwVHUIGHWwAAAPgmV3dUkKT2jdtLcn5QYXv2dklGUAHehaACAABe6PRp6Te/MfYfeUS6+uqLX2MPDbi6o8LRo1JpqRQQIDVv7tp7Ae72+uuvq23bturQoYOCgoI0ceJEjR07Vn5+1T9Wz507V4MHD1ZCQoLjWGxsrD755BN9+umnioiIUFRUlHJzc3XFFVecd53JkycrLy/P8Tp06JBLPh8AAKYqzZV+/IOx33nKhYMB9u4G7ggqFDL6AQAAAL7N1R0VpDPjH1KPpzp1XXtHhc6xnZ26LlwvwOwCAABA7f35z9LevVKzZtJf/lKza9w1+sG+fsuWRlgB8FQxMTHy9/dXVlZWleNZWVmKj4+v9prY2FgtXbpUxcXFOn78uBISEvTUU0+pdTVzTtLS0rRq1SotXrz4nPcGDBigffv2KScnRwEBAYqOjlZ8fHy160hScHBwlVERAAD4pJ+mGOMcIttLHS8y1yy8lXRi05luB67E6AcAAAD4sAprhQ7nH5YktYymowLch44KAAB4mZ9/lv72N2P/H/+QIiNrdp27Rj/Y1z/P71sBjxEUFKQePXooJSXFccxqtSolJUXXXHPNBa8NCQlRs2bNVF5erkWLFunWW28955x58+apSZMmGjp06HnXiYmJUXR0tFavXq1jx47plltuqfsHAgDAmx3/QdrzhrF/5RuS/0UCeo6OCi4OKpQXGuGJs+8JAAAA+JCMggyVW8sV4BegphFNXXYfV3RUKLeWKzXHWK9zEzoqeBv+zhEAAC+SmSmNHCmVl0sjRkjDh9f8Wvvoh6wsqbBQCg93SYmOjgqtGOELLzBp0iSNHj1aV155pXr27KkZM2aosLBQY8eOlSSNGjVKzZo107Rp0yRJGzZs0JEjR9S9e3cdOXJEzz//vKxWq5588skq61qtVs2bN0+jR49WQDWtRebNm6eOHTsqNjZW69ev1+9+9zs9/vjjat++ves/NAAAnsZaIX3/sCSb1PJeKf6Gi1/jrqCCfbREYLQUFO3aewEAAAAmSMtNkyQ1j2wufz9/l92nfcyZjgo2m00Wi6Xea+49sVdl1jKFBYa5dGwFXIOgAgAAXuLIEemGG6Tdu42RDzNn1u766GipYUPp5Emj60GXLi4p0xFUoKMCvMHIkSOVnZ2tqVOnKjMzU927d9eKFSsUFxcnSUpPT5ef35kmZMXFxZoyZYr279+viIgIDRkyRO+++66io6OrrLtq1Sqlp6dr3Lhx1d43NTVVkydP1okTJ5SUlKRnnnlGjz/+uMs+JwAAHm3vbGOMQ2CUdMVrNbsmojIVW+jidmH2oALdFAAAAOCj0vPSJcnlv+hv3bC1/C3+KigtUEZBhhIaJNR7zR3ZOyQZYx/8LAwS8DYEFQAA8ALp6UZIYd8+qUULafVqI6xQW61bS5s2uTaowOgHeJuJEydq4sSJ1b63Zs2aKj/37dtXO3bsuOiaAwYMkM1mO+/7f/3rX/XXv/61VnUCAOCTTmdKPz1j7Hd7SQqNr9l1Z3dUsNkkJ/w1VrXsHRsIKgAAAMBHpeUZHRVaRrV06X2C/IPUqmEr7T2xV6k5qU4JKmw/tl2SEVSA9yFaAgCAh9u/X7ruOiOk0KqV9PXXUnJy3dayhwf2u7BDLqMfAAAAUCPWMmnjQ1JZntSoh9Tm4ZpfG9ZCsvhJFael4izX1egIKvBwCwAAAN/kro4KktS+8ZnxD86wI8f4g6LOsZ2dsh7ci6ACAAAebM8eqW9fKS1NatvWCCm0rEew1R4ecFVQoahIysgw9umoAAAAgPOylkvf3icd+VTyC5Kumi3VZh6uf5AUlmjsF7gwhVvI6AcAAAD4Nnd1VJCkdo3bSZJSj6c6ZT06Kni3OgUVZs2apaSkJIWEhKhXr17auHHjec8tKyvTCy+8oOTkZIWEhKhbt25asWJFlXOSkpJksVjOeT366KOSpBMnTui3v/2t2rdvr9DQULVo0UKPPfaY8vLy6lI+AABeYedOo5PC4cNSx47SV19JzZvXb01Xd1Q4eNDYRkVJDRu65h4AAADwctZyaf0oKf1jyS9QunaR1PjK2q8TXpnCLTjg3PrOxugHAAAA+Dh3dlS4LO4ySdJH2z/SqZJT9Vqr3FruCDzQUcE71Tqo8NFHH2nSpEl67rnntHnzZnXr1k0DBw7UsWPHqj1/ypQpeuuttzRz5kzt2LFDDz/8sEaMGKEff/zRcc7333+vjIwMx2vlypWSpDvvvFOSdPToUR09elSvvvqqtm3bpvnz52vFihV64IEH6vKZAQDweD//bHRSyMyUunaV1qyRmjat/7r2oMIBF32Xa1+3dWvXjQkGAACAF7NWSN+NkdI+kCwBUp9PpGY3120te3jAVR0VbDaCCgAAAPBpNptNabmVHRWiXd9R4e4udyu5YbKOnjqq59c8X6+19p3Yp9KKUoUFhrmldjhfrYMK06dP1/jx4zV27Fh16tRJs2fPVlhYmN5+++1qz3/33Xf19NNPa8iQIWrdurUmTJigIUOG6LXXXnOcExsbq/j4eMfrv//9r5KTk9W3b19JUpcuXbRo0SINGzZMycnJuuGGG/TSSy/p008/VXl5eR0/OgAAnunHH6Xrr5eys6XLL5e+/FJq0sQ5a589+sFmc86aZ7N3amjFCF8AAAD8krVC2jBOOriwMqTwsdT81rqvZw8PFLooqFCcJVWclmSRwlz/12UAAACAu+WV5OlUqdHZIDEy0eX3CwkI0czBMyVJr294XT9n/VzntXZk75AkdYzpKD9LnYYIwGS1+k+ttLRUmzZtUv/+/c8s4Oen/v37a/369dVeU1JSopCQkCrHQkNDtW7duvPe47333tO4ceNkucCfYubl5SkyMlIBAQHnvW9+fn6VFwAAnm7jRumGG6Tjx6WePaWUFKlxY+et36KF5OcnnT4tZWU5b107e1ChNX9wBgAAgLPZrNLGB6UD70gWf+lXH0qJI+q3pqs7KthHSoQlSv5BrrkHAAAAYCJ7N4WYsBiFB4W75Z6D2w7WiA4jVGGr0KPLH5Wtjn9Rtz17uySpU2wnZ5YHN6pVUCEnJ0cVFRWKi4urcjwuLk6ZmZnVXjNw4EBNnz5de/bskdVq1cqVK7V48WJlZGRUe/7SpUuVm5urMWPGXLCOF198UQ899NB5z5k2bZqioqIcr8RE16eAAACoj2+/lfr3l3Jzpd69pZUrpYYNnXuPoCDJ/l+Jrhj/cPboBwAAAECSEVLYMF7aP78ypPCB1OL2+q8bUdnGq8BFc80Y+wAAAAAfl56XLklqEeXeDmIzBs1QWGCY1qav1btb363TGvaOCp1jOzuzNLiRy/tgvP7662rbtq06dOigoKAgTZw4UWPHjpWfX/W3njt3rgYPHqyEhIRq38/Pz9fQoUPVqVMnPf/88+e97+TJk5WXl+d4HTp0yBkfBwAAl/jqK2nAAOnUKalvX+nzz6XISNfc6+zxD87G6AcAAABUYbNKGx+W9r8tWfyk3gulFnc6Z217gKDosFRR4pw1z+YIKvBwCwAAAN+Ulmd0VGgZ1dKt920R1ULPXvesJOmJlU8otzi31mvQUcH71SqoEBMTI39/f2X9old0VlaW4uPjq70mNjZWS5cuVWFhodLS0rRr1y5FRESodTV/apmWlqZVq1bpwQcfrHatU6dOadCgQWrQoIGWLFmiwMDA89YaHBysyMjIKi8AADzRqlXS4MFSYaHRUWH5cikiwnX3s/9XsLODCjYbox8AAABwFptN+v5Rad8cI6RwzbtSy5HOWz84VgoIl2STCtOct65dYWWnBjoqAAAAwEeZ1VFBkiZdM0kdYjroWOExTVk9pVbXllvLlZqTKknq3ISOCt6qVkGFoKAg9ejRQykpKY5jVqtVKSkpuuaaay54bUhIiJo1a6by8nItWrRIt9566znnzJs3T02aNNHQoUPPeS8/P18DBgxQUFCQli1bppCQkNqUDgCAR/rf/6Sbb5ZOnzbCCp9+KoWFufaergoqZGcbYQuLRWrp3gAuAAAAPI3NJv0wUdo7W5JFunqBlHSvc+9hsZwJEbhi/AOjHwAAAODjzOqoIElB/kGaNWSWJOnNH97U5ozNNb52/8n9KqkoUWhAqJKik1xUIVyt1qMfJk2apDlz5mjBggXauXOnJkyYoMLCQo0dO1aSNGrUKE2ePNlx/oYNG7R48WLt379fa9eu1aBBg2S1WvXkk09WWddqtWrevHkaPXq0AgICqrxnDykUFhZq7ty5ys/PV2ZmpjIzM1VRUVGXzw0AgOmWLZOGD5dKSqRbb5WWLJHckcOzBxUOOPm7XPt6zZtLwcHOXRsAAABexGaTNv1O2vOGjJDCPKnVfa65V3jlWIZCF8w1I6gAAAAAH2dmRwVJuqHVDbq7y92y2qx65LNHZLVZa3TdjuwdkqSOsR3lZ6n1r7vhIQIufkpVI0eOVHZ2tqZOnarMzEx1795dK1asUFxcnCQpPT1dfn5n/g+iuLhYU6ZM0f79+xUREaEhQ4bo3XffVXR0dJV1V61apfT0dI0bN+6ce27evFkbNmyQJLVp06bKewcOHFBSUlJtPwYAAKb697+le+6RysulO+6Q3n9fusBEI6dqVfldrrM7KtjXa8UIXwAAgEuXzSZtniTtninJIvWaK7Ue7br7OToqOPnhtqJEKjps7IfzgAsAAADflJZb2VEh2rwWua8NeE2f7f5MG45s0NzNczW+x/iLXrP92HZJUqfYTq4uDy5U66CCJE2cOFETJ06s9r01a9ZU+blv377asWPHRdccMGCAbDZbte/169fvvO8BAOBt3n9fGjVKqqiQ7r1XWrBACqjTfyPXjb2jwuHDRjcHZ3U/sAcVWvMHZwAAAJcmm0368Y9S6gzj515zpOSxrr2nq4IKhemSbJJ/mBTSxLlrAwAAAB6gpLxEGQUZkszrqCBJCQ0S9Kd+f9KkLybpqZSnNKLjCMWExVzwmh05xu+eO8d2dkeJcBF6YQAA4EYLFkj33WeEFMaMkd55x70hBUmKjZXCw43vkdPTnbeuffQDQQUAAIBLkM0mbfk/add04+eeb0nJD7j+vhGV3Q4KnDzX7OyxDxaLc9cGAAAAPMDhfKODWEhAiGLDYk2t5be9fquuTbrqxOkTmrxq8kXPp6OCbyCoAACAm8yZI40da3yH+9BD0ty5kr+/++uwWFwz/oHRDwAAAJcom0366Wlp5yvGz1e9IbV5yD33dnRU2GfU4SyF9qACD7cAAADwTel5xl+xtYhqIYvJ4dwAvwC9MfQNSdK/fvyXvjv83XnPrbBWaFfOLkkEFbwdQQUAANxg1iwjnGCzSRMnSrNnS34m/rewveuBK4IKdFQAAAC4hNhs0tZnpR1/NX6+8h9S2wnuu394krEty5dKTzpvXXuHhggebgEAAOCb0vLSJEkto1qaXImhT4s+Gt1ttCTpkc8eUYW1otrz9p/cr5KKEoUEhKhVNMFib0ZQAQAAF3v3XSOcIEl/+IP097+b3z3W2UGFsjLp0KGqawMAAOAS8PPz0vaXjP0er0vtHnXv/QPCpNCmxn6BE1O4Z49+AAAAAHzQ2R0VPMXfbvqbokOi9WPmj3rzhzerPWdH9g5JUoeYDvL3M6FlMZyGoAIAAC72+uvG9vHHpVdeMT+kIJ0JExxw0ijf9HTJapVCQ6W4OOesCQAAAA/38wvStheM/Sv+n9T+MXPqCK/8K6pCJz3cSgQVAAAA4PPScj2ro4IkNQlvopduMILQU1ZPUVZB1jnnbM/eLknqHNvZrbXB+QgqAADgQtnZ0ubNxv4TT3hGSEGSWlV+l+usjgr2dVq18pzPCAAAABfa9pL083PG/uWvSh1+b14t9jCBUzsqVIYewmklCwAAAN9kH/3gSR0VJOk3PX6jHk17KK8kT0+sfOKc9+0dFTrFdnJ3aXAyggoAALjQqlXG2N7LLpOaNjW7mjOcPfrBvg5jHwAAAC4B26dJW6cY+91fljr+wdx6nB1UKD0pleVWrk1QAQAAAL7JPvqhZbTndFSQJH8/f70x9A1ZZNG7W9/V12lfV3mfjgq+g6ACAAAu9PnnxnbgQHPr+KWkJGOblyedPFn/9ewjJAgqAAAA+Lh9b0s/PW3sd/uL1OlJc+uRzgoqOGn0gz3wEBIvBYQ5Z00AAADAg1htVkdQwdM6KkhSz2Y9Nf6K8ZKkRz57RGUVZZKkCmuFduXskkRHBV9AUAEAABex2aQvvjD2PS2oEBYmxccb+87oqnD26AcAAAD4sN0zjW2nyVLnyebWYmfveuCsjgr2deimAAAAAB+VXZitkooSWWRR88jmZpdTrb/c+Bc1Dm2s7dnb9fcNf5ckHcg9oOLyYgX7B6t1Q/5qztsRVAAAwEV+/lnKyJBCQ6Vf/crsas7lzPEPjH4AAAC4BBQdlU5ukWSROjxudjVn2DsqFKZJ1vL6r2fvzBDBwy0AAAB8U1pemiSpaYOmCvIPMrma6jUOa6yX+78sSXr+q+d1JP+IdmTvkCR1iOkgfz9/M8uDExBUAADARexjH/r1k0JCTC2lWgQVAAAAUCsZK4xtoyulkFhzazlbaILkFyTZyqWiw/Vfz9FRgYdbAAAA+Cb72IeWUS1NruTCxl4+Vtc0v0YFpQWa9MUkbT+2XZLUuUlnkyuDMxBUAADARTx17IOdfUzDgXqO8s3NlU6eNPaTkuq3FgAAADzY0f8Z24Qh5tbxSxY/KTzJ2C+s58OtRFABAAAAPi8t1+io0CKqhcmVXJifxU9vDH1DfhY/fbz9Y83bMk+S1Cmmk8mVwRkIKgAA4AJFRdLatca+pwYVnNVRwR50aNJEioio31oAAADwUNYyKbMyiZsw2NxaqmMPFRQ4oV2YffRDeKv6rwUAAAB4IG/pqCBJ3eO769GrHpUk7TmxRxIdFXwFQQUAAFzgq6+kkhKpRQupfXuzq6mes4IKjH0AAAC4BOSsl8rypeAYY/SDp3FWUMFaIRUerLomAAAA4GPS8ryjo4Ldi9e/qLjwOMfPnWLpqOALCCoAAOACn39ubAcMkCwWc2s5H3uwIC1Nqqio+zr2jgoEFQAAAHyYfexD04GSn7+5tVTHWUGF04clW7nkFySFJtS/LsADzZo1S0lJSQoJCVGvXr20cePG857br18/WSyWc15Dhw6t9vyHH35YFotFM2bMcFH1AADAGRwdFaI9v6OCJEWFROnVAa9KksICw9S6IV9G+4IAswsAAMAXfVHZFddTxz5IUkKCFBQklZZKhw9LLev4TGrvqNCKzrgAAAC+6+hyY9vUA8c+SFJE5cOofWxDXdmDDuEtPTOQAdTTRx99pEmTJmn27Nnq1auXZsyYoYEDByo1NVVNmjQ55/zFixertLTU8fPx48fVrVs33Xnnneecu2TJEn333XdKSCDkAwCAJ7PZbF7XUUGSft3118orzlNiVKIC/PgVty+gowIAAE526JC0c6fk5yfdeKPZ1Zyfn5+UlGTs12f8A6MfAAAAfFzRESl3qySL0VHBEzmro4I96MDYB/io6dOna/z48Ro7dqw6deqk2bNnKywsTG+//Xa15zdq1Ejx8fGO18qVKxUWFnZOUOHIkSP67W9/q4ULFyowMNAdHwUAANTRjuwdOnH6hIL8g5TcMNnscmrMYrHo0Z6P6pb2t5hdCpyEoAIAAE5mH/vQq5fUsKG5tVyMPVxAUAEAAADnZR/70LinFBJjbi3nE17ZUaEkWyorqPs69qADQQX4oNLSUm3atEn9+/d3HPPz81P//v21fv36Gq0xd+5c3X333QoPD3ccs1qtuv/++/XEE0+oc+fOTq8bAAA41+KdiyVJN7W+SeFB4Rc5G3AdggoAADiZPagwYIC5ddSEfVzDgTp2yK2okNLSqq4FAAAAH5NRGVRI8NCxD5IUFCUFNzb2C+sx/oGgAnxYTk6OKioqFBcXV+V4XFycMjMzL3r9xo0btW3bNj344INVjr/88ssKCAjQY489VqM6SkpKlJ+fX+UFAADcZ9HORZKk2zreZnIluNQRVAAAwInKy6VVq4z9gR7aFfds9e2ocPSoVFoqBQRIzZs7ry4AAAB4CGuZlLHS2E8YYm4tF2PvqlCf8Q/20Q/hpHCBX5o7d666du2qnj17Oo5t2rRJr7/+uubPny+LxVKjdaZNm6aoqCjHKzEx0VUlAwCAX9h3Yp9+yvpJ/hZ/3dr+VrPLwSWOoAIAAE70ww9Sbq4UHS1ddZXZ1VxcfYMK9uuSkiR/f6eUBAAAAE+S/Y1UfkoKjpUa9TC7mguzd0GoT1ChkI4K8F0xMTHy9/dXVlZWleNZWVmKj4+/4LWFhYX68MMP9cADD1Q5vnbtWh07dkwtWrRQQECAAgIClJaWpj/84Q9KSkqqdq3JkycrLy/P8Tp06FC9PhcAAKg5ezeFfkn91DisscnV4FJHUAEAACeyj33o39/oMuDp7EGFuo5+sF/Xmu9xAQAAfNPRyrEPTQdJFg//Gqm+QYWyAqn4WNW1AB8SFBSkHj16KCUlxXHMarUqJSVF11xzzQWv/eSTT1RSUqL77ruvyvH7779fW7du1ZYtWxyvhIQEPfHEE/rc/j+QfyE4OFiRkZFVXgAAwD3sQYXbO95uciWA5AW/QgEAoKovv5ROnZJuucXsSs5l/x7GG8Y+SFKryo62x45JBQVSRETtrrd3VGhFZ1wAAADfdHS5sU0YbG4dNRFhH/1QxxRuYeV1QQ2loCjn1AR4mEmTJmn06NG68sor1bNnT82YMUOFhYUaO3asJGnUqFFq1qyZpk2bVuW6uXPnavjw4WrcuOpfXjZu3PicY4GBgYqPj1f79u1d+2EAAECtHMo7pI1HNsoii4Z3GG52OQBBBQCAdyktlYYNkwoLpa1bpa5dza7ojJMnpQ0bjP0BA8ytpaaioqRGjaQTJ4zuCLX997QHFeioAAAA4IMKD0l524xOCk294AG3vh0V7AEHuinAh40cOVLZ2dmaOnWqMjMz1b17d61YsUJxcXGSpPT0dPn5Ve2ekpqaqnXr1umLL74wo2QAAOAkS3YtkST1Tuytpg2amlwNQFABAOBldu0yQgqSNGeO9Pe/m1vP2VJSJKtV6tBBatHC7GpqrnXrugcVGP0AAADgwzJWGNvGvaRgL5hfaw8YFB6QbNbaj6qwBxwIKsDHTZw4URMnTqz2vTVr1pxzrH379rLZbDVe/+DBg3WsDAAAuBJjH+BpPHy4IAAAVW3demb/3Xel06fNq+WX7H9c4i1jH+zsYxv21+EPzxj9AAAA4MPsYx+aesHYB0kKS5Qs/lJFsXQ6s/bXE1QAAACAj8oqyNLatLWSpNs63mZyNYCBoAIAwKv8/POZ/dxc6d//Nq2UKmw26fPPjX1vCyrYuyHUNqhQVCRlZlZdAwAAAD6iolTKXGXsNxtibi015RdohBUko6tCbdlHP4STwgUAAIBv+U/qf2STTVcmXKmW0S3NLgeQRFABAOBl7B0V7H/BP2eOebWcLTVVSk+XgoKkvn3NrqZ26hpUsI99iI6WGjZ0akkAAACXju8flb6+zQgGeJKcb6TyAimkidTwcrOrqTl7N4SCOrQLK6SjAgAAAHyTfezDbR3opgDPQVABAOBV7B0V/vpXyc9PWrtW2rXL3JqkM90Urr1WCgszt5basgcVDtTyj87s5zP2Ad5u1qxZSkpKUkhIiHr16qWNGzee99yysjK98MILSk5OVkhIiLp166YVK1ZUOScpKUkWi+Wc16OPPuo4JzMzU/fff7/i4+MVHh6uK664QosWLXLZZwQAeKiS49KeN6TDS4yXJ3GMfRgkWbzo66O6BhVstjMdFQgqAAAAwIecPH1Sqw+sliTd3ul2k6sBzvCi/6UJALjUnTghHTli7A8aJA2p7ED7r3+ZV5PdF18YW28b+yCdCRrs3298P1tT9g4MjH2AN/voo480adIkPffcc9q8ebO6deumgQMH6tixY9WeP2XKFL311luaOXOmduzYoYcfflgjRozQjz/+6Djn+++/V0ZGhuO1cuVKSdKdd97pOGfUqFFKTU3VsmXL9PPPP+u2227TXXfdVWUdAMAlIHfrmf3ds8yrozpH/2dsE7xk7INdXYMKxVlSxWkjlBHewvl1AQAAACZZlrpM5dZydWnSRe0atzO7HMCBoAIAwGvYuykkJUmRkdL48cbPCxZIJSWmlaWSEmnNGmPfG4MKLVoY3SmKi6XMzJpfR1ABvmD69OkaP368xo4dq06dOmn27NkKCwvT22+/Xe357777rp5++mkNGTJErVu31oQJEzRkyBC99tprjnNiY2MVHx/veP33v/9VcnKy+p41F+bbb7/Vb3/7W/Xs2VOtW7fWlClTFB0drU2bNrn8MwMAPMjJn87sZ6+VTm49/7nuVJgu5W03fmkff5PZ1dROeGUKt6CW7cLswYawRMkv0Lk1AQAAACZavGuxJOn2jnRTgGchqAAA8BpbK7+3vewyYztkiJSQIOXkSP/5j3l1rVsnFRVJ8fFS167m1VFXgYFGWEGq3fgH+7kEFeCtSktLtWnTJvXv399xzM/PT/3799f69eurvaakpEQhISFVjoWGhmrdunXnvcd7772ncePGyWKxOI737t1bH330kU6cOCGr1aoPP/xQxcXF6tev33nvm5+fX+UFAPABuZVBBYu/sd3jIV0V7N0UYq6RghuZW0tt1bWjgv18xj4AAADAh5wqOaXP9xpzi2/reJvJ1QBVEVQAAHgNe0cFexggIEAaO9bYnzPHnJok6XPjOU8DBkhn/R7Sq5w9/qGm7OfarwW8TU5OjioqKhQXF1fleFxcnDLP015k4MCBmj59uvbs2SOr1aqVK1dq8eLFysjIqPb8pUuXKjc3V2PGjKly/OOPP1ZZWZkaN26s4OBg/eY3v9GSJUvUpk2bateZNm2aoqKiHK/ExMTaf2AAgOexd1Bo91tje+A9qTTXtHIcMiqDCk0Hm1tHXdiDBqePSBXFNb+OoAIAAAB80PI9y1VSUaI2jdqoaxMv/Cs7+DSCCgAAr/HLjgqS9MADxnbVqtr9kt2Z7EEFbxz7YGfvilDTf0ObjdEPuDS9/vrratu2rTp06KCgoCBNnDhRY8eOlZ9f9Y/Vc+fO1eDBg5WQkFDl+LPPPqvc3FytWrVKP/zwgyZNmqS77rpLP9sTWb8wefJk5eXlOV6HDh1y+mcDALiZtdwYryBJ7SZK0V2liiJp/3xTy1JFiZS5ythP8MKgQnBjKaCBsV+YVvPrCivbhYWTwgUAAIDvWLRzkSRj7IPFW//KDj6LoAIAwCtYrdK2bcb+2eMVWrWSbqocmzt3rvvrysgwAhQWy5k6vFFtgwrHjhnjLiwWqWVL19UFuFJMTIz8/f2VlZVV5XhWVpbi4+OrvSY2NlZLly5VYWGh0tLStGvXLkVERKh1NYmdtLQ0rVq1Sg8++GCV4/v27dM//vEPvf3227rxxhvVrVs3Pffcc7ryyis1a1b1Lb+Dg4MVGRlZ5QUA8HL5qZK1RAqIkCJaSW0fNY7vniXZrObVlb1OKi+UQuKlht3Nq6OuLBbj31Oq3fgHOioAAADAx5wuO63le5ZLMoIKgKchqAAA8AoHDkiFhVJwsNS2bdX3xo83tvPmSWVl7q1r5Upje8UVUmyse+/tTPbxDQcO1Ox8+3nNm0tBQa6pCXC1oKAg9ejRQykpKY5jVqtVKSkpuuaaay54bUhIiJo1a6by8nItWrRIt9566znnzJs3T02aNNHQoUOrHC8qKpKkc7ow+Pv7y2o18RdTAAD3yq1sFxbdVbL4SUm/lgIjpYK9UsZK8+o6anyRqYRBRl3eyB42IKgAAACAS9gX+75QYVmhEiMTdWXClWaXA5zDS/8XJwDgUmPvht6pkxQQUPW9W281QgIZGdJnn7m3Ll8Y+yDVvqMCYx/gKyZNmqQ5c+ZowYIF2rlzpyZMmKDCwkKNHTtWkjRq1ChNnjzZcf6GDRu0ePFi7d+/X2vXrtWgQYNktVr15JNPVlnXarVq3rx5Gj16tAJ+8f+0OnTooDZt2ug3v/mNNm7cqH379um1117TypUrNXz4cJd/ZgCAh8j9ydhGdzO2gRFSa+O/f7Sn+g47bnH0f8Y2YYh5NdRXbYMKFSVS0ZHKaxn9AAAAAN9gH/twW8fbGPsAj0RQAQDgFbZW/sHZZZed+15QkDRmjLE/Z47bSpLVKn3xhbE/YID77usK9sDBkSNSScnFzyeoAF8xcuRIvfrqq5o6daq6d++uLVu2aMWKFYqLi5MkpaenKyMjw3F+cXGxpkyZok6dOmnEiBFq1qyZ1q1bp+jo6Crrrlq1Sunp6Ro3btw59wwMDNTy5csVGxurYcOG6bLLLtM777yjBQsWaMgQL/6lEACgdk5WBhUadjtzrO0jxvbIf6WCGra6cqaCg1L+TsniL8V78VyzcPvohxr+GxamSbJJAeFSsBe3SQMAAAAqlVaUalnqMkmMfYDnCrj4KQAAmM/eUaG6oIIkPfig9Mor0ooV0qFDUmKi62v68UcpJ0eKiJAu0iXe48XEGJ+joEBKS5Patbvw+fbRDwQV4AsmTpyoiRMnVvvemjVrqvzct29f7dix46JrDhgwQDab7bzvt23bVosWLapVnQAAH+MY/XDWA25kOyl+gJT5hbRntnT5y+6tKaOym0LMNVJQtHvv7Uy17ahw9tgH/tIMAAAAPmD1gdXKK8lTXHiceif2NrscoFp0VAAAeAV7R4WuXat/v107qW9fo8vB22+7pyZ7N4UbbjC6Ongzi0VqVfmHZzUZ/2A/pxWdcQEAAGqvOEc6fdTYj/7FA267R43tvn9J5afdW5cvjH2QqgYVLhAcdDg7qAAAAAD4gMU7F0uSRnQYIX8/f5OrAapHUAEA4PGKiqS9e43983VUkKTx443t3LlSRYXr6/r8c2M7cKDr7+UO9u4ItQkq0FEBAACgDuzdFCKSpcAGVd9LGCqFt5RKT0jpH7mvpopiKTOlsobB7ruvK0QkGdvyU1LJ8YufX1jZLiycFC4AAAC8X4W1Qkt3LZUk3dbxNnOLAS6AoAIAwOPt2GF0SoiNlSrHxlfr9tulhg2N0Q/2bgeucuqU9M03xv6AAa69l7vUNKhQWmr8G599DQAAAGoh9ydjG11NCtfPX2o7wdjf/Y+adQRwhmNrpYoiKbSpFN3NPfd0Ff8QKTTB2LeHEC6EjgoAAADwIWvT1yq7KFsNQxqqX1I/s8sBzougAgDA4/38s7G9UDcFSQoJke6/39ifM8e1NX35pVRebvyivk0b197LXexjHA5c5Lvc9HTj+/KwMKlJE9fXBQAA4HNOVgYVGp4nEND6AckvWDqxSTq+0T012cc+NB1szAXzdmePf7gYggoAAADwIYt2LJIk3drhVgX6B5pcDXB+BBUAAB5va2Vn3K5dL3yedGb8w6efSpmZrqvJ3rHBV8Y+SDXvqGB/v1Ur3/gOGwAAwO3sox+q66ggSSExUsu7jf3d/3BPTRnLja23j32wq2lQwWY7K6jA6AcAAAB4N6vNqiW7lkiSbu94u8nVABdGUAEA4PFq2lFBkrp0ka65xuh2MH++62r6/HNj66tBhQt1GLYHFRj7AAAAUAfWMilvu7F/vo4KktTuUWOb/rFUfMy1NRXsl/JTJYu/FH+Ta+/lLo6gwkXahZWelMryjf3wJJeWBAAAALjaxiMbdeTUEUUERah/6/5mlwNcEEEFAIDHq01HBelMV4V//UuyWp1fz/790t69UkCAdP31zl/fLElJxjY/Xzp58vzn2UdDEFQAAACog/xUyVoqBTS48C/GG18lNe5pnLtvrmtrso99iP2VFBTl2nu5S3hld4SLdVSwvx/aVAoIc21NAAAAgIvZxz7c3O5mhQSEmFwNcGEEFQAAHi0rS8rOlvz8pE6danbNXXdJkZHSvn3Sl186vyZ7N4VrrjHu4ytCQ6WmTY39C41/OHv0AwAAAGrJMfahq2S5yNcybSu7Kux5U7KWu64me1ChqY+MfZBqPvrBMfaBFC4AAAC8m81m06KdRlCBsQ/wBgQVAAAezd5NoU0bKayGf+AUHi7de6+xP2eO82vyxbEPdmePfzgfRj8AAADUw8mfjO2Fxj7YtbxLCo6Rig5JR/7rmnoqiqWs1cZ+whDX3MMM9uBBUfqFQx6Fle3CwknhAgAAwLv9lPWTDuQeUGhAqAa38aEQMnwWQQUAgEf7+Wdje9lltbvOPv5hyRIpJ8d59ZSVSasrv8clqOD6egAAAHyOo6NCDYIK/iFS8oPG/u5/uKaerK+kitNSaDOjy4OvCI2X/IIlW4UR9DgfOioAAADAR9jHPgxqM0jhQeEmVwNcHEEFAIBHs3dU6FrL70yvuMJ4lZZK77zjvHq++046dUqKiTHW9zX2cQ4HDlT//smTUm6usZ+U5I6KAAAAfExuZUeF6Bomcds+bIyIyEqR8nY6v56MyrEPCYMli8X565vF4idFVD7cXmj8A0EFAAAA+Aj72IfbOt5mciVAzRBUAAB4tLp2VJDOdFWYM0ey2ZxTj33sw003SX4++N+iF+uoYA8wxMUZIzYAAABQC8XZ0ukMY7+m3QvCW0rNhhn7e95wfk1HlxvbBB9sDWsPH1wwqFD5gBvB6AcAAAB4r53ZO7UzZ6cC/QJ1c7ubzS4HqBEf/BULAMBXlJdL27cb+7XtqCBJ994rhYVJu3ZJ33zjnJrsQYUBA5yznqe5WFCBsQ8AAAD1YB/7EJEsBUbU/Lq2jxrb/QukslPOq+fUPunUHskSIMX3d966nuJiQQVruVSYVvVcAAAAwAst3rlYktS/dX9Fh0SbWwxQQwQVAAAea+9eqaTE+Mv9VnX4A6fISOnuu439OXPqX09OjrRpk7Hv60GF9HQjKPJL9o4KdfnPAwAA4JJ3snLsQ8Nutbsu/kapQTup/JR04F3n1XO0cuxDbB8pMNJ563qKcPvoh/PMNSs6LNnKJb8gKTTBfXUBAAAATmYf+3B7x9tNrgSoOYIKAACPtbXyD866dKn7mAX7+IdPPpFyc+tXz6pVxgiJrl2lBB/9HrNpUyk42AgpHD587vt0VAAAAKiH3MqgQnQtgwoWP6ldZVeFPbOcN9fMl8c+SBfvqGA/HtHK+DcGAAAAvND+k/v1Y+aP8rP46Zb2t5hdDlBj/K8wAIDH+vlnY3vZZXVfo1cvI+hw+rS0cGH96rGPfRg4sH7reDI/PykpydivbvwDQQUAAIB6sI9+iK7DA26r0VJAuJS3Qzr2Vf1rKT8tHfvS2E8YUv/1PJE9qFB4nqBCYWWnhXDahQEAAMB72cc+9G3ZV7HhsSZXA9QcQQUAgMeyd1To2rXua1gsZ7oq/POfdf/jM5tN+uILY99Xxz7Y2UMIB6rpkGs/RlABAACglqxlRshAqv3oB0kKipKS7jf2d/+j/vUcWyNVFEthzaWozvVfzxNFVAYQSo5LZfnnvu/oqMDDLQAAALwXYx/grQgqAAA8ljM6KkjSffcZ4wy2bpW+/75ua2zbJh09KoWGStdeW796PF2ryu9zf9lRoaJCOniw6jkAAACoofxdkrVUCmgghSfVbQ37+IfDS6WiauZ01cbR/xnbpoONdK8vCmwgBccY+wXVpHAJKgAAAMDLHck/ou8OfydJGtFxhMnVALVDUAEA4JFOnTrz1/v16aggSY0aSXfcYezPmVO3NezdFPr2lUJC6lePp7N3S/hlUOHIEamsTAoMlJo1c39dAAAAXu1kZbuwhpfVPRgQ3UVq0leyVUh73qpfPfaggq+OfbCzhxAKqhn/YA8vRJDCBQAAgHdasmuJJOma5tcooUGCydUAtUNQAQDgkbZtM7bNmhlBg/qyj3/44AMjBFFbn39ubAcOrH8tnu58QQX7z0lJkr+/W0sCAADwfrk/GdvoOox9OJu9q8K+f0oVJXVbI3+PVLBX8guU4m+sXz2e7oJBBToqAAAAwLsx9gHejKACAMAjba38g7P6dlOwu+46qV07qbBQ+vDD2l1bVCR9/bWxfykEFexjHQ78ojuu/WfGPgAAANRBrr2jQj2DCs2HS6EJUvEx6dCiuq2RUdlNIfZaYzyCLwuvfHj95eiHsgKpJLvqOQAAAIAXyS7M1tdpxhfXt3W8zeRqgNojqAAA8Eg//2xsL7vMOetZLGe6KtR2/MPXX0slJVLz5lKHDs6px5PZgwjZ2VW7T9g7KrTmD84AAABq76S9o0I9H3D9AqU2vzH2d8+q2xpHlxvbhMH1q8UbnK+jQmFlcCG4sRQU5d6aAAAAACf4T+p/ZLVZdUXTK9SqIeFbeB+CCgAAj+TsjgqSNHq0FBgoff+99NNPNb/u7LEPdR0n7E2ioqTGjY39s7sqEFQAAACoo+JjUnGmJIsU1aX+67UZL1kCpJxvpRM/1u7a8iIpa42x3/QSCioU/iKoYA8u0E0BAAAAXso+9uG2DnRTgHciqAAA+P/s3XlYVdX+x/H3YZ4CFQUEUdQcS3EmtdJbJIk5Xa/aTdOwNE1vGfdWaqbdBrkNmmWWZuqvtNJKM0ujlEav5phZOWuJ1wRHQFHGs39/HDl6ZFAQ2Ayf1/Psh332WWuv7zrDZnH4nrUqHMMo/RkVAOrUgX79bPvFmVXhq69sP6vDsg958pIRLk1UyNtXooKIiIhIMeUt++DTGFx9rv18nnWh/t9s+/uKOatC8rdgzQSv+uDX8tpjqejsMyr8Dob14vG8RAUfDW5FREREpPLZkbyDhIMJAAxoOcDkaERKRokKIiJS4fzvf5CSAi4upb/UQt7yD4sXw7lzVy5/+DDs3AlOThAZWbqxVGR5yz8cvOSLZ3n7DfWlMxEREZHiyVv2oWZ46Z2zyVjbzz/eh8xTV1/v0mUfqsN0YV71wOIM1iw4f/TicSUqiIiIiEgltC5xHb0/6E34nHCyrdmEB4bTvHY1WK9YqiQlKoiISIWTN5tC8+bg5la65779dts/2lNT4eOPr1w+bzaFTp2gZs3SjaUiy5s1IS85IT0dkpMd7xMRERGRq5SXqFCjFBMV6nSFGq0h9zwcXHh1dQwDjn5h2w+uBss+ADi5gHcD2/7ZS7Jwz16YLsxHWbgiIiIiUrFZDSuf7v6Urgu6csvCW/h87+dYsPC3ln9j+eDlZocnUmJKVBARkQpnx4WZcVu1Kv1zOznB/ffb9t9668rlv/zS9rNHj9KPpSK7PFEhb9mHmjWhRg1TQhIRERGpvPKWfqhZiuuaWSzQdJxtf98bjssaFObMXts/651cIfD20oulorMv/3BpooJmVJDqa/bs2YSFheHh4UFERASbNm0qtGz37t2xWCz5tl69egGQnZ3NE088QatWrfD29iY4OJhhw4bx559/lld3REREqqys3CwW/rSQG9+4kX5L+7H+8Hrcnd0Z1W4Ue8bt4aOBH9GopsazUnkpUUFERCqcvBkVWpfi57iXiokBZ2f4739tyzoUJjcX1q617UdFlU0sFVXe8g55CQp5P7Xsg4iIiEgx5WZB2oVBZ2nOqAAQdg+4+tn+6f5n/JXL/3lhNoU6t4KrT+nGUpFdnqhgGJD+u+N9ItXE0qVLiY2NZerUqWzbto3w8HCioqI4duxYgeWXL1/O0aNH7duvv/6Ks7MzAwcOBODcuXNs27aNp556im3btrF8+XL27NlDnz59yrNbIiIiVcqZzDNMXz+dRq82YsTKEew6sQtfd18mdJ3AH+P/YG7vuTTxb2J2mCLXrESJCsXJus3OzuaZZ56hcePGeHh4EB4eTny84x/PYWFhBWbmjh071l4mIyODsWPH4u/vj4+PDwMGDCA5bw5qERGpUspyRgWA4GC48OUP3n678HJbtsDp0+DnZ1v6oTrJm1Hh99/Bar04s4KWfRAREREppjN7wJoNrr4XlyAoLS7e0GiEbX/f7CuXz0tUCI4u3TgqOu8L2bZ5yz1kJEFuBlicwSvUvLhETDBjxgxGjhxJTEwMLVu2ZM6cOXh5ebFgwYICy9eqVYugoCD7tmbNGry8vOyJCn5+fqxZs4ZBgwbRrFkzbrrpJl5//XW2bt1KYmJieXZNRESk0ks+m8yTCU9Sf2Z9/rXmXxw5c4S6PnV5MfJFDj96mLjIOIJ8gswOU6TUFDtRobhZt5MnT2bu3LnMmjWLnTt3Mnr0aPr3789PP/1kL7N582aHzNw1a9YA2Ae8AI8++iifffYZH330Ed999x1//vknf/3rX4sbvoiIVHBZWbB7t22/rGZUABg1yvbz3XchM7PgMnnLPkRGgotL2cVSEYWG2madyMiApCQlKoiIiIiU2OmfbT9rtLYt11Damoyx/fzzCzhzoPByOelw7FvbfnDP0o+jIsubNSH9wqA2b2YFr1DbMhgi1URWVhZbt24lMjLSfszJyYnIyEg2bNhwVeeYP38+d999N97e3oWWSU1NxWKxUKOQdQMzMzNJS0tz2ERERKqzA6cOMObzMTSY2YBp66aRkpFCM/9mvN37bX5/5Hce6/oYvu6+ZocpUuqKnahQ3KzbRYsWMWnSJKKjo2nUqBFjxowhOjqa6dOn28vUqVPHITP3888/p3HjxnTr1g2wDW7nz5/PjBkzuO2222jfvj0LFy5k/fr1/PjjjyXsuoiIVES7d0NOjm0Wg3r1yq6dO++0nf/kSfjkk4LL5CUq9OhRdnFUVK6uUL++bf/33y8u/aBEBREREZFiSslLVCjlZR/y+DaBuncCBux7s/Byyd+ANcs2q4Nv87KJpaK6fOmHvJ9a9kGqmRMnTpCbm0tgYKDD8cDAQJKSkq5Yf9OmTfz666888MADhZbJyMjgiSee4O9//zu+vgX/QyUuLg4/Pz/7FhqqmU1ERKR6OnrmKIM/HkzT15syZ+scMnMziQiJYPmg5ewcu5P7292Pu4u72WGKlJliJSqUJOs2MzMTDw8Ph2Oenp6sW7eu0DYWL17MiBEjsFz4psHWrVvJzs52aLd58+bUr1+/yHaVmSsiUvn88ovtZ+sy+sJZHmdnGHFhltx58/Lfn5ICGzfa9qOiyi6OiqzhhRlyDx68OKNC3jERERERuUqnL6xrVrOMEhUAml5YOvPAfMg5V3CZS5d9KMuBdkWUl5Bw/ijknFeigkgJzZ8/n1atWtGpkLURs7OzGTRoEIZh8OabhSdOTZw4kdTUVPt2+PDhsgpZRESkQnvlx1f48LcPsRpWel7fk2+Hf8uG+zfQv0V/nCzF/q65SKVTrFd5SbJuo6KimDFjBvv27cNqtbJmzRqWL1/O0aNHCyy/YsUKUlJSuO++++zHkpKScHNzyzddWFHtKjNXRKRy2nHhc9xWrcq+rREjbJ/Rfv01HLhsltyvv4bcXGjWDBqU8lLClUXe7AkHDmjpBxEREZESS7lk6YeyUrcneIdBdgoc+iD//YYBf66+WLa6casJrhe+2Z3+B5y9MF2Yj7JwpXqpXbs2zs7OJCcnOxxPTk4mKKjo9a7T09NZsmQJ999/f4H35yUpHDp0iDVr1hQ6mwKAu7s7vr6+DpuIiEh19OeZPwF4pvszrB6ymm5h3exf4hapDso8HefVV1+lSZMmNG/eHDc3N8aNG0dMTAxOTgU3PX/+fHr27ElwcPA1tavMXBGRyunSGRXKWoMGF2dLePttx/vyln2orrMpwMWkhB9/hPPnwcnp4nIQIiIiInIVzidDRjJggRo3ll07Ts7Q5CHb/t7XbYkJl0rbY/sHvZMbBN1WdnFUVBaL4/IPeTMqeCsLV6oXNzc32rdvT0JCgv2Y1WolISGBzp07F1n3o48+IjMzk6FDh+a7Ly9JYd++faxduxZ/f/9Sj11ERKQqOnHuBAD1/fShq1RPxUpUKEnWbZ06dVixYgXp6ekcOnSI3bt34+PjQ6MCvpJ56NAh1q5dm2+ds6CgILKyskhJSbnqdpWZKyJSOZXnjAoAI0fafi5cCNnZtn3DUKICXFzm4YcfbD/r1QM3N/PiEREREal0Ui4Mbq+7Hly8y7atxiPA2QNOb4cTly2TmTebQkC3so+joiooUUFLP0g1FBsby7x583jnnXfYtWsXY8aMIT09nZiYGACGDRvGxIkT89WbP38+/fr1y5eEkJ2dzd/+9je2bNnCe++9R25uLklJSSQlJZGVlVUufRIREams8hIV/L2U5CfVU7ESFa4l69bDw4OQkBBycnJYtmwZffv2zVdm4cKFBAQE0KtXL4fj7du3x9XV1aHdPXv2kJiYeMV2RUSk8jh1Co4cse3fWIZfOLtU794QGAjJyfD557Zje/fCoUO2f8p361Y+cVREeTmF58453hYRERGRq2Rf9iG87Nty94cGf7ft753teN/RL2w/g6vhsg95vC9k4abtgvO2KXaVqCDV0eDBg3n55ZeZMmUKbdq0Yfv27cTHx9uX+k1MTMy3ZO+ePXtYt25dgcs+HDlyhJUrV/K///2PNm3aULduXfu2fv36cumTiIhIZZWXqFDbq7bJkYiYw6W4FWJjYxk+fDgdOnSgU6dOzJw5M1/WbUhICHFxcQBs3LiRI0eO0KZNG44cOcLTTz+N1Wrl8ccfdziv1Wpl4cKFDB8+HBcXx7D8/Py4//77iY2NpVatWvj6+vKPf/yDzp07c9NNN5W07yIiUsHkLfsQFgblNRGOqyvcdx+88AK89Rb0739xNoWbbwbvavqFM8ifmKBEBREREZFiOn0hUaFmOSQqADQdCwcXwuGP4PwM8AyE7LNw7Hvb/cHR5RNHRZSXlJD8DWCAi48tuUOkGho3bhzjxo0r8L5vv/0237FmzZphXL6kzAVhYWGF3iciIiJFU6KCVHfFTlQYPHgwx48fZ8qUKSQlJdGmTZt8WbdOThcnasjIyGDy5MkcPHgQHx8foqOjWbRoETVq1HA479q1a0lMTGTEiBEFtvvKK6/g5OTEgAEDyMzMJCoqijfeeKO44YuISAWWl6jQunX5tvvAA7ZEhS+/tM2k8NVXtuPVedkHAH9/8PGBs2dtt/OWghARERGRq5S39EONchrg1moP/jfByR/hwDy4cTIkfw3WLNuMAtc1LZ84KqK8RIW03RdvWyzmxSMiIiIi1VpGTgbp2emAEhWk+ip2ogIUL+u2W7du7Ny584rn7NGjR5HZtx4eHsyePZvZs2cXWkZERCq3HRc+x23Vqnzbvf56uO02+PprmDMHvvnGdry6JypYLLZZFPKeF82oICIiIlIMuVm2ZQag/GZUANusCht+hH1zoOUE+DNv2Yfo6v2P+cuXedCyDyIiIiJiopPnTgLgbHHGz93P5GhEzOF05SIiIiLlw6wZFQBGjrT9nD4dzp2DwEBz4qhoLk1OUKKCiIiISDGk7QZrNrj6gVf98mu3/kBwrwPnj8D/VsCfq23Hg3uWXwwVkXcD4JJEDW9NFyYiIiIi5rl02QdLdU4olmpNiQoiIlIhWK0XExXKe0YFgP79bUsdZGfbbvfoUb2/cJZHiQoiIiIiJZTys+1njdblO7B0dofrL2Thbp8A5xLByR0C/1J+MVREzu7gFXLxtmZUEBERERETXZqoIFJdKVFBRETsMjNhwQLYvLn82/7jD0hPB3d3aNKk/Nt3d4dhwy7eru7LPuRpeOGLZl5eUKeOubGIlJXZs2cTFhaGh4cHERERbNq0qdCy2dnZPPPMMzRu3BgPDw/Cw8OJj493KBMWFobFYsm3jR07FoA//vijwPstFgsfffRRmfZVRETK0ekLiQrluexDnusfBIsTnD1gux3YHVy8yj+OiubS5AQlKoiIiIiIiZSoIKJEBRERueD77yE8HO6/H266CZ58ErKyyq/9HTtsP1u2BBeX8mv3UnnLPzg5wR13mBNDRdOsme1n06aaYUKqpqVLlxIbG8vUqVPZtm0b4eHhREVFcezYsQLLT548mblz5zJr1ix27tzJ6NGj6d+/Pz/99JO9zObNmzl69Kh9W7NmDQADBw4EIDQ01OH+o0eP8u9//xsfHx969qzm03KLiFQlKRcGuDVMSFTwrg8hfS/erqvfL4ASFURERESkwshLVPD38jc5EhHzKFFBRKSaO33a9g/6bt1gzx647jrbMgzTpkGXLrB7d/nEkbfsQ+vW5dNeQVq0gCVL4KOPICDAvDgqkttug7g4eOMNsyMRKRszZsxg5MiRxMTE0LJlS+bMmYOXlxcLFiwosPyiRYuYNGkS0dHRNGrUiDFjxhAdHc306dPtZerUqUNQUJB9+/zzz2ncuDHdunUDwNnZ2eH+oKAgPvnkEwYNGoSPj0+59FtEpNpIT4Sc8+a0fenSD2ZoOvbifrASFQDwbnhx3yfMtDBEREREROwzKnhqRgWpvpSoICJSTRkGLF1q++f822/bjo0aBYcOwYcfQs2asHUrtGsHb75pK1+W8mZUaNWqbNu5ksGD4a9/NTeGisTZGSZMgM6dzY5EpPRlZWWxdetWIiMj7cecnJyIjIxkw4YNBdbJzMzEw8PD4Zinpyfr1q0rtI3FixczYsQILIVMS7J161a2b9/O/fffX2ismZmZpKWlOWwiIlKE3EzY9i/4tAF83gyO/VC+7Z9PgoxjgAVq3Fi+becJvA2ajYeWE+A6E9ZWq4jyZlHwDAZnj6LLioiIiIiUIS39IKJEBRGRaunQIejdG+6+G5KToXlz29IPc+faEhQGDrTNcBAZCefPw0MP2conJ5ddTBVhRgURqV5OnDhBbm4ugYGBDscDAwNJSkoqsE5UVBQzZsxg3759WK1W1qxZw/Llyzl69GiB5VesWEFKSgr33XdfoXHMnz+fFi1a0KVLl0LLxMXF4efnZ99CQ0Ov3EERkeoqdTd8dRPsvjDbzbnDkNAddkwBa075xJC37MN1TcDFq3zavJzFAu1fgTZxWsMrT52u4OwJQVrnTURERETMdfL8SUCJClK9KVFBRKQayc2FmTPhhhtg1Spwc4Onn4bt2+GWWxzLhoTAl1/CK6+Au7utfKtW8NlnpR/X+fOwb59t3+wZFUREivLqq6/SpEkTmjdvjpubG+PGjSMmJgYnp4KH1fPnz6dnz54EBwcXeP/58+d5//33i5xNAWDixImkpqbat8OHD19zX0REqhzDgH1zIb4dnN4O7v7QdQk0HA6GFX59FtbeCmd/L/tYTl9Y9qFmeNm3JVfPpyEMOA43LTQ7EhERERGp5jSjgogSFUREqo2ffoKICHj0UUhPtyUmbN8OU6faEhEK4uQE48fD5s22BILjx6FPHxg92naO0rJzJ1itUKcOXPbFZhGRMlO7dm2cnZ1Jvmy6mOTkZIKCggqsU6dOHVasWEF6ejqHDh1i9+7d+Pj40KhRo3xlDx06xNq1a3nggQcKjeHjjz/m3LlzDBs2rMhY3d3d8fX1ddhEROQSGSfgh/6weTTknrd9Y77nDmgwGDr/H3R5H1x94cQG+KIN/PFB2caTN6NCDSUqVDgu3pphQkRERERMp0QFESUqiIhUeenp8Nhj0LEjbN0Kfn7w1lvw7bfQosXVnaNVK9i0Cf75T9vtuXOhbVtbAkNp2LHjYjv6zFBEyoubmxvt27cnISHBfsxqtZKQkEDnzp2LrOvh4UFISAg5OTksW7aMvn375iuzcOFCAgIC6NWrV6HnmT9/Pn369KFOnTol74iISHV3dA2sbgX/+xSc3KDtdPhLPHhdMptN2N+h589QuzNkp8H6e2DDfZB9pmxiSrkwo0INrWsmIiIiIiL5KVFBRIkKIiJV2pdfwo03wssv25Z9GDQIdu+GkSNtsyUUh4eH7Txr19qWhdi3Dzp3hueeg5xrXOr3l19sP1vrc1wRKWexsbHMmzePd955h127djFmzBjS09OJiYkBYNiwYUycONFefuPGjSxfvpyDBw/yww8/cOedd2K1Wnn88ccdzmu1Wlm4cCHDhw/HxcWlwLb379/P999/X+SMCyIiUoTcTNj2T/imB2QkgW9ziNoILWLBUsBg1ycMIr+HG5+y3f/7O/BFOzhZStm3l8aVusu2r6UfRERERESkAHmJCv5e/iZHImIeJSqIiFRBx47BkCFw553wxx8QGgqffQZLl0Ihs5lftdtvt82AMGiQLfnhqafg1lvhwIGSn/PSGRVERMrT4MGDefnll5kyZQpt2rRh+/btxMfHE3hhHZrExESOHj1qL5+RkcHkyZNp2bIl/fv3JyQkhHXr1lGjRg2H865du5bExERGjBhRaNsLFiygXr169OjRo0z6JiJSpaXugq9ugt0zbLebjIE7t0LNNkXXc3KB1s/A7d+AVyic3Q9fdYGdL4JhLZ3Y0naDkQOuNWxtiIiIiIiIXOJc9jnO55wHNKOCVG8WwzAMs4MoD2lpafj5+ZGamqo1fUWkyjIM+L//g3/9C06dss2a8PDD8Oyz4ONT+m299x6MHQtpabbzv/Ya3Hdf8ZdvCAy0JVds3gwdOpRunCJSNVX3sV1177+IVGOGAfvnwrZYyD0P7rUhYj7U61P8c2Wdho2j4PDHttuBt0HnRY5LRpTEwXfhx+EQcCtEfndt5xKRaqG6j+2qe/9FRKT6SUxNpMHMBrg6uZI5OROL1kOWKqQ4YzvNqCAiUkXs22eb7WDECFuSQng4/PgjvPJK6ScpgC0ZYehQ+PlnuOUWOHvW1vbf/gYnT179eZKTbUkKFgu0bFn6cYqIiIhIFZFxHL7vB5vH2JIUgu6A6B0lS1IAcKsJN38IEW+Dsxckfw1ftIb/rby2OFN+tv2soWUfREREREQkv5PnbB+g1/aqrSQFqdaUqCAiUsllZcHzz9uWTfjmG/D0hBdftM1O0LFj2bcfFmZrNy4OXFxg+XJbLF99dXX1f/nF9rNJE/DyKrMwRURERKQyO7oGVreGIyvByQ3azYC/xINn3Ws7r8UCje+/uGxE5kn4vi9sHgsXpmIttpQL65rVVKKCiIiIiIjkd+LcCUDLPogoUUFEpBLbsAHat4fJkyEzE3r0gF9/hcceA1fX8ovD2RkmTLDN4NCsGRw9ClFR8MgjcP4Kn+/uuPA5bqtWZR+niIiIiFQyuZmw7Z/wTQ/ISALfFhC1EZo/CpZS/EjDrzn0+BGa/9N2e98b8GUnSPm1eOcxDDidN6NC69KLT0REREREqgwlKojYKFFBRKQSSk2FsWOha1dbYkLt2rB4McTHQ6NG5sXVvj1s2wYPPWS7/dpr0KEDbN9eeJ28GRVa63NcEREREblU6k74MgJ2z7DdbvIQ3LnFNvNBWXB2h3YvQ/d48AiE1F8hvgPsnW1LQLgaGUmQedyWROF3Q9nEKSIiIiIilZoSFURslKggIlLJrFgBLVvCG2/YPi+97z7YvRuGDLHNXGs2Ly+YPRtWrYKAANi5Ezp1gpdeAqs1f3nNqCAiIiIiDgwD9r0J8e0h5Wdwrw23roSOs8GlHNYKC46C6B1QtydYM2HLONtyEBknrlz39IXB7XVNyidWERERERGpdJSoIGKjRAURkUriyBH461+hf3/480+4/npYuxYWLgR/f7Ojyy862jZbQp8+kJ0Njz8Ot98Ohw9fLJOTY0tkAM2oICIiIiJAxnFbUsDmhyA3A4J62JIG6vUu3zg8AqD7Kmg3E5zc4Mhn8EVrSFpbdL2UvGUfwss8RBERERERqZzyEhX8PSvgB/si5UiJCiIiFVxurm2GghYt4JNPwMUFJk2yzURw++1mR1e0gADbDBBvvWWbaeHbb20zJyxZYrt//37IyABvb2jY0MxIRURERMR0R7+C1a1tSQFObtDuFfjLF+BZ15x4LBZo/ghEbQLfFnD+KHzdA356AnKzCq6TcmFGhZpKVBARERERkYKdOK8ZFURAiQoiIhXaL7/AzTfDuHFw5gxERMC2bfD88+DpaXZ0V8digZEjYft22xIQqanw97/D0KHwww+2MjfeCE76jSQiIiJSPeVmwtZY+CYKMpLAr6UtOaD5eLBUgEFizXC4cwtc/yBgwK4XYU1XSNuXv+zpvBkVNF2YiIiIiIgUTEs/iNhUgL/4RUTkcufPw5NPQrt28OOPcN118Prr8N//2mYkqIyaNIF162DKFFtSwnvvwYMP2u6rrH0SERERkWuUuhO+jIA9r9huNxkLUVsq3owELl7QaQ7csgzcasKpLRDfFg7+HxiGrUxuJqTttu1r6QcRERERESnEyXMnASUqiChRQUSkgjl3Dm67DaZNg5wc6NsXdu6EsWPB2dns6K6Nqyv8+9+2hIVGjS5+pttaXzgTERERqV4MA/a+AfHtIeVncK8N3T6Djq+DSwWeOiz0rxC9AwK6QU46/BgD6++BrBRI2wVGji2Rwaue2ZGKiIiIiEgFpRkVRGyUqCAiUoHk5sKQIbZZFGrWhGXLYMUKqFfFPufs3Nm2FMSoUdC8OfTubXZEIiIiIlJuMo7D931hy1jIzYC6URD9C4TcZXZkV8erHtyWAOHPg8UZDi2BL9rAgfm2+2u0tq1/JiIiIiIichnDMJSoIHKBi9kBiIjIRf/6ly0xwc0NPv0UbrnF7IjKznXXwdy5ZkchIiIiIuXqzy/hx+GQkQxObtDmRWj2D7BUsu9RODnDDZMg8Hb4798h/XfY+7rtPi37ICIiIiIihUjPTiczNxNQooJIJfskQESk6nrtNZg507b/zjtVO0lBRERERKqZ3AzY+ih8e6ctScGvJURthuaPVL4khUvVjoDo7RA25OKxmm3MikZERERERCq4vNkUPFw88HL1MjkaEXNpRgURkQrg009h/Hjbflwc3H23qeGIiIiIiJSe1N3w38GQssN2u+k420wKLp7mxlVaXH2hy2II6Q3J30L9gWZHJCIiIiIiFVReooK/pz8WLRkn1ZwSFURETLZ5M/z972AYMGoUPPGE2RGJiIiIiJSSs39AQjfIOAbudeCmhRDSy+yoykaDwbZNRERERESkEHmJClr2QUSJCiIipvr9d7jrLjh/Hu68E2bPBiVRioiIiEiVkJUC3/WyJSnUbAPdvwDPILOjEhERERERMY0SFUQuqsQLQYqIVG6nT0N0NBw7BuHh8OGH4KL0MRERERGpCqzZsG4gpO4EzxDo9rmSFEREREREpNo7ee4koEQFEVCigoiIKTIzoX9/2L0b6tWDVavguuvMjkpEREREpBQYBmx+CJLWgos3dP8cvELMjkpERERERMR0mlFB5CIlKoiIlDPDgPvvh+++syUnrFoFIfrcVkRERESqil0vwYG3weIEXZfaln0QERERERERJSqIXEKJCiIi5WzKFHjvPXB2ho8/htatzY5IRERERKSUJH4M25+w7bebCSG9TA1HRERERESkIjlxXokKInmUqCAiUo4WLIDnnrPtz50LPXqYG4+IiIiISKk5sRE23Gvbb/owNPuHufGIiIiIiIhUMJpRQeQiJSqIiJSTNWvgwQdt+08+aVv+QURERESkSjj7B3zfB3IzIPguaDfD7IhEREREREQqnLxEBX9Pf5MjETGfEhVERMrBL7/AgAGQkwP33APPPmt2RCIiIiIipSQrBb7rBRnHoGYb6PoBODmbHZWIiIiIiEiFoxkVRC5SooKISBk7cgSio+HMGejWzbb8g8VidlQiIiIiIqXAmg3rBkLqTvAMgW6fg6uP2VGJiIiIiIhUOIZhcPLcSUCJCiKgRAURkTJ15gzcdRf873/QvDl88gm4u5sdlYiIiIhIKTAM2DwWktaCizd0/xy8QsyOSkRErmD27NmEhYXh4eFBREQEmzZtKrRs9+7dsVgs+bZevXrZyxiGwZQpU6hbty6enp5ERkayb9++8uiKiIhIpXIm6wzZ1mwA/L209IOIEhVERMpITg4MGgTbt0NAAKxeDTVrmh2ViIiIiEgp2fUyHJgHFifousS27IOIiFRoS5cuJTY2lqlTp7Jt2zbCw8OJiori2LFjBZZfvnw5R48etW+//vorzs7ODBw40F7mxRdf5LXXXmPOnDls3LgRb29voqKiyMjIKK9uiYiIVAp5yz54uXrh5eplcjQi5lOigohIGTAMGDsW4uPB0xM++wwaNjQ7KhERERGRUpK4DLY/bttvNxNC7jI1HBERuTozZsxg5MiRxMTE0LJlS+bMmYOXlxcLFiwosHytWrUICgqyb2vWrMHLy8ueqGAYBjNnzmTy5Mn07duX1q1b8+677/Lnn3+yYsWKcuyZiIhIxZeXqKBlH0RslKggIlIGXnwR3noLLBb44APo1MnsiERERERESsmJTbBhqG2/6T+g2T/MjUdERK5KVlYWW7duJTIy0n7MycmJyMhINmzYcFXnmD9/PnfffTfe3t4A/P777yQlJTmc08/Pj4iIiKs+p4iISHWhRAURRy5mByAiUtUsXQoTJtj2Z86Evn1NDUdEREREpPSc/QO+7w25GRDcC9q9YnZEIiJylU6cOEFubi6BgYEOxwMDA9m9e/cV62/atIlff/2V+fPn248lJSXZz3H5OfPuu1xmZiaZmZn222lpaVfdBxERkcpMiQoijjSjgohIKVq3DoYPt+0/8gg8/LC58YiIiIiIlJqsVPiuF2Qcg5ptoOsScHI2OyoRESkn8+fPp1WrVnS6xmkj4+Li8PPzs2+hoaGlFKGIiEjFlpeo4O/pb3IkIhWDEhVERErJ3r222RMyM6FfP5g+3eyIRERERERKiTUb1g2E1J3gGQzdPgNXH7OjEhGRYqhduzbOzs4kJyc7HE9OTiYoKKjIuunp6SxZsoT777/f4XheveKcc+LEiaSmptq3w4cPF7crIiIilZJmVBBxpEQFEZFScPw4REfDqVPQqRO89x4468tlIiIiIlIVGAZsHgtJa8DFG7p9Dl71zI5KRESKyc3Njfbt25OQkGA/ZrVaSUhIoHPnzkXW/eijj8jMzGTo0KEOxxs2bEhQUJDDOdPS0ti4cWOh53R3d8fX19dhExERqQ5OnjsJKFFBJI+L2QGIiFR2589Dnz5w4AA0bAgrV4KXl9lRiYiIiIiUkl0vw4F5YHGyLfdQq63ZEYmISAnFxsYyfPhwOnToQKdOnZg5cybp6enExMQAMGzYMEJCQoiLi3OoN3/+fPr164e/v+NU1RaLhfHjx/Pcc8/RpEkTGjZsyFNPPUVwcDD9+vUrr26JiIhUCifOa0YFkUspUUFE5BpYrXDvvfDjj1CjBqxeDYGBZkclIiIiIlJKEpfB9sdt++1egZC7zI1HRESuyeDBgzl+/DhTpkwhKSmJNm3aEB8fT+CFDzMSExNxcnKchHfPnj2sW7eOr776qsBzPv7446SnpzNq1ChSUlK4+eabiY+Px8PDo8z7IyIiUplo6QcRR0pUEBG5Bo8/DsuWgZsbrFgBzZubHZGIiIiISCk5sQk2XJjiu+k4aPawufGIiEipGDduHOPGjSvwvm+//TbfsWbNmmEYRqHns1gsPPPMMzzzzDOlFaKIiEiVpEQFEUdOVy4iIiIFmT0bpk+37S9cCN26mRuPiIiIiEipST8E3/eB3AwI7mWbTUFERERERERKTIkKIo6UqCAiUgKffQYPX/hC2XPPwT33mBuPiIiIiEipyUqFb3tBRjLUCIeuH4CTJmQUEREREREpKath5eS5k4ASFUTyKFFBRKSYtm6Fu+8GqxXuvx8mTTI7IhERERGRUmLNhnUDIfU38AyG7p+D63VmRyUiIiIiIlKppWakkmvkAuDv6W9yNCIVgxIVRESK4dAhuOsuOHcOevSAN98Ei8XsqERERERESoFhwOaxkLQGXLyh22fgVc/sqERERERERCq9vGUffNx8cHdxNzkakYpBiQoiIlcpJQWioyEpCVq1go8+AldXs6MSERERESklu16GA/PA4gRdPoBa7cyOSEREREREpEo4eV7LPohcTokKIiJXISsL/vpX2LkTgoNh9Wrw9TU7KhERERGRUnJ4OWx/wrbfdgbU621uPCIiIiIiIlVI3owKSlQQuUiJCiIiV2AYMHIkfPMN+PjAqlVQTzPgiohUGbNnzyYsLAwPDw8iIiLYtGlToWWzs7N55plnaNy4MR4eHoSHhxMfH+9QJiwsDIvFkm8bO3asQ7kNGzZw22234e3tja+vL7feeivnz58vkz6KiBTpxCZYPxQwoOk4aPaw2RGJiIiIiIhUKUpUEMlPiQoiIlfw73/Du++Cs7NtuYc2bcyOSERESsvSpUuJjY1l6tSpbNu2jfDwcKKiojh27FiB5SdPnszcuXOZNWsWO3fuZPTo0fTv35+ffvrJXmbz5s0cPXrUvq1ZswaAgQMH2sts2LCBO++8kx49erBp0yY2b97MuHHjcHLS8FxEyln6Ifi+D+Seh+BoaPcKWCxmRyUiIiIiIlKlKFFBJD99EioiUoR33rElKgC88Qbceae58YiISOmaMWMGI0eOJCYmhpYtWzJnzhy8vLxYsGBBgeUXLVrEpEmTiI6OplGjRowZM4bo6GimT59uL1OnTh2CgoLs2+eff07jxo3p1q2bvcyjjz7Kww8/zIQJE7jhhhto1qwZgwYNwt3dvcz7LCJil5UK3/aCjGSoEQ5dl4CTi9lRiYiIiIiIVDn2RAVPJSqI5FGigohIIRIS4IEHbPsTJsCoUebGIyIipSsrK4utW7cSGRlpP+bk5ERkZCQbNmwosE5mZiYeHh4Oxzw9PVm3bl2hbSxevJgRI0ZgufAN5WPHjrFx40YCAgLo0qULgYGBdOvWrdBz5LWblpbmsImIXBNrNqwbCKm/gWcwdP8cXK8zOyoREREREZEqSTMqiOSnRAURkQL89hsMGAA5OXD33fD882ZHJCIipe3EiRPk5uYSGBjocDwwMJCkpKQC60RFRTFjxgz27duH1WplzZo1LF++nKNHjxZYfsWKFaSkpHDffffZjx08eBCAp59+mpEjRxIfH0+7du24/fbb2bdvX4HniYuLw8/Pz76FhoaWoMciIhcYBmwZB0lrwNkLun0GXvXMjkpERERERKTKyktU8PfyNzkSkYpDiQoiIpc5ehSioyE1FW6+GRYuBC0ZLiIiAK+++ipNmjShefPmuLm5MW7cOGJiYnAq5BfF/Pnz6dmzJ8HBwfZjVqsVgAcffJCYmBjatm3LK6+8QrNmzQpdcmLixImkpqbat8OHD5d+50Sk+tg9Hfa/BVig6wdQq53ZEYmIiIiIiFRpJ8+fBDSjgsil9K83EZFLnD0Ld90FiYnQtCmsWAGXzfAtIiJVRO3atXF2diY5OdnheHJyMkFBQQXWqVOnDitWrCA9PZ1Dhw6xe/dufHx8aNSoUb6yhw4dYu3atTyQt47QBXXr1gWgZcuWDsdbtGhBYmJige26u7vj6+vrsImIlMjh5fDT47b9djOgXh9z4xEREREREakGtPSDSH5KVBARueDcOejdG7Ztgzp1YPVq8NcsTCIiVZabmxvt27cnISHBfsxqtZKQkEDnzp2LrOvh4UFISAg5OTksW7aMvn375iuzcOFCAgIC6NWrl8PxsLAwgoOD2bNnj8PxvXv30qBBg2vokYjIFZzcDOuHAgY0GQvNHjE7IhERERERkWpBiQoi+bmYHYCISEWQl6Tw7bdw3XXw+efQuLHZUYmISFmLjY1l+PDhdOjQgU6dOjFz5kzS09OJiYkBYNiwYYSEhBAXFwfAxo0bOXLkCG3atOHIkSM8/fTTWK1WHn/8cYfzWq1WFi5cyPDhw3FxcRxyWywWHnvsMaZOnUp4eDht2rThnXfeYffu3Xz88cfl03ERqX7SD8F3vSH3PNTtCe1ngsVidlQiIiIiIiJVXq41l1PnTwFKVBC5lBIVRKTaO38e+vaFr78GHx+Ij4dOncyOSkREysPgwYM5fvw4U6ZMISkpiTZt2hAfH09gYCAAiYmJODldnIQsIyODyZMnc/DgQXx8fIiOjmbRokXUqFHD4bxr164lMTGRESNGFNju+PHjycjI4NFHH+XUqVOEh4ezZs0aGitLTkTKQlYqfNsLMpKhRmu4eSk46eMAERERERGR8pCSkYLVsALg76lpnEXyWAzDMMwOojykpaXh5+dHamqq1vQVEbuMDOjXD778Ery9bUkKN99sdlQiInIl1X1sV937LyLFYM2Gb++CpK/Asy702AjeoWZHJSIil6juY7vq3n8REan69pzYQ/PZzfFz9yNlQorZ4YiUqeKM7ZyKvFdEpArLzIQBA2xJCl5esHq1khREREREpAoxDNjyD1uSgrMXdPtMSQoiIiIiIiLl7MS5E4CWfRC5nBIVRKRaysyEv/3Nlpzg6QmrVsGtt5odlYiIiIhIKTEM+HkS7J8LWKDr+1CrvdlRiYiIiIiIVDt5iQr+Xlr2QeRSJUpUmD17NmFhYXh4eBAREcGmTZsKLZudnc0zzzxD48aN8fDwIDw8nPj4+Hzljhw5wtChQ/H398fT05NWrVqxZcsW+/1nz55l3Lhx1KtXD09PT1q2bMmcOXNKEr6IVHNZWTBoEHz+OXh4wGefQffuZkclIiIiIlJKrLmw6UHY+R/b7favQr2+5sYkIiIiIiJSTZ08fxLQjAoilyt2osLSpUuJjY1l6tSpbNu2jfDwcKKiojh27FiB5SdPnszcuXOZNWsWO3fuZPTo0fTv35+ffvrJXub06dN07doVV1dXvvjiC3bu3Mn06dOpWbOmvUxsbCzx8fEsXryYXbt2MX78eMaNG8fKlStL0G0Rqa6ys+Huu2HlSnB3t/28/XazoxIRERERKSW5mfDfu+HAPLA4Qae3oNk/zI5KRERERESk2tLSDyIFK3aiwowZMxg5ciQxMTH2WQ28vLxYsGBBgeUXLVrEpEmTiI6OplGjRowZM4bo6GimT59uL/PCCy8QGhrKwoUL6dSpEw0bNqRHjx40btzYXmb9+vUMHz6c7t27ExYWxqhRowgPDy9yNgcRkUtlZ8M998Ann9iSFD79FO64w+yoRERERERKSfZZ+O4uOPwxOLlB16Vw/UizoxIREREREanW7IkKnkpUELlUsRIVsrKy2Lp1K5GRkRdP4OREZGQkGzZsKLBOZmYmHh4eDsc8PT1Zt26d/fbKlSvp0KEDAwcOJCAggLZt2zJv3jyHOl26dGHlypUcOXIEwzD45ptv2Lt3Lz169ChOF0SkmsrJgaFD4eOPwc3NlqwQFWV2VCIiIiIipSTzJHx9OyStBRdv6L4K6v/N7KhERERERESqPc2oIFKwYiUqnDhxgtzcXAIDAx2OBwYGkpSUVGCdqKgoZsyYwb59+7BaraxZs4bly5dz9OhRe5mDBw/y5ptv0qRJE7788kvGjBnDww8/zDvvvGMvM2vWLFq2bEm9evVwc3PjzjvvZPbs2dx6660FtpuZmUlaWprDJiLVU04ODBsGH34Irq6wbBn07Gl2VCIiIiIipeTc/2DNLXByE7jVgtu+hqDIK9cTERERERGRMqdEBZGCFXvph+J69dVXadKkCc2bN8fNzY1x48YRExODk9PFpq1WK+3atWPatGm0bduWUaNGMXLkSObMmWMvM2vWLH788UdWrlzJ1q1bmT59OmPHjmXt2rUFthsXF4efn599Cw0NLeuuikgFlJsL990HH3wALi7w0Udw111mRyUiIiIiUkrS9sJXXSFtF3iGwB0/QO1OZkclIiIiIiIiFyhRQaRgxUpUqF27Ns7OziQnJzscT05OJigoqMA6derUYcWKFaSnp3Po0CF2796Nj48PjRo1spepW7cuLVu2dKjXokULEhMTATh//jyTJk1ixowZ9O7dm9atWzNu3DgGDx7Myy+/XGC7EydOJDU11b4dPny4OF0VkSogNxdGjID33rMlKXz4IfTta3ZUIiIiIiKl5NQ2WHMznEuE65pCj/+CX8sr1xMREREREZFyo0QFkYIVK1HBzc2N9u3bk5CQYD9mtVpJSEigc+fORdb18PAgJCSEnJwcli1bRt9L/lvYtWtX9uzZ41B+7969NGjQAIDs7Gyys7MdZmEAcHZ2xmq1Ftieu7s7vr6+DpuIVB9WK4wcCe++C87OsGQJ9O9vdlQiIiIiIqUk+TtY2x0yj0PNdraZFLwbmB2ViIiIiIiIXCYvUcHfy9/kSEQqFpfiVoiNjWX48OF06NCBTp06MXPmTNLT04mJiQFg2LBhhISEEBcXB8DGjRs5cuQIbdq04ciRIzz99NNYrVYef/xx+zkfffRRunTpwrRp0xg0aBCbNm3irbfe4q233gLA19eXbt268dhjj+Hp6UmDBg347rvvePfdd5kxY0ZpPA4iUoVYrfDgg7BwoS1J4f33YcAAs6MSERERESkl/1sJ6waBNRMCukG3leCq5HwREREREZGKJseaQ0pGCqAZFUQuV+xEhcGDB3P8+HGmTJlCUlISbdq0IT4+nsDAQAASExMdZj7IyMhg8uTJHDx4EB8fH6Kjo1m0aBE1atSwl+nYsSOffPIJEydO5JlnnqFhw4bMnDmTIUOG2MssWbKEiRMnMmTIEE6dOkWDBg14/vnnGT169DV0X0SqGqsVHnoI3n4bnJxg0SIYNMjsqERERERESsnBd2Dj/WDkQkgfuHkpOHuYHZWIiIiIiIgU4PT50xgYANTyrGVyNCIVi8UwDMPsIMpDWloafn5+pKamahkIkSrKMGDsWHjzTbBYbMs+DB1qdlQiIlIWqvvYrrr3X6Ta2jUDfvqnbb/hcIh4G5yK/f0DERGpYKr72K66919ERKq2Xcd30fKNltT0qMmpJ06ZHY5ImSvO2M6pyHtFRCoJw4BHHrmYpPB//6ckBRERERGpIgwDfn7yYpJC81i4aYGSFERERERERCq4E+dOAFr2QaQg+lRDRCo9w4DYWJg1y5akMH8+DBtmdlQiIiIiIqXAmgtbxsL+ubbb4dOg5QTbwFdEREREREQqNCUqiBROiQoiUqkZBjz2GMycabs9bx7ExJgakoiIiIhI6cjNgg33QuKHgAU6zYHrR5kdlYiIiIiIiFwlJSqIFE6JCiJSaRkGTJgA06fbbs+dC/ffb25MIiIiIiKlIvss/DAAkr4CJ1fo8h7UH2h2VCIiIiIiIlIMSlQQKZwSFUSkUjIMePJJePFF2+3Zs2GUvlwmIiIiIlVB5kn4thec3Agu3nDLJ1D3DrOjEhERERERkWLKS1Tw9/Q3ORKRikeJCiJSKU2dCnFxtv1Zs+Chh8yNR0RERESkVJw7At/0gNSd4FYLuq+G2hFmRyUiIiIiIiIlcPL8SUAzKogURIkKIlLp/Pvf8Oyztv2ZM2HcOFPDEREREREpHWn74Js7IP0QeAbDX76CGjeYHZWIiIiIiIiUkJZ+ECmcEhVEpFJ57jl4+mnb/vTp8MgjpoYjIiIiIlI6Tv0E394JGcfguia2JAWfMLOjEhERERERkWugRAWRwilRQUQqjbg4eOop2/6LL0JsrLnxiIiIiIiUimPfw3e9ITsNaraB7vHgGWh2VCIiIiIiInKNlKggUjglKohIpfDiizBpkm1/2jR47DFz4xERERERKRX/+wz+OwhyMyDgVrh1Jbj5mR2ViIiIiIiIlAIlKogUzsnsAERErmT6dHjiCdv+s8/CxInmxiMiIiIiUioOvgs/9LclKYT0sc2koCQFEREpY7NnzyYsLAwPDw8iIiLYtGlTkeVTUlIYO3YsdevWxd3dnaZNm7J69Wr7/bm5uTz11FM0bNgQT09PGjduzLPPPothGGXdFRERkQotOzeb1MxUQIkKIgXRjAoiUqHNnAn/+pdt/+mnYfJkM6MRERERESklu2fCtkdt+w2HQcR8cNKf6CIiUraWLl1KbGwsc+bMISIigpkzZxIVFcWePXsICAjIVz4rK4s77riDgIAAPv74Y0JCQjh06BA1atSwl3nhhRd48803eeedd7jhhhvYsmULMTEx+Pn58fDDD5dj70RERCqWk+dPAuBkcaKGRw1zgxGpgPQpiIhUWLNmwaMXPrt96imYOtXceERERERErplhwI4p8NtzttvNxkO76WDRhIciIlL2ZsyYwciRI4mJiQFgzpw5rFq1igULFjBhwoR85RcsWMCpU6dYv349rq6uAISFhTmUWb9+PX379qVXr172+z/44IMrztQgIiJS1Z08Z0tUqOlRE2cnZ5OjEal49EmIiFRIb7wBeUn3kybBv/9tbjwiIiIiItfMmgtbxl5MUmj9HLSboSQFEREpF1lZWWzdupXIyEj7MScnJyIjI9mwYUOBdVauXEnnzp0ZO3YsgYGB3HjjjUybNo3c3Fx7mS5dupCQkMDevXsB+Pnnn1m3bh09e/Ys8JyZmZmkpaU5bCIiIlXRiXMnAC37IFIYzaggIhXO3Lkwdqxt//HH4bnnwGIxNyYRERERkWuSmwUbhkHiUsACHd+AJqPNjkpERKqREydOkJubS2BgoMPxwMBAdu/eXWCdgwcP8vXXXzNkyBBWr17N/v37eeihh8jOzmbqhakvJ0yYQFpaGs2bN8fZ2Znc3Fyef/55hgwZUuA54+Li+Le+kSIiItWAEhVEiqZEBRGpUN5+G0Zf+Lz2n/+E//xHSQoiIiIiUsnlpMMPA+Dol+DkCp0XQ4NBZkclIiJyRVarlYCAAN566y2cnZ1p3749R44c4aWXXrInKnz44Ye89957vP/++9xwww1s376d8ePHExwczPDhw/Odc+LEicTGxtpvp6WlERoaWm59EhERKS9KVBApmhIVRKTCWLgQRo2y7Y8fDy+9pCQFEREREankMk/Bd3fBiQ3g7AW3LIfgKLOjEhGRaqh27do4OzuTnJzscDw5OZmgoKAC69StWxdXV1ecnS+uq92iRQuSkpLIysrCzc2Nxx57jAkTJnD33XcD0KpVKw4dOkRcXFyBiQru7u64u7uXYs9ERERK5r0d7/HBrx/wevTrhNUIK/XzK1FBpGhaCFNEKoR33oH77wfDgIcfhhkzlKQgIiIiIpXcuT9hbTdbkoJbTbg9QUkKIiJiGjc3N9q3b09CQoL9mNVqJSEhgc6dOxdYp2vXruzfvx+r1Wo/tnfvXurWrYubmxsA586dw8nJ8WNmZ2dnhzoiIiIVSXZuNg9/8TBDPxnKqn2reHn9y2XSjhIVRIqmRAURMd3ixRATY0tSeOghmDlTSQoiIiIiUsmd2Q9rukLqr+BZFyK/h9o3mR2ViIhUc7GxscybN4933nmHXbt2MWbMGNLT04mJiQFg2LBhTJw40V5+zJgxnDp1ikceeYS9e/eyatUqpk2bxtixY+1levfuzfPPP8+qVav4448/+OSTT5gxYwb9+/cv9/6JiIhcyfH049yx6A5mbZplP7bk1yVk5WaVelsnzitRQaQoWvpBREz1/vswfLgtSeHBB2HWLCUpiIiIiEgld/pn+CYKMpLB53q47SvwaWh2VCIiIgwePJjjx48zZcoUkpKSaNOmDfHx8QQGBgKQmJjoMDtCaGgoX375JY8++iitW7cmJCSERx55hCeeeMJeZtasWTz11FM89NBDHDt2jODgYB588EGmTJlS7v0TEREpyraj2+i/tD+JqYn4uPnwf33/j3FfjCPpbBLx++Pp06xPqbanGRVEiqZEBRExzdKlcO+9YLXCAw/AG2+Ak+Z5EREREZHK7NgP8F1vyE6Fmm2gezx4BpodlYiIiN24ceMYN25cgfd9++23+Y517tyZH3/8sdDzXXfddcycOZOZM2eWUoQiIiKl770d7/HAZw+QkZNBk1pNWHH3ClrWacn6w+uZ8eMMFu1YVOqJCifPnQTA39O/VM8rUlUoUUGkCtmzB558Ek6eNDuSKzMMWLfOlqQwYgTMnaskBRERERGp5I6sgnV/g9wMqHMLdPsM3PzMjkpERERERKTayrHm8MSaJ5jx4wwAel7fk/cHvE8NjxoA3Bt+LzN+nMFnez4jJSPFfrw0aEYFkaIpUUGkijhxAnr2hN9/NzuS4hk+HObNU5KCiIiIiFzm1Fb46THISgEnV3Byu2y7imPOF35aXC/uF6d+gcecC47398Xw431g5ELwXXDzh+DiWZ6PmIiIiIiIiFzi5LmTDP54MAm/JwAw6eZJPPOXZ3C+5O+68MBwbgy4kV+P/cpHv33EyPYjS619JSqIFE2JCiJVQHY2DBpkS1Jo1AimTQOLxeyorqxOHejWTUkKIiIiInKZ9MPwbS/ISDY7kvwsTrbEh0sTIZzcIP2Q7f6woXDTAluCg4iIiIiIiJji56Sf6be0H3+k/IG3qzf/1+//+FvLv+UrZ7FYGNpqKBMSJrD4l8WllqiQmZPJmawzgBIVRAqjRAWRKiA2Fr75Bnx8YOVKuOEGsyMSERERESmhnHT4vo8tSaFGa2jzAlizwZp1Ybt0P+sKxy87lnvhp5F9cf9K5zVyHeMzrGBkgjUTci6Lvdkj0G6GLZlBRERERERETPHhbx8S82kM57LP0ahmI1YMXkGrwFaFlh/SeggTEyby/aHv+SPlD8JqhF1zDCfP29bodrY44+ehJQFFCqJEBZFK7u234fXXbfuLFytJQUREREQqMcMKG4bD6e3gXge6rQTvBubHlC+JoYAECLca4NvU3FhFRERERESqsVxrLk9+/SQv/PcFAO5odAdL/raEWp61iqxXz7cef2n4F77+/Wve2/EeT9765DXHkrfsg7+XP05KZhcpkN4ZIpXYunXw0EO2/Wefhb59zY1HREREROSa/PJvOLzMtmzCrZ+Yn6QAttkRnN3B9Tpw9wfPuuBdH667HvxaQs02ULuTkhRERERERERMdPr8aXq938uepPBYl8dYPWT1FZMU8tzb+l4AFu1YhGEY1xxPXqKCln0QKZwSFUQqqcREGDAAsrNh4EB48toT/EREREREzHNoKfz6jG2/01tQp6u58YiIiIiIiEil8Nux3+g4ryNfHvgSTxdPPhjwAS/e8SIuTlc/sfyAFgPwdPFkz8k9bPlzyzXHZJ9RwdP/ms8lUlUpUUGkEjp3Dvr1g2PHoE0bWLgQLBazoxIREamcZs+eTVhYGB4eHkRERLBp06ZCy2ZnZ/PMM8/QuHFjPDw8CA8PJz4+3qFMWFgYFosl3zZ27Fh7me7du+e7f/To0WXWR5EK7+QW+PE+236Lf0Gj+8yMRkRERERERCqJ5buWE/F2BAdOH6CBXwPW37+eu2+8u9jnuc79Ovo17wfYZlW4VifPnQQ0o4JIUZSoIFLJGAaMGAE//QR16sCKFeDtbXZUIiIildPSpUuJjY1l6tSpbNu2jfDwcKKiojh27FiB5SdPnszcuXOZNWsWO3fuZPTo0fTv35+ffvrJXmbz5s0cPXrUvq1ZswaAgQMHOpxr5MiRDuVefPHFsuuoSEV27k/4vi/kZkBwNIT/x+yIREREREREpIKzGlae+vopBnw4gPTsdP4S9he2jNpCm6A2JT7n0NZDAVjy6xKyc7OvKT4t/SByZUpUEKlk/vMfWLoUXFxg2TJoUAGW7RUREamsZsyYwciRI4mJiaFly5bMmTMHLy8vFixYUGD5RYsWMWnSJKKjo2nUqBFjxowhOjqa6dOn28vUqVOHoKAg+/b555/TuHFjunXr5nAuLy8vh3K+vr5l2leRCinnPHzfD87/CX4toesH4ORsdlQiIiIiIiJSgaVmpNJ3SV+e++E5AMZHjOere7+65qSAHo17EOAdwPFzx/nqwFfXdC4lKohcmRIVRCqRzz6DJ5+07b/+Otxyi7nxiIiIVGZZWVls3bqVyMhI+zEnJyciIyPZsGFDgXUyMzPx8PBwOObp6cm6desKbWPx4sWMGDECy2XrNL333nvUrl2bG2+8kYkTJ3Lu3LlCY83MzCQtLc1hE6n0DAM2joBTm8HdH7p9Bq5K2BEREREREZHC7T6xm4i3I/h87+e4O7vzbr93eeXOV3Bxcrnmc7s4ufD3G/8OXPvyDyfOK1FB5EqUqCBSSezcCUOG2D7PHTMGHnzQ7IhEREQqtxMnTpCbm0tgYKDD8cDAQJKSkgqsExUVxYwZM9i3bx9Wq5U1a9awfPlyjh49WmD5FStWkJKSwn333edw/J577mHx4sV88803TJw4kUWLFjF06NBCY42Li8PPz8++hYaGFq+zIhXRb9Pg0BKwuMDNH4NPI7MjEhERERERkQrssz2f0WleJ/ac3EM933qsG7GOe8PvLdU27m1tO9+nez4lNSO1xOfRjAoiV6ZEBZFK4PRp6NsXzpyBbt3g1VfNjkhERKR6evXVV2nSpAnNmzfHzc2NcePGERMTg5NTwcPq+fPn07NnT4KDgx2Ojxo1iqioKFq1asWQIUN49913+eSTTzhw4ECB55k4cSKpqan27fDhw6XeN5FydXg57Jhs2+/4BgR2NzUcERERERERqdj+s+4/9FnShzNZZ7i1wa1sHbWVDsEdSr2ddnXb0aJ2CzJyMli2a1mJz6NEBZErU6KCSAWXkwODB8P+/dCgAXz0Ebi6mh2ViIhI5Ve7dm2cnZ1JTk52OJ6cnExQUFCBderUqcOKFStIT0/n0KFD7N69Gx8fHxo1yv9N8EOHDrF27VoeeOCBK8YSEREBwP79+wu8393dHV9fX4dNpNI6vR3WX/jGS9OH4fqRpoYjIiIiIiIiFds3v3/DxISJAIzrOI61964lwDugTNqyWCz2WRWuZfkHJSqIXJkSFUQquMcfhzVrwMsLPv0U6tQxOyIREZGqwc3Njfbt25OQkGA/ZrVaSUhIoHPnzkXW9fDwICQkhJycHJYtW0bfvn3zlVm4cCEBAQH06tXrirFs374dgLp16xavEyKVzflk+K4P5J6DoB7QbrrZEYmIiIiIiEgFlmPN4eH4hwEY3X40s6Jn4epctt/mHNJ6CADf/vEtiamJJTrHyXMnAfD39C+1uESqGiUqiFRg77wDr7xi23/3XQgPNzceERGRqiY2NpZ58+bxzjvvsGvXLsaMGUN6ejoxMTEADBs2jIkTJ9rLb9y4keXLl3Pw4EF++OEH7rzzTqxWK48//rjDea1WKwsXLmT48OG4uLg43HfgwAGeffZZtm7dyh9//MHKlSsZNmwYt956K61bty77TouYJTcDfugP5w7DdU3h5qXg5HLleiIiIiIiIlJtvbn5TX499iu1PGvx/O3Pl0ub9f3q061BNwDe/+X9Ytc/n32e9Ox0QDMqiBRFnwqJVFA//gijRtn2p0yBAQPMjUdERKQqGjx4MMePH2fKlCkkJSXRpk0b4uPjCQwMBCAxMREnp4u5vRkZGUyePJmDBw/i4+NDdHQ0ixYtokaNGg7nXbt2LYmJiYwYMSJfm25ubqxdu5aZM2eSnp5OaGgoAwYMYPLkyWXaVxFTGQZsehBObADXGtDtM3CrYXZUIiIiIiIiUoEdTz/OlG+nAPD8bc9Ty7NWubV9b+t7+e7QdyzasYgnuj6BxWK56ronz9tmU3BxcsHXXct3ihTGYhiGYXYQ5SEtLQ0/Pz9SU1O1pq9UeEeOQIcOkJQE/fvDxx+Dk+Y/ERERsavuY7vq3n+phHa+CNufAIsz/CUegiLNjkhERKTCqO5ju+refxERKdyoz0Yxb9s82gS1YcvILTg7OZdb26kZqQRNDyIjJ4Oto7bSrm67q667PWk7bee2JcgniKP/PFqGUYpUPMUZ2+lfnyIVzPnztuSEpCS48Ubbkg9KUhARERGRSut/n8H2Cbb99q8qSUFERERERESuaOufW3l729sAzOo5q1yTFAD8PPzo06wPAIt+XlSsuifOnQC07IPIlejfnyIViGHYlnvYvBlq1YJPPwUfH7OjEhEREREpoZRfYf09gAHXj4YmD5kdkYiIiIiIiFRwhmHwjy/+gYHBPa3u4eb6N5sSx72t7wXgg18/IMeac9X1lKggcnWUqCBSgUyfDosXg7MzfPQRNGpkdkQiIiIiIiWUcRy+6w05ZyHwL9DhNSjGmp4iIiIiIiJSPS3esZgN/9uAt6s3L0a+aFocUY2jqONVh+T0ZNYcWHPV9ZSoIHJ1lKggUkHEx8MTT9j2Z86E224zNRwRERERkZLLzYIfBkD6H+DTGG7+CJxczY5KREREREREKrgzmWd4fO3jAEy+dTIhviGmxeLq7MrdN94NwOJfFl91PXuigqcSFUSKokQFkQpgzx64+26wWuGBB2DsWLMjEhEREREpIcOALQ/B8R/A1Re6fQbu/mZHJSIiIiIiIpXAc98/R9LZJK6vdT2P3vSo2eEwtPVQAD7Z9QlnMs9cVZ2T504C4O+lv4VFiqJEBRGTpaZC3762n127wuzZmhFXRERERCqxPa/CgflgcYKuS8CvhdkRiYiIiIiISCWw58QeXvnxFQBmRs3E3cXd5IigY3BHmvo35XzOeZbvWn5VdU6c19IPIldDiQoiJsrNhb//3TajQmgoLFsGbm5mRyUiIiIiUkJ/xsNP/7Ttt30ZgnuaG4+IiIiIiIhUCoZhMP7L8WRbs4luEk2vpr3MDgkAi8XCva3vBWDRjkVXVce+9IMSFUSKpEQFERNNmgRffAGenrBiBQQGmh2RiIiIiEgJpe6G/w4GwwqNRkCz8WZHJCIiIiIiIpXEqn2riN8fj6uTK69EvWJ2OA7yln/4+vev+V/a/65YXokKIldHiQoiJnnvPXjxRdv+woXQrp258YiIiIiIlFjmKfiuN2SnQZ1boOObWs9MRERERERErkpmTibj48cDENs5lqb+Tc0N6DJhNcK4pf4tGBi8/8v7VyyvRAWRq6NEBRETbNkCDzxg2584EQYPNjceEREREZESs2bDuoFwdj94N4BbloGz1jMTERERERGRqzNjwwwOnD5AXZ+6PHnLk2aHU6C85R8W71hcZDnDMJSoIHKVlKggUs6OHoV+/SAjA3r1gmefNTsiEREREZFrsHU8JH8NLj7Q7TPwqGN2RCIiIiIiIlJJ/C/tfzz3w3MAvHTHS1znfp3JERVs4A0DcXN245djv/Bz0s+FljuXfY6MnAxAiQoiV6JEBZFylJkJAwbAkSPQvLlt+QdnZ7OjEhEREREpob1vwL43AAt0eQ9qtDI7IhEREREREalEnlj7BOeyz9EltAv3tLrH7HAKVcOjBr2b9gZg0Y5FhZbLm03B3dkdb1fvcolNpLJSooJIOTEMGDMGNmyAGjVg5Urw8zM7KhERERGREkpKgK0P2/bbxEG9PubGIyIiIiIiIpXKD4d+4P1f3seChVk9Z2GxWMwOqUh5yz+8/8v75FpzCyxz8vxJAPy9/Ct8f0TMpkQFkXIyaxYsXAhOTrB0KTRpYnZEIiIiIiIllLYP1g0EIxfC7oUWj5sdkYiIiIiIiFQiudZc/vHFPwAY1X4U7eq2MzmiK+vZpCf+nv4cPXuUhN8TCiyTN6OCln0QuTIlKoiUg4QEiI217b/0EvToYW48IiIiIiIllpUC3/eGrNPgfxNEvAX6loiIiIiIiIgUw7xt8/g5+WdqeNTgudueMzucq+Lm7MbgGwYDhS//oEQFkaunRAWRMnbgAAwcCLm5MGwYPPqo2RGJiIiIiJSQNQf+ezek7QGvenDrJ+DsYXZUIiIiIiIiUomcPHeSJ79+EoBn//Jspfqn/r3htuUflu9aztmss/nuV6KCyNVTooJIGTpzBvr2hdOnISIC5s7Vl81EREREpBL76V9w9Etw9oJbV4JnkNkRiYiIiIiISCUz5ZspnDp/ilYBrRjdYbTZ4RRLREgE19e6nnPZ51ixe0W+++2JCp5KVBC5EiUqiJQRqxXuvRd++w3q1oXly8FDXzYTERERkcpq/zzY86ptv/O7UKutufGIiIiIiIhIpfNz0s/M2ToHgNd6voaLk4vJERWPxWJhaKuhQMHLP2hGBZGrp0QFkTIydSp8+im4u8OKFRAcbHZEIiIiIiIllPwdbH7Itt/qGag/wNx4REREREREpNIxDIN/fPEPrIaVQTcMontYd7NDKpGhrW2JCmsPruXomaMO9ylRQeTqKVFBpAx89BE895xtf9486NTJ3HhERERERErs7EFYNwCMHGhwN9w42eyIREREREREpBJa+ttSfkj8AU8XT16+42WzwymxxrUa0yW0C1bDyvu/vO9w38nzJwElKohcDSUqiJSy7dvhvvts+//8p235BxERERGRSik7Db7rA5knoVYHiFgAFovZUYmIiIiIiEglk56Vzr+++hcAk26ZRKhfqMkRXZt7W9v++XP58g95Myr4e/mXe0wilY0SFURK0bFj0LcvnDsHUVHwwgtmRyQiIiIiUkLWXPjvEEj9DTzrwq0rwMXT7KhERERERESkEpr2wzSOnDlCwxoN+VeXf5kdzjUbdMMg3Jzd+Dn5Z35J/sV+XEs/iFw9JSqIlJKsLPjb3yAxEZo0gQ8+AGdns6MSERERESmhnyfCn5+Dswfc+il4hZgdkYiIiJSC2bNnExYWhoeHBxEREWzatKnI8ikpKYwdO5a6devi7u5O06ZNWb16tUOZI0eOMHToUPz9/fH09KRVq1Zs2bKlLLshIiKVyIFTB3h5g22ph1eiXsHDxcPkiK5dLc9a9GrSC4DFOxYDYBiGEhVEikGJCiKl5OGH4YcfwNcXVq6EmjXNjkhEREREpIQOvgO7XrLtRywE/47mxiMiIiKlYunSpcTGxjJ16lS2bdtGeHg4UVFRHDt2rMDyWVlZ3HHHHfzxxx98/PHH7Nmzh3nz5hEScjGB8fTp03Tt2hVXV1e++OILdu7cyfTp06mpD8dEROSC2K9iycrNokfjHvRp1sfscEpN3vIP7/3yHrnWXM5mnSUrNwtQooLI1XAxOwCRquDNN2HuXNtyvR98AM2bmx2RiIiIiEgJHV8Pm0bZ9m+YDGF3mxuPiIiIlJoZM2YwcuRIYmJiAJgzZw6rVq1iwYIFTJgwIV/5BQsWcOrUKdavX4+rqysAYWFhDmVeeOEFQkNDWbhwof1Yw4YNy64TIiJSqcTvj2flnpW4OLnw6p2vYrFYzA6p1EQ3iaamR02OnDnCt398S6OajQDwdPHEy9XL5OhEKj7NqCByjb77zjabAkBcHERHmxuPiIiIiEiJpR+CH/qDNQtC/wqt/212RCIiIlJKsrKy2Lp1K5GRkfZjTk5OREZGsmHDhgLrrFy5ks6dOzN27FgCAwO58cYbmTZtGrm5uQ5lOnTowMCBAwkICKBt27bMmzev0DgyMzNJS0tz2EREpGrKys3ikfhHAHgk4hGa165a3/J0d3Fn0A2DAFi0Y5GWfRApJiUqiFyDP/6Av/0NcnLgnnvg8cfNjkhEREREpISyz8J3fSHjGNQIh87vgkV/MoqIiFQVJ06cIDc3l8DAQIfjgYGBJCUlFVjn4MGDfPzxx+Tm5rJ69Wqeeuoppk+fznPPPedQ5s0336RJkyZ8+eWXjBkzhocffph33nmnwHPGxcXh5+dn30JDQ0uvkyIiUqG8tvE19p7cS6B3IFO6TTE7nDKRt/zDsl3LSExNBJSoIHK1tPSDSAmdPQt9+8KJE9C+Pbz9tm3pBxERERGRSsewwoZhkPIzeARCt5Xg4m12VCIiImIyq9VKQEAAb731Fs7OzrRv354jR47w0ksvMXXqVHuZDh06MG3aNADatm3Lr7/+ypw5cxg+fHi+c06cOJHY2Fj77bS0NCUriIhUQUfPHOXf39lm6Xsh8gV83X1NjqhsdAntQqOajTh4+iDzf5oPKFFB5GqV6Osxs2fPJiwsDA8PDyIiIti0aVOhZbOzs3nmmWdo3LgxHh4ehIeHEx8fn6/ckSNHGDp0KP7+/nh6etKqVSu2bNniUGbXrl306dMHPz8/vL296dixI4mJiSXpgsg1sVrhvvtgxw4IDIQVK8DT0+yoRERERERKaMcU+N8n4OQGt3wC3vXNjkhERERKWe3atXF2diY5OdnheHJyMkFBQQXWqVu3Lk2bNsXZ2dl+rEWLFiQlJZGVlWUv07JlS4d6LVq0KPRzW3d3d3x9fR02ERGpeiYkTOBs1lkiQiK4N/xes8MpMxaLhaGthgLwxf4vAPD38jczJJFKo9iJCkuXLiU2NpapU6eybds2wsPDiYqK4tixYwWWnzx5MnPnzmXWrFns3LmT0aNH079/f3766Sd7mdOnT9O1a1dcXV354osv2LlzJ9OnT6dmzZr2MgcOHODmm2+mefPmfPvtt+zYsYOnnnoKDw+PEnRb5No89xwsWwZubrB8OdSrZ3ZEIiIiIiIl9Mf78Nvztv2It6FOZ3PjERERkTLh5uZG+/btSUhIsB+zWq0kJCTQuXPBv/+7du3K/v37sVqt9mN79+6lbt26uLm52cvs2bPHod7evXtp0KBBGfRCREQqgw2HN/Duz+9iwcKsnrNwquLLCg5tPdThdm1PzaggcjWKfWWYMWMGI0eOJCYmhpYtWzJnzhy8vLxYsGBBgeUXLVrEpEmTiI6OplGjRowZM4bo6GimT59uL/PCCy8QGhrKwoUL6dSpEw0bNqRHjx40btzYXubJJ58kOjqaF198kbZt29K4cWP69OlDQEBACbotUnKffAIXZrbjzTehSxdz4xERERERKbETm+DHEbb9lk9Aw6r7LRcRERGB2NhY5s2bxzvvvMOuXbsYM2YM6enpxMTEADBs2DAmTpxoLz9mzBhOnTrFI488wt69e1m1ahXTpk1j7Nix9jKPPvooP/74I9OmTWP//v28//77vPXWWw5lRESk+rAaVv7xxT8AGNF2BB1DOpocUdlr4t+Em+rdZL+tpR9Erk6xEhWysrLYunUrkZGRF0/g5ERkZCQbNmwosE5mZma+WQ88PT1Zt26d/fbKlSvp0KEDAwcOJCAggLZt2zJv3jz7/VarlVWrVtG0aVOioqIICAggIiKCFStWFCd8kWv2yy9w74XPbh9+GEaMMDceEREREZESO3cEfugH1kwI6Q2tnzc7IhERESljgwcP5uWXX2bKlCm0adOG7du3Ex8fT2BgIACJiYkcPXrUXj40NJQvv/ySzZs307p1ax5++GEeeeQRJkyYYC/TsWNHPvnkEz744ANuvPFGnn32WWbOnMmQIUPKvX8iImK+BT8tYOvRrfi6+zLt9mlmh1Nu8pZ/ACUqiFwti2EYxtUW/vPPPwkJCWH9+vUO04E9/vjjfPfdd2zcuDFfnXvuuYeff/6ZFStW0LhxYxISEujbty+5ublkZmYC2BMZYmNjGThwIJs3b+aRRx5hzpw5DB8+nKSkJOrWrYuXlxfPPfccf/nLX4iPj2fSpEl88803dOvWLV+7mZmZ9vMDpKWlERoaSmpqqtY9kxI5cQI6dYLff4fbb4f4eHBxMTsqERGR6iktLQ0/P79qO7ar7v2XUpBzDtbeCqe2gt+N0GM9uF5ndlQiIiLVUnUf21X3/ouIVCUpGSk0mdWEE+dO8ErUK4y/abzZIZWbE+dOUHd6XXKsOSwZsITBNw42OyQRUxRnbFfmi8K8+uqrNGnShObNm+Pm5sa4ceOIiYnByeli01arlXbt2jFt2jTatm3LqFGjGDlyJHPmzLHfD9C3b18effRR2rRpw4QJE7jrrrvsZS4XFxeHn5+ffQsNDS3rrkoVlp0NgwbZkhQaNYKlS5WkICIiIiKVlGHAjzG2JAX32tBtpZIUREREREREpEQMw+DomaN8uf9LRn42khPnTtCyTkvGdqxeSwDV9qrN6Paj8XP3o0uo1gwXuRrF+ldr7dq1cXZ2Jjk52eF4cnIyQUFBBdapU6cOK1asICMjg5MnTxIcHMyECRNo1KiRvUzdunVp2bKlQ70WLVqwbNkye7suLi4Flrl0CYlLTZw4kdjYWPvtvBkVREoiNha++QZ8fGDlSvD3NzsiEREREZES+vVZSPwQnFzhlmXg09DsiERERERERKo9wzBIz07nTOYZzmSd4UzmGc5mnXXYd3V2xcfNBx83H65zu8720/06+20PFw8sFkuZxXg++zy/Hf+NHck72JG8g1+O/cKO5B2cOHfCodyrd76Kq7NrmcVRUb3W8zVe6/lamT4HIlVJsRIV3NzcaN++PQkJCfTr1w+wzXaQkJDAuHHjiqzr4eFBSEgI2dnZLFu2jEGDBtnv69q1K3v27HEov3fvXho0aGBvt2PHjkWWuZy7uzvu7u7F6Z5Igd5+G15/3ba/eDHccIO58YiIiIiIlFjix/DLVNt+xzch4FZz4xEREREREamkLk0suDShoKAkg0t/FnY8PSsdg6terb1Azhbni4kMFxIYHJIaCkhuuLx83rFsaza/HvvVnpSwI3kH+07tw2pY87XrZHGiqX9TWge25m8t/kZko8hr6kdlpQQFkeIp9uT1sbGxDB8+nA4dOtCpUydmzpxJeno6MTExAAwbNoyQkBDi4uIA2LhxI0eOHKFNmzYcOXKEp59+GqvVyuOPP24/56OPPkqXLl2YNm0agwYNYtOmTbz11lu89dZb9jKPPfYYgwcP5tZbb+Uvf/kL8fHxfPbZZ3z77bfX+BCIFG7dOnjoIdv+s89C377mxiMiIiIiUmKntsGGYbb9Zo9C4/vNjUdERERERKQMGYZBZm4m57LPkZ6VbvuZnX71t3MKPn5pcsK1JhYUxMniZE8YuM79OvtPb1dvcqw59kSHs1ln7XGkZ6cDkGvkkpqZSmpmKpwp9dAA8Pf0JzwonNYBrWkdaNta1mmJp6tn2TQoIlVWsRMVBg8ezPHjx5kyZQpJSUm0adOG+Ph4AgMDAUhMTMTJyclePiMjg8mTJ3Pw4EF8fHyIjo5m0aJF1KhRw16mY8eOfPLJJ0ycOJFnnnmGhg0bMnPmTIYMGWIv079/f+bMmUNcXBwPP/wwzZo1Y9myZdx8883X0H2RwiUmwoABkJ0NAwfCk0+aHZGIiIiISAmdPwrf94Xc81D3Tmj7otkRiYiIiIhINWAYBlm5WWTmZtp+5mQWuZ+Zk2kvf/l+XtJBcRIOCvr2f2mzYLHPSHB5coE94aCw4wXU8XTxLPY3862GlfSs9HwJDIXdLuq+vBkeLFhoUaeFLRnhkqSEIJ8gzRwgIqXCYhhG6ad7VUBpaWn4+fmRmpqKr6+v2eFIBXfuHNx8M/z0E7RpY5tZwdvb7KhEREQkT3Uf21X3/ksx5WbA2u5wciP4NoceP4Kbn9lRiYiIyAXVfWxX3fsvlcul39C/9J/il//z3OHYhTLnc86T9++YvH/yWrA47F9+X97tkt5X0jYuTS5wSCYoJHmgqASErNys0nwKSszVyRVvN2+8XL3wdr3w8/LbhR0v4PalyQVerl5V8h/3hmFUyX6JSNkqztiu2DMqiFR1hgEjRtiSFOrUgRUrlKQgIiIiIpWUYcDGB2xJCm41odtnSlIQERERkSrJMAwycjKuOnGgyDJF1CuLqf6rExcnF9yd3XFzdsPdxb3IfXeXC7edL953tYkEl972cvXC1dnV7K5XOkpSEJGypkSFMnTvvZCSYnYUUlypqfDDD+DiAsuWQYMGZkckIiIiZWn27Nm89NJLJCUlER4ezqxZs+jUqVOBZbOzs4mLi+Odd97hyJEjNGvWjBdeeIE777zTXiYsLIxDhw7lq/vQQw8xe/Zsh2OGYRAdHU18fDyffPIJ/fr1K9W+lar190JWitlRSHHlpMGx78HiDDd/DNddb3ZEIiIiIqa795N7SclIMTsMKYEca06hCQflnUSQ90/zy/8hbj/m5o2Xy8Xbnq6eOFmc7LMqGBgO+0CBt0t637W0ATgmCRSxX9ykAyfLxaXDRUSkelOiQhn66is4dszsKKSkXn8dbrnF7ChERESkLC1dupTY2FjmzJlDREQEM2fOJCoqij179hAQEJCv/OTJk1m8eDHz5s2jefPmfPnll/Tv35/169fTtm1bADZv3kxubq69zq+//sodd9zBwIED851v5syZlecbCklfQYYGt5VWh1kQdJvZUYiIiIhUCF8d+Ipj6RrbVmVuzm75kgfyvmVv31zyHys04eCyY16uXrg46d8rIiIi18JiXJoiV4WZsdbZ++9DRka5NCWlrHlz6NLF7ChERESkMKU1touIiKBjx468/vrrAFitVkJDQ/nHP/7BhAkT8pUPDg7mySefZOzYsfZjAwYMwNPTk8WLFxfYxvjx4/n888/Zt2+fQ1LC9u3bueuuu9iyZQt169Yt1owKpqzj+8f7kKvBbaXk2wzqdDU7ChERESmEKWO7CsSUz21/eZ+MHI1tKyNni3OBiQOXJhh4unoqiUBERMQkxRnb6bd1GbrnHrMjEBEREZHCZGVlsXXrViZOnGg/5uTkRGRkJBs2bCiwTmZmJh4eHg7HPD09WbduXaFtLF68mNjYWIckhXPnznHPPfcwe/ZsgoKCSqE35SBMg1sRERERqRruaaWxrYiIiIjZtBiQiIiIiFRLJ06cIDc3l8DAQIfjgYGBJCUlFVgnKiqKGTNmsG/fPqxWK2vWrGH58uUcPXq0wPIrVqwgJSWF++67z+H4o48+SpcuXejbt+9VxZqZmUlaWprDJiIiIiIiIiIiIlJZKVFBREREROQqvfrqqzRp0oTmzZvj5ubGuHHjiImJwcmp4GH1/Pnz6dmzJ8HBwfZjK1eu5Ouvv2bmzJlX3W5cXBx+fn72LTQ09Fq7IiIiIiIiIiIiImIaJSqIiIiISLVUu3ZtnJ2dSU5OdjienJxc6HIMderUYcWKFaSnp3Po0CF2796Nj48PjRo1ylf20KFDrF27lgceeMDh+Ndff82BAweoUaMGLi4uuLjYVmMbMGAA3bt3L7DdiRMnkpqaat8OHz5cgh6LiIiIiIiIiIiIVAxKVBARERGRasnNzY327duTkJBgP2a1WklISKBz585F1vXw8CAkJIScnByWLVtW4BIOCxcuJCAggF69ejkcnzBhAjt27GD79u32DeCVV15h4cKFBbbn7u6Or6+vwyYiIiIiIiIiIiJSWbmYHYCIiIiIiFliY2MZPnw4HTp0oFOnTsycOZP09HRiYmIAGDZsGCEhIcTFxQGwceNGjhw5Qps2bThy5AhPP/00VquVxx9/3OG8VquVhQsXMnz4cPuMCXmCgoIKnLGhfv36NGzYsIx6KiIiIiIiIiIiIlJxKFFBRERERKqtwYMHc/z4caZMmUJSUhJt2rQhPj6ewMBAABITE3FyujgJWUZGBpMnT+bgwYP4+PgQHR3NokWLqFGjhsN5165dS2JiIiNGjCjP7oiIiIiIiIiIiIhUChbDMAyzgygPaWlp+Pn5kZqaqqlyRURERCq56j62q+79FxEREalKqvvYrrr3X0RERKQqKc7YzqnIe0VERERERERERERERERERERKkRIVREREREREREREREREREREpNwoUUFERERERERERERERERERETKjRIVREREREREREREREREREREpNwoUUFERERERERERERERERERETKjRIVREREREREREREREREREREpNwoUUFERERERERERERERERERETKjRIVREREREREREREREREREREpNy4mB1AeTEMA4C0tDSTIxERERGRa5U3pssb41U3GtuKiIiIVB0a22psKyIiIlJVFGdsW20SFc6cOQNAaGioyZGIiIiISGk5c+YMfn5+ZodR7jS2FREREal6NLbV2FZERESkqriasa3FqCapularlT///JPrrrsOi8VSLm2mpaURGhrK4cOH8fX1LZc2zVDV+lnZ+1NZ4q/IcVaE2MyMoTzbLmlbZRljWZy7tM9Z3PNda/vXUt+suma2rT6XzzXLMAzOnDlDcHAwTk7VbzUzjW3LTlXrZ2XvT2WJvyLHWRFi09i2bOqZdW6NbTXOK4+6ZratsW3509i27FS1flb2/lSW+CtynBUhNo1ty6aeWefW2FbjvPKoa2bbFX1sW21mVHBycqJevXqmtO3r61vhfqGXharWz8ren8oSf0WOsyLEZmYM5dl2SdsqyxjL4tylfc7inu9a27+W+mbVNbNt9bnsVcdvm+XR2LbsVbV+Vvb+VJb4K3KcFSE2jW3Lpp5Z59bYVuO88qhrZtsa25YfjW3LXlXrZ2XvT2WJvyLHWRFi09i2bOqZdW6NbTXOK4+6ZrZdUce21S9FV0REREREREREREREREREREyjRAUREREREREREREREREREREpN0pUKEPu7u5MnToVd3d3s0MpU1Wtn5W9P5Ul/oocZ0WIzcwYyrPtkrZVljGWxblL+5zFPd+1tn8t9c2qa2bb6rNUVdXlea5q/azs/aks8VfkOCtCbBrblk09s86tsa3GeeVR18y2K8J1U8pedXmeq1o/K3t/Kkv8FTnOihCbxrZlU8+sc2tsq3FeedQ1s+2KcN0sisUwDMPsIERERERERERERERERERERKR60IwKIiIiIiIiIiIiIiIiIiIiUm6UqCAiIiIiIiIiIiIiIiIiIiLlRokKIiIiIiIiIiIiIiIiIiIiUm6UqFBCTz/9NBaLxWFr3rx5kXU++ugjmjdvjoeHB61atWL16tXlFO3V+/777+nduzfBwcFYLBZWrFhhvy87O5snnniCVq1a4e3tTXBwMMOGDePPP/+84nmPHDnC0KFD8ff3x9PTk1atWrFly5Yy7IlNUf0BSE5O5r777iM4OBgvLy/uvPNO9u3bd9XnX7JkCRaLhX79+pVu4EBcXBwdO3bkuuuuIyAggH79+rFnzx6HMt27d8/3Ohw9evQVz71r1y769OmDn58f3t7edOzYkcTExBLH+uabb9K6dWt8fX3x9fWlc+fOfPHFF/b733rrLbp3746vry8Wi4WUlJQrnvNq+n+tcQFs2LCB2267DW9vb3x9fbn11ls5f/58mcb1n//8B4vFwvjx4+3HMjIyGDt2LP7+/vj4+DBgwACSk5OveK7iPJcFtZvHMAx69uxZ4PukpO0W1F5SUhL33nsvQUFBeHt7065dOwYNGlTk9fSZZ54hICDAfl9wcDD//e9/i4zPMAymTJmCj49Pked+8MEHady4MZ6entSpU4e+ffuye/fuIs89derUfOds1KiR/f7ivi8L+n3i7u7OnDlzCn3M3nrrrSKvqXn9r1u3Lq6urlgsFoYPHw4UfT1+7bXX8PPzw8nJCWdnZ+rUqZPvOl9Y/dmzZxMWFoaHhwcRERFs2rSJ0aNHY7FYmDlz5hXbzqvv5uZGzZo18fHxcXhtFVX3o48+omnTpjg7O+Pq6oq7uzstW7a0P4ZhYWH5HmOLxcLYsWMd6rq4uODp6enw/ius7kMPPcRjjz2Gt7e3/fEKDg7m4YcfJjU19Yp1854fT09Pbr/9dm699dZ877/C6nfs2NFet2PHjnTu3DnfNayoPs+ePZvQ0FCcnZ1xc3PD09OTdu3asWzZMgByc3N56qmnaNiwIZ6enjRu3Jhnn30WwzDsz5O7uzshISHUrl0bT09PIiMjr+r3Z0GvE6kYNLbV2BY0ts2jsa3Gthrbamyrsa3GthrbVm4a22psCxrb5tHYVmNbjW01ttXYVmPbCj22NaREpk6datxwww3G0aNH7dvx48cLLf/f//7XcHZ2Nl588UVj586dxuTJkw1XV1fjl19+Kceor2z16tXGk08+aSxfvtwAjE8++cR+X0pKihEZGWksXbrU2L17t7FhwwajU6dORvv27Ys856lTp4wGDRoY9913n7Fx40bj4MGDxpdffmns37+/jHtTdH+sVqtx0003GbfccouxadMmY/fu3caoUaOM+vXrG2fPnr3iuX///XcjJCTEuOWWW4y+ffuWeuxRUVHGwoULjV9//dXYvn27ER0dnS+2bt26GSNHjnR4HaamphZ53v379xu1atUyHnvsMWPbtm3G/v37jU8//dRITk4ucawrV640Vq1aZezdu9fYs2ePMWnSJMPV1dX49ddfDcMwjFdeecWIi4sz4uLiDMA4ffp0qfT/WuNav3694evra8TFxRm//vqrsXv3bmPp0qVGRkZGmcW1adMmIywszGjdurXxyCOP2I+PHj3aCA0NNRISEowtW7YYN910k9GlS5ciz1Wc57KwdvPMmDHD6NmzZ773SUnbLay9O+64w+jYsaOxceNG48CBA8azzz5rAEbjxo0LvZ6GhoYatWrVMubPn2+8//77Ro0aNQw3N7ciH/P//Oc/hp+fnzF48GCjcePGRo8ePYzQ0FDj999/dzj33Llzje+++874/fffja1btxq9e/c2QkNDjZycnELPffvttxtOTk7GwoULjYSEBKNHjx5G/fr1jfPnzxuGUfz35dSpU42aNWsaDRo0MJYtW2Zs2rTJmD59uuHs7Gx8+umn+R6zSZMmGYDRu3fvQq+pef1/6aWXjODgYMPX19fw9fU1/vzzz0Kvx0uWLDFcXV2Nli1bGtOnTzcGDhxo+Pj4GG3btrVf5wu7ns+cOdNwc3MzFixYYPz222/GyJEjDS8vL+OGG24wgoODjVdeeaXI3wVLliwx3Nzc7HG3bt3a8PHxMTZu3Gh8+umnxp49ewqtm/f7tVOnTkZoaKgxdOhQw8XFxZgyZYr9MTx27JjD87FmzRoDMGbNmmU4OzsbN910kxEUFGQMGTLEcHFxMVq3bm1//xVWd+TIkYaPj49x0003Ga+++qpx++23G0FBQcb1119vDBgw4Ip1/fz8jBUrVhg///yzccMNNxienp753n+F1ff29jZWrFhhvPvuu4aLi4tRs2ZNY+vWrQ7XsMLqPvXUU4abm5txww03GDfeeKPRt29f47rrrjOeeOIJw8nJydi2bZvx/PPPG/7+/sbnn39u/P7778ZHH31k+Pj4GMOHD7c/z48++qjh5uZmeHt7G19//bXRp08fo2HDhvb3QUHynudLXyc1atS4pt8/Uno0ttXYVmPbizS21dhWY1uNbTW21dhWY9vKTWNbjW01tr1IY1uNbTW21dhWY1uNbSvy2FaJCiU0depUIzw8/KrLDxo0yOjVq5fDsYiICOPBBx8s5chKz9X84tu0aZMBGIcOHSq0zBNPPGHcfPPNpRxd8V3enz179hiAffBjGIaRm5tr1KlTx5g3b16R58rJyTG6dOlivP3228bw4cPLZMB7uWPHjhmA8d1339mPdevWrcDBS1EGDx5sDB06tJSjy69mzZrG22+/7XDsm2++ueoB7+UK6v+1xhUREWFMnjz5ms5XnLjOnDljNGnSxFizZo3Dc5eSkmK4uroaH330kb3srl27DMDYsGFDoee72ueysHbz/PTTT0ZISIhx9OjRq3rfX6ndotrz9vY23n33XYfyHh4eRr169Qo8V0GPzX//+18DMN54440C61itViMoKMh46aWX7NfqlJQUw93d3fjggw+K7NvPP/9sAIX+QW61Wg1vb2+jbt26DjFeeu7ivi+nTp1qeHh4GM8884zD8Xbt2hlPPvlkvsfsiSeeMFxcXAq9TuX1/7nnnrM/D127djWcnZ2NPn36FHo97tSpkzF27Fj77dzcXCM4ONh46KGH7Nf5wq7nl9dNTEw0nJycjPHjxxsNGjQwXnnllSJ/F+TVz3tt5bUdFxdn73NhdfN+v95www32xzDv92veY3i5Rx55xGjcuLExcOBAo0ePHg6vsYiICGPQoEGFvv/y6gYGBhovvfSS/Xje6+CRRx4x3NzcjOzs7Kuq+9NPPxnBwcGGm5vbFd9/Dz/8sP3Ds7xY//Wvf13Vazuv7Y4dOxpjx461v64ufaxr1aplzJs3z+jVq5cxYsQIh/p//etfDX9/f2Ps2LH219iLL75or3s177HCXmN5z7OYS2NbG41tNbYtjMa2+Wlsq7FtQTS21dhWY1uNbSsCjW1tNLbV2LYwGtvmp7GtxrYF0dhWY1uNbct+bKulH67Bvn37CA4OplGjRgwZMqTIKZg2bNhAZGSkw7GoqCg2bNhQ1mGWqdTUVCwWCzVq1Ci0zMqVK+nQoQMDBw4kICCAtm3bMm/evPILshCZmZkAeHh42I85OTnh7u7OunXriqybN6XR/fffX6YxXipvSppatWo5HH/vvfeoXbs2N954IxMnTuTcuXOFnsNqtbJq1SqaNm1KVFQUAQEBREREXNWUUVcrNzeXJUuWkJ6eTufOnUvtvIX1v6RxHTt2jI0bNxIQEECXLl0IDAykW7duV3zuryWusWPH0qtXr3zXgq1bt5Kdne1wvHnz5tSvX7/Qa0RxnsvC2gU4d+4c99xzD7NnzyYoKOiKfbiadotqr0uXLixdupRTp05htVpZsmQJOTk5nDx5ssDraUGPTUBAAAC///57gTH+/vvvJCUl2evs27ePFi1aYLFYePrppwu9Vqenp7Nw4UIaNmxIaGhooedOT0/n9OnT9ngfeughwsPDHZ6r4rwvAXJycnj22Wdp0KABQ4YMYcmSJezdu5cePXrke8wWL14MwLJlywq8pub1/8cff7Q/Dy4uLgQFBfHDDz8UeD3Oyspi69atDo+zk5MTkZGR/PTTT/brfEHX8zfffNOhrtVqZfjw4bRv356DBw/az1fY74K8tm+77Tb7a6tnz56cOnWKF154gRUrVhT5eyTv92uXLl1YuXIlR44coUePHqxZs8b+GF4qKyuLxYsXM2LECH788Ueuv/56h9dYVFQUu3fvLvD9l1e3X79+JCcnOzxefn5+RERE8Msvv+Dr64uLi8sV6+a9/9544w1uuummIl8jWVlZLFq0iNzcXO644w77Nax+/fq4u7szYsSIQq9heW0PHz6cbdu22R+vpUuXkpKSwu23387HH39MRkYG3bt3p0uXLiQkJLB3714Afv75Z9atW8epU6eIjIy0v8buuOMOIiMj2bBhg73/hV2zinqNVfaxUFWisa3Gthrb5qexbeE0ttXYtjAa22psq7GtVAQa22psq7FtfhrbFk5jW41tC6Oxrca2GtuWsTJPhaiiVq9ebXz44YfGzz//bMTHxxudO3c26tevb6SlpRVY3tXV1Xj//fcdjs2ePdsICAgoj3BLhCtkCJ0/f95o166dcc899xR5Hnd3d8Pd3d2YOHGisW3bNmPu3LmGh4eH8X//93+lHHHRLu9PVlaWUb9+fWPgwIHGqVOnjMzMTOM///mPARg9evQo9Dw//PCDERISYp+GqDwyc3Nzc41evXoZXbt2dTg+d+5cIz4+3tixY4exePFiIyQkxOjfv3+h58nLvPTy8jJmzJhh/PTTT0ZcXJxhsViMb7/99ppi3LFjh+Ht7W04Ozsbfn5+xqpVq/KVKWlmbmH9v5a4NmzYYABGrVq1jAULFhjbtm0zxo8fb7i5uRl79+4t9bg++OAD48Ybb3SYZiove/O9994z3Nzc8tXp2LGj8fjjjxd4vqt9Lotq1zAMY9SoUcb9999vv32l9/2V2r1Se6dPnzZ69OhhAIaLi4vh6+trPPfcc4VeTy9/bPIecx8fn0Ifm7zM3T///NPhWn3LLbcY/v7++a7Vs2fPNry9vQ3AaNasWZHTG+ade+7cuQ7xenl52d97xX1frl692njvvfeM3r17G4B9mzNnToGPGWC4uroWek3Ni7FZs2YOz0OTJk0MJyenAq/Hr7zyigEY69evd4jt0UcfNby8vOzX+cKu55fWnTZtmnHHHXcY//rXv4xOnTrZM3MLq5vX9meffebw2ho2bJhRr149w2KxGK6uroX+Hsn7/ZqRkWEMGzbMAAwnJycDMN555518j/fSpUsNZ2dn48iRI4arq6sxduxYh9dY3u/mgt5/eXVXrFhhf41dqk+fPoaXl5cxadKkQtu9tO6l77+BAwcW+f7Lq59X99JrWIcOHYw77rij0GtYXt2tW7fan6tLX1dOTk6Gs7Oz8eWXXxqGYXufPfHEE4bFYjFcXFwMi8ViTJgwwV730vfYY489ZnTq1Mneh0GDBhUY/5EjRwp8jV1aX8ylsa3GthrbOtLYtmga29pobJufxrYa2xqGxrZiPo1tNbbV2NaRxrZF09jWRmPb/DS21djWMDS2LWtKVCglp0+fNnx9ffNNmZSnqg14s7KyjN69extt27a94tparq6uRufOnR2O/eMf/zBuuumm0gr1qhTUny1bthjh4eEGYDg7OxtRUVFGz549jTvvvLPAc6SlpRlhYWHG6tWr7cfKY8A7evRoo0GDBsbhw4eLLJeQkFDk9Ed5F5y///3vDsd79+5t3H333dcUY2ZmprFv3z5jy5YtxoQJE4zatWsbv/32m0OZkg54r7b/xYkr74I9ceJEh/KtWrUyJkyYUKpxJSYmGgEBAcbPP/9sP3atA96reS6v1O6nn35qXH/99caZM2fs919pwFtUu7179y6yPcMwjHHjxhmdOnUy1q5da2zfvt14+umnDT8/P2PHjh32MpdeTy9/bPIe8/Dw8Ksa8F5q4MCBRr9+/fJdq1NSUoy9e/ca3333ndG7d2+jXbt2ha7XVNC5T58+bbi4uBgdOnQosM6V3peGYRgvvfSS0bRpU2PlypXGDz/8YHh4eBju7u7GmjVr8j1meYOTSx+zS6+peWs7rl271n7/pQPegq7H7dq1yzcYycrKMho3bmx4eXnZr/MFXc9HjBhhr7tlyxYjMDDQOHLkiH0gkzfgLex3QV7bn376qcNrK69+7969C437pptusv9+vfQxnDRpkuHj42P4+PgYa9ascajXo0cP46677rL3pzgD3ry6Bb0OUlNTjVq1ahlBQUFGVlZWvuf48roLFy50eP9dacDbo0cPo2vXrvZ2L72GXTrQLOgaltf2pYPOS19Xw4cPN0JCQuzvxQ8++MCoV6+e8cEHHxg7duww3n33XaNGjRqVesArxaexbeE0tr12GttqbHs5jW01ttXYVmNbjW2lLGlsWziNba+dxrYa215OY1uNbTW21dhWY9urp6UfSkmNGjVo2rQp+/fvL/D+oKAgkpOTHY4lJydf1ZQ9FU12djaDBg3i0KFDrFmzBl9f3yLL161bl5YtWzoca9GiRZFTrpWX9u3bs337dlJSUjh69Cjx8fGcPHmSRo0aFVj+wIED/PHHH/Tu3RsXFxdcXFx49913WblyJS4uLhw4cKDUYxw3bhyff/4533zzDfXq1SuybEREBEChr8PatWvj4uJSJs+Hm5sb119/Pe3btycuLo7w8HBeffXVazonFK//xYmrbt26ACV+LIoT19atWzl27Bjt2rWzv26+++47XnvtNVxcXAgMDCQrK4uUlBSHekVdI67mubxSu2vWrOHAgQPUqFHDfj/AgAED6N69e7Hb3bt3b5HtHThwgNdff50FCxZw++23Ex4eztSpU+nQoQOzZ8+2n+vS62lQUJD9sbn0MT99+nShj03e8YKuufXr1893rfbz86NJkybceuutfPzxx+zevZtPPvnkqs9do0YNPDw8MAyjwDpXel+eP3+eSZMmMWPGDHr37s3NN9/MjTfeSLNmzXjmmWfyPWb16tUjMDDQ4TG79HnPi61Hjx4Oz8O+ffuwWq20aNHCof0WLVqQlJSEs7OzvW7edf7UqVPceuut9ut8QdfzNm3a2Nv94YcfOHbsGPXr1+fll19m8+bNHDp0iH/+859YrdYCXzd5bWdmZjq8tvJe/y1atCjytR4UFMThw4cdHkMXFxcaNWrE4MGDefnll+11Dh06xNq1a3nggQcA2/NpGIbD+y+v3cvff5fWvfx1cObMGe68806sVit//etfcXV1dYi1oLqXv/8++ugjoOD3X179e++9197updewS2O9/Bp2adu1a9fG2dmZ7du3O7yuDMOgffv29vfiY489xoQJE7j77rtp1aoV9957L+PHj3d4fPL2L79d1DXr0tdYnso6FqoONLYtnMa210ZjW41tC6Kxrca2GttqbAsa20rZ0di2cBrbXhuNbTW2LYjGthrbamyrsS1obHu1lKhQSs6ePcuBAwfsL8DLde7cmYSEBIdja9asKdW1oMpD3kVw3759rF27Fn9//yvW6dq1K3v27HE4tnfvXho0aFBWYRabn58fderUYd++fWz5//buPaiK644D+Pe+eSsqT0FBEdQEDaK1aBEVqliHAD5i1QLGKCaKxijGZ5SYiZpGayxtUmkTrI3RYlU0xcQgglFsECyIVgpIUKxBnWicBDWA3F//YO4Ol7ca0ZjvZ4YZ9+49ex67e+7XmTO7eXkIDw9v9nt9+/bFmTNnUFBQoPw9++yzGDVqFAoKClp8P9L9EBHExcVh3759OHLkCDw9PdssU1BQAAAtXod6vR5DhgzpkPNhNBqV98ndj/vp/720y8PDA66urvc8FvfTruDg4CbXzeDBgzF9+nTl3zqdzmyOKC4uRkVFRYtzRHvOZVv1rly5EoWFhWb7AWDz5s1ITk6+53p9fX1brc/0vi+12vynR6PRwGg0KtsN51N/f3/odDpMnTpVGfOamppWx8bT0xPOzs5m4/ntt98iJycHfn5+rc7VUv+koRav3eaO/dVXX6GqqgpPP/10s2Xaui9r5ZpviQAAFyRJREFUa2tRW1urjIup/zY2NqitrQVgPmbDhw/H7du3zcas4XmfNm0aunXrhkWLFinnwc/PD2q1Gs8884zy/qrGZf39/ZGRkWE2zxsMBgQFBZnV3fjcf/nll7CxsUFGRgaioqJQWFiIf//733BwcMCCBQvg6uqKJUuWIDQ0tMXr1d/fH59//rlybRmNRmRkZCAgIAAlJSVwcXFpsWxAQACOHDliNoam39fG11ZycjIcHR0xfvx4APW/zWVlZWb3X3p6uhIaG15jDcs2vA6+/fZbjBkzBhqNBrdv30ZgYGCTc9xcWS8vL+X+O378uBKSm7v/TOVnzpyp1GuawwoLC5GTk6O0tfEc1rBuvV6vjDVQf101HGvTeN2+fbvJfarX62EwGJCRkaH04fDhw0pZ0z3W2pxlusZMGtZNjx9m25Yx294fZltmW2ZbZltmW2bbhuWZbakjMdu2jNn2/jDbMtsy2zLbMtsy2zYsz2z7AB76MxueUIsXL5asrCwpLy+X7OxsCQkJkW7dusm1a9dERCQqKsrsER7Z2dmi1Wpl48aNUlRUJGvWrBGdTidnzpx5VF1o1nfffSf5+fmSn58vAJR3GV28eFFqamrk2WefFTc3NykoKJDKykrlr7q6WjnG6NGjJTExUdk+efKkaLVaefPNN6W0tFR27NghVlZW8uGHHz7S/oiIpKSkSGZmppSVlUlqaqr07NlTJkyYYHaMxueysYf1CLGXXnpJOnXqJFlZWWZjffv2bREROX/+vKxdu1by8vKkvLxc9u/fL7169ZIRI0aYHcfHx0f27t2rbO/du1d0Op0kJSVJaWmpJCYmikajkWPHjt13W5ctWyZHjx6V8vJyKSwslGXLlolKpZLPPvtMROrfj5Wfny9//vOfBYB8/vnnkp+fL9evX1eO0fi6aav/P0S7Nm/eLHZ2drJ7924pLS2VVatWiYWFhdmjnh5Gu0SaPlrrxRdflB49esiRI0ckLy9PAgICmjwy6Yc4l43rbQzNPMLoQeptWF9NTY14eXlJYGCg5OTkyPnz52Xjxo0CQDZs2KDMp/b29mJjY6PMp/379xeVSiWbN2+WTz/9VAYPHiyDBw82G/PGbdywYYN07txZIiIi5IMPPpBf/vKX4uLiIqNHj1bm6rKyMlm3bp3k5eXJxYsXJTs7W8LCwqRLly5y9erVFo8dGBgoNjY2kpSUJNu3bxcHBwdRq9VSUVFxX/fl4sWLZeDAgdKnTx9JTEyU4cOHi42NjRgMBklMTGwyZgsWLBAAEh0drcyparVaoqOjm/R///79UlhYKF27dhU7Ozs5duyYMh///Oc/l5iYGGU+3rVrl+j1evHz8xNnZ2eZOHGi2NnZSWFhoTLPm+bzXr16yerVq5X5PC4uTgwGg2zbtk3OnTsnsbGx0rlzZ7ly5YryCLGGvwXN1W0wGGT+/Pmi1WolMDBQbG1t5c033xSNRiNJSUlK2fDwcAkLC1PKmn5fe/XqJV5eXhITEyNarVbeeOMNsbCwkHfffVdE6t/fZW1tbfb4SlPZgIAAcXFxkejoaNFqtTJw4ECz+6+urk60Wq3ZO+s2bNggnTp1Em9vb+nTp4+EhISIu7u7lJeXS2Vlpdy9e7fVsg3PT3h4uHh6ejZ7/3l7e0u3bt1k6dKlTcouWbJEtFqtODo6ytmzZ5vMYXV1dWIwGCQkJEQ5nuk8Ozk5ib+/v0RERIitra2sWbNGVCqVpKWlKY8UGzBggCQkJMjevXulW7duEhYWppznRYsWiV6vF2tra8nMzFT60PDxe43nT9N5bu46oUeP2ZbZ1oTZltmW2ZbZltmW2ZbZltn2x47ZltnWhNmW2ZbZltmW2ZbZltn28c62XKhwn6ZMmSIuLi6i1+ule/fuMmXKFLMfyaCgIImJiTErk5KSIt7e3qLX6+Wpp56StLS0Dm5120zvomr8FxMTI+Xl5c3uAyCZmZnKMXr27Clr1qwxO+7HH38sTz/9tBgMBunbt68kJSU98v6IiGzZskXc3NxEp9NJjx49ZNWqVWbhXaT5c9nQwwq8LY11cnKyiNS/x2rEiBHSpUsXMRgM4uXlJUuWLGny7rmGZUzef/998fLyEgsLCxk4cKCkpqY+UFtnzpwpPXv2FL1eLw4ODhIcHKyEShGRNWvWtNoXkabXTVv9/yHaJSKyfv16cXNzEysrKwkICGgS2h5Gu0SaBs87d+7I3Llzxd7eXqysrCQyMlIqKyvNyvwQ5/J+Au+D1Nu4vpKSEpkwYYI4OjqKlZWVDBgwQIYOHWo2n1pZWcn8+fPN6m9rzBtvG41Gee2118RgMAgAUalU4uTkZDZXX758WcaNGyeOjo6i0+nEzc1Npk2bJv/9739b7f+UKVPExsZGaYejo6PyPq37uS+nTJkiTk5OolarlT9PT0/ZtGmTGI3GZsfslVdeMZtTu3TpYnadmvrv5OQkBoNBOnfurARi03wMQLp162Y2HyckJLQ5z3/88cei0+lEo9GYzeeJiYnSo0cP0ev18rOf/Uy++OILEREl8LZVt6m8RqMRg8EgBoPB7NoylVWpVNKpUyezsikpKdKrVy9Rq9Wi1WpFr9eLj4+PMoYiIocOHRIAEhERYXYuUlJSxMvLS3mHnMFgaHL/mcquX7/ebIyjoqJaHK/y8vJWyzY8P8HBwVJcXNzi/QdAiouLmy3bu3dvcXZ2bnYOM9UdFxdndszExERxcXERlUolWq1WLCwsZMCAAbJ9+3YRqX+v58svvywajUb5z8TKlSulurpaOU86nU5cXV2Va93Uh4aaywMtXSf06DHbMtuaMNsy2zLbMtsy2zLbMtsy2/7YMdsy25ow2zLbMtsy2zLbMtsy2z7e2VYl0sLLWYiIiIiIiIiIiIiIiIiIiIh+YOq2v0JERERERERERERERERERET0w+BCBSIiIiIiIiIiIiIiIiIiIuowXKhAREREREREREREREREREREHYYLFYiIiIiIiIiIiIiIiIiIiKjDcKECERERERERERERERERERERdRguVCAiIiIiIiIiIiIiIiIiIqIOw4UKRERERERERERERERERERE1GG4UIGIiIiIiIiIiIiIiIiIiIg6DBcqEBH9BCUkJMDJyQkqlQqpqantKpOVlQWVSoWbN28+1LY9Tjw8PPDOO+886mYQERERUSuYbduH2ZaIiIjo8cds2z7MtkRPBi5UIKLHwowZM6BSqaBSqaDX6+Hl5YW1a9fi7t27j7ppbbqX0Pg4KCoqwuuvv46tW7eisrIS48aNe2h1jRw5EgsXLnxoxyciIiJ6HDHbdhxmWyIiIqKHi9m24zDbEtFPjfZRN4CIyCQ0NBTJycmorq7GwYMHMW/ePOh0Oixfvvyej1VXVweVSgW1muuxGisrKwMAhIeHQ6VSPeLWEBERET2ZmG07BrMtERER0cPHbNsxmG2J6KeGvwRE9NgwGAxwdnZGz5498dJLLyEkJAQHDhwAAFRXVyM+Ph7du3eHtbU1hg4diqysLKXstm3b0LlzZxw4cAD9+/eHwWBARUUFqqursXTpUri7u8NgMMDLywvvv/++Uu7s2bMYN24cbGxs4OTkhKioKHz99dfK/pEjR2LBggV49dVX0aVLFzg7OyMhIUHZ7+HhAQCIjIyESqVStsvKyhAeHg4nJyfY2NhgyJAhOHz4sFl/KysrMX78eFhaWsLT0xMfffRRk0dW3bx5E7NmzYKDgwPs7OwwevRonD59utVxPHPmDEaPHg1LS0t07doVsbGxqKqqAlD/6LCwsDAAgFqtbjXwHjx4EN7e3rC0tMSoUaNw4cIFs/3Xr1/H1KlT0b17d1hZWcHX1xc7d+5U9s+YMQNHjx7Fli1blFXXFy5cQF1dHV544QV4enrC0tISPj4+2LJlS6t9Mp3fhlJTU83af/r0aYwaNQq2traws7ODv78/8vLylP3Hjx9HYGAgLC0t4e7ujgULFuDWrVvK/mvXriEsLEw5Hzt27Gi1TUREREStYbZltm0Jsy0RERH92DDbMtu2hNmWiB4EFyoQ0WPL0tISNTU1AIC4uDj861//wq5du1BYWIjJkycjNDQUpaWlyvdv376Nt956C3/5y1/wn//8B46OjoiOjsbOnTvx+9//HkVFRdi6dStsbGwA1IfJ0aNHw8/PD3l5efj0009x9epVPPfcc2bt+Otf/wpra2vk5OTgt7/9LdauXYv09HQAQG5uLgAgOTkZlZWVynZVVRV+9atfISMjA/n5+QgNDUVYWBgqKiqU40ZHR+Orr75CVlYW9uzZg6SkJFy7ds2s7smTJ+PatWv45JNPcOrUKQwaNAjBwcG4ceNGs2N269YtjB07Fvb29sjNzcXu3btx+PBhxMXFAQDi4+ORnJwMoD5wV1ZWNnucS5cuYcKECQgLC0NBQQFmzZqFZcuWmX3n+++/h7+/P9LS0nD27FnExsYiKioKJ0+eBABs2bIFAQEBmD17tlKXu7s7jEYj3NzcsHv3bpw7dw6rV6/GihUrkJKS0mxb2mv69Olwc3NDbm4uTp06hWXLlkGn0wGo/w9IaGgoJk6ciMLCQvz973/H8ePHlXEB6gP6pUuXkJmZiX/84x949913m5wPIiIiovvFbMtsey+YbYmIiOhxxmzLbHsvmG2JqEVCRPQYiImJkfDwcBERMRqNkp6eLgaDQeLj4+XixYui0Wjk8uXLZmWCg4Nl+fLlIiKSnJwsAKSgoEDZX1xcLAAkPT292TrfeOMNGTNmjNlnly5dEgBSXFwsIiJBQUHyi1/8wuw7Q4YMkaVLlyrbAGTfvn1t9vGpp56SxMREEREpKioSAJKbm6vsLy0tFQCyefNmERE5duyY2NnZyffff292nN69e8vWrVubrSMpKUns7e2lqqpK+SwtLU3UarVcuXJFRET27dsnbU3/y5cvl/79+5t9tnTpUgEg33zzTYvlxo8fL4sXL1a2g4KC5OWXX261LhGRefPmycSJE1vcn5ycLJ06dTL7rHE/bG1tZdu2bc2Wf+GFFyQ2Ntbss2PHjolarZY7d+4o18rJkyeV/aZzZDofRERERO3FbMtsy2xLRERETwpmW2ZbZlsieli0D30lBBFRO/3zn/+EjY0NamtrYTQaMW3aNCQkJCArKwt1dXXw9vY2+351dTW6du2qbOv1egwYMEDZLigogEajQVBQULP1nT59GpmZmcpK3YbKysqU+hoeEwBcXFzaXLFZVVWFhIQEpKWlobKyEnfv3sWdO3eUlbnFxcXQarUYNGiQUsbLywv29vZm7auqqjLrIwDcuXNHeV9ZY0VFRRg4cCCsra2Vz4YPHw6j0Yji4mI4OTm12u6Gxxk6dKjZZwEBAWbbdXV1WLduHVJSUnD58mXU1NSguroaVlZWbR7/j3/8Iz744ANUVFTgzp07qKmpwTPPPNOutrVk0aJFmDVrFv72t78hJCQEkydPRu/evQHUj2VhYaHZY8FEBEajEeXl5SgpKYFWq4W/v7+yv2/fvk0eW0ZERETUXsy2zLYPgtmWiIiIHifMtsy2D4LZlohawoUKRPTYGDVqFN577z3o9Xq4urpCq62foqqqqqDRaHDq1CloNBqzMg3DqqWlpdm7rywtLVutr6qqCmFhYXjrrbea7HNxcVH+bXoMlYlKpYLRaGz12PHx8UhPT8fGjRvh5eUFS0tLTJo0SXkkWntUVVXBxcXF7J1uJo9DEHv77bexZcsWvPPOO/D19YW1tTUWLlzYZh937dqF+Ph4bNq0CQEBAbC1tcXbb7+NnJycFsuo1WqIiNlntbW1ZtsJCQmYNm0a0tLS8Mknn2DNmjXYtWsXIiMjUVVVhTlz5mDBggVNjt2jRw+UlJTcQ8+JiIiI2sZs27R9zLb1mG2JiIjox4bZtmn7mG3rMdsS0YPgQgUiemxYW1vDy8uryed+fn6oq6vDtWvXEBgY2O7j+fr6wmg04ujRowgJCWmyf9CgQdizZw88PDyUcH0/dDod6urqzD7Lzs7GjBkzEBkZCaA+vF64cEHZ7+Pjg7t37yI/P19ZDXr+/Hl88803Zu27cuUKtFotPDw82tWWfv36Ydu2bbh165ayOjc7OxtqtRo+Pj7t7lO/fv1w4MABs8+++OKLJn0MDw/Hb37zGwCA0WhESUkJ+vfvr3xHr9c3OzbDhg3D3Llzlc9aWmls4uDggO+++86sXwUFBU2+5+3tDW9vb7zyyiuYOnUqkpOTERkZiUGDBuHcuXPNXl9A/Srcu3fv4tSpUxgyZAiA+tXTN2/ebLVdRERERC1htmW2bQmzLREREf3YMNsy27aE2ZaIHoT6UTeAiKgt3t7emD59OqKjo7F3716Ul5fj5MmTWL9+PdLS0los5+HhgZiYGMycOROpqakoLy9HVlYWUlJSAADz5s3DjRs3MHXqVOTm5qKsrAyHDh3C888/3ySktcbDwwMZGRm4cuWKElj79OmDvXv3oqCgAKdPn8a0adPMVvP27dsXISEhiI2NxcmTJ5Gfn4/Y2Fiz1cUhISEICAhAREQEPvvsM1y4cAEnTpzAypUrkZeX12xbpk+fDgsLC8TExODs2bPIzMzE/PnzERUV1e7HhwHAiy++iNLSUixZsgTFxcX46KOPsG3bNrPv9OnTB+np6Thx4gSKioowZ84cXL16tcnY5OTk4MKFC/j6669hNBrRp08f5OXl4dChQygpKcFrr72G3NzcVtszdOhQWFlZYcWKFSgrK2vSnjt37iAuLg5ZWVm4ePEisrOzkZubi379+gEAli5dihMnTiAuLg4FBQUoLS3F/v37ERcXB6D+PyChoaGYM2cOcnJycOrUKcyaNavN1d1ERERE94rZltmW2ZaIiIieFMy2zLbMtkT0ILhQgYh+FJKTkxEdHY3FixfDx8cHERERyM3NRY8ePVot995772HSpEmYO3cu+vbti9mzZ+PWrVsAAFdXV2RnZ6Ourg5jxoyBr68vFi5ciM6dO0Otbv/0uGnTJqSnp8Pd3R1+fn4AgN/97newt7fHsGHDEBYWhrFjx5q91wwAtm/fDicnJ4wYMQKRkZGYPXs2bG1tYWFhAaD+UWUHDx7EiBEj8Pzzz8Pb2xu//vWvcfHixRbDq5WVFQ4dOoQbN25gyJAhmDRpEoKDg/GHP/yh3f0B6h+rtWfPHqSmpmLgwIH405/+hHXr1pl9Z9WqVRg0aBDGjh2LkSNHwtnZGREREWbfiY+Ph0ajQf/+/eHg4ICKigrMmTMHEyZMwJQpUzB06FBcv37dbJVuc7p06YIPP/wQBw8ehK+vL3bu3ImEhARlv0ajwfXr1xEdHQ1vb28899xzGDduHF5//XUA9e+rO3r0KEpKShAYGAg/Pz+sXr0arq6uyjGSk5Ph6uqKoKAgTJgwAbGxsXB0dLyncSMiIiJqD2ZbZltmWyIiInpSMNsy2zLbEtH9Uknjl8cQEdEj8b///Q/u7u44fPgwgoODH3VziIiIiIjuG7MtERERET0pmG2JiB4OLlQgInpEjhw5gqqqKvj6+qKyshKvvvoqLl++jJKSEuh0ukfdPCIiIiKidmO2JSIiIqInBbMtEVHH0D7qBhAR/VTV1tZixYoV+PLLL2Fra4thw4Zhx44dDLtERERE9KPDbEtERERETwpmWyKijsEnKhAREREREREREREREREREVGHUT/qBhAREREREREREREREREREdFPBxcqEBERERERERERERERERERUYfhQgUiIiIiIiIiIiIiIiIiIiLqMFyoQERERERERERERERERERERB2GCxWIiIiIiIiIiIiIiIiIiIiow3ChAhEREREREREREREREREREXUYLlQgIiIiIiIiIiIiIiIiIiKiDsOFCkRERERERERERERERERERNRhuFCBiIiIiIiIiIiIiIiIiIiIOsz/Af18pHsDAY3lAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6399201,
     "sourceId": 10334686,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4916.951206,
   "end_time": "2025-01-28T10:31:25.456246",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-28T09:09:28.505040",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00ea5b5ed6be4d94b3d800e53d28f82a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_da2aa745b8244ccc95dabfc6d62cef61",
        "IPY_MODEL_2d727d963e0443eda3e87fc5d42012a6",
        "IPY_MODEL_efb1be4dc79248d6afb1146332acb53a"
       ],
       "layout": "IPY_MODEL_bd888f4dba67461db4e766d8d9e86b79",
       "tabbable": null,
       "tooltip": null
      }
     },
     "01676b6c0f0f41179b4cf1ada7e523a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d26cbcbb968c443096fd77969faf2ce2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_afff7eb4e9a941778ee0f789616262ec",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "07c2e8d4cabf430fbb3d27176caa5c46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80d1056fa7164d91b73657710d07bcc9",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a33721f44f9e4314863c4ef717a3e1ef",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "09044ea3e6be4b5cbe476db1c79091f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b14139042a64e15ade8421a72e1d3e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0dd996f3205449ed8f4aa47a474d9ced": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1392187e41c54d35977920cac253f4f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "185957f902b44cc98499c9916f4bce48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_01676b6c0f0f41179b4cf1ada7e523a0",
        "IPY_MODEL_f9c680b7dea94917b9440e0fcf5513d2",
        "IPY_MODEL_34d441bbfb904060bf28db33c5139db8"
       ],
       "layout": "IPY_MODEL_9b3178d49365412eb998005c65dc924a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1b31b5a68113477a861865dadfd581be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81b2e6d09ef44e74941b7fa48d43e4b1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ef283afe94bd452ba7a21da782c163fe",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡112/112â€‡[00:00&lt;00:00,â€‡12.2kB/s]"
      }
     },
     "2d727d963e0443eda3e87fc5d42012a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_51513542a5dd4c3d876034883f07001f",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e1c55e291639447ebf504387bea0d2c4",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "34d441bbfb904060bf28db33c5139db8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b9a8ebc657854fe4af1f11243bd71b79",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d863aa263cec49c7af189d8a51300d58",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡2.00/2.00â€‡[00:00&lt;00:00,â€‡163B/s]"
      }
     },
     "47c6393c49b643e7b5ec908c376c0c67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fa273db4164a4ca7a9aa7fa040558683",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_de8d8acce5744eca9068798a56a8d3bd",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡175kB/s]"
      }
     },
     "51513542a5dd4c3d876034883f07001f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fe0355c02e24bb28e4f980a3c8e1a61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6040f77c2a7744beaadfabe9d7ac73d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d5811ac66864b2b8fe3452d3119a942": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_09044ea3e6be4b5cbe476db1c79091f2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0b14139042a64e15ade8421a72e1d3e1",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:â€‡100%"
      }
     },
     "80d1056fa7164d91b73657710d07bcc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81b2e6d09ef44e74941b7fa48d43e4b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "879d7e35d2cf444aa8e0b3b85236398d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "883813edbbaf4c26add3473d5e87c618": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b5b8d37acd0c4598967c2ff28d9bad75",
        "IPY_MODEL_ee92a559cf284f9a8e63d6bd4cccfc78",
        "IPY_MODEL_47c6393c49b643e7b5ec908c376c0c67"
       ],
       "layout": "IPY_MODEL_8a809eea602d4db8b37f8d53d573fa01",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8a809eea602d4db8b37f8d53d573fa01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b3178d49365412eb998005c65dc924a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a33721f44f9e4314863c4ef717a3e1ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "afff7eb4e9a941778ee0f789616262ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5b8d37acd0c4598967c2ff28d9bad75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0dd996f3205449ed8f4aa47a474d9ced",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_879d7e35d2cf444aa8e0b3b85236398d",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "b9a8ebc657854fe4af1f11243bd71b79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd888f4dba67461db4e766d8d9e86b79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4a3d1fd2a2145c3aee39ed9002e1981": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c9ce307c6f8e4fdbbd0f3d038d27d366": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfc16575230a49a4b7810d7556c7948c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d26cbcbb968c443096fd77969faf2ce2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d863aa263cec49c7af189d8a51300d58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da1c9f0e4315478eb31abe7378ddf475": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da2aa745b8244ccc95dabfc6d62cef61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cfc16575230a49a4b7810d7556c7948c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c4a3d1fd2a2145c3aee39ed9002e1981",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:â€‡100%"
      }
     },
     "de8d8acce5744eca9068798a56a8d3bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dea9f1276cb54e1a820f6031fed02319": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e1c55e291639447ebf504387bea0d2c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e5d831c11c554c07bc87fc14f892c09a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7d5811ac66864b2b8fe3452d3119a942",
        "IPY_MODEL_07c2e8d4cabf430fbb3d27176caa5c46",
        "IPY_MODEL_1b31b5a68113477a861865dadfd581be"
       ],
       "layout": "IPY_MODEL_f75a8f7d8815467f948ad612ebfd31a0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ee92a559cf284f9a8e63d6bd4cccfc78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6040f77c2a7744beaadfabe9d7ac73d2",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1392187e41c54d35977920cac253f4f2",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "ef283afe94bd452ba7a21da782c163fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "efb1be4dc79248d6afb1146332acb53a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_da1c9f0e4315478eb31abe7378ddf475",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_dea9f1276cb54e1a820f6031fed02319",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡229k/229kâ€‡[00:00&lt;00:00,â€‡5.99MB/s]"
      }
     },
     "f75a8f7d8815467f948ad612ebfd31a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9c680b7dea94917b9440e0fcf5513d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c9ce307c6f8e4fdbbd0f3d038d27d366",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5fe0355c02e24bb28e4f980a3c8e1a61",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "fa273db4164a4ca7a9aa7fa040558683": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
