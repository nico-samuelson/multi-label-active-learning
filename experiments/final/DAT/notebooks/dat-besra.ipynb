{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee37cf0",
   "metadata": {
    "papermill": {
     "duration": 0.005951,
     "end_time": "2025-02-09T07:17:58.273263",
     "exception": false,
     "start_time": "2025-02-09T07:17:58.267312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c186fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:17:58.284531Z",
     "iopub.status.busy": "2025-02-09T07:17:58.284286Z",
     "iopub.status.idle": "2025-02-09T07:18:35.790612Z",
     "shell.execute_reply": "2025-02-09T07:18:35.789932Z"
    },
    "papermill": {
     "duration": 37.513422,
     "end_time": "2025-02-09T07:18:35.792103",
     "exception": false,
     "start_time": "2025-02-09T07:17:58.278681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea40a22",
   "metadata": {
    "papermill": {
     "duration": 0.005077,
     "end_time": "2025-02-09T07:18:35.802947",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.797870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc60a742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:35.814389Z",
     "iopub.status.busy": "2025-02-09T07:18:35.813910Z",
     "iopub.status.idle": "2025-02-09T07:18:35.817165Z",
     "shell.execute_reply": "2025-02-09T07:18:35.816602Z"
    },
    "papermill": {
     "duration": 0.010234,
     "end_time": "2025-02-09T07:18:35.818449",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.808215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac0e6ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:35.829671Z",
     "iopub.status.busy": "2025-02-09T07:18:35.829467Z",
     "iopub.status.idle": "2025-02-09T07:18:35.832925Z",
     "shell.execute_reply": "2025-02-09T07:18:35.832310Z"
    },
    "papermill": {
     "duration": 0.010366,
     "end_time": "2025-02-09T07:18:35.834085",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.823719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946feb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:35.845356Z",
     "iopub.status.busy": "2025-02-09T07:18:35.845152Z",
     "iopub.status.idle": "2025-02-09T07:18:35.857908Z",
     "shell.execute_reply": "2025-02-09T07:18:35.857329Z"
    },
    "papermill": {
     "duration": 0.019591,
     "end_time": "2025-02-09T07:18:35.859081",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.839490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ac5a2",
   "metadata": {
    "papermill": {
     "duration": 0.005012,
     "end_time": "2025-02-09T07:18:35.869361",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.864349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd74edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:35.880224Z",
     "iopub.status.busy": "2025-02-09T07:18:35.880032Z",
     "iopub.status.idle": "2025-02-09T07:18:35.937110Z",
     "shell.execute_reply": "2025-02-09T07:18:35.935306Z"
    },
    "papermill": {
     "duration": 0.064477,
     "end_time": "2025-02-09T07:18:35.938962",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.874485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-besra'\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "sequence_length = 192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8a0b2",
   "metadata": {
    "papermill": {
     "duration": 0.00501,
     "end_time": "2025-02-09T07:18:35.949251",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.944241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c9ae53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:35.960503Z",
     "iopub.status.busy": "2025-02-09T07:18:35.960208Z",
     "iopub.status.idle": "2025-02-09T07:18:36.105028Z",
     "shell.execute_reply": "2025-02-09T07:18:36.104048Z"
    },
    "papermill": {
     "duration": 0.152867,
     "end_time": "2025-02-09T07:18:36.107170",
     "exception": false,
     "start_time": "2025-02-09T07:18:35.954303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctor-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643d3cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:36.119274Z",
     "iopub.status.busy": "2025-02-09T07:18:36.119024Z",
     "iopub.status.idle": "2025-02-09T07:18:36.140477Z",
     "shell.execute_reply": "2025-02-09T07:18:36.139807Z"
    },
    "papermill": {
     "duration": 0.028861,
     "end_time": "2025-02-09T07:18:36.141798",
     "exception": false,
     "start_time": "2025-02-09T07:18:36.112937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d3767",
   "metadata": {
    "papermill": {
     "duration": 0.005515,
     "end_time": "2025-02-09T07:18:36.152803",
     "exception": false,
     "start_time": "2025-02-09T07:18:36.147288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f1c2d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:36.164317Z",
     "iopub.status.busy": "2025-02-09T07:18:36.164081Z",
     "iopub.status.idle": "2025-02-09T07:18:36.972029Z",
     "shell.execute_reply": "2025-02-09T07:18:36.971094Z"
    },
    "papermill": {
     "duration": 0.815727,
     "end_time": "2025-02-09T07:18:36.973864",
     "exception": false,
     "start_time": "2025-02-09T07:18:36.158137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fec6256f7f44095a2537dd876739f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf59b9243704d1ca2e8fb032a341c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5282e976b44c89a75234a4ec7200b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f684769719504de0aaee18c6b600c45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef5dbbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:36.988269Z",
     "iopub.status.busy": "2025-02-09T07:18:36.988016Z",
     "iopub.status.idle": "2025-02-09T07:18:36.992054Z",
     "shell.execute_reply": "2025-02-09T07:18:36.991482Z"
    },
    "papermill": {
     "duration": 0.011913,
     "end_time": "2025-02-09T07:18:36.993207",
     "exception": false,
     "start_time": "2025-02-09T07:18:36.981294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e615e06a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.005720Z",
     "iopub.status.busy": "2025-02-09T07:18:37.005502Z",
     "iopub.status.idle": "2025-02-09T07:18:37.011142Z",
     "shell.execute_reply": "2025-02-09T07:18:37.010328Z"
    },
    "papermill": {
     "duration": 0.013133,
     "end_time": "2025-02-09T07:18:37.012262",
     "exception": false,
     "start_time": "2025-02-09T07:18:36.999129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x78dce6ce6e60>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x78dce6ce7160>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataloaders(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45276c0",
   "metadata": {
    "papermill": {
     "duration": 0.00559,
     "end_time": "2025-02-09T07:18:37.023799",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.018209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976c87b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.036249Z",
     "iopub.status.busy": "2025-02-09T07:18:37.036032Z",
     "iopub.status.idle": "2025-02-09T07:18:37.039629Z",
     "shell.execute_reply": "2025-02-09T07:18:37.038854Z"
    },
    "papermill": {
     "duration": 0.011005,
     "end_time": "2025-02-09T07:18:37.040775",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.029770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf390a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.053241Z",
     "iopub.status.busy": "2025-02-09T07:18:37.053048Z",
     "iopub.status.idle": "2025-02-09T07:18:37.057208Z",
     "shell.execute_reply": "2025-02-09T07:18:37.056637Z"
    },
    "papermill": {
     "duration": 0.011635,
     "end_time": "2025-02-09T07:18:37.058375",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.046740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03a9ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.071169Z",
     "iopub.status.busy": "2025-02-09T07:18:37.070975Z",
     "iopub.status.idle": "2025-02-09T07:18:37.082738Z",
     "shell.execute_reply": "2025-02-09T07:18:37.082154Z"
    },
    "papermill": {
     "duration": 0.019495,
     "end_time": "2025-02-09T07:18:37.083841",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.064346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77585714",
   "metadata": {
    "papermill": {
     "duration": 0.00568,
     "end_time": "2025-02-09T07:18:37.095591",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.089911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "126d95c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.109550Z",
     "iopub.status.busy": "2025-02-09T07:18:37.109312Z",
     "iopub.status.idle": "2025-02-09T07:18:37.114538Z",
     "shell.execute_reply": "2025-02-09T07:18:37.113746Z"
    },
    "papermill": {
     "duration": 0.014269,
     "end_time": "2025-02-09T07:18:37.115755",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.101486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a2451",
   "metadata": {
    "papermill": {
     "duration": 0.005738,
     "end_time": "2025-02-09T07:18:37.127297",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.121559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b21e334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.140047Z",
     "iopub.status.busy": "2025-02-09T07:18:37.139848Z",
     "iopub.status.idle": "2025-02-09T07:18:37.158142Z",
     "shell.execute_reply": "2025-02-09T07:18:37.157341Z"
    },
    "papermill": {
     "duration": 0.026298,
     "end_time": "2025-02-09T07:18:37.159510",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.133212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_score(p, y, alpha=0.1, beta=3):\n",
    "    \"\"\"Calculates Beta score for a given probability p and label y.\"\"\"\n",
    "    \n",
    "    if y == 1:\n",
    "        return -betaln(alpha, beta + 1) + betaln(alpha + p, beta + 1 - p)\n",
    "    elif y == 0:\n",
    "        return -betaln(alpha + 1, beta) + betaln(alpha + 1 - p, beta + p)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: y must be 0 or 1.\")\n",
    "\n",
    "def bayesian_update(prior, likelihood, evidence, alpha=0.1, beta_param=3):\n",
    "    \"\"\" \n",
    "    Bayes' Theorem: P(y'|x') = P(x'|y') * P(y') / P(x')\n",
    "    P(y'|x') or likelihood = model probs\n",
    "    p(y') or prior = class probabilities\n",
    "    p(x') or evidence = 1 / number of data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Beta score to simulate the posterior\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    \n",
    "    # We calculate the posterior using the Beta distribution\n",
    "    return posterior\n",
    "\n",
    "def compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx):\n",
    "    scores_before = []\n",
    "    scores_after = []\n",
    "\n",
    "    # Before data addition: calculate Beta score for predicted prob\n",
    "    scores_before.append(beta_score(predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    scores_before.append(beta_score(1-predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    \n",
    "    # After data addition: use Bayesian update (posterior probability)\n",
    "    # class_probs = labeled_dataset.get_per_class_probs() \n",
    "    # label_probs = labeled_dataset.get_global_probs() \n",
    "    \n",
    "    for k in range(2):\n",
    "        prior = predicted_prob\n",
    "        likelihood = class_probs[class_idx][k]  # Likelihood is the true label (0 or 1)\n",
    "        posterior = bayesian_update(prior, likelihood, 1)\n",
    "        scores_after.append(beta_score(posterior, int(1 if posterior >= 0.5 else 0)))\n",
    "\n",
    "    score_diff_0 = scores_after[0] - scores_before[0]\n",
    "    score_diff_1 = scores_after[1] - scores_before[1]\n",
    "    return label_probs['0'] * score_diff_0 + label_probs['1'] * score_diff_1\n",
    "\n",
    "# Function to compute Expected Score Change (∆Q)\n",
    "def besra_sampling(models, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    \n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    labeled_dataset = DoctorAnswerDataset(current_X_train, current_y_train, tokenizer, max_length=sequence_length)\n",
    "    label_probs = labeled_dataset.get_global_probs()\n",
    "    class_probs = labeled_dataset.get_per_class_probs()\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    start_time = time.time()\n",
    "    score_changes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        # all_probs = []\n",
    "        model_probs = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.sigmoid(logits)  # Multi-label classification uses sigmoid\n",
    "                model_probs.append(probs.unsqueeze(0))  # Add batch dimension for averaging\n",
    "        \n",
    "        # Stack all model predictions and compute the mean across models\n",
    "        model_probs = torch.cat(model_probs, dim=0)  # Concatenate predictions across models\n",
    "        probs = model_probs.mean(dim=0)  # Take the mean along the model axis\n",
    "\n",
    "        # Calculate Beta scores before and after data addition\n",
    "        for i in range(len(probs)):\n",
    "            score_diff = []\n",
    "            for class_idx in range(probs.shape[1]):\n",
    "                predicted_prob = probs[i, class_idx].item()\n",
    "                score_diff.append(compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx))\n",
    "            \n",
    "            score_changes.append(np.mean(score_diff))\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    \n",
    "    accelerator.wait_for_everyone()\n",
    "    \n",
    "    if accelerator.is_local_main_process:\n",
    "        num_of_candidates = len(score_changes[:math.ceil(0.1 * len(score_changes))])\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "\n",
    "        # Determine number of clusters\n",
    "        if num_of_candidates <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            n_clusters = n_clusters\n",
    "        elif num_of_candidates > n_clusters and num_of_candidates < nearest_cp - current_train_size:\n",
    "            n_clusters = num_of_candidates\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            n_clusters = nearest_cp - current_train_size\n",
    "\n",
    "        score_changes = np.array(score_changes)\n",
    "        score_changes = score_changes.reshape(-1, 1)\n",
    "            \n",
    "        kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "        kmeans.fit(score_changes)\n",
    "\n",
    "        if current_train_size > checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Samples above threshold:\", num_of_candidates)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]  # Indices of samples in the current cluster\n",
    "                \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances to the cluster center\n",
    "                cluster_distances = np.linalg.norm(score_changes[cluster_indices] - cluster_center, axis=1)\n",
    "                closest_sample_index = cluster_indices[np.argmin(cluster_distances)]  # Closest sample index\n",
    "                collected_indices.add(closest_sample_index)\n",
    "\n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "            \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    '1-FR': [y_train[i][0] for i in temp],\n",
    "                    '2-GI': [y_train[i][1] for i in temp],\n",
    "                    '3-PI': [y_train[i][2] for i in temp],\n",
    "                    '4-DM': [y_train[i][3] for i in temp],\n",
    "                    '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                    '6-RE': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Samples above threshold:\", num_of_candidates)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac3fb1",
   "metadata": {
    "papermill": {
     "duration": 0.005854,
     "end_time": "2025-02-09T07:18:37.171227",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.165373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f65436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.184211Z",
     "iopub.status.busy": "2025-02-09T07:18:37.183987Z",
     "iopub.status.idle": "2025-02-09T07:18:37.193974Z",
     "shell.execute_reply": "2025-02-09T07:18:37.193179Z"
    },
    "papermill": {
     "duration": 0.017863,
     "end_time": "2025-02-09T07:18:37.195114",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.177251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "\n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}')\n",
    "            models.append(model)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (models, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2977f3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.207511Z",
     "iopub.status.busy": "2025-02-09T07:18:37.207248Z",
     "iopub.status.idle": "2025-02-09T07:18:37.210556Z",
     "shell.execute_reply": "2025-02-09T07:18:37.209808Z"
    },
    "papermill": {
     "duration": 0.010824,
     "end_time": "2025-02-09T07:18:37.211794",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.200970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [[50, 67, 42], [81, 90, 11], [14, 7, 33], [3, 44, 85], [94, 21, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49641649",
   "metadata": {
    "papermill": {
     "duration": 0.005682,
     "end_time": "2025-02-09T07:18:37.223262",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.217580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5938, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2125, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2185, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2094, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1328, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1332, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1526, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.956202268600464 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.638, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4006, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.296, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2339, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2346, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1755, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2175, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1383, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1454, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1626, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.346954584121704 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3775, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2018, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.156, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1346, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1357, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.381959676742554 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      " Samples above threshold:38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 14.251822471618652 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5014, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2488, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1246, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1349, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1152, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 10/10, Train Loss: 0.1113, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 42.17918300628662 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2113, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1783, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.126, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1426, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1308, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1262, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 43.83941435813904 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4709, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2373, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1271, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1207, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1453, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.125, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 43.99132323265076 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.476076602935791 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4131, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2118, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1746, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1392, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1364, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1472, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1239, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6509\n",
      "Epoch 8/10, Train Loss: 0.1129, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 10/10, Train Loss: 0.0762, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Model 1 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 44.28083872795105 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4368, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2259, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1364, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1193, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 9/10, Train Loss: 0.0825, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6509\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6509\n",
      "Model 2 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 48.059139251708984 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3895, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1391, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1379, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1147, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 9/10, Train Loss: 0.0828, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Epoch 10/10, Train Loss: 0.0727, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Model 3 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 47.744293212890625 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.853496313095093 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1316, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.1145, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1007, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7518\n",
      "Model 1 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.237754821777344 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3992, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1895, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1478, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.1202, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1119, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0871, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6517\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 2 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.255454540252686 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3559, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1774, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1419, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1153, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1109, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 9/10, Train Loss: 0.0946, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Model 3 - Iteration 128: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 52.16835379600525 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9634, F1 Micro: 0.9723, F1 Macro: 0.653\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.682092905044556 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3789, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1866, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1549, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.702\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7091\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.73      0.71      0.71       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.96      0.98      0.97       407\n",
      "\n",
      "Training completed in 57.04997491836548 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3804, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1907, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1666, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1605, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.13, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6514\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 9/10, Train Loss: 0.0584, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Model 2 - Iteration 156: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 52.84941339492798 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3513, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1839, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7639\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6505\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Model 3 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.74      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 54.39747071266174 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9636, F1 Micro: 0.9724, F1 Macro: 0.6642\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.422894716262817 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.313, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.176, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7655\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7963\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7776\n",
      "Model 1 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 58.70521879196167 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3309, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.0877, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.72\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7484\n",
      "Epoch 10/10, Train Loss: 0.0422, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Model 2 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.96      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.76      0.74      0.75       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 56.979634046554565 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2941, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.193, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1527, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0747, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7543\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9519, F1 Micro: 0.9628, F1 Macro: 0.7757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0596, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7765\n",
      "Epoch 10/10, Train Loss: 0.0401, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7506\n",
      "Model 3 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 62.12252974510193 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9644, F1 Micro: 0.973, F1 Macro: 0.6824\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.124062776565552 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3093, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1978, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.187, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1515, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1359, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.11, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0374, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Model 1 - Iteration 203: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 63.32197618484497 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3293, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2052, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Model 2 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 66.46509671211243 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2987, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2021, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 6/10, Train Loss: 0.1255, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0868, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Model 3 - Iteration 203: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 63.39730978012085 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9654, F1 Micro: 0.9737, F1 Macro: 0.6964\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.33074140548706 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3114, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1777, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1786, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7441\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7532\n",
      "Epoch 8/10, Train Loss: 0.0597, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0508, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Model 1 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 67.81052374839783 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1818, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.102, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7623\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0661, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Model 2 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.94      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 64.14883399009705 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3018, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1519, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9535, F1 Micro: 0.9642, F1 Macro: 0.7561\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7633\n",
      "Model 3 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.96      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 64.42204689979553 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9659, F1 Micro: 0.9741, F1 Macro: 0.7089\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.106420516967773 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3139, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1931, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1636, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7384\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.071, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0481, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 1 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 70.32486009597778 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3281, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1502, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7431\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7394\n",
      "Epoch 9/10, Train Loss: 0.0512, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Model 2 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.11425590515137 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3031, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1657, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1661, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0438, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0406, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Model 3 - Iteration 241: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.85723161697388 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9666, F1 Micro: 0.9746, F1 Macro: 0.7172\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 7.451473236083984 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1864, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1804, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0583, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0357, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Model 1 - Iteration 250: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.40086317062378 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3203, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1902, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Model 2 - Iteration 250: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.817791223526 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2956, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1784, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1717, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0551, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Model 3 - Iteration 250: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.68051218986511 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9674, F1 Micro: 0.9753, F1 Macro: 0.7254\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.11353874206543 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2986, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2004, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Epoch 9/10, Train Loss: 0.0459, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Model 1 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 74.7831757068634 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3189, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2036, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1969, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1458, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.6492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 7/10, Train Loss: 0.089, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Model 2 - Iteration 265: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.27982664108276 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2974, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2044, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.6492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0461, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0405, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.3066258430481 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9678, F1 Micro: 0.9755, F1 Macro: 0.7307\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.51957368850708 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3022, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2105, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1896, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0633, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 10/10, Train Loss: 0.039, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7478\n",
      "Model 1 - Iteration 279: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.57091522216797 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2129, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.196, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1795, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.066, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 10/10, Train Loss: 0.0395, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7969\n",
      "Model 2 - Iteration 279: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.56048488616943 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2114, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1928, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.752\n",
      "Epoch 7/10, Train Loss: 0.0596, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0366, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Model 3 - Iteration 279: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.79222583770752 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9684, F1 Micro: 0.976, F1 Macro: 0.7366\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.811100006103516 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.297, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1853, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 5/10, Train Loss: 0.1164, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.761\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0351, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7632\n",
      "Model 1 - Iteration 292: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.62165093421936 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3107, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1725, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1042, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0435, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7771\n",
      "Model 2 - Iteration 292: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.16049885749817 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2885, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1867, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0685, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 9/10, Train Loss: 0.0477, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Model 3 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.27549242973328 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7401\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.5886900424957275 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1912, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1966, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1659, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Epoch 6/10, Train Loss: 0.089, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7493\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "Epoch 9/10, Train Loss: 0.044, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 300: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.10492610931396 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3085, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1239, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 6/10, Train Loss: 0.086, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0763, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 8/10, Train Loss: 0.0515, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.768\n",
      "Model 2 - Iteration 300: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.14958071708679 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2867, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1587, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.08, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 7/10, Train Loss: 0.0717, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0516, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 9/10, Train Loss: 0.0421, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Model 3 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.73514437675476 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9691, F1 Micro: 0.9765, F1 Macro: 0.7432\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.189394950866699 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2698, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0863, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.64182639122009 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2844, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1772, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1214, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.088, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 7/10, Train Loss: 0.065, Accuracy: 0.9599, F1 Micro: 0.9699, F1 Macro: 0.7345\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7569\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7569\n",
      "Model 2 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.33254432678223 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2597, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1583, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0796, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0626, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0433, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9792, F1 Micro: 0.9842, F1 Macro: 0.9709\n",
      "Model 3 - Iteration 310: Accuracy: 0.9792, F1 Micro: 0.9842, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       0.97      1.00      0.98       407\n",
      "   macro avg       0.95      1.00      0.97       407\n",
      "weighted avg       0.97      1.00      0.98       407\n",
      " samples avg       0.97      1.00      0.98       407\n",
      "\n",
      "Training completed in 87.71371865272522 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9694, F1 Micro: 0.9768, F1 Macro: 0.7498\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.581148386001587 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1826, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1447, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 5/10, Train Loss: 0.1089, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.082, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0636, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7393\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7552\n",
      "Epoch 10/10, Train Loss: 0.0331, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Model 1 - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.7918210029602 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1891, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 6/10, Train Loss: 0.0818, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7568\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0381, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0357, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7769\n",
      "Model 2 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.71403646469116 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.264, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.184, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1401, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Epoch 5/10, Train Loss: 0.1093, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.747\n",
      "Epoch 6/10, Train Loss: 0.0795, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 7/10, Train Loss: 0.0646, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0449, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Model 3 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.9441466331482 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7519\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.4298200607299805 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2771, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1556, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7595\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Model 1 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.99714660644531 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2865, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7394\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0677, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9599, F1 Micro: 0.9699, F1 Macro: 0.7394\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7521\n",
      "Epoch 10/10, Train Loss: 0.0357, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7811\n",
      "Model 2 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.80707740783691 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1903, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1288, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0889, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Epoch 7/10, Train Loss: 0.0603, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 8/10, Train Loss: 0.0402, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7595\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Model 3 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.65219855308533 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7543\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.725095987319946 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2693, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 5/10, Train Loss: 0.1108, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7548\n",
      "Epoch 6/10, Train Loss: 0.0889, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7497\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0391, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Model 1 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.9089457988739 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2836, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1739, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1434, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8204\n",
      "Epoch 7/10, Train Loss: 0.0698, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7969\n",
      "Epoch 8/10, Train Loss: 0.0368, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7902\n",
      "Model 2 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.38358902931213 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2621, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1818, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1067, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0771, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0651, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7781\n",
      "Model 3 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.40033292770386 s\n",
      "Averaged - Iteration 340: Accuracy: 0.97, F1 Micro: 0.9772, F1 Macro: 0.7559\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.3768057823181152 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2786, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1827, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 5/10, Train Loss: 0.111, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.775\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0532, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0303, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Model 1 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.71180629730225 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1797, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1034, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 6/10, Train Loss: 0.0683, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Epoch 7/10, Train Loss: 0.0495, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0493, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Model 2 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.36573791503906 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2717, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1548, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 6/10, Train Loss: 0.0673, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0472, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Epoch 9/10, Train Loss: 0.0337, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.9114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Model 3 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.32681798934937 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7577\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.9826338291168213 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1848, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1051, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0772, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0524, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7429\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Model 1 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.10415530204773 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2693, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1878, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1405, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1111, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0782, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.0558, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0469, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7487\n",
      "Epoch 10/10, Train Loss: 0.0265, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7469\n",
      "Model 2 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.3398871421814 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1883, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1386, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1077, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8226\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Model 3 - Iteration 360: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.13777494430542 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9704, F1 Micro: 0.9775, F1 Macro: 0.76\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.792402505874634 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1273, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0955, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 6/10, Train Loss: 0.0589, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7595\n",
      "Epoch 7/10, Train Loss: 0.0546, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7569\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Model 1 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 92.06148838996887 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2546, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1721, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.099, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0648, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0526, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0317, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7521\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7416\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7595\n",
      "Model 2 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.82512307167053 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2395, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1533, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1355, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0969, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0591, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7459\n",
      "Epoch 8/10, Train Loss: 0.034, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Model 3 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.54241180419922 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9705, F1 Micro: 0.9776, F1 Macro: 0.7613\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.1254353523254395 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2451, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1476, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1323, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 6/10, Train Loss: 0.072, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Epoch 7/10, Train Loss: 0.0568, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Epoch 8/10, Train Loss: 0.0364, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Model 1 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 93.59558773040771 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2573, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1586, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1364, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0695, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7988\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7491\n",
      "Epoch 10/10, Train Loss: 0.0233, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7502\n",
      "Model 2 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.59049153327942 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2402, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1568, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1571, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 4/10, Train Loss: 0.1376, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 6/10, Train Loss: 0.0716, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7402\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Model 3 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.31208872795105 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9706, F1 Micro: 0.9777, F1 Macro: 0.7616\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7054829597473145 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2541, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1815, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1576, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 4/10, Train Loss: 0.1293, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1005, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.0733, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0475, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 8/10, Train Loss: 0.0357, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 9/10, Train Loss: 0.0323, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7576\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7291\n",
      "Model 1 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.95609664916992 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2576, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1587, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1331, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1068, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0724, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7937\n",
      "Epoch 7/10, Train Loss: 0.0455, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0337, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.764\n",
      "Model 2 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.1623101234436 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2458, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1811, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 4/10, Train Loss: 0.1284, Accuracy: 0.9583, F1 Micro: 0.9688, F1 Macro: 0.7293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0433, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7546\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9535, F1 Micro: 0.9649, F1 Macro: 0.7788\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.754\n",
      "Model 3 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.78      0.78       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 95.06576681137085 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9707, F1 Micro: 0.9777, F1 Macro: 0.7624\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2099719047546387 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2515, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1394, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 5/10, Train Loss: 0.0906, Accuracy: 0.9567, F1 Micro: 0.9664, F1 Macro: 0.7571\n",
      "Epoch 6/10, Train Loss: 0.0654, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0472, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 8/10, Train Loss: 0.0323, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0314, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Model 1 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.7257628440857 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1655, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1458, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Epoch 5/10, Train Loss: 0.0891, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.7883\n",
      "Epoch 6/10, Train Loss: 0.063, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 7/10, Train Loss: 0.0517, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Epoch 8/10, Train Loss: 0.028, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Model 2 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.09340071678162 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2411, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1402, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 4/10, Train Loss: 0.1341, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7395\n",
      "Epoch 5/10, Train Loss: 0.0889, Accuracy: 0.9583, F1 Micro: 0.9674, F1 Macro: 0.7875\n",
      "Epoch 6/10, Train Loss: 0.0551, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0447, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0279, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7772\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7551\n",
      "Model 3 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.67833971977234 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9707, F1 Micro: 0.9778, F1 Macro: 0.7628\n",
      "Total sampling time: 160.85 seconds\n",
      "Total runtime: 5826.016121149063 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aef1e27",
   "metadata": {
    "papermill": {
     "duration": 0.005684,
     "end_time": "2025-02-09T07:18:37.251159",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.245475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 2\n",
      "Random seed: [81, 90, 11]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3918, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.28, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2134, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2275, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2151, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1362, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1356, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1654, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.601462602615356 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5672, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.359, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2132, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1532, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2049, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1265, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1302, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1522, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 37.97661995887756 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5373, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2713, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2123, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2138, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1374, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1382, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1649, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.18605637550354 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 17.714525938034058 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5049, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2606, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2082, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.203, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1282, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 9/10, Train Loss: 0.1365, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 10/10, Train Loss: 0.1361, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Model 1 - Iteration 63: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 40.675230503082275 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4524, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2412, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1999, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1599, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1352, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1222, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 9/10, Train Loss: 0.1415, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1274, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Model 2 - Iteration 63: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 44.051629066467285 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4546, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2562, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2095, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2078, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1681, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.17, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1373, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1356, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 9/10, Train Loss: 0.15, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1463, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Model 3 - Iteration 63: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 42.39577102661133 s\n",
      "Averaged - Iteration 63: Accuracy: 0.965, F1 Micro: 0.9734, F1 Macro: 0.6538\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.644502639770508 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4334, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2258, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2278, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1639, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1595, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1326, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.1253, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0939, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "Model 1 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 49.08278179168701 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.395, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2209, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1555, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1662, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 7/10, Train Loss: 0.1441, Accuracy: 0.9599, F1 Micro: 0.9688, F1 Macro: 0.6493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1329, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.6558\n",
      "Epoch 9/10, Train Loss: 0.1214, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.0881, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Model 2 - Iteration 97: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.6558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 47.193233489990234 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3921, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2215, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2282, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1743, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1627, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1366, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.1263, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.0932, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Model 3 - Iteration 97: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 49.28553342819214 s\n",
      "Averaged - Iteration 97: Accuracy: 0.966, F1 Micro: 0.9741, F1 Macro: 0.6616\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.949989795684814 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4066, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2199, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1885, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1813, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1845, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1381, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1351, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Epoch 9/10, Train Loss: 0.1022, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Model 1 - Iteration 128: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 54.18630909919739 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2104, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1915, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1882, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1396, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 8/10, Train Loss: 0.1436, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1064, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 10/10, Train Loss: 0.0883, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Model 2 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 52.775816679000854 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3739, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.221, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1881, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1852, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.194, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1503, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1449, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Epoch 9/10, Train Loss: 0.1048, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0846, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Model 3 - Iteration 128: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 54.24461388587952 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9671, F1 Micro: 0.975, F1 Macro: 0.683\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.447660684585571 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.216, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.194, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1804, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1483, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7651\n",
      "Epoch 7/10, Train Loss: 0.1165, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7635\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Model 1 - Iteration 156: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 57.73736238479614 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3509, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2094, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1912, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1776, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1521, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1155, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7662\n",
      "Model 2 - Iteration 156: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 56.6256000995636 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2134, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1978, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1904, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1669, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1068, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 10/10, Train Loss: 0.0638, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7553\n",
      "Model 3 - Iteration 156: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 56.77618622779846 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6997\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.550647258758545 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3527, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2288, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1696, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "Epoch 6/10, Train Loss: 0.1365, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0899, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7791\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7791\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7653\n",
      "Model 1 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 57.85815405845642 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3293, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2295, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1687, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.144, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7632\n",
      "Epoch 7/10, Train Loss: 0.1017, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7569\n",
      "Model 2 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 59.39185452461243 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3282, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2261, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1845, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.18, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1525, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7223\n",
      "Epoch 8/10, Train Loss: 0.0867, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.757\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7562\n",
      "Model 3 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.93      0.94      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.97      0.98       407\n",
      "   macro avg       0.82      0.70      0.72       407\n",
      "weighted avg       0.98      0.97      0.97       407\n",
      " samples avg       0.98      0.97      0.98       407\n",
      "\n",
      "Training completed in 61.4459867477417 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.709\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.213710308074951 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3461, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2139, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1569, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1144, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Model 1 - Iteration 203: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 65.56933665275574 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3229, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2119, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1999, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7514\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Model 2 - Iteration 203: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 63.738425731658936 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3261, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1781, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1343, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7793\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7937\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7783\n",
      "Model 3 - Iteration 203: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 63.730430603027344 s\n",
      "Averaged - Iteration 203: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.7195\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.13715648651123 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3366, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2125, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1867, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.189, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1685, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.115, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "Model 1 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.05029010772705 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3163, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2117, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1736, Accuracy: 0.9567, F1 Micro: 0.9663, F1 Macro: 0.6473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.118, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7893\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Model 2 - Iteration 223: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 66.2384979724884 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3146, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2103, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1861, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1912, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1792, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1012, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "Model 3 - Iteration 223: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 70.23907852172852 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9694, F1 Micro: 0.9767, F1 Macro: 0.7251\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.202703714370728 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3236, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1525, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0562, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7637\n",
      "Epoch 10/10, Train Loss: 0.039, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7745\n",
      "Model 1 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.28675723075867 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3039, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2097, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1735, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.1698, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0822, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.0451, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Model 2 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.95975017547607 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.306, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.212, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.185, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1683, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 7/10, Train Loss: 0.0839, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Epoch 10/10, Train Loss: 0.0396, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Model 3 - Iteration 241: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.81155061721802 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7333\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 7.405116081237793 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3249, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1994, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1498, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 7/10, Train Loss: 0.0776, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 9/10, Train Loss: 0.0377, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7783\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8209\n",
      "Model 1 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.29205274581909 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3034, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1593, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7803\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7761\n",
      "Model 2 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.25078225135803 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3054, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2055, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.174, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1373, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0468, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Model 3 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.12022948265076 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9701, F1 Micro: 0.9773, F1 Macro: 0.7392\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.039723634719849 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3083, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Epoch 7/10, Train Loss: 0.0621, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7559\n",
      "Epoch 8/10, Train Loss: 0.0566, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.0408, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7644\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7644\n",
      "Model 1 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 71.49808549880981 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2848, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.185, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1787, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7561\n",
      "Model 2 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.21276021003723 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2935, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2094, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1198, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7552\n",
      "Epoch 9/10, Train Loss: 0.0503, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7981\n",
      "Model 3 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.72096848487854 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7403\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.813911437988281 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2993, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1887, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1581, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0863, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.801\n",
      "Epoch 8/10, Train Loss: 0.0511, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8015\n",
      "Model 1 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.47819495201111 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.284, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1869, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1415, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7673\n",
      "Epoch 8/10, Train Loss: 0.0536, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7755\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Model 2 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.6305627822876 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2873, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1867, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1759, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "Epoch 7/10, Train Loss: 0.0581, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7937\n",
      "Epoch 8/10, Train Loss: 0.0513, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7884\n",
      "Epoch 10/10, Train Loss: 0.0308, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Model 3 - Iteration 279: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.8794949054718 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9705, F1 Micro: 0.9776, F1 Macro: 0.745\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.16048526763916 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2935, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1991, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0932, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.05, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Epoch 10/10, Train Loss: 0.0325, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7894\n",
      "Model 1 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.1682710647583 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2811, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2019, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0642, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7656\n",
      "Epoch 9/10, Train Loss: 0.0479, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7502\n",
      "Model 2 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.74445629119873 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.279, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.0634, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7461\n",
      "Epoch 8/10, Train Loss: 0.0523, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.031, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7962\n",
      "Model 3 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.77703547477722 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9707, F1 Micro: 0.9777, F1 Macro: 0.7489\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.286224365234375 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1925, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8002\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0872, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9679, F1 Micro: 0.9752, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0443, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0292, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8219\n",
      "Model 1 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.26397132873535 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2689, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.188, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0892, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "Epoch 7/10, Train Loss: 0.0604, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7611\n",
      "Epoch 8/10, Train Loss: 0.0462, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0428, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7595\n",
      "Model 2 - Iteration 300: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.7759039402008 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2705, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.193, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1744, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1352, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7772\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0425, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7552\n",
      "Model 3 - Iteration 300: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.1072690486908 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9709, F1 Micro: 0.9779, F1 Macro: 0.7535\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.054144382476807 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2639, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1949, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1702, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9615, F1 Micro: 0.9701, F1 Macro: 0.6505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1329, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0853, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 7/10, Train Loss: 0.0546, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Model 1 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.8754677772522 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2511, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.0609, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7752\n",
      "Epoch 8/10, Train Loss: 0.0561, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7662\n",
      "Model 2 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.1601071357727 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2502, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1693, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0867, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.0633, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0574, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7971\n",
      "Model 3 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.38908529281616 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9711, F1 Micro: 0.978, F1 Macro: 0.7563\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.980865955352783 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2736, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1845, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1788, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0625, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7781\n",
      "Model 1 - Iteration 320: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.72925925254822 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2568, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1412, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Epoch 6/10, Train Loss: 0.0895, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7236\n",
      "Epoch 8/10, Train Loss: 0.052, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Model 2 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.15974020957947 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2591, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1827, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "Epoch 6/10, Train Loss: 0.0885, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 7/10, Train Loss: 0.0681, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7556\n",
      "Epoch 8/10, Train Loss: 0.052, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7673\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9615, F1 Micro: 0.9711, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Model 3 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.58870244026184 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9711, F1 Micro: 0.978, F1 Macro: 0.7578\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.970689058303833 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2847, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1709, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1118, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7799\n",
      "Epoch 6/10, Train Loss: 0.0715, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7881\n",
      "Epoch 9/10, Train Loss: 0.0338, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.803\n",
      "Model 1 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 88.81496167182922 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1847, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1106, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Epoch 6/10, Train Loss: 0.07, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 7/10, Train Loss: 0.0558, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 8/10, Train Loss: 0.0426, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 9/10, Train Loss: 0.0372, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.756\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Model 2 - Iteration 330: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.04608225822449 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2741, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7541\n",
      "Epoch 6/10, Train Loss: 0.0801, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7936\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0461, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "Epoch 9/10, Train Loss: 0.0375, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.7303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7802\n",
      "Model 3 - Iteration 330: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.57491135597229 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9711, F1 Micro: 0.978, F1 Macro: 0.7572\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5347418785095215 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2595, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1727, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1456, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1261, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.7906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1075, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7819\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7478\n",
      "Model 1 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.06080317497253 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2461, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1695, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1415, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1242, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 6/10, Train Loss: 0.0687, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7552\n",
      "Epoch 7/10, Train Loss: 0.0476, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7338\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7393\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7236\n",
      "Model 2 - Iteration 340: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.58119583129883 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2489, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1484, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1363, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7929\n",
      "Epoch 6/10, Train Loss: 0.0742, Accuracy: 0.9583, F1 Micro: 0.9688, F1 Macro: 0.7263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0544, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7763\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8042\n",
      "Model 3 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.06280779838562 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7593\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.333564043045044 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1528, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1301, Accuracy: 0.9615, F1 Micro: 0.9712, F1 Macro: 0.7434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1094, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 6/10, Train Loss: 0.0696, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Epoch 7/10, Train Loss: 0.0461, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7573\n",
      "Epoch 8/10, Train Loss: 0.035, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Epoch 9/10, Train Loss: 0.024, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7573\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Model 1 - Iteration 350: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.42139959335327 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2465, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1285, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1048, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0728, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0476, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 9/10, Train Loss: 0.0228, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Model 2 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.18064856529236 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2482, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1577, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1353, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0777, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7265\n",
      "Epoch 8/10, Train Loss: 0.034, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0267, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7981\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Model 3 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.10249352455139 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9714, F1 Micro: 0.9782, F1 Macro: 0.761\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7968077659606934 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2681, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1662, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 5/10, Train Loss: 0.0856, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 6/10, Train Loss: 0.0712, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0286, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Model 1 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.90793943405151 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2485, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.164, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0864, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 6/10, Train Loss: 0.0759, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.7399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0529, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0321, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7458\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Model 2 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.03641414642334 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2521, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1664, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1611, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0774, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7428\n",
      "Epoch 7/10, Train Loss: 0.0571, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7802\n",
      "Epoch 8/10, Train Loss: 0.0333, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.8904\n",
      "Model 3 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.6017107963562 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9714, F1 Micro: 0.9783, F1 Macro: 0.7624\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.571282386779785 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2503, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1189, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7505\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0753, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.75\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8236\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Model 1 - Iteration 370: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.55375862121582 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2358, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1497, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1171, Accuracy: 0.9599, F1 Micro: 0.97, F1 Macro: 0.7302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0996, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7664\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7567\n",
      "Model 2 - Iteration 370: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 90.46836113929749 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2379, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 5/10, Train Loss: 0.1099, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 6/10, Train Loss: 0.0769, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0512, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.78\n",
      "Epoch 10/10, Train Loss: 0.0207, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Model 3 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.54173040390015 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9715, F1 Micro: 0.9784, F1 Macro: 0.764\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.154982089996338 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2573, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1497, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1396, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1294, Accuracy: 0.9615, F1 Micro: 0.9712, F1 Macro: 0.7434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0937, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0452, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8031\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Model 1 - Iteration 380: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.82597470283508 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2428, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1465, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1382, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.138, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Epoch 5/10, Train Loss: 0.099, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0469, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Model 2 - Iteration 380: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.95225739479065 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2444, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1498, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1089, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 7/10, Train Loss: 0.0481, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7673\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7977\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7549\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Model 3 - Iteration 380: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.31915426254272 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7656\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6616463661193848 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2491, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.165, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1426, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1247, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.744\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0667, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0375, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7458\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Model 1 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.51946759223938 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2362, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1626, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1405, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 4/10, Train Loss: 0.1169, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0855, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 7/10, Train Loss: 0.0364, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.73\n",
      "Epoch 8/10, Train Loss: 0.0306, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.744\n",
      "Epoch 9/10, Train Loss: 0.0295, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Model 2 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.9260880947113 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2398, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1449, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1333, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 6/10, Train Loss: 0.0726, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7312\n",
      "Epoch 7/10, Train Loss: 0.0424, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7491\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7495\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8437\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.803\n",
      "Model 3 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 95.09192514419556 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9716, F1 Micro: 0.9784, F1 Macro: 0.7663\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2635128498077393 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2488, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1752, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1331, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 5/10, Train Loss: 0.0958, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7929\n",
      "Epoch 6/10, Train Loss: 0.0575, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0468, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0333, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0204, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7672\n",
      "Model 1 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.66148495674133 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2342, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.174, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1335, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 4/10, Train Loss: 0.1323, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1032, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0623, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Epoch 7/10, Train Loss: 0.0492, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Epoch 8/10, Train Loss: 0.0397, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Model 2 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 96.95193600654602 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2413, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1761, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1412, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1348, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.1049, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7663\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7788\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7608\n",
      "Epoch 10/10, Train Loss: 0.0182, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 97.50334525108337 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9716, F1 Micro: 0.9784, F1 Macro: 0.7667\n",
      "Total sampling time: 162.89 seconds\n",
      "Total runtime: 5818.381468057632 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8bf0d",
   "metadata": {
    "papermill": {
     "duration": 0.005751,
     "end_time": "2025-02-09T07:18:37.278775",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.273024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc39548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T07:18:37.291588Z",
     "iopub.status.busy": "2025-02-09T07:18:37.291342Z",
     "iopub.status.idle": "2025-02-09T08:54:45.523753Z",
     "shell.execute_reply": "2025-02-09T08:54:45.522811Z"
    },
    "papermill": {
     "duration": 5768.240495,
     "end_time": "2025-02-09T08:54:45.525329",
     "exception": false,
     "start_time": "2025-02-09T07:18:37.284834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 3\n",
      "Random seed: [14, 7, 33]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5339, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3609, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2712, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2079, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2245, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1625, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2034, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1394, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1358, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1462, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.968395948410034 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6345, Accuracy: 0.9247, F1 Micro: 0.9395, F1 Macro: 0.6216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3936, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2767, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2144, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2256, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.161, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2104, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1331, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1375, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.01359677314758 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.535, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3536, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.265, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2017, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2122, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1355, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1444, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.45265245437622 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 13.11604928970337 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4554, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2758, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2329, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1592, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1511, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1436, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1302, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 42.90877175331116 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2872, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.238, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1622, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1605, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1279, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1595, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1369, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 48.56250858306885 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.264, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2342, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.133, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1656, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1535, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.882824182510376 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 13.546692132949829 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1244, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.144, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.11, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1107, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0825, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Model 1 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 52.815117597579956 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4259, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2049, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1545, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1624, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1422, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1105, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1288, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1027, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Model 2 - Iteration 97: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 51.29267072677612 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3707, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2015, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1532, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1218, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1351, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.1062, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Model 3 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 49.62870216369629 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9646, F1 Micro: 0.9731, F1 Macro: 0.6536\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 12.153138399124146 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3737, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1966, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1577, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1563, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 7/10, Train Loss: 0.1195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.6484\n",
      "Model 1 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 49.642563819885254 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4108, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2004, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1545, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1755, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1474, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1343, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6549\n",
      "Epoch 9/10, Train Loss: 0.0966, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0758, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Model 2 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 53.23671770095825 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3623, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1989, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.16, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1619, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1408, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.1151, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1083, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 10/10, Train Loss: 0.0938, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.6492\n",
      "Model 3 - Iteration 128: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 51.78299379348755 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9651, F1 Micro: 0.9735, F1 Macro: 0.663\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 10.824454545974731 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3443, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1883, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.1293, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Model 1 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 53.90916562080383 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.376, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2208, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1704, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1899, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1708, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.142, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1281, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8034\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Model 2 - Iteration 156: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 57.227057456970215 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3316, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1752, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1942, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.18, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1622, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1507, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.6494\n",
      "Epoch 8/10, Train Loss: 0.1122, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.649\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7108\n",
      "Model 3 - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.73      0.71      0.71       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 55.8245153427124 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9659, F1 Micro: 0.9741, F1 Macro: 0.6749\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 9.798256635665894 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2972, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.174, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1598, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.6471\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.648\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.6907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.702\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7019\n",
      "Model 1 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.70      0.71      0.70       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 58.4238862991333 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3234, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1707, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1836, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7663\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Model 2 - Iteration 181: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 60.49588465690613 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2855, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1745, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1854, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1334, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.089, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "Model 3 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 65.04120397567749 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6857\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.385684490203857 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2976, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1792, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1508, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6998\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9551, F1 Micro: 0.9654, F1 Macro: 0.649\n",
      "Epoch 8/10, Train Loss: 0.0496, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7486\n",
      "Model 1 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.97       407\n",
      "\n",
      "Training completed in 61.263055086135864 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3235, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1825, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1725, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9615, F1 Micro: 0.9712, F1 Macro: 0.7434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0788, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0425, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 9/10, Train Loss: 0.0482, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7876\n",
      "Epoch 10/10, Train Loss: 0.0313, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Model 2 - Iteration 203: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 62.88441610336304 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.29, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1778, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.186, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1802, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1702, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.7035\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7635\n",
      "Model 3 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.96      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.81      0.74      0.76       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 62.399102449417114 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9668, F1 Micro: 0.9747, F1 Macro: 0.6965\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 8.073243379592896 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3051, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9327, F1 Micro: 0.9468, F1 Macro: 0.6304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.7167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0375, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7445\n",
      "Model 1 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.74      0.76       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.97       407\n",
      "\n",
      "Training completed in 66.78720808029175 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3244, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.764\n",
      "Epoch 5/10, Train Loss: 0.1058, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8013\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9519, F1 Micro: 0.9636, F1 Macro: 0.7221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8209\n",
      "Epoch 10/10, Train Loss: 0.0381, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.82\n",
      "Model 2 - Iteration 223: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 66.35976362228394 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3016, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1813, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1612, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.12, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9503, F1 Micro: 0.9626, F1 Macro: 0.7189\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Epoch 9/10, Train Loss: 0.0389, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.763\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Model 3 - Iteration 223: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 63.46265268325806 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9673, F1 Micro: 0.9752, F1 Macro: 0.7087\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.328283786773682 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2982, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1837, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1725, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1421, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1307, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1125, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7628\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0406, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7553\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 72.73177242279053 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3178, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1812, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1703, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1405, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1212, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7501\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Model 2 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.26984667778015 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2911, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1847, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1525, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0374, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7393\n",
      "Model 3 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 69.95207118988037 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9678, F1 Micro: 0.9755, F1 Macro: 0.7172\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 6.667283535003662 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1454, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0907, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.0684, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7196\n",
      "Epoch 8/10, Train Loss: 0.0465, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.767\n",
      "Model 1 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 73.20596575737 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2947, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7887\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Epoch 6/10, Train Loss: 0.0811, Accuracy: 0.9615, F1 Micro: 0.9701, F1 Macro: 0.7902\n",
      "Epoch 7/10, Train Loss: 0.0673, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7832\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7439\n",
      "Model 2 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.0363416671753 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2669, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1628, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1023, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7597\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7904\n",
      "Epoch 8/10, Train Loss: 0.0551, Accuracy: 0.9487, F1 Micro: 0.9603, F1 Macro: 0.7532\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7771\n",
      "Model 3 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.62809753417969 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9681, F1 Micro: 0.9757, F1 Macro: 0.7233\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 6.3434648513793945 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1921, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1181, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.7031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7977\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Model 1 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 74.42751955986023 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.308, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1903, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1281, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7439\n",
      "Epoch 7/10, Train Loss: 0.0569, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7937\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7583\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Model 2 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.11931824684143 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2872, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1934, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1578, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 5/10, Train Loss: 0.1179, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7876\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.51311349868774 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9684, F1 Micro: 0.976, F1 Macro: 0.7282\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      " Acquired samples:14\n",
      "Sampling duration: 5.840310573577881 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2906, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Epoch 6/10, Train Loss: 0.0907, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0565, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0615, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7767\n",
      "Model 1 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 78.27882361412048 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.306, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1829, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1085, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7632\n",
      "Epoch 6/10, Train Loss: 0.0824, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.749\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8029\n",
      "Epoch 9/10, Train Loss: 0.0453, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7649\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7447\n",
      "Model 2 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.79      0.82      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 76.58783411979675 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1779, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7587\n",
      "Epoch 7/10, Train Loss: 0.0652, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7533\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7936\n",
      "Epoch 9/10, Train Loss: 0.0448, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7618\n",
      "Epoch 10/10, Train Loss: 0.0366, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7419\n",
      "Model 3 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 73.05492234230042 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9687, F1 Micro: 0.9761, F1 Macro: 0.7336\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.344592571258545 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2837, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1933, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1867, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "Epoch 8/10, Train Loss: 0.0502, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7978\n",
      "Epoch 9/10, Train Loss: 0.0438, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7967\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7798\n",
      "Model 1 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 78.99386739730835 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2988, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1933, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Epoch 5/10, Train Loss: 0.1113, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0858, Accuracy: 0.9728, F1 Micro: 0.979, F1 Macro: 0.7975\n",
      "Epoch 7/10, Train Loss: 0.0682, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7956\n",
      "Epoch 8/10, Train Loss: 0.0515, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0464, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7526\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.752\n",
      "Model 2 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.979, F1 Macro: 0.7975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.93      0.93      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.98      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 77.40681838989258 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2766, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1876, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1554, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 5/10, Train Loss: 0.1375, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7929\n",
      "Epoch 7/10, Train Loss: 0.075, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7927\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7543\n",
      "Model 3 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 77.1779317855835 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9689, F1 Micro: 0.9763, F1 Macro: 0.7384\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.7825539112091064 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1806, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7374\n",
      "Epoch 5/10, Train Loss: 0.1091, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0566, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 10/10, Train Loss: 0.0339, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.7608\n",
      "Model 1 - Iteration 300: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.48862767219543 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2991, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1784, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1243, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0988, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 6/10, Train Loss: 0.0824, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Epoch 7/10, Train Loss: 0.0697, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 8/10, Train Loss: 0.0562, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7556\n",
      "Epoch 9/10, Train Loss: 0.0391, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8012\n",
      "Epoch 10/10, Train Loss: 0.0314, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.7745\n",
      "Model 2 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.22495079040527 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2797, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1948, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 5/10, Train Loss: 0.1175, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.7174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7597\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.8134\n",
      "Epoch 10/10, Train Loss: 0.0335, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8218\n",
      "Model 3 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.92930221557617 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9692, F1 Micro: 0.9765, F1 Macro: 0.7423\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10Sampling duration: 4.628735303878784 seconds\n",
      "\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2798, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1967, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1666, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1546, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1183, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0942, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0657, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0442, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0405, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7375\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Model 1 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.07325625419617 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1967, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1335, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "Epoch 5/10, Train Loss: 0.0942, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 6/10, Train Loss: 0.0787, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Epoch 8/10, Train Loss: 0.0498, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7651\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Model 2 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.84571886062622 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2726, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1964, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1664, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7503\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7479\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0473, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 9/10, Train Loss: 0.0418, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Model 3 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.90870571136475 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9694, F1 Micro: 0.9767, F1 Macro: 0.7456\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.170130014419556 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2919, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2024, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0518, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.755\n",
      "Epoch 9/10, Train Loss: 0.0443, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Model 1 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 84.5763623714447 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3067, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1989, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7773\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0814, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8207\n",
      "Epoch 8/10, Train Loss: 0.0556, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0515, Accuracy: 0.976, F1 Micro: 0.9818, F1 Macro: 0.7912\n",
      "Epoch 10/10, Train Loss: 0.0342, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Model 2 - Iteration 320: Accuracy: 0.976, F1 Micro: 0.9818, F1 Macro: 0.7912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.38865208625793 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2839, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2013, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1451, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.7893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.744\n",
      "Epoch 9/10, Train Loss: 0.0423, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Model 3 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.86113166809082 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9697, F1 Micro: 0.9769, F1 Macro: 0.7479\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.845425605773926 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2577, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2153, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0522, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 9/10, Train Loss: 0.0389, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7681\n",
      "Model 1 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.10269069671631 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.274, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2103, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1527, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1264, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.101, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0413, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7751\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Model 2 - Iteration 330: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.1808762550354 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2525, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2129, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1638, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7568\n",
      "Epoch 7/10, Train Loss: 0.0573, Accuracy: 0.9647, F1 Micro: 0.9735, F1 Macro: 0.7451\n",
      "Epoch 8/10, Train Loss: 0.0465, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7451\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Model 3 - Iteration 330: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.40607404708862 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7501\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.3843324184417725 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.242, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1579, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0619, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 9/10, Train Loss: 0.0396, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.8313\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Model 1 - Iteration 340: Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.0462999343872 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2568, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1227, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.782\n",
      "Epoch 5/10, Train Loss: 0.0968, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Epoch 6/10, Train Loss: 0.0787, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7594\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7573\n",
      "Model 2 - Iteration 340: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.11329460144043 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2391, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0655, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0558, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7449\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7383\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Model 3 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 86.1947569847107 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9701, F1 Micro: 0.9772, F1 Macro: 0.7518\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.2031664848327637 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2613, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1875, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1351, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7553\n",
      "Epoch 7/10, Train Loss: 0.0652, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Model 1 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.76005601882935 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2731, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1837, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.976, F1 Micro: 0.9818, F1 Macro: 0.8051\n",
      "Epoch 5/10, Train Loss: 0.0902, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7555\n",
      "Epoch 6/10, Train Loss: 0.0623, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.749\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.769\n",
      "Epoch 8/10, Train Loss: 0.051, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7467\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7558\n",
      "Model 2 - Iteration 350: Accuracy: 0.976, F1 Micro: 0.9818, F1 Macro: 0.8051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.81       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.82520842552185 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.253, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1875, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1134, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.774\n",
      "Epoch 6/10, Train Loss: 0.0717, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Epoch 7/10, Train Loss: 0.0626, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0321, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7543\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 87.39597177505493 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7539\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7043190002441406 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2541, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1835, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1627, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1503, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 5/10, Train Loss: 0.1223, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.8225\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Model 1 - Iteration 360: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.8225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.40460872650146 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7663\n",
      "Epoch 5/10, Train Loss: 0.0993, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7415\n",
      "Epoch 6/10, Train Loss: 0.0784, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.7408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0313, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.765\n",
      "Model 2 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.30384063720703 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2476, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1833, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1562, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.12, Accuracy: 0.9567, F1 Micro: 0.9668, F1 Macro: 0.7512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 7/10, Train Loss: 0.0558, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7709\n",
      "Epoch 8/10, Train Loss: 0.0475, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0385, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0381, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.803\n",
      "Model 3 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.75616693496704 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9704, F1 Micro: 0.9775, F1 Macro: 0.7557\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.413426160812378 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2433, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1539, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1341, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1096, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7795\n",
      "Epoch 6/10, Train Loss: 0.0869, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "Model 1 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.26677465438843 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2574, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1475, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1125, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0938, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0739, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7569\n",
      "Epoch 8/10, Train Loss: 0.0464, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Epoch 9/10, Train Loss: 0.0435, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7483\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7762\n",
      "Model 2 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.56733226776123 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2399, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1808, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1383, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "Epoch 6/10, Train Loss: 0.0865, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7623\n",
      "Epoch 7/10, Train Loss: 0.0452, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7584\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7446\n",
      "Model 3 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.66712951660156 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9705, F1 Micro: 0.9775, F1 Macro: 0.7573\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.020819664001465 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2387, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1734, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.9567, F1 Micro: 0.9664, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0941, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 6/10, Train Loss: 0.0726, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.774\n",
      "Epoch 7/10, Train Loss: 0.0458, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "Epoch 8/10, Train Loss: 0.0373, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7461\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7892\n",
      "Model 1 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.20999765396118 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2515, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.175, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1631, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7673\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.9679, F1 Micro: 0.9752, F1 Macro: 0.8172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0837, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7446\n",
      "Epoch 8/10, Train Loss: 0.037, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7769\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7565\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Model 2 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.52150249481201 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2365, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1764, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1029, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7379\n",
      "Epoch 6/10, Train Loss: 0.0763, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Epoch 7/10, Train Loss: 0.0482, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7501\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7734\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Model 3 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.5828812122345 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9705, F1 Micro: 0.9776, F1 Macro: 0.7584\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6194207668304443 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.233, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1605, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1489, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1133, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0966, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0635, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 7/10, Train Loss: 0.0513, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.801\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7567\n",
      "Epoch 9/10, Train Loss: 0.024, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7752\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Model 1 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.38190484046936 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2434, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Epoch 5/10, Train Loss: 0.0893, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7927\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7393\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7769\n",
      "Model 2 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.96      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.83      0.78       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 93.0988609790802 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.228, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1609, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.121, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Epoch 5/10, Train Loss: 0.11, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7946\n",
      "Epoch 6/10, Train Loss: 0.0709, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7927\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7513\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.765\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.46020746231079 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7594\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.437959909439087 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2268, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1699, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.0967, Accuracy: 0.9519, F1 Micro: 0.9622, F1 Macro: 0.709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0697, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0388, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0353, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.028, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 10/10, Train Loss: 0.0204, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7562\n",
      "Model 1 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.82476902008057 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2422, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1666, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1374, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1155, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 5/10, Train Loss: 0.0793, Accuracy: 0.9519, F1 Micro: 0.9627, F1 Macro: 0.7549\n",
      "Epoch 6/10, Train Loss: 0.0676, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0394, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7491\n",
      "Epoch 8/10, Train Loss: 0.0389, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.755\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Model 2 - Iteration 400: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.8271234035492 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2224, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1416, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.787\n",
      "Epoch 5/10, Train Loss: 0.095, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.7726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0744, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.04, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7484\n",
      "Epoch 8/10, Train Loss: 0.037, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7538\n",
      "Epoch 10/10, Train Loss: 0.019, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Model 3 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.71014714241028 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9707, F1 Micro: 0.9777, F1 Macro: 0.7608\n",
      "Total sampling time: 143.63 seconds\n",
      "Total runtime: 5767.172822237015 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86abe09d",
   "metadata": {
    "papermill": {
     "duration": 0.146797,
     "end_time": "2025-02-09T08:54:45.825735",
     "exception": false,
     "start_time": "2025-02-09T08:54:45.678938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eddbcafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T08:54:46.174109Z",
     "iopub.status.busy": "2025-02-09T08:54:46.173767Z",
     "iopub.status.idle": "2025-02-09T10:31:03.218510Z",
     "shell.execute_reply": "2025-02-09T10:31:03.217813Z"
    },
    "papermill": {
     "duration": 5777.245025,
     "end_time": "2025-02-09T10:31:03.219983",
     "exception": false,
     "start_time": "2025-02-09T08:54:45.974958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 4\n",
      "Random seed: [3, 44, 85]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5266, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3356, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3008, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2329, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3085, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2216, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2113, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.203, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1898, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 37.51451086997986 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5975, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3447, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3028, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2258, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2719, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2902, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2063, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1928, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1763, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 37.51385164260864 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5206, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3234, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2841, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 8/10, Train Loss: 0.1935, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Epoch 9/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6501\n",
      "Epoch 10/10, Train Loss: 0.1607, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6489\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 32.32963037490845 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 15.238528728485107 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4236, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2639, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2259, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1737, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1856, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1473, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1593, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1404, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.0932514667511 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4539, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2771, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2225, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1757, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1567, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1489, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1476, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1351, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 44.677008390426636 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4169, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2188, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1713, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1393, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1411, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.13, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 44.71586060523987 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 13.894577503204346 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2459, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2199, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1726, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1316, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1337, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0829, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0926, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7196\n",
      "Model 1 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 52.12331223487854 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3833, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2494, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1668, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1327, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1249, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0907, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "Model 2 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 51.45790147781372 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3397, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2448, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1869, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1235, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 8/10, Train Loss: 0.1104, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0713, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0872, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7379\n",
      "Model 3 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.73      0.75      0.74       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 50.882028579711914 s\n",
      "Averaged - Iteration 97: Accuracy: 0.964, F1 Micro: 0.9727, F1 Macro: 0.6772\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 12.008928060531616 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.348, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.211, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1835, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1308, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1202, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.702\n",
      "Epoch 9/10, Train Loss: 0.0902, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.702\n",
      "Model 1 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.70      0.71      0.70       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.96      0.98      0.97       407\n",
      "\n",
      "Training completed in 53.94671964645386 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2107, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2052, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1699, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 7/10, Train Loss: 0.1281, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 8/10, Train Loss: 0.1131, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7226\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Model 2 - Iteration 128: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.82      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 50.67369723320007 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3388, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2067, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2024, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1748, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1588, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1511, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Epoch 7/10, Train Loss: 0.1223, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1055, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0818, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7488\n",
      "Epoch 10/10, Train Loss: 0.0684, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "Model 3 - Iteration 128: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.75      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 52.35052227973938 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9645, F1 Micro: 0.9731, F1 Macro: 0.689\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 11.02311658859253 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3379, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2243, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1603, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.13, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.648\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Model 1 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 54.42532753944397 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3646, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2251, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1846, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1696, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1399, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7235\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Model 2 - Iteration 156: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 57.836570024490356 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3381, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2234, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1794, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2013, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1652, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 6/10, Train Loss: 0.1404, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7377\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7486\n",
      "Model 3 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.73      0.75      0.74       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 54.22564721107483 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9653, F1 Micro: 0.9736, F1 Macro: 0.6923\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 10.04000973701477 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3143, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1385, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 7/10, Train Loss: 0.1065, Accuracy: 0.9503, F1 Micro: 0.9613, F1 Macro: 0.6443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "Model 1 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 61.76190114021301 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3283, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.7449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Epoch 10/10, Train Loss: 0.0413, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Model 2 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 62.066027879714966 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3071, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "Epoch 7/10, Train Loss: 0.0856, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7483\n",
      "Epoch 8/10, Train Loss: 0.0663, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7496\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "Model 3 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 60.23691368103027 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9659, F1 Micro: 0.9741, F1 Macro: 0.7044\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.968193054199219 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1774, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.189, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1658, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9599, F1 Micro: 0.9699, F1 Macro: 0.7306\n",
      "Epoch 7/10, Train Loss: 0.1085, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7367\n",
      "Model 1 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.73      0.74      0.74       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 64.59016561508179 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3111, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1783, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1101, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0801, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Epoch 9/10, Train Loss: 0.0464, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Model 2 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 66.99335193634033 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1822, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7376\n",
      "Epoch 9/10, Train Loss: 0.0448, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7377\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7377\n",
      "Model 3 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 62.99020528793335 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.7124\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 8.055322170257568 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3061, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1984, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1899, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.764\n",
      "Epoch 6/10, Train Loss: 0.1196, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7528\n",
      "Epoch 9/10, Train Loss: 0.0434, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8087\n",
      "Epoch 10/10, Train Loss: 0.0356, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8108\n",
      "Model 1 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 65.95914840698242 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3193, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1993, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.176, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1615, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 8/10, Train Loss: 0.071, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7627\n",
      "Epoch 9/10, Train Loss: 0.0406, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7503\n",
      "Epoch 10/10, Train Loss: 0.0394, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7444\n",
      "Model 2 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 65.73571062088013 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3016, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1983, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1879, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.7144\n",
      "Epoch 6/10, Train Loss: 0.1185, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0787, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Epoch 9/10, Train Loss: 0.0413, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Epoch 10/10, Train Loss: 0.0395, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Model 3 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 62.48235535621643 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9665, F1 Micro: 0.9746, F1 Macro: 0.721\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.429273366928101 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3021, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2043, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1666, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7361\n",
      "Epoch 6/10, Train Loss: 0.1044, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7401\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.756\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7626\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7718\n",
      "Model 1 - Iteration 241: Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.44      1.00      0.62         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.72      0.83      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 68.86930990219116 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3161, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2046, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1671, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1287, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7201\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7367\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0468, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0441, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 2 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.49294543266296 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3028, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2022, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0598, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7755\n",
      "Epoch 9/10, Train Loss: 0.0411, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7568\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Model 3 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.31895661354065 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9668, F1 Micro: 0.9748, F1 Macro: 0.7273\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 6.729102849960327 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.287, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2157, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.148, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7648\n",
      "Epoch 6/10, Train Loss: 0.111, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7538\n",
      "Epoch 7/10, Train Loss: 0.0759, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7541\n",
      "Epoch 8/10, Train Loss: 0.0532, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.756\n",
      "Epoch 9/10, Train Loss: 0.042, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7531\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7541\n",
      "Model 1 - Iteration 250: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 69.99695777893066 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3028, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2156, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2014, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1352, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7964\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0759, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Epoch 8/10, Train Loss: 0.053, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0443, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Model 2 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.99540495872498 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2856, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1959, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7622\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7552\n",
      "Epoch 8/10, Train Loss: 0.0549, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7664\n",
      "Epoch 9/10, Train Loss: 0.0431, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.031, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Model 3 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.6349618434906 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9672, F1 Micro: 0.9751, F1 Macro: 0.7327\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 6.379346132278442 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2789, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.207, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2036, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1709, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7648\n",
      "Epoch 7/10, Train Loss: 0.0755, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7747\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7487\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7531\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7736\n",
      "Model 1 - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.74      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 74.64152550697327 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2061, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1992, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0708, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "Epoch 8/10, Train Loss: 0.0465, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.037, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Model 2 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.95879983901978 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2771, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2044, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1938, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7537\n",
      "Epoch 7/10, Train Loss: 0.0715, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 8/10, Train Loss: 0.0475, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7459\n",
      "Model 3 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.00723171234131 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9675, F1 Micro: 0.9753, F1 Macro: 0.7366\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 5.828984260559082 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2843, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1825, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.204, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7656\n",
      "Epoch 6/10, Train Loss: 0.0894, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7944\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7539\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7617\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7736\n",
      "Epoch 10/10, Train Loss: 0.0316, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7622\n",
      "Model 1 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.41544604301453 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2977, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1999, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1601, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0671, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7655\n",
      "Epoch 10/10, Train Loss: 0.0308, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Model 2 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.66756796836853 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "Epoch 7/10, Train Loss: 0.0579, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7803\n",
      "Epoch 8/10, Train Loss: 0.0493, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7723\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7664\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Model 3 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.24567174911499 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9678, F1 Micro: 0.9756, F1 Macro: 0.7409\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.4260358810424805 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2669, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1895, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.175, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Epoch 6/10, Train Loss: 0.0847, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7625\n",
      "Epoch 8/10, Train Loss: 0.047, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7747\n",
      "Model 1 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.1080207824707 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2801, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1896, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 6/10, Train Loss: 0.0803, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.07, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "Epoch 8/10, Train Loss: 0.0476, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.34547066688538 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.267, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1896, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1536, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0836, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7556\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7522\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Model 3 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.5732774734497 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9681, F1 Micro: 0.9758, F1 Macro: 0.7446\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.791106224060059 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2605, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1881, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1541, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7632\n",
      "Epoch 6/10, Train Loss: 0.0808, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Epoch 7/10, Train Loss: 0.0582, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7505\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7726\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7942\n",
      "Model 1 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 77.01123690605164 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2726, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1991, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1868, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.72\n",
      "Epoch 5/10, Train Loss: 0.0977, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0777, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "Epoch 7/10, Train Loss: 0.06, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.038, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7953\n",
      "Model 2 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 80.31073451042175 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2601, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1985, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1798, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1452, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.0972, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.7898\n",
      "Epoch 6/10, Train Loss: 0.0788, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0336, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0206, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7664\n",
      "Model 3 - Iteration 300: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.67618608474731 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9683, F1 Micro: 0.9759, F1 Macro: 0.7442\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.593057632446289 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1751, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0998, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "Epoch 6/10, Train Loss: 0.0704, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7644\n",
      "Epoch 7/10, Train Loss: 0.043, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 8/10, Train Loss: 0.0504, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7847\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7625\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Model 1 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.22040700912476 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2668, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1745, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1532, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 7/10, Train Loss: 0.0431, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7966\n",
      "Epoch 8/10, Train Loss: 0.045, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 9/10, Train Loss: 0.0295, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7883\n",
      "Model 2 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.99413204193115 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2501, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1915, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 3/10, Train Loss: 0.1679, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1367, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0852, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "Epoch 6/10, Train Loss: 0.0612, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0391, Accuracy: 0.9776, F1 Micro: 0.983, F1 Macro: 0.8237\n",
      "Epoch 8/10, Train Loss: 0.0406, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8189\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7919\n",
      "Model 3 - Iteration 310: Accuracy: 0.9776, F1 Micro: 0.983, F1 Macro: 0.8237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.13640713691711 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9686, F1 Micro: 0.9762, F1 Macro: 0.7484\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.198379993438721 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2426, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1713, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9583, F1 Micro: 0.9688, F1 Macro: 0.7418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "Epoch 6/10, Train Loss: 0.0764, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7855\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7486\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7734\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7557\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8144\n",
      "Model 1 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 80.2202513217926 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1722, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1694, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 7/10, Train Loss: 0.0556, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.75\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7636\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7567\n",
      "Epoch 10/10, Train Loss: 0.0201, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7653\n",
      "Model 2 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.78      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 81.28890657424927 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2382, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1505, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1109, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.0678, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.776\n",
      "Epoch 7/10, Train Loss: 0.0494, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.035, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8042\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0204, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7764\n",
      "Model 3 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.11329388618469 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9686, F1 Micro: 0.9762, F1 Macro: 0.7502\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.848405122756958 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2393, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1782, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1386, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1169, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.7589\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7587\n",
      "Epoch 8/10, Train Loss: 0.0336, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7655\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0194, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7633\n",
      "Model 1 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.4865083694458 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.252, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1787, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1386, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1145, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0809, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7756\n",
      "Epoch 8/10, Train Loss: 0.0321, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.8695\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.843\n",
      "Epoch 10/10, Train Loss: 0.0171, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "Model 2 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 86.23994517326355 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2392, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.178, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1283, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7795\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7611\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0322, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0176, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8042\n",
      "Model 3 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.31588983535767 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9689, F1 Micro: 0.9764, F1 Macro: 0.7525\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.484872579574585 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2283, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1695, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7656\n",
      "Epoch 6/10, Train Loss: 0.0745, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 7/10, Train Loss: 0.0617, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7868\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7867\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "Model 1 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.52100086212158 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2406, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1712, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.108, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 2 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.73278331756592 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2253, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1846, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1417, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7503\n",
      "Epoch 5/10, Train Loss: 0.0945, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.07, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Model 3 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.30321645736694 s\n",
      "Averaged - Iteration 340: Accuracy: 0.969, F1 Micro: 0.9765, F1 Macro: 0.7545\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.015284538269043 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2441, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1494, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.0903, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7646\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7727\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7549\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7636\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7636\n",
      "Model 1 - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.74      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 87.55677509307861 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2531, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1612, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1483, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1348, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.0892, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.059, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0365, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0295, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7755\n",
      "Epoch 10/10, Train Loss: 0.0235, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Model 2 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.02640795707703 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2414, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1401, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1193, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0776, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0583, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "Epoch 7/10, Train Loss: 0.0387, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 9/10, Train Loss: 0.0323, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.66821885108948 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9691, F1 Micro: 0.9765, F1 Macro: 0.7562\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.6701085567474365 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2199, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1802, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1081, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7487\n",
      "Epoch 7/10, Train Loss: 0.0512, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7477\n",
      "Epoch 8/10, Train Loss: 0.0339, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8302\n",
      "Epoch 9/10, Train Loss: 0.0199, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.832\n",
      "Model 1 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.6201536655426 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2315, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1809, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1333, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.108, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 6/10, Train Loss: 0.0682, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0214, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7807\n",
      "Model 2 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.43244457244873 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2176, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1813, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1279, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1003, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 6/10, Train Loss: 0.0611, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.744\n",
      "Epoch 7/10, Train Loss: 0.0472, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7752\n",
      "Epoch 8/10, Train Loss: 0.0336, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7744\n",
      "Epoch 9/10, Train Loss: 0.0189, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8034\n",
      "Model 3 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.55662512779236 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9693, F1 Micro: 0.9767, F1 Macro: 0.758\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.191513776779175 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1511, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1417, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0714, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Epoch 8/10, Train Loss: 0.0405, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.7885\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7574\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.765\n",
      "Model 1 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.23814272880554 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.238, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1504, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1401, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1109, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 6/10, Train Loss: 0.0652, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Epoch 7/10, Train Loss: 0.051, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Model 2 - Iteration 370: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.93      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.97       407\n",
      "\n",
      "Training completed in 93.49950003623962 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2274, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1501, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.126, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0623, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8022\n",
      "Epoch 8/10, Train Loss: 0.0357, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 10/10, Train Loss: 0.0181, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7479\n",
      "Model 3 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.15177917480469 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9694, F1 Micro: 0.9768, F1 Macro: 0.7598\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2180471420288086 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2244, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1607, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1176, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7383\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0517, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7655\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Model 1 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 94.8260509967804 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2327, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1627, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1197, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 5/10, Train Loss: 0.1112, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.062, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7764\n",
      "Epoch 7/10, Train Loss: 0.0496, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0375, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Model 2 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.544682264328 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.226, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1627, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1554, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1074, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7937\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7419\n",
      "Epoch 6/10, Train Loss: 0.0566, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0443, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7576\n",
      "Epoch 9/10, Train Loss: 0.0259, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0206, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Model 3 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.72      0.79      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 94.88888382911682 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9694, F1 Micro: 0.9768, F1 Macro: 0.7604\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.686422348022461 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1579, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1649, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1295, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7449\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7444\n",
      "Epoch 7/10, Train Loss: 0.0429, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7487\n",
      "Epoch 9/10, Train Loss: 0.0273, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7495\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7484\n",
      "Model 1 - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 92.99125742912292 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2375, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1273, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1039, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0694, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0437, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.778\n",
      "Model 2 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.48457264900208 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2268, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1599, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7177\n",
      "Epoch 5/10, Train Loss: 0.0883, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0618, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 7/10, Train Loss: 0.042, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.747\n",
      "Epoch 8/10, Train Loss: 0.0281, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7431\n",
      "Epoch 9/10, Train Loss: 0.0246, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0181, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7503\n",
      "Model 3 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 92.72487330436707 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9695, F1 Micro: 0.9768, F1 Macro: 0.7606\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4633517265319824 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2119, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1575, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1598, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0896, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.746\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0508, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0343, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0248, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0193, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Model 1 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 103.23334240913391 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2191, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1586, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1522, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.141, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0856, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0452, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 8/10, Train Loss: 0.0364, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 9/10, Train Loss: 0.0279, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7123\n",
      "Epoch 10/10, Train Loss: 0.0237, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7806\n",
      "Model 2 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.2571051120758 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2072, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1271, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.075, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 6/10, Train Loss: 0.061, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Epoch 7/10, Train Loss: 0.0423, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0314, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Model 3 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.67087316513062 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7614\n",
      "Total sampling time: 149.18 seconds\n",
      "Total runtime: 5776.2398862838745 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b104ef",
   "metadata": {
    "papermill": {
     "duration": 0.298103,
     "end_time": "2025-02-09T10:31:03.826152",
     "exception": false,
     "start_time": "2025-02-09T10:31:03.528049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 5\n",
      "Random seed: [94, 21, 5]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3554, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2554, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1465, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2033, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.128, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1336, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.51424503326416 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5508, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3494, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2433, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1288, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1334, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.23381328582764 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5872, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3649, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2613, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2079, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.226, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1624, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1384, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1439, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.53029775619507 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 14.984652996063232 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2339, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2016, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1772, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1606, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1204, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1266, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0971, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Model 1 - Iteration 63: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 43.408944845199585 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4421, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2219, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2015, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1707, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.129, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1593, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1241, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1293, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0935, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Model 2 - Iteration 63: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 45.314940452575684 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2471, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1791, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1352, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1672, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1274, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1396, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1037, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Model 3 - Iteration 63: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 42.22866868972778 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: \n",
      "34Acquired samples: 34\n",
      "Sampling duration: 14.046696662902832 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3747, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2207, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1757, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1407, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1157, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1163, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.0908, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0826, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Model 1 - Iteration 97: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 48.71394324302673 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3555, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2164, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1738, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1387, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1189, Accuracy: 0.9519, F1 Micro: 0.9629, F1 Macro: 0.6453\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9359, F1 Micro: 0.9497, F1 Macro: 0.6337\n",
      "Epoch 9/10, Train Loss: 0.0835, Accuracy: 0.9407, F1 Micro: 0.9538, F1 Macro: 0.6376\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9535, F1 Micro: 0.9642, F1 Macro: 0.6463\n",
      "Model 2 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 41.74727511405945 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.386, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2329, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1833, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1562, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1315, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.1213, Accuracy: 0.9567, F1 Micro: 0.9664, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0936, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1001, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Model 3 - Iteration 97: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 46.44457983970642 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9655, F1 Micro: 0.9737, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.28170657157898 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3491, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1253, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Epoch 8/10, Train Loss: 0.142, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1089, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Model 1 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 50.011375427246094 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3299, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1947, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1421, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1262, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.6487\n",
      "Epoch 8/10, Train Loss: 0.1373, Accuracy: 0.9471, F1 Micro: 0.9591, F1 Macro: 0.6423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0973, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Model 2 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 50.28756022453308 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3529, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2081, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1557, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1447, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1282, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1366, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Model 3 - Iteration 128: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 49.59447693824768 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9655, F1 Micro: 0.9738, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 11.882497787475586 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3544, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.209, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2066, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1678, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 8/10, Train Loss: 0.0879, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6517\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6512\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 51.2020742893219 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3463, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2075, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2058, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1692, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.14, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 7/10, Train Loss: 0.1299, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.6482\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6544\n",
      "Model 2 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 51.30134963989258 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3637, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2178, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2097, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1731, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 6/10, Train Loss: 0.1365, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 7/10, Train Loss: 0.1287, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7027\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6969\n",
      "Model 3 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 49.502195596694946 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9656, F1 Micro: 0.9738, F1 Macro: 0.6541\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 10.822997808456421 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.317, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1943, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1743, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1812, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1536, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1197, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.6492\n",
      "Epoch 9/10, Train Loss: 0.0822, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6514\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Model 1 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 54.1738121509552 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3046, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1964, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1885, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1848, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1551, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1259, Accuracy: 0.9535, F1 Micro: 0.9641, F1 Macro: 0.6461\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9503, F1 Micro: 0.9615, F1 Macro: 0.644\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6512\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Model 2 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 54.78628635406494 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3262, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1988, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.193, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1748, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.178, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1521, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1199, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.6471\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.6482\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7008\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7097\n",
      "Model 3 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 53.56286144256592 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9662, F1 Micro: 0.9742, F1 Macro: 0.6544\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.62708044052124 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3062, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2082, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2244, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1683, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1628, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.6502\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 10/10, Train Loss: 0.0544, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Model 1 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 56.76532769203186 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3016, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2078, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2233, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1799, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 6/10, Train Loss: 0.1551, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.6492\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.6482\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9503, F1 Micro: 0.9614, F1 Macro: 0.6437\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6541\n",
      "Model 2 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 56.69518446922302 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3139, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2246, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1692, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.1652, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.1059, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.0764, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Model 3 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 56.199143409729004 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9664, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 8.75067663192749 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2966, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1781, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 7/10, Train Loss: 0.1187, Accuracy: 0.9535, F1 Micro: 0.9641, F1 Macro: 0.6461\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6882\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Model 1 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 60.0838725566864 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2887, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1676, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6514\n",
      "Epoch 7/10, Train Loss: 0.1126, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Model 2 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 59.98376774787903 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3035, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1613, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1257, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7019\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Model 3 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 56.495261669158936 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9665, F1 Micro: 0.9745, F1 Macro: 0.6545\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.990073919296265 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2892, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1982, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.121, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 8/10, Train Loss: 0.0553, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7198\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7495\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Model 1 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 66.32563662528992 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1971, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1955, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.119, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Model 2 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 70.12010192871094 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2961, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2001, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1971, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1502, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1069, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7226\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Model 3 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 65.5883276462555 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.6621\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 7.202866792678833 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2951, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1655, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1316, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 7/10, Train Loss: 0.0729, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Model 1 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 66.22957348823547 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2898, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1645, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.6482\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7192\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Epoch 8/10, Train Loss: 0.0571, Accuracy: 0.9503, F1 Micro: 0.9615, F1 Macro: 0.7268\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.7599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.72\n",
      "Model 2 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.81      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 63.59818625450134 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3034, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1976, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1695, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1468, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0356, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Model 3 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 65.46081233024597 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9671, F1 Micro: 0.9749, F1 Macro: 0.6716\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 6.885089874267578 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2796, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.187, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9615, F1 Micro: 0.9711, F1 Macro: 0.7314\n",
      "Epoch 7/10, Train Loss: 0.0723, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 8/10, Train Loss: 0.0523, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0394, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7623\n",
      "Model 1 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 67.78188443183899 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2742, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9535, F1 Micro: 0.9639, F1 Macro: 0.6456\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.7896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.118, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7187\n",
      "Epoch 8/10, Train Loss: 0.0549, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Epoch 9/10, Train Loss: 0.0417, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.767\n",
      "Model 2 - Iteration 265: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 64.21453428268433 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2836, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1788, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9615, F1 Micro: 0.97, F1 Macro: 0.6502\n",
      "Epoch 5/10, Train Loss: 0.1503, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1341, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7402\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7512\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 64.97107768058777 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9676, F1 Micro: 0.9753, F1 Macro: 0.6814\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.381805896759033 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2827, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1955, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1031, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7632\n",
      "Epoch 10/10, Train Loss: 0.0352, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Model 1 - Iteration 279: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.9836938381195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2752, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1974, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.137, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 7/10, Train Loss: 0.0735, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 8/10, Train Loss: 0.053, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7633\n",
      "Model 2 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 69.61038875579834 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2911, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.201, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1787, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0574, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.764\n",
      "Epoch 9/10, Train Loss: 0.0563, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 10/10, Train Loss: 0.0396, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Model 3 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 70.83727955818176 s\n",
      "Averaged - Iteration 279: Accuracy: 0.968, F1 Micro: 0.9757, F1 Macro: 0.6903\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.772886276245117 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1894, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1745, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1372, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 6/10, Train Loss: 0.1014, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7194\n",
      "Epoch 7/10, Train Loss: 0.0776, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0426, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Model 1 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.0581955909729 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2702, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1864, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1598, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1193, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7611\n",
      "Epoch 7/10, Train Loss: 0.0699, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Model 2 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 70.2361102104187 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1911, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.1047, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Model 3 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.48079943656921 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.6978\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.2296528816223145 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.184, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1869, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Model 1 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.54440402984619 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2519, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Epoch 9/10, Train Loss: 0.0488, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0311, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Model 2 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.03322839736938 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2644, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1873, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1791, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1192, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.113, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7478\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "Model 3 - Iteration 300: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.7069821357727 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9689, F1 Micro: 0.9763, F1 Macro: 0.7049\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.8497254848480225 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1902, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Epoch 7/10, Train Loss: 0.062, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 9/10, Train Loss: 0.0411, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Model 1 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.7543272972107 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1745, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0925, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0578, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7937\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7978\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Model 2 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 76.14500284194946 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7574\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7788\n",
      "Epoch 9/10, Train Loss: 0.0481, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7817\n",
      "Model 3 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.97      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.78      0.79      0.78       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 75.41444325447083 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9692, F1 Micro: 0.9765, F1 Macro: 0.7103\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.7387518882751465 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.25, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1957, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1056, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0855, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.784\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7483\n",
      "Epoch 8/10, Train Loss: 0.0441, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7886\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7586\n",
      "Model 1 - Iteration 320: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.72358083724976 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2459, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1941, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Epoch 7/10, Train Loss: 0.062, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Model 2 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.80902814865112 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1992, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1579, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1202, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.7891\n",
      "Epoch 7/10, Train Loss: 0.0689, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0459, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0339, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 77.25677585601807 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9694, F1 Micro: 0.9767, F1 Macro: 0.7153\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.137401342391968 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2541, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1777, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.144, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0858, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.8035\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Model 1 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.8035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.55930471420288 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2521, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1795, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1772, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1485, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1499, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0711, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 8/10, Train Loss: 0.0484, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Model 2 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.05365514755249 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.265, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1797, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7471\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 9/10, Train Loss: 0.0458, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Model 3 - Iteration 330: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.41924023628235 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9697, F1 Micro: 0.9769, F1 Macro: 0.7203\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.797999858856201 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2459, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1876, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0801, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7473\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.757\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7439\n",
      "Model 1 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.11781072616577 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2456, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1893, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.115, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7673\n",
      "Epoch 7/10, Train Loss: 0.0528, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7761\n",
      "Model 2 - Iteration 340: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.06875562667847 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.254, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1915, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1668, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1342, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Model 3 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.24795460700989 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7242\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.546391487121582 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1089, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Epoch 6/10, Train Loss: 0.0773, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7579\n",
      "Epoch 7/10, Train Loss: 0.0602, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 10/10, Train Loss: 0.0233, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7568\n",
      "Model 1 - Iteration 350: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.80550265312195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2497, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1587, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1413, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1101, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 8/10, Train Loss: 0.0482, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 2 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.66984510421753 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1632, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1228, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0674, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0478, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0405, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7763\n",
      "Model 3 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.38276958465576 s\n",
      "Averaged - Iteration 350: Accuracy: 0.97, F1 Micro: 0.9771, F1 Macro: 0.7276\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.10758113861084 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2517, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1931, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1598, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1376, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.049, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.777\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Model 1 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.8431978225708 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2478, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1923, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1388, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0538, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7512\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Model 2 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.6046450138092 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1645, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0768, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0525, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0322, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.8048\n",
      "Model 3 - Iteration 360: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.93      0.96      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.79      0.83      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 86.99413394927979 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7309\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.6065456867218018 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2316, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1671, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1775, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1443, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0934, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7495\n",
      "Epoch 8/10, Train Loss: 0.0295, Accuracy: 0.9567, F1 Micro: 0.9676, F1 Macro: 0.7433\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7663\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Model 1 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.0583598613739 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2286, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 5/10, Train Loss: 0.097, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 6/10, Train Loss: 0.0608, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 7/10, Train Loss: 0.0508, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.744\n",
      "Epoch 8/10, Train Loss: 0.0318, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8218\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7754\n",
      "Model 2 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.56216239929199 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2359, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1775, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1517, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1031, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 6/10, Train Loss: 0.0759, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7966\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0394, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Model 3 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 86.55532741546631 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9703, F1 Micro: 0.9774, F1 Macro: 0.7335\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.3567864894866943 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2458, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1562, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1355, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1075, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0697, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "Epoch 8/10, Train Loss: 0.0403, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Epoch 9/10, Train Loss: 0.0295, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0187, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Model 1 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.37515354156494 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2401, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1573, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1425, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1166, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7514\n",
      "Epoch 7/10, Train Loss: 0.0635, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7632\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Model 2 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.62259435653687 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.251, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1592, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.6569\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0796, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.778\n",
      "Epoch 10/10, Train Loss: 0.0186, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7595\n",
      "Model 3 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.05238199234009 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9703, F1 Micro: 0.9774, F1 Macro: 0.7357\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6866202354431152 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2324, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1489, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1461, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 4/10, Train Loss: 0.1328, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.702\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7579\n",
      "Epoch 6/10, Train Loss: 0.0684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7438\n",
      "Epoch 7/10, Train Loss: 0.0457, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7282\n",
      "Epoch 8/10, Train Loss: 0.0329, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Model 1 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 83.25370597839355 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2322, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1501, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1466, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1245, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Epoch 6/10, Train Loss: 0.0686, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7762\n",
      "Epoch 7/10, Train Loss: 0.044, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.775\n",
      "Epoch 9/10, Train Loss: 0.027, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Model 2 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.9761655330658 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2407, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1541, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.152, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0821, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0509, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.754\n",
      "Epoch 9/10, Train Loss: 0.0279, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Model 3 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.39033818244934 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9704, F1 Micro: 0.9775, F1 Macro: 0.7379\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.353621006011963 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2335, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.16, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1392, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1322, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1025, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 6/10, Train Loss: 0.0641, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7865\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7755\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0195, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Model 1 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.35015487670898 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2294, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1411, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1334, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0669, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 7/10, Train Loss: 0.0524, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7854\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7936\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "Model 2 - Iteration 400: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.16266345977783 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2385, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1616, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1422, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0756, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7901\n",
      "Epoch 8/10, Train Loss: 0.0397, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Model 3 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.32394099235535 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7399\n",
      "Total sampling time: 155.04 seconds\n",
      "Total runtime: 5357.678358793259 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6399201,
     "sourceId": 10334686,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11593.732794,
   "end_time": "2025-02-09T10:31:08.093275",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-09T07:17:54.360481",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c3ab12b2ff44afd917554438893dbaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c8a7a31d0cf456a9b8301db6d19235a",
       "placeholder": "​",
       "style": "IPY_MODEL_89b9a89d4fe44524ac6034649c823b27",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "0e014e2e5a64491391dd2a707745c718": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10a7b07b9a194777bb00ea36623cd067": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17f1065df7a34eb6bb633058d5a98190": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d03e49f07b144a2bb106cb296d25449": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f897e90d495c4341bb5afa2013391be5",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4e0899f02cb9442e860b2646fbe8296f",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "3fec6256f7f44095a2537dd876739f07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0c3ab12b2ff44afd917554438893dbaa",
        "IPY_MODEL_cd30fe6508044672a967037cd36a0e2b",
        "IPY_MODEL_7345d038f6b749cc824892d951518d89"
       ],
       "layout": "IPY_MODEL_487648d764b94f8296c604b4a5b2325f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "48614ca79221417d8eae402c8e76ef13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "487648d764b94f8296c604b4a5b2325f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c60997817db4c52bfab56bc52fdf617": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7523dac3b2ed4f81a1ff22a55a6ab460",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_760f5e770e344b43862cca067a7573ef",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "4e0899f02cb9442e860b2646fbe8296f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4f5282e976b44c89a75234a4ec7200b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7957415e731476aa40af371eb515e28",
        "IPY_MODEL_4c60997817db4c52bfab56bc52fdf617",
        "IPY_MODEL_a1811601efd34114bec2296f60459f12"
       ],
       "layout": "IPY_MODEL_9541bbe318a24e6f9052bfb24e33f037",
       "tabbable": null,
       "tooltip": null
      }
     },
     "56485c734e9042f3add353849de8fdb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "614c4c67d0144a2ea05696c90e49a8ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "634b13dc6d50485cbf93a7f5c509d4c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_614c4c67d0144a2ea05696c90e49a8ca",
       "placeholder": "​",
       "style": "IPY_MODEL_911338966be34d56890e6f80ab87fd5b",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "69573df571384f509d853694a82ecfae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7345d038f6b749cc824892d951518d89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_56485c734e9042f3add353849de8fdb2",
       "placeholder": "​",
       "style": "IPY_MODEL_ad771d7f241d47298d54d48375186181",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 170B/s]"
      }
     },
     "73ebadd2b90e4c2d8d75fd89eb93a112": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7523dac3b2ed4f81a1ff22a55a6ab460": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "760f5e770e344b43862cca067a7573ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "771d1a0cd12a4f2184063636390bbc4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78f3267c0f26405e9f021b97f44d10a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7ee29f13498f4e8285f3962c4cbf56b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f51985fb62d461082255511a99cb673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fea7593e339445fc84bba99b79690b7a",
       "placeholder": "​",
       "style": "IPY_MODEL_0e014e2e5a64491391dd2a707745c718",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "8952ec3a4ac9451f913aba9039092e83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8954371743b94bd496a1dd482756e52e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "89b9a89d4fe44524ac6034649c823b27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b0085a6345449598298e3483bf85ea3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10a7b07b9a194777bb00ea36623cd067",
       "placeholder": "​",
       "style": "IPY_MODEL_771d1a0cd12a4f2184063636390bbc4f",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 151kB/s]"
      }
     },
     "911338966be34d56890e6f80ab87fd5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9541bbe318a24e6f9052bfb24e33f037": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c8a7a31d0cf456a9b8301db6d19235a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cf59b9243704d1ca2e8fb032a341c75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_634b13dc6d50485cbf93a7f5c509d4c8",
        "IPY_MODEL_d75eb50fe1e345849023c72b8e2e4846",
        "IPY_MODEL_c43160ca1c1b403788fcdf6ddc931a37"
       ],
       "layout": "IPY_MODEL_e379cb696bf74faeb58ddb62f2cbde93",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a1811601efd34114bec2296f60459f12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_efca13e8f1434daf9ae0ebb94d4a5ba0",
       "placeholder": "​",
       "style": "IPY_MODEL_fa0113f04e604ccfaad3e65b1512ec6c",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 11.4kB/s]"
      }
     },
     "ad771d7f241d47298d54d48375186181": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b7957415e731476aa40af371eb515e28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_69573df571384f509d853694a82ecfae",
       "placeholder": "​",
       "style": "IPY_MODEL_48614ca79221417d8eae402c8e76ef13",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "c43160ca1c1b403788fcdf6ddc931a37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8952ec3a4ac9451f913aba9039092e83",
       "placeholder": "​",
       "style": "IPY_MODEL_8954371743b94bd496a1dd482756e52e",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.31MB/s]"
      }
     },
     "cd30fe6508044672a967037cd36a0e2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_17f1065df7a34eb6bb633058d5a98190",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_78f3267c0f26405e9f021b97f44d10a2",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "d75eb50fe1e345849023c72b8e2e4846": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7ee29f13498f4e8285f3962c4cbf56b5",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_73ebadd2b90e4c2d8d75fd89eb93a112",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "e379cb696bf74faeb58ddb62f2cbde93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e55ae5b523214505b57e06325139e272": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efca13e8f1434daf9ae0ebb94d4a5ba0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f684769719504de0aaee18c6b600c45a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7f51985fb62d461082255511a99cb673",
        "IPY_MODEL_1d03e49f07b144a2bb106cb296d25449",
        "IPY_MODEL_8b0085a6345449598298e3483bf85ea3"
       ],
       "layout": "IPY_MODEL_e55ae5b523214505b57e06325139e272",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f897e90d495c4341bb5afa2013391be5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa0113f04e604ccfaad3e65b1512ec6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fea7593e339445fc84bba99b79690b7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
